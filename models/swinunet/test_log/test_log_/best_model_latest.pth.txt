[17:21:19.695] Namespace(cfg='../../common/configs/simmim_swin_base_patch4_window7_224.yaml', output_dir='./Results/Latin2', yaml='simmim', model='swinunet', dataset='UDIADS_BIB', manuscript='Latin2', udiadsbib_root='../../U-DIADS-Bib-MS_patched', divahisdb_root='../../DivaHisDB', use_patched_data=True, num_classes=6, img_size=224, batch_size=24, is_savenii=True, test_save_dir='../predictions', use_tta=True, deterministic=1, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[17:21:19.696] Testing with checkpoint: best_model_latest.pth
[17:21:19.697] Saving predictions to: ./Results/Latin2/predictions
[17:21:19.697] Starting inference on UDIADS_BIB dataset
[17:21:19.984] Found 1620 patches for Latin2
[17:21:19.988] Processing: 076 (54 patches)
[17:21:20.141] ðŸ”€ Using Test-Time Augmentation for 076
[17:21:35.189] Completed: 076
[17:21:35.190] Processing: 079 (54 patches)
[17:21:35.208] ðŸ”€ Using Test-Time Augmentation for 079
[17:21:49.249] Completed: 079
[17:21:49.250] Processing: 082 (54 patches)
[17:21:49.282] ðŸ”€ Using Test-Time Augmentation for 082
[17:22:03.210] Completed: 082
[17:22:03.211] Processing: 095 (54 patches)
[17:22:03.249] ðŸ”€ Using Test-Time Augmentation for 095
[17:22:17.184] Completed: 095
[17:22:17.184] Processing: 106 (54 patches)
[17:22:17.212] ðŸ”€ Using Test-Time Augmentation for 106
[17:22:30.980] Completed: 106
[17:22:30.980] Processing: 111 (54 patches)
[17:22:30.999] ðŸ”€ Using Test-Time Augmentation for 111
[17:22:44.893] Completed: 111
[17:22:44.894] Processing: 115 (54 patches)
[17:22:44.910] ðŸ”€ Using Test-Time Augmentation for 115
[17:22:58.596] Completed: 115
[17:22:58.597] Processing: 117 (54 patches)
[17:22:58.619] ðŸ”€ Using Test-Time Augmentation for 117
[17:23:12.460] Completed: 117
[17:23:12.460] Processing: 128 (54 patches)
[17:23:12.491] ðŸ”€ Using Test-Time Augmentation for 128
[17:23:26.281] Completed: 128
[17:23:26.281] Processing: 134 (54 patches)
[17:23:26.301] ðŸ”€ Using Test-Time Augmentation for 134
[17:23:40.062] Completed: 134
[17:23:40.062] Processing: 138 (54 patches)
[17:23:40.084] ðŸ”€ Using Test-Time Augmentation for 138
[17:23:53.967] Completed: 138
[17:23:53.967] Processing: 142 (54 patches)
[17:23:53.995] ðŸ”€ Using Test-Time Augmentation for 142
[17:24:07.775] Completed: 142
[17:24:07.775] Processing: 159 (54 patches)
[17:24:07.802] ðŸ”€ Using Test-Time Augmentation for 159
[17:24:21.653] Completed: 159
[17:24:21.654] Processing: 166 (54 patches)
[17:24:21.672] ðŸ”€ Using Test-Time Augmentation for 166
[17:24:35.339] Completed: 166
[17:24:35.340] Processing: 185 (54 patches)
[17:24:35.365] ðŸ”€ Using Test-Time Augmentation for 185
[17:24:48.991] Completed: 185
[17:24:48.991] Processing: 200 (54 patches)
[17:24:49.009] ðŸ”€ Using Test-Time Augmentation for 200
[17:25:02.646] Completed: 200
[17:25:02.647] Processing: 203 (54 patches)
[17:25:02.676] ðŸ”€ Using Test-Time Augmentation for 203
[17:25:16.128] Completed: 203
[17:25:16.129] Processing: 208 (54 patches)
[17:25:16.161] ðŸ”€ Using Test-Time Augmentation for 208
[17:25:29.775] Completed: 208
[17:25:29.775] Processing: 229 (54 patches)
[17:25:29.792] ðŸ”€ Using Test-Time Augmentation for 229
[17:25:43.214] Completed: 229
[17:25:43.214] Processing: 230 (54 patches)
[17:25:43.237] ðŸ”€ Using Test-Time Augmentation for 230
[17:25:56.498] Completed: 230
[17:25:56.499] Processing: 235 (54 patches)
[17:25:56.526] ðŸ”€ Using Test-Time Augmentation for 235
[17:26:09.941] Completed: 235
[17:26:09.941] Processing: 236 (54 patches)
[17:26:09.984] ðŸ”€ Using Test-Time Augmentation for 236
[17:26:23.551] Completed: 236
[17:26:23.551] Processing: 248 (54 patches)
[17:26:23.571] ðŸ”€ Using Test-Time Augmentation for 248
[17:26:37.210] Completed: 248
[17:26:37.210] Processing: 249 (54 patches)
[17:26:37.244] ðŸ”€ Using Test-Time Augmentation for 249
[17:26:51.044] Completed: 249
[17:26:51.044] Processing: 250 (54 patches)
[17:26:51.065] ðŸ”€ Using Test-Time Augmentation for 250
[17:27:04.976] Completed: 250
[17:27:04.976] Processing: 251 (54 patches)
[17:27:05.002] ðŸ”€ Using Test-Time Augmentation for 251
[17:27:18.523] Completed: 251
[17:27:18.523] Processing: 252 (54 patches)
[17:27:18.543] ðŸ”€ Using Test-Time Augmentation for 252
[17:27:32.079] Completed: 252
[17:27:32.079] Processing: 275 (54 patches)
[17:27:32.107] ðŸ”€ Using Test-Time Augmentation for 275
[17:27:45.471] Completed: 275
[17:27:45.471] Processing: 277 (54 patches)
[17:27:45.490] ðŸ”€ Using Test-Time Augmentation for 277
[17:27:59.071] Completed: 277
[17:27:59.071] Processing: 297 (54 patches)
[17:27:59.098] ðŸ”€ Using Test-Time Augmentation for 297
[17:28:12.676] Completed: 297
[17:28:12.676] 
Per-class metrics:
[17:28:12.676] --------------------------------------------------------------------------------
[17:28:12.676] Background     : Precision=0.9852, Recall=0.9886, F1=0.9869, IoU=0.9741
[17:28:12.676] Paratext       : Precision=0.7540, Recall=0.6923, F1=0.7218, IoU=0.5647
[17:28:12.676] Decoration     : Precision=0.8013, Recall=0.7668, F1=0.7837, IoU=0.6443
[17:28:12.676] Main Text      : Precision=0.8198, Recall=0.8143, F1=0.8170, IoU=0.6907
[17:28:12.676] Title          : Precision=0.8369, Recall=0.8285, F1=0.8327, IoU=0.7133
[17:28:12.676] Chapter Headings: Precision=0.8453, Recall=0.4926, F1=0.6225, IoU=0.4519
[17:28:12.676] 
Mean metrics:
[17:28:12.676] ----------------------------------------
[17:28:12.677] Mean Precision: 0.8404
[17:28:12.677] Mean Recall: 0.7639
[17:28:12.677] Mean F1: 0.7941
[17:28:12.677] Mean IoU: 0.6732
[17:28:12.677] Inference completed on 30 images
[20:47:10.728] Namespace(cfg='../../common/configs/swin_tiny_patch4_window7_224_lite.yaml', output_dir='./Results/a2/Latin2', yaml='swintiny', model='swinunet', dataset='UDIADS_BIB', manuscript='Latin2', udiadsbib_root='../../U-DIADS-Bib-MS_patched', divahisdb_root='../../DivaHisDB', use_patched_data=True, num_classes=6, img_size=224, batch_size=24, is_savenii=True, test_save_dir='../predictions', use_tta=True, deterministic=1, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[20:47:10.728] Testing with checkpoint: best_model_latest.pth
[20:47:10.729] Saving predictions to: ./Results/a2/Latin2/predictions
[20:47:10.729] Starting inference on UDIADS_BIB dataset
[20:47:10.941] Found 1620 patches for Latin2
[20:47:10.945] Processing: 076 (54 patches)
[20:47:10.994] ðŸ”€ Using Test-Time Augmentation for 076
[20:47:19.218] Completed: 076
[20:47:19.219] Processing: 079 (54 patches)
[20:47:19.263] ðŸ”€ Using Test-Time Augmentation for 079
[20:47:26.384] Completed: 079
[20:47:26.385] Processing: 082 (54 patches)
[20:47:26.461] ðŸ”€ Using Test-Time Augmentation for 082
[20:47:33.660] Completed: 082
[20:47:33.660] Processing: 095 (54 patches)
[20:47:33.688] ðŸ”€ Using Test-Time Augmentation for 095
[20:47:40.744] Completed: 095
[20:47:40.744] Processing: 106 (54 patches)
[20:47:40.766] ðŸ”€ Using Test-Time Augmentation for 106
[20:47:47.599] Completed: 106
[20:47:47.599] Processing: 111 (54 patches)
[20:47:47.622] ðŸ”€ Using Test-Time Augmentation for 111
[20:47:54.465] Completed: 111
[20:47:54.465] Processing: 115 (54 patches)
[20:47:54.487] ðŸ”€ Using Test-Time Augmentation for 115
[20:48:01.056] Completed: 115
[20:48:01.056] Processing: 117 (54 patches)
[20:48:01.072] ðŸ”€ Using Test-Time Augmentation for 117
[20:48:07.561] Completed: 117
[20:48:07.562] Processing: 128 (54 patches)
[20:48:07.587] ðŸ”€ Using Test-Time Augmentation for 128
[20:48:14.073] Completed: 128
[20:48:14.073] Processing: 134 (54 patches)
[20:48:14.095] ðŸ”€ Using Test-Time Augmentation for 134
[20:48:20.576] Completed: 134
[20:48:20.576] Processing: 138 (54 patches)
[20:48:20.599] ðŸ”€ Using Test-Time Augmentation for 138
[20:48:27.051] Completed: 138
[20:48:27.052] Processing: 142 (54 patches)
[20:48:27.078] ðŸ”€ Using Test-Time Augmentation for 142
[20:48:33.461] Completed: 142
[20:48:33.461] Processing: 159 (54 patches)
[20:48:33.495] ðŸ”€ Using Test-Time Augmentation for 159
[20:48:39.974] Completed: 159
[20:48:39.975] Processing: 166 (54 patches)
[20:48:39.991] ðŸ”€ Using Test-Time Augmentation for 166
[20:48:46.621] Completed: 166
[20:48:46.621] Processing: 185 (54 patches)
[20:48:46.642] ðŸ”€ Using Test-Time Augmentation for 185
[20:48:53.366] Completed: 185
[20:48:53.366] Processing: 200 (54 patches)
[20:48:53.395] ðŸ”€ Using Test-Time Augmentation for 200
[20:49:00.041] Completed: 200
[20:49:00.041] Processing: 203 (54 patches)
[20:49:00.078] ðŸ”€ Using Test-Time Augmentation for 203
[20:49:06.986] Completed: 203
[20:49:06.986] Processing: 208 (54 patches)
[20:49:07.018] ðŸ”€ Using Test-Time Augmentation for 208
[20:49:13.455] Completed: 208
[20:49:13.455] Processing: 229 (54 patches)
[20:49:13.491] ðŸ”€ Using Test-Time Augmentation for 229
[20:49:19.819] Completed: 229
[20:49:19.819] Processing: 230 (54 patches)
[20:49:19.858] ðŸ”€ Using Test-Time Augmentation for 230
[20:49:26.458] Completed: 230
[20:49:26.458] Processing: 235 (54 patches)
[20:49:26.487] ðŸ”€ Using Test-Time Augmentation for 235
[20:49:32.888] Completed: 235
[20:49:32.888] Processing: 236 (54 patches)
[20:49:32.919] ðŸ”€ Using Test-Time Augmentation for 236
[20:49:39.543] Completed: 236
[20:49:39.543] Processing: 248 (54 patches)
[20:49:39.562] ðŸ”€ Using Test-Time Augmentation for 248
[20:49:45.974] Completed: 248
[20:49:45.974] Processing: 249 (54 patches)
[20:49:46.008] ðŸ”€ Using Test-Time Augmentation for 249
[20:49:52.527] Completed: 249
[20:49:52.528] Processing: 250 (54 patches)
[20:49:52.563] ðŸ”€ Using Test-Time Augmentation for 250
[20:49:59.132] Completed: 250
[20:49:59.133] Processing: 251 (54 patches)
[20:49:59.164] ðŸ”€ Using Test-Time Augmentation for 251
[20:50:05.690] Completed: 251
[20:50:05.690] Processing: 252 (54 patches)
[20:50:05.710] ðŸ”€ Using Test-Time Augmentation for 252
[20:50:12.187] Completed: 252
[20:50:12.187] Processing: 275 (54 patches)
[20:50:12.207] ðŸ”€ Using Test-Time Augmentation for 275
[20:50:18.661] Completed: 275
[20:50:18.662] Processing: 277 (54 patches)
[20:50:18.688] ðŸ”€ Using Test-Time Augmentation for 277
[20:50:25.188] Completed: 277
[20:50:25.188] Processing: 297 (54 patches)
[20:50:25.210] ðŸ”€ Using Test-Time Augmentation for 297
[20:50:31.667] Completed: 297
[20:50:31.667] 
Per-class metrics:
[20:50:31.667] --------------------------------------------------------------------------------
[20:50:31.667] Background     : Precision=0.9737, Recall=0.9738, F1=0.9737, IoU=0.9488
[20:50:31.667] Paratext       : Precision=0.6613, Recall=0.6648, F1=0.6631, IoU=0.4960
[20:50:31.667] Decoration     : Precision=0.6985, Recall=0.7346, F1=0.7161, IoU=0.5577
[20:50:31.667] Main Text      : Precision=0.5983, Recall=0.6407, F1=0.6188, IoU=0.4480
[20:50:31.667] Title          : Precision=0.7075, Recall=0.5892, F1=0.6430, IoU=0.4738
[20:50:31.667] Chapter Headings: Precision=0.6667, Recall=0.2361, F1=0.3488, IoU=0.2112
[20:50:31.667] 
Mean metrics:
[20:50:31.668] ----------------------------------------
[20:50:31.668] Mean Precision: 0.7177
[20:50:31.668] Mean Recall: 0.6399
[20:50:31.668] Mean F1: 0.6606
[20:50:31.668] Mean IoU: 0.5226
[20:50:31.668] Inference completed on 30 images
[01:49:41.806] Namespace(cfg='../../common/configs/swin_tiny_patch4_window7_224_lite.yaml', output_dir='./Results/a2/Latin2', yaml='swintiny', model='swinunet', dataset='UDIADS_BIB', manuscript='Latin2', udiadsbib_root='../../U-DIADS-Bib-MS_patched', divahisdb_root='../../DivaHisDB', use_patched_data=True, num_classes=6, img_size=224, batch_size=24, is_savenii=True, test_save_dir='../predictions', use_tta=True, multiscale=True, deterministic=1, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False)
[01:49:41.806] Testing with checkpoint: best_model_latest.pth
[01:49:41.808] Saving predictions to: ./Results/a2/Latin2/predictions
[01:49:41.808] 
[01:49:41.808] === Starting Testing ===
[01:49:41.808] Dataset: UDIADS_BIB
[01:49:41.808] Model: swinunet
[01:49:41.808] Manuscript: Latin2
[01:49:41.808] TEST-TIME AUGMENTATION (TTA): ENABLED
[01:49:41.808]   â†’ TTA applies 8 augmentations (original, hflip, vflip, hflip+vflip, rot90/180/270, rot90+hflip) and averages predictions
[01:49:41.808]   â†’ Improves accuracy especially for rare classes but increases inference time by ~8x
[01:49:41.808] MULTI-SCALE TESTING: ENABLED
[01:49:41.808]   â†’ Multi-scale testing runs inference at 3 scales (0.75x, 1.0x, 1.25x) and averages predictions
[01:49:41.809]   â†’ Improves accuracy for documents with varying text sizes (1-3% improvement)
[01:49:41.809]   â†’ Combined with TTA: ~24x slower but maximum accuracy
[01:49:41.809] Save predictions: True
[01:49:41.809] 
[01:49:41.809] Starting inference on UDIADS_BIB dataset
[01:49:42.041] Found 1620 patches for Latin2
[01:49:42.043] Processing: 076 (54 patches)
[01:49:42.095] Using Test-Time Augmentation for 076
[01:49:43.616] ERROR: Testing failed: Input image size (4*168) doesn't match model (224*224).
[01:49:43.656] Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/test.py", line 965, in main
    result = inference(args, model, test_save_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/test.py", line 814, in inference
    pred_full = stitch_patches(
                ^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/test.py", line 619, in stitch_patches
    probs_patch = predict_patch_multiscale(probs_patch_tta_tensor, model, use_amp=use_amp)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/test.py", line 546, in predict_patch_multiscale
    output = model(scaled_tensor.to(device))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/vision_transformer.py", line 50, in forward
    logits = self.swin_unet(x)
             ^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/swin_transformer_unet_skip_expand_decoder_sys.py", line 770, in forward
    x, x_downsample = self.forward_features(x)
                      ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/swin_transformer_unet_skip_expand_decoder_sys.py", line 728, in forward_features
    x = self.patch_embed(x)
        ^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/swin_transformer_unet_skip_expand_decoder_sys.py", line 567, in forward
    assert H == self.img_size[0] and W == self.img_size[1], \
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: Input image size (4*168) doesn't match model (224*224).

[02:05:15.832] Testing: Latin2 | TTA: ON | Multi-scale: ON
[02:05:15.833] 
[02:05:16.025] Found 1620 patches
[02:05:16.030] Processing: 076
[02:05:16.264] ERROR: Testing failed: Input image size (168*168) doesn't match model (224*224).
[02:05:16.268] Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/test.py", line 961, in main
    result = inference(args, model, test_save_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/test.py", line 838, in inference
    pred_full = stitch_patches(
                ^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/test.py", line 646, in stitch_patches
    probs_patch = predict_patch_with_tta_and_multiscale(patch_tensor_single, model, use_amp=use_amp)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/test.py", line 579, in predict_patch_with_tta_and_multiscale
    probs_tta = predict_patch_with_tta(scaled_tensor, model, use_amp=use_amp)  # Returns (C, H, W) numpy array
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/test.py", line 495, in predict_patch_with_tta
    output = model(transformed.to(device))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/vision_transformer.py", line 50, in forward
    logits = self.swin_unet(x)
             ^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/swin_transformer_unet_skip_expand_decoder_sys.py", line 770, in forward
    x, x_downsample = self.forward_features(x)
                      ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/swin_transformer_unet_skip_expand_decoder_sys.py", line 728, in forward_features
    x = self.patch_embed(x)
        ^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/swin_transformer_unet_skip_expand_decoder_sys.py", line 567, in forward
    assert H == self.img_size[0] and W == self.img_size[1], \
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: Input image size (168*168) doesn't match model (224*224).

[02:05:25.036] Testing: Latin14396 | TTA: ON | Multi-scale: ON
[02:05:25.037] 
[02:05:25.272] Found 1620 patches
[02:05:25.276] Processing: 014
[02:05:25.992] ERROR: Testing failed: Input image size (168*168) doesn't match model (224*224).
[02:05:25.997] Traceback (most recent call last):
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/test.py", line 961, in main
    result = inference(args, model, test_save_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/test.py", line 838, in inference
    pred_full = stitch_patches(
                ^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/test.py", line 646, in stitch_patches
    probs_patch = predict_patch_with_tta_and_multiscale(patch_tensor_single, model, use_amp=use_amp)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/test.py", line 579, in predict_patch_with_tta_and_multiscale
    probs_tta = predict_patch_with_tta(scaled_tensor, model, use_amp=use_amp)  # Returns (C, H, W) numpy array
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/test.py", line 495, in predict_patch_with_tta
    output = model(transformed.to(device))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/vision_transformer.py", line 50, in forward
    logits = self.swin_unet(x)
             ^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/swin_transformer_unet_skip_expand_decoder_sys.py", line 770, in forward
    x, x_downsample = self.forward_features(x)
                      ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/swin_transformer_unet_skip_expand_decoder_sys.py", line 728, in forward_features
    x = self.patch_embed(x)
        ^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/iwi5/iwi5250h/Transformer_Models/models/swinunet/swin_transformer_unet_skip_expand_decoder_sys.py", line 567, in forward
    assert H == self.img_size[0] and W == self.img_size[1], \
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: Input image size (168*168) doesn't match model (224*224).

[02:08:43.893] Testing: Latin2 | TTA: ON | Multi-scale: ON
[02:08:43.893] 
[02:08:44.062] Found 1620 patches
[02:08:44.067] Processing: 076
[02:09:09.960] Processing: 079
[02:09:38.424] Processing: 082
[02:10:02.678] Processing: 095
[02:10:26.968] Processing: 106
[02:10:52.362] Processing: 111
[02:11:16.654] Processing: 115
[02:11:40.942] Processing: 117
[02:12:05.358] Processing: 128
[02:12:29.182] Processing: 134
[02:12:52.989] Processing: 138
[02:13:16.814] Processing: 142
[02:13:41.025] Processing: 159
[02:14:05.678] Processing: 166
[02:14:30.303] Processing: 185
[02:14:54.749] Processing: 200
[02:15:18.870] Processing: 203
[02:15:43.144] Processing: 208
[02:16:08.176] Processing: 229
[02:16:33.379] Processing: 230
[02:16:57.493] Processing: 235
| TTA: ON | Multi-scale: ON
[02:16:34.259] 
[02:16:34.418] Found 1620 patches
[02:16:34.419] Processing: 076
[02:16:58.229] Processing: 079
[02:17:21.188] Processing: 082
[02:17:44.027] Processing: 095
[02:18:07.054] Processing: 106
[02:18:30.595] Processing: 111
[02:18:53.797] Processing: 115
[02:19:16.930] Processing: 117
[02:19:40.073] Processing: 128
[02:20:03.185] Processing: 134
[02:20:26.250] Processing: 138
[02:20:49.567] Processing: 142
[02:21:12.804] Processing: 159
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [02:21:35.943] Processing: 166
                                                                                                                 [02:21:59.065] Processing: 185
[02:22:22.196] Processing: 200
[02:22:45.386] Processing: 203
[02:23:08.766] Processing: 208
[02:23:31.726] Processing: 229
[02:23:54.731] Processing: 230
[02:24:17.650] Processing: 235
[02:24:40.539] Processing: 236
[02:25:03.734] Processing: 248
[02:25:26.643] Processing: 249
[02:25:49.745] Processing: 250
[02:26:12.841] Processing: 251
[02:26:35.890] Processing: 252
[02:26:58.982] Processing: 275
[02:27:22.089] Processing: 277
[02:27:45.700] Processing: 297
[02:28:08.801] 
Per-class metrics:
[02:28:08.801] --------------------------------------------------------------------------------
[02:28:08.801] Background     : Precision=0.9917, Recall=0.9960, F1=0.9938, IoU=0.9877
[02:28:08.801] Paratext       : Precision=0.8837, Recall=0.7383, F1=0.8045, IoU=0.6729
[02:28:08.801] Decoration     : Precision=0.9191, Recall=0.9173, F1=0.9182, IoU=0.8487
[02:28:08.801] Main Text      : Precision=0.9238, Recall=0.8778, F1=0.9002, IoU=0.8185
[02:28:08.801] Title          : Precision=0.8403, Recall=0.8839, F1=0.8615, IoU=0.7567
[02:28:08.801] Chapter Headings: Precision=0.9104, Recall=0.6700, F1=0.7719, IoU=0.6286
[02:28:08.801] 
Mean metrics:
[02:28:08.801] ----------------------------------------
[02:28:08.801] Mean Precision: 0.9115
[02:28:08.801] Mean Recall: 0.8472
[02:28:08.801] Mean F1: 0.8750
[02:28:08.801] Mean IoU: 0.7855
