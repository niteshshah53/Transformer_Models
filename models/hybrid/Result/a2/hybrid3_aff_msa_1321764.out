### Starting TaskPrologue of job 1321764 on tg067 at Thu Nov 13 10:42:30 PM CET 2025
Running on cores 6-7,14-15,22-23,30-31 with governor ondemand
Thu Nov 13 22:42:30 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 2080 Ti     On  |   00000000:AF:00.0 Off |                  N/A |
| 28%   28C    P8             19W /  250W |       1MiB /  11264MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue


========================================================================
Training Hybrid2 Baseline Model with Smart Skip Connections and Multi-Scale Aggregation: Latin2
========================================================================
Dataset: U-DIADS-Bib-MS_patched
Architecture: Swin Transformer Encoder ‚Üí 2 Swin Blocks Bottleneck ‚Üí Simple CNN Decoder
Decoder: Simple Decoder (EfficientNet-b4 channel configuration)

Components Enabled:
  ‚úì Swin Encoder (4 stages: 96‚Üí192‚Üí384‚Üí768 dim)
  ‚úì Bottleneck: 2 Swin Transformer blocks (768 dim, 24 heads)
  ‚úì Simple CNN Decoder (channels: [256, 128, 64, 32])
  ‚úì Smart Skip Connections
  ‚úì Multi-Scale Aggregation
  ‚úì Positional Embeddings (default: enabled)
  ‚úì GroupNorm (default normalization)

Components Disabled (baseline):
  ‚úó CBAM Attention
  ‚úó Smart Skip Connections
  ‚úó Cross-Attention Bottleneck
  ‚úó Multi-Scale Aggregation
  ‚úó BatchNorm
========================================================================
All arguments validated successfully!
Setting random seed to 1234 for reproducible training...
Setting up U-DIADS-Bib dataset...
Using 6 classes for manuscript: Latin2
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin2/Image/training
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin2/mask/training_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin2/Image/validation
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin2/mask/validation_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder
================================================================================
================================================================================
üöÄ SIMPLE DECODER (Flag-Controlled Enhancements)
================================================================================
  ‚Ä¢ EfficientNet Variant: b4
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Enhancement Flags:
  ‚Ä¢ Deep Supervision: False
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: True
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: True
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Model moved to CUDA
Model created successfully with 6 classes

=== Starting Training ===
Dataset: UDIADS_BIB
Model: Hybrid2
Batch size: 4
Max epochs: 300
Learning rate: 0.0001


================================================================================
TRAINING CONFIGURATION
================================================================================
Dataset: UDIADS_BIB
Model: Hybrid2
Batch Size: 4
Max Epochs: 300
Learning Rate: 0.0001
Number of Classes: 6
Output Directory: ./Result/a2/Latin2
Early Stopping Patience: 150 epochs
================================================================================

üìä Dataset Statistics:
   - Training samples: 540
   - Validation samples: 540
   - Batch size: 4
   - Steps per epoch: 135


================================================================================
COMPUTING CLASS WEIGHTS
================================================================================
Raw ENS weights: [9.99999990e-05 1.03287895e-04 9.99999990e-05 9.99999990e-05
 1.00003115e-04 1.00000103e-04]

Class Distribution:
Class                Pixels          Frequency       Weight         
-----------------------------------------------------------------
0                        25,105,103        92.6557%         0.9945
1                            34,471         0.1272%         1.0272
2                           638,823         2.3577%         0.9945
3                         1,075,139         3.9680%         0.9945
4                           103,758         0.3829%         0.9946
5                           137,746         0.5084%         0.9945

Total pixels: 27,095,040.0
Beta: 0.9999
Smoothing: 0.0
Weight range: [0.9945, 1.0272]
================================================================================
üìà Class weights computed with ENS method (smoothing=0.1)
   Final weights: [0.99454474 1.0272443  0.99454474 0.99454474 0.99457574 0.99454576]

‚úì Loss functions created: CE (weighted, label_smoothing=0.1), Focal (Œ≥=2.0), Dice
  üìä OneCycleLR: 135 steps/epoch √ó 300 epochs = 40500 total steps
üöÄ Hybrid2 Best Practice: Differential Learning Rates
  üìä Encoder LR:     0.000010 (10x smaller, 119 params)
  üìä Bottleneck LR:  0.000050 (5x smaller, 26 params)
  üìä Decoder LR:     0.000100 (base LR, 84 params)
  ‚öôÔ∏è  Scheduler: OneCycleLR (Peak: 10x, Warmup: 30%, Cosine)
  ‚öôÔ∏è  Weight decay: Encoder=1e-3, Bottleneck=5e-3, Decoder=1e-2

üîç Checking for checkpoint at: ./Result/a2/Latin2/best_model_latest.pth
   Absolute path: /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid/Result/a2/Latin2/best_model_latest.pth
   File exists: False

================================================================================
STARTING TRAINING
================================================================================
Early stopping patience: 150 epochs
Learning rate scheduler: OneCycleLR (better convergence for transformers)
================================================================================

EPOCH 1/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5889
  ‚Ä¢ Validation Loss: 0.5160
  ‚Ä¢ Learning Rate: 0.000100
    ‚úì New best checkpoint saved! Val loss: 0.5160
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 2/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4853
  ‚Ä¢ Validation Loss: 0.4662
  ‚Ä¢ Learning Rate: 0.000101
    ‚úì New best checkpoint saved! Val loss: 0.4662
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 3/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4422
  ‚Ä¢ Validation Loss: 0.4392
  ‚Ä¢ Learning Rate: 0.000102
    ‚úì New best checkpoint saved! Val loss: 0.4392
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 4/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4184
  ‚Ä¢ Validation Loss: 0.4222
  ‚Ä¢ Learning Rate: 0.000104
    ‚úì New best checkpoint saved! Val loss: 0.4222
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 5/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3959
  ‚Ä¢ Validation Loss: 0.4079
  ‚Ä¢ Learning Rate: 0.000107
    ‚úì New best checkpoint saved! Val loss: 0.4079
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 6/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3818
  ‚Ä¢ Validation Loss: 0.4055
  ‚Ä¢ Learning Rate: 0.000110
    ‚úì New best checkpoint saved! Val loss: 0.4055
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 7/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3783
  ‚Ä¢ Validation Loss: 0.4219
  ‚Ä¢ Learning Rate: 0.000113
    No improvement (current: 0.4219, best: 0.4055)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 8/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3689
  ‚Ä¢ Validation Loss: 0.3910
  ‚Ä¢ Learning Rate: 0.000117
    ‚úì New best checkpoint saved! Val loss: 0.3910
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 9/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3624
  ‚Ä¢ Validation Loss: 0.3871
  ‚Ä¢ Learning Rate: 0.000122
    ‚úì New best checkpoint saved! Val loss: 0.3871
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 10/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3641
  ‚Ä¢ Validation Loss: 0.3888
  ‚Ä¢ Learning Rate: 0.000127
    No improvement (current: 0.3888, best: 0.3871)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 11/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3599
  ‚Ä¢ Validation Loss: 0.3861
  ‚Ä¢ Learning Rate: 0.000133
    ‚úì New best checkpoint saved! Val loss: 0.3861
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 12/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3569
  ‚Ä¢ Validation Loss: 0.3830
  ‚Ä¢ Learning Rate: 0.000139
    ‚úì New best checkpoint saved! Val loss: 0.3830
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 13/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3540
  ‚Ä¢ Validation Loss: 0.3889
  ‚Ä¢ Learning Rate: 0.000146
    No improvement (current: 0.3889, best: 0.3830)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 14/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3584
  ‚Ä¢ Validation Loss: 0.3801
  ‚Ä¢ Learning Rate: 0.000153
    ‚úì New best checkpoint saved! Val loss: 0.3801
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 15/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3471
  ‚Ä¢ Validation Loss: 0.3823
  ‚Ä¢ Learning Rate: 0.000160
    No improvement (current: 0.3823, best: 0.3801)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 16/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3483
  ‚Ä¢ Validation Loss: 0.3885
  ‚Ä¢ Learning Rate: 0.000168
    No improvement (current: 0.3885, best: 0.3801)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 17/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3517
  ‚Ä¢ Validation Loss: 0.3779
  ‚Ä¢ Learning Rate: 0.000177
    ‚úì New best checkpoint saved! Val loss: 0.3779
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 18/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3455
  ‚Ä¢ Validation Loss: 0.3801
  ‚Ä¢ Learning Rate: 0.000186
    No improvement (current: 0.3801, best: 0.3779)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 19/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3435
  ‚Ä¢ Validation Loss: 0.3807
  ‚Ä¢ Learning Rate: 0.000195
    No improvement (current: 0.3807, best: 0.3779)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 20/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3424
  ‚Ä¢ Validation Loss: 0.3746
  ‚Ä¢ Learning Rate: 0.000205
    ‚úì New best checkpoint saved! Val loss: 0.3746
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 21/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3418
  ‚Ä¢ Validation Loss: 0.3831
  ‚Ä¢ Learning Rate: 0.000216
    No improvement (current: 0.3831, best: 0.3746)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 22/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3467
  ‚Ä¢ Validation Loss: 0.3777
  ‚Ä¢ Learning Rate: 0.000226
    No improvement (current: 0.3777, best: 0.3746)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 23/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3396
  ‚Ä¢ Validation Loss: 0.3727
  ‚Ä¢ Learning Rate: 0.000237
    ‚úì New best checkpoint saved! Val loss: 0.3727
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 24/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3368
  ‚Ä¢ Validation Loss: 0.3695
  ‚Ä¢ Learning Rate: 0.000249
    ‚úì New best checkpoint saved! Val loss: 0.3695
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 25/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3423
  ‚Ä¢ Validation Loss: 0.3716
  ‚Ä¢ Learning Rate: 0.000261
    No improvement (current: 0.3716, best: 0.3695)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 26/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3377
  ‚Ä¢ Validation Loss: 0.3705
  ‚Ä¢ Learning Rate: 0.000273
    No improvement (current: 0.3705, best: 0.3695)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 27/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3340
  ‚Ä¢ Validation Loss: 0.3818
  ‚Ä¢ Learning Rate: 0.000286
    No improvement (current: 0.3818, best: 0.3695)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 28/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3354
  ‚Ä¢ Validation Loss: 0.3714
  ‚Ä¢ Learning Rate: 0.000298
    No improvement (current: 0.3714, best: 0.3695)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 29/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3387
  ‚Ä¢ Validation Loss: 0.3788
  ‚Ä¢ Learning Rate: 0.000312
    No improvement (current: 0.3788, best: 0.3695)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 30/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3340
  ‚Ä¢ Validation Loss: 0.3893
  ‚Ä¢ Learning Rate: 0.000325
    No improvement (current: 0.3893, best: 0.3695)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 31/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3341
  ‚Ä¢ Validation Loss: 0.3668
  ‚Ä¢ Learning Rate: 0.000339
    ‚úì New best checkpoint saved! Val loss: 0.3668
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 32/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3310
  ‚Ä¢ Validation Loss: 0.3749
  ‚Ä¢ Learning Rate: 0.000353
    No improvement (current: 0.3749, best: 0.3668)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 33/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3339
  ‚Ä¢ Validation Loss: 0.3688
  ‚Ä¢ Learning Rate: 0.000367
    No improvement (current: 0.3688, best: 0.3668)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 34/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3351
  ‚Ä¢ Validation Loss: 0.3760
  ‚Ä¢ Learning Rate: 0.000381
    No improvement (current: 0.3760, best: 0.3668)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 35/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3382
  ‚Ä¢ Validation Loss: 0.3770
  ‚Ä¢ Learning Rate: 0.000396
    No improvement (current: 0.3770, best: 0.3668)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 36/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3376
  ‚Ä¢ Validation Loss: 0.3712
  ‚Ä¢ Learning Rate: 0.000411
    No improvement (current: 0.3712, best: 0.3668)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 37/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3291
  ‚Ä¢ Validation Loss: 0.3759
  ‚Ä¢ Learning Rate: 0.000426
    No improvement (current: 0.3759, best: 0.3668)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 38/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3329
  ‚Ä¢ Validation Loss: 0.3790
  ‚Ä¢ Learning Rate: 0.000441
    No improvement (current: 0.3790, best: 0.3668)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 39/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3336
  ‚Ä¢ Validation Loss: 0.3779
  ‚Ä¢ Learning Rate: 0.000456
    No improvement (current: 0.3779, best: 0.3668)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 40/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3389
  ‚Ä¢ Validation Loss: 0.3778
  ‚Ä¢ Learning Rate: 0.000472
    No improvement (current: 0.3778, best: 0.3668)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 41/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3362
  ‚Ä¢ Validation Loss: 0.3800
  ‚Ä¢ Learning Rate: 0.000487
    No improvement (current: 0.3800, best: 0.3668)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 42/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3350
  ‚Ä¢ Validation Loss: 0.3645
  ‚Ä¢ Learning Rate: 0.000503
    ‚úì New best checkpoint saved! Val loss: 0.3645
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 43/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3185
  ‚Ä¢ Validation Loss: 0.3614
  ‚Ä¢ Learning Rate: 0.000519
    ‚úì New best checkpoint saved! Val loss: 0.3614
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 44/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3187
  ‚Ä¢ Validation Loss: 0.3615
  ‚Ä¢ Learning Rate: 0.000534
    No improvement (current: 0.3615, best: 0.3614)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 45/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3191
  ‚Ä¢ Validation Loss: 0.3645
  ‚Ä¢ Learning Rate: 0.000550
    No improvement (current: 0.3645, best: 0.3614)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 46/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3169
  ‚Ä¢ Validation Loss: 0.3669
  ‚Ä¢ Learning Rate: 0.000566
    No improvement (current: 0.3669, best: 0.3614)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 47/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3187
  ‚Ä¢ Validation Loss: 0.3653
  ‚Ä¢ Learning Rate: 0.000581
    No improvement (current: 0.3653, best: 0.3614)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 48/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3282
  ‚Ä¢ Validation Loss: 0.3624
  ‚Ä¢ Learning Rate: 0.000597
    No improvement (current: 0.3624, best: 0.3614)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 49/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3279
  ‚Ä¢ Validation Loss: 0.3697
  ‚Ä¢ Learning Rate: 0.000613
    No improvement (current: 0.3697, best: 0.3614)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 50/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3149
  ‚Ä¢ Validation Loss: 0.3709
  ‚Ä¢ Learning Rate: 0.000628
    No improvement (current: 0.3709, best: 0.3614)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 51/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3229
  ‚Ä¢ Validation Loss: 0.3625
  ‚Ä¢ Learning Rate: 0.000644
    No improvement (current: 0.3625, best: 0.3614)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 52/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3345
  ‚Ä¢ Validation Loss: 0.4039
  ‚Ä¢ Learning Rate: 0.000659
    No improvement (current: 0.4039, best: 0.3614)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 53/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3386
  ‚Ä¢ Validation Loss: 0.3662
  ‚Ä¢ Learning Rate: 0.000674
    No improvement (current: 0.3662, best: 0.3614)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 54/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3270
  ‚Ä¢ Validation Loss: 0.3688
  ‚Ä¢ Learning Rate: 0.000689
    No improvement (current: 0.3688, best: 0.3614)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 55/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3510
  ‚Ä¢ Validation Loss: 0.3727
  ‚Ä¢ Learning Rate: 0.000704
    No improvement (current: 0.3727, best: 0.3614)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 56/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3340
  ‚Ä¢ Validation Loss: 0.3696
  ‚Ä¢ Learning Rate: 0.000719
    No improvement (current: 0.3696, best: 0.3614)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 57/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3260
  ‚Ä¢ Validation Loss: 0.3680
  ‚Ä¢ Learning Rate: 0.000733
    No improvement (current: 0.3680, best: 0.3614)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 58/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3314
  ‚Ä¢ Validation Loss: 0.3673
  ‚Ä¢ Learning Rate: 0.000747
    No improvement (current: 0.3673, best: 0.3614)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 59/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3243
  ‚Ä¢ Validation Loss: 0.3665
  ‚Ä¢ Learning Rate: 0.000761
    No improvement (current: 0.3665, best: 0.3614)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 60/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3236
  ‚Ä¢ Validation Loss: 0.3659
  ‚Ä¢ Learning Rate: 0.000775
    No improvement (current: 0.3659, best: 0.3614)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 61/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3179
  ‚Ä¢ Validation Loss: 0.3656
  ‚Ä¢ Learning Rate: 0.000789
    No improvement (current: 0.3656, best: 0.3614)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 62/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3196
  ‚Ä¢ Validation Loss: 0.3652
  ‚Ä¢ Learning Rate: 0.000802
    No improvement (current: 0.3652, best: 0.3614)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 63/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3235
  ‚Ä¢ Validation Loss: 0.3649
  ‚Ä¢ Learning Rate: 0.000815
    No improvement (current: 0.3649, best: 0.3614)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 64/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3205
  ‚Ä¢ Validation Loss: 0.3649
  ‚Ä¢ Learning Rate: 0.000827
    No improvement (current: 0.3649, best: 0.3614)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 65/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3233
  ‚Ä¢ Validation Loss: 0.3648
  ‚Ä¢ Learning Rate: 0.000839
    No improvement (current: 0.3648, best: 0.3614)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 66/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3233
  ‚Ä¢ Validation Loss: 0.3652
  ‚Ä¢ Learning Rate: 0.000851
    No improvement (current: 0.3652, best: 0.3614)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 67/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3237
  ‚Ä¢ Validation Loss: 0.3649
  ‚Ä¢ Learning Rate: 0.000863
    No improvement (current: 0.3649, best: 0.3614)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 68/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3212
  ‚Ä¢ Validation Loss: 0.3651
  ‚Ä¢ Learning Rate: 0.000874
    No improvement (current: 0.3651, best: 0.3614)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 69/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3236
  ‚Ä¢ Validation Loss: 0.3649
  ‚Ä¢ Learning Rate: 0.000884
    No improvement (current: 0.3649, best: 0.3614)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 70/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3252
  ‚Ä¢ Validation Loss: 0.3648
  ‚Ä¢ Learning Rate: 0.000895
    No improvement (current: 0.3648, best: 0.3614)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 71/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3229
  ‚Ä¢ Validation Loss: 0.3647
  ‚Ä¢ Learning Rate: 0.000905
    No improvement (current: 0.3647, best: 0.3614)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 72/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3225
  ‚Ä¢ Validation Loss: 0.3646
  ‚Ä¢ Learning Rate: 0.000914
    No improvement (current: 0.3646, best: 0.3614)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 73/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3245
  ‚Ä¢ Validation Loss: 0.3645
  ‚Ä¢ Learning Rate: 0.000923
    No improvement (current: 0.3645, best: 0.3614)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 74/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3224
  ‚Ä¢ Validation Loss: 0.3648
  ‚Ä¢ Learning Rate: 0.000932
    No improvement (current: 0.3648, best: 0.3614)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 75/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3231
  ‚Ä¢ Validation Loss: 0.3646
  ‚Ä¢ Learning Rate: 0.000940
    No improvement (current: 0.3646, best: 0.3614)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 76/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3200
  ‚Ä¢ Validation Loss: 0.3646
  ‚Ä¢ Learning Rate: 0.000947
    No improvement (current: 0.3646, best: 0.3614)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 77/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3179
  ‚Ä¢ Validation Loss: 0.3643
  ‚Ä¢ Learning Rate: 0.000955
    No improvement (current: 0.3643, best: 0.3614)
    ‚ö† No improvement for 34 epochs (patience: 150, remaining: 116)

EPOCH 78/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3257
  ‚Ä¢ Validation Loss: 0.3644
  ‚Ä¢ Learning Rate: 0.000961
    No improvement (current: 0.3644, best: 0.3614)
    ‚ö† No improvement for 35 epochs (patience: 150, remaining: 115)

EPOCH 79/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3221
  ‚Ä¢ Validation Loss: 0.3644
  ‚Ä¢ Learning Rate: 0.000967
    No improvement (current: 0.3644, best: 0.3614)
    ‚ö† No improvement for 36 epochs (patience: 150, remaining: 114)

EPOCH 80/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3211
  ‚Ä¢ Validation Loss: 0.3642
  ‚Ä¢ Learning Rate: 0.000973
    No improvement (current: 0.3642, best: 0.3614)
    ‚ö† No improvement for 37 epochs (patience: 150, remaining: 113)

EPOCH 81/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3226
  ‚Ä¢ Validation Loss: 0.3642
  ‚Ä¢ Learning Rate: 0.000978
    No improvement (current: 0.3642, best: 0.3614)
    ‚ö† No improvement for 38 epochs (patience: 150, remaining: 112)

EPOCH 82/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3181
  ‚Ä¢ Validation Loss: 0.3642
  ‚Ä¢ Learning Rate: 0.000983
    No improvement (current: 0.3642, best: 0.3614)
    ‚ö† No improvement for 39 epochs (patience: 150, remaining: 111)

EPOCH 83/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3245
  ‚Ä¢ Validation Loss: 0.3639
  ‚Ä¢ Learning Rate: 0.000987
    No improvement (current: 0.3639, best: 0.3614)
    ‚ö† No improvement for 40 epochs (patience: 150, remaining: 110)

EPOCH 84/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3261
  ‚Ä¢ Validation Loss: 0.3640
  ‚Ä¢ Learning Rate: 0.000990
    No improvement (current: 0.3640, best: 0.3614)
    ‚ö† No improvement for 41 epochs (patience: 150, remaining: 109)

EPOCH 85/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3231
  ‚Ä¢ Validation Loss: 0.3640
  ‚Ä¢ Learning Rate: 0.000993
    No improvement (current: 0.3640, best: 0.3614)
    ‚ö† No improvement for 42 epochs (patience: 150, remaining: 108)

EPOCH 86/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3188
  ‚Ä¢ Validation Loss: 0.3640
  ‚Ä¢ Learning Rate: 0.000996
    No improvement (current: 0.3640, best: 0.3614)
    ‚ö† No improvement for 43 epochs (patience: 150, remaining: 107)

EPOCH 87/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3243
  ‚Ä¢ Validation Loss: 0.3637
  ‚Ä¢ Learning Rate: 0.000998
    No improvement (current: 0.3637, best: 0.3614)
    ‚ö† No improvement for 44 epochs (patience: 150, remaining: 106)

EPOCH 88/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3201
  ‚Ä¢ Validation Loss: 0.3637
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.3637, best: 0.3614)
    ‚ö† No improvement for 45 epochs (patience: 150, remaining: 105)

EPOCH 89/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3236
  ‚Ä¢ Validation Loss: 0.3638
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.3638, best: 0.3614)
    ‚ö† No improvement for 46 epochs (patience: 150, remaining: 104)

EPOCH 90/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3242
  ‚Ä¢ Validation Loss: 0.3637
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.3637, best: 0.3614)
    ‚ö† No improvement for 47 epochs (patience: 150, remaining: 103)

EPOCH 91/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3207
  ‚Ä¢ Validation Loss: 0.3636
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.3636, best: 0.3614)
    ‚ö† No improvement for 48 epochs (patience: 150, remaining: 102)

EPOCH 92/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3206
  ‚Ä¢ Validation Loss: 0.3634
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.3634, best: 0.3614)
    ‚ö† No improvement for 49 epochs (patience: 150, remaining: 101)

EPOCH 93/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3230
  ‚Ä¢ Validation Loss: 0.3633
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.3633, best: 0.3614)
    ‚ö† No improvement for 50 epochs (patience: 150, remaining: 100)

EPOCH 94/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3235
  ‚Ä¢ Validation Loss: 0.3631
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.3631, best: 0.3614)
    ‚ö† No improvement for 51 epochs (patience: 150, remaining: 99)

EPOCH 95/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3197
  ‚Ä¢ Validation Loss: 0.3630
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.3630, best: 0.3614)
    ‚ö† No improvement for 52 epochs (patience: 150, remaining: 98)

EPOCH 96/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3217
  ‚Ä¢ Validation Loss: 0.3628
  ‚Ä¢ Learning Rate: 0.000998
    No improvement (current: 0.3628, best: 0.3614)
    ‚ö† No improvement for 53 epochs (patience: 150, remaining: 97)

EPOCH 97/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3204
  ‚Ä¢ Validation Loss: 0.3625
  ‚Ä¢ Learning Rate: 0.000997
    No improvement (current: 0.3625, best: 0.3614)
    ‚ö† No improvement for 54 epochs (patience: 150, remaining: 96)

EPOCH 98/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3181
  ‚Ä¢ Validation Loss: 0.3624
  ‚Ä¢ Learning Rate: 0.000996
    No improvement (current: 0.3624, best: 0.3614)
    ‚ö† No improvement for 55 epochs (patience: 150, remaining: 95)

EPOCH 99/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3140
  ‚Ä¢ Validation Loss: 0.3628
  ‚Ä¢ Learning Rate: 0.000995
    No improvement (current: 0.3628, best: 0.3614)
    ‚ö† No improvement for 56 epochs (patience: 150, remaining: 94)

EPOCH 100/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3199
  ‚Ä¢ Validation Loss: 0.3625
  ‚Ä¢ Learning Rate: 0.000994
   üíæ Periodic checkpoint saved: epoch_100.pth
    No improvement (current: 0.3625, best: 0.3614)
    ‚ö† No improvement for 57 epochs (patience: 150, remaining: 93)

EPOCH 101/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3169
  ‚Ä¢ Validation Loss: 0.3620
  ‚Ä¢ Learning Rate: 0.000993
    No improvement (current: 0.3620, best: 0.3614)
    ‚ö† No improvement for 58 epochs (patience: 150, remaining: 92)

EPOCH 102/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3182
  ‚Ä¢ Validation Loss: 0.3619
  ‚Ä¢ Learning Rate: 0.000992
    No improvement (current: 0.3619, best: 0.3614)
    ‚ö† No improvement for 59 epochs (patience: 150, remaining: 91)

EPOCH 103/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3200
  ‚Ä¢ Validation Loss: 0.3620
  ‚Ä¢ Learning Rate: 0.000991
    No improvement (current: 0.3620, best: 0.3614)
    ‚ö† No improvement for 60 epochs (patience: 150, remaining: 90)

EPOCH 104/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3224
  ‚Ä¢ Validation Loss: 0.3618
  ‚Ä¢ Learning Rate: 0.000989
    No improvement (current: 0.3618, best: 0.3614)
    ‚ö† No improvement for 61 epochs (patience: 150, remaining: 89)

EPOCH 105/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3149
  ‚Ä¢ Validation Loss: 0.3631
  ‚Ä¢ Learning Rate: 0.000987
    No improvement (current: 0.3631, best: 0.3614)
    ‚ö† No improvement for 62 epochs (patience: 150, remaining: 88)

EPOCH 106/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3178
  ‚Ä¢ Validation Loss: 0.3615
  ‚Ä¢ Learning Rate: 0.000986
    No improvement (current: 0.3615, best: 0.3614)
    ‚ö† No improvement for 63 epochs (patience: 150, remaining: 87)

EPOCH 107/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3148
  ‚Ä¢ Validation Loss: 0.3619
  ‚Ä¢ Learning Rate: 0.000984
    No improvement (current: 0.3619, best: 0.3614)
    ‚ö† No improvement for 64 epochs (patience: 150, remaining: 86)

EPOCH 108/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3156
  ‚Ä¢ Validation Loss: 0.3608
  ‚Ä¢ Learning Rate: 0.000982
    ‚úì New best checkpoint saved! Val loss: 0.3608
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 109/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3192
  ‚Ä¢ Validation Loss: 0.3618
  ‚Ä¢ Learning Rate: 0.000980
    No improvement (current: 0.3618, best: 0.3608)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 110/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3173
  ‚Ä¢ Validation Loss: 0.3604
  ‚Ä¢ Learning Rate: 0.000978
    ‚úì New best checkpoint saved! Val loss: 0.3604
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 111/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3160
  ‚Ä¢ Validation Loss: 0.3613
  ‚Ä¢ Learning Rate: 0.000976
    No improvement (current: 0.3613, best: 0.3604)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 112/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3129
  ‚Ä¢ Validation Loss: 0.3617
  ‚Ä¢ Learning Rate: 0.000973
    No improvement (current: 0.3617, best: 0.3604)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 113/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4063
  ‚Ä¢ Validation Loss: 0.6072
  ‚Ä¢ Learning Rate: 0.000971
    No improvement (current: 0.6072, best: 0.3604)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 114/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5986
  ‚Ä¢ Validation Loss: 0.6040
  ‚Ä¢ Learning Rate: 0.000968
    No improvement (current: 0.6040, best: 0.3604)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 115/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5961
  ‚Ä¢ Validation Loss: 0.5995
  ‚Ä¢ Learning Rate: 0.000965
    No improvement (current: 0.5995, best: 0.3604)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 116/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5920
  ‚Ä¢ Validation Loss: 0.5964
  ‚Ä¢ Learning Rate: 0.000963
    No improvement (current: 0.5964, best: 0.3604)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 117/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5869
  ‚Ä¢ Validation Loss: 0.5928
  ‚Ä¢ Learning Rate: 0.000960
    No improvement (current: 0.5928, best: 0.3604)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 118/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5809
  ‚Ä¢ Validation Loss: 0.5853
  ‚Ä¢ Learning Rate: 0.000957
    No improvement (current: 0.5853, best: 0.3604)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 119/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5775
  ‚Ä¢ Validation Loss: 0.5822
  ‚Ä¢ Learning Rate: 0.000954
    No improvement (current: 0.5822, best: 0.3604)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 120/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5737
  ‚Ä¢ Validation Loss: 0.5788
  ‚Ä¢ Learning Rate: 0.000951
    No improvement (current: 0.5788, best: 0.3604)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 121/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5710
  ‚Ä¢ Validation Loss: 0.5746
  ‚Ä¢ Learning Rate: 0.000947
    No improvement (current: 0.5746, best: 0.3604)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 122/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5668
  ‚Ä¢ Validation Loss: 0.5677
  ‚Ä¢ Learning Rate: 0.000944
    No improvement (current: 0.5677, best: 0.3604)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 123/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5695
  ‚Ä¢ Validation Loss: 0.5748
  ‚Ä¢ Learning Rate: 0.000940
    No improvement (current: 0.5748, best: 0.3604)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 124/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5661
  ‚Ä¢ Validation Loss: 0.5702
  ‚Ä¢ Learning Rate: 0.000937
    No improvement (current: 0.5702, best: 0.3604)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 125/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5624
  ‚Ä¢ Validation Loss: 0.5674
  ‚Ä¢ Learning Rate: 0.000933
    No improvement (current: 0.5674, best: 0.3604)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 126/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5604
  ‚Ä¢ Validation Loss: 0.5652
  ‚Ä¢ Learning Rate: 0.000929
    No improvement (current: 0.5652, best: 0.3604)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 127/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5572
  ‚Ä¢ Validation Loss: 0.5584
  ‚Ä¢ Learning Rate: 0.000925
    No improvement (current: 0.5584, best: 0.3604)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 128/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5223
  ‚Ä¢ Validation Loss: 0.5849
  ‚Ä¢ Learning Rate: 0.000921
    No improvement (current: 0.5849, best: 0.3604)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 129/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5017
  ‚Ä¢ Validation Loss: 0.4877
  ‚Ä¢ Learning Rate: 0.000917
    No improvement (current: 0.4877, best: 0.3604)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 130/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4711
  ‚Ä¢ Validation Loss: 0.4729
  ‚Ä¢ Learning Rate: 0.000913
    No improvement (current: 0.4729, best: 0.3604)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 131/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4565
  ‚Ä¢ Validation Loss: 0.4505
  ‚Ä¢ Learning Rate: 0.000909
    No improvement (current: 0.4505, best: 0.3604)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 132/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4311
  ‚Ä¢ Validation Loss: 0.4389
  ‚Ä¢ Learning Rate: 0.000905
    No improvement (current: 0.4389, best: 0.3604)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 133/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4235
  ‚Ä¢ Validation Loss: 0.4340
  ‚Ä¢ Learning Rate: 0.000900
    No improvement (current: 0.4340, best: 0.3604)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 134/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4177
  ‚Ä¢ Validation Loss: 0.4297
  ‚Ä¢ Learning Rate: 0.000896
    No improvement (current: 0.4297, best: 0.3604)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 135/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4140
  ‚Ä¢ Validation Loss: 0.4340
  ‚Ä¢ Learning Rate: 0.000891
    No improvement (current: 0.4340, best: 0.3604)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 136/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4167
  ‚Ä¢ Validation Loss: 0.4400
  ‚Ä¢ Learning Rate: 0.000886
    No improvement (current: 0.4400, best: 0.3604)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 137/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4175
  ‚Ä¢ Validation Loss: 0.4272
  ‚Ä¢ Learning Rate: 0.000881
    No improvement (current: 0.4272, best: 0.3604)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 138/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4099
  ‚Ä¢ Validation Loss: 0.4268
  ‚Ä¢ Learning Rate: 0.000877
    No improvement (current: 0.4268, best: 0.3604)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 139/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4027
  ‚Ä¢ Validation Loss: 0.4207
  ‚Ä¢ Learning Rate: 0.000872
    No improvement (current: 0.4207, best: 0.3604)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 140/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4093
  ‚Ä¢ Validation Loss: 0.4202
  ‚Ä¢ Learning Rate: 0.000867
    No improvement (current: 0.4202, best: 0.3604)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 141/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3824
  ‚Ä¢ Validation Loss: 0.4071
  ‚Ä¢ Learning Rate: 0.000861
    No improvement (current: 0.4071, best: 0.3604)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 142/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3697
  ‚Ä¢ Validation Loss: 0.3916
  ‚Ä¢ Learning Rate: 0.000856
    No improvement (current: 0.3916, best: 0.3604)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 143/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3676
  ‚Ä¢ Validation Loss: 0.3915
  ‚Ä¢ Learning Rate: 0.000851
    No improvement (current: 0.3915, best: 0.3604)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 144/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3651
  ‚Ä¢ Validation Loss: 0.3852
  ‚Ä¢ Learning Rate: 0.000846
    No improvement (current: 0.3852, best: 0.3604)
    ‚ö† No improvement for 34 epochs (patience: 150, remaining: 116)

EPOCH 145/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3603
  ‚Ä¢ Validation Loss: 0.3836
  ‚Ä¢ Learning Rate: 0.000840
    No improvement (current: 0.3836, best: 0.3604)
    ‚ö† No improvement for 35 epochs (patience: 150, remaining: 115)

EPOCH 146/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3509
  ‚Ä¢ Validation Loss: 0.3858
  ‚Ä¢ Learning Rate: 0.000835
    No improvement (current: 0.3858, best: 0.3604)
    ‚ö† No improvement for 36 epochs (patience: 150, remaining: 114)

EPOCH 147/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3514
  ‚Ä¢ Validation Loss: 0.3797
  ‚Ä¢ Learning Rate: 0.000829
    No improvement (current: 0.3797, best: 0.3604)
    ‚ö† No improvement for 37 epochs (patience: 150, remaining: 113)

EPOCH 148/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3540
  ‚Ä¢ Validation Loss: 0.3786
  ‚Ä¢ Learning Rate: 0.000823
    No improvement (current: 0.3786, best: 0.3604)
    ‚ö† No improvement for 38 epochs (patience: 150, remaining: 112)

EPOCH 149/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3686
  ‚Ä¢ Validation Loss: 0.4096
  ‚Ä¢ Learning Rate: 0.000818
    No improvement (current: 0.4096, best: 0.3604)
    ‚ö† No improvement for 39 epochs (patience: 150, remaining: 111)

EPOCH 150/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3534
  ‚Ä¢ Validation Loss: 0.3792
  ‚Ä¢ Learning Rate: 0.000812
    No improvement (current: 0.3792, best: 0.3604)
    ‚ö† No improvement for 40 epochs (patience: 150, remaining: 110)

EPOCH 151/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3455
  ‚Ä¢ Validation Loss: 0.3799
  ‚Ä¢ Learning Rate: 0.000806
    No improvement (current: 0.3799, best: 0.3604)
    ‚ö† No improvement for 41 epochs (patience: 150, remaining: 109)

EPOCH 152/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3431
  ‚Ä¢ Validation Loss: 0.3789
  ‚Ä¢ Learning Rate: 0.000800
    No improvement (current: 0.3789, best: 0.3604)
    ‚ö† No improvement for 42 epochs (patience: 150, remaining: 108)

EPOCH 153/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3410
  ‚Ä¢ Validation Loss: 0.3809
  ‚Ä¢ Learning Rate: 0.000794
    No improvement (current: 0.3809, best: 0.3604)
    ‚ö† No improvement for 43 epochs (patience: 150, remaining: 107)

EPOCH 154/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3392
  ‚Ä¢ Validation Loss: 0.3716
  ‚Ä¢ Learning Rate: 0.000788
    No improvement (current: 0.3716, best: 0.3604)
    ‚ö† No improvement for 44 epochs (patience: 150, remaining: 106)

EPOCH 155/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3457
  ‚Ä¢ Validation Loss: 0.3760
  ‚Ä¢ Learning Rate: 0.000782
    No improvement (current: 0.3760, best: 0.3604)
    ‚ö† No improvement for 45 epochs (patience: 150, remaining: 105)

EPOCH 156/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3422
  ‚Ä¢ Validation Loss: 0.3743
  ‚Ä¢ Learning Rate: 0.000776
    No improvement (current: 0.3743, best: 0.3604)
    ‚ö† No improvement for 46 epochs (patience: 150, remaining: 104)

EPOCH 157/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3386
  ‚Ä¢ Validation Loss: 0.3762
  ‚Ä¢ Learning Rate: 0.000769
    No improvement (current: 0.3762, best: 0.3604)
    ‚ö† No improvement for 47 epochs (patience: 150, remaining: 103)

EPOCH 158/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3473
  ‚Ä¢ Validation Loss: 0.3835
  ‚Ä¢ Learning Rate: 0.000763
    No improvement (current: 0.3835, best: 0.3604)
    ‚ö† No improvement for 48 epochs (patience: 150, remaining: 102)

EPOCH 159/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3464
  ‚Ä¢ Validation Loss: 0.3764
  ‚Ä¢ Learning Rate: 0.000757
    No improvement (current: 0.3764, best: 0.3604)
    ‚ö† No improvement for 49 epochs (patience: 150, remaining: 101)

EPOCH 160/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3402
  ‚Ä¢ Validation Loss: 0.3718
  ‚Ä¢ Learning Rate: 0.000750
    No improvement (current: 0.3718, best: 0.3604)
    ‚ö† No improvement for 50 epochs (patience: 150, remaining: 100)

EPOCH 161/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3385
  ‚Ä¢ Validation Loss: 0.3701
  ‚Ä¢ Learning Rate: 0.000744
    No improvement (current: 0.3701, best: 0.3604)
    ‚ö† No improvement for 51 epochs (patience: 150, remaining: 99)

EPOCH 162/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3316
  ‚Ä¢ Validation Loss: 0.3683
  ‚Ä¢ Learning Rate: 0.000737
    No improvement (current: 0.3683, best: 0.3604)
    ‚ö† No improvement for 52 epochs (patience: 150, remaining: 98)

EPOCH 163/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3293
  ‚Ä¢ Validation Loss: 0.3742
  ‚Ä¢ Learning Rate: 0.000731
    No improvement (current: 0.3742, best: 0.3604)
    ‚ö† No improvement for 53 epochs (patience: 150, remaining: 97)

EPOCH 164/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3313
  ‚Ä¢ Validation Loss: 0.3682
  ‚Ä¢ Learning Rate: 0.000724
    No improvement (current: 0.3682, best: 0.3604)
    ‚ö† No improvement for 54 epochs (patience: 150, remaining: 96)

EPOCH 165/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3265
  ‚Ä¢ Validation Loss: 0.3682
  ‚Ä¢ Learning Rate: 0.000717
    No improvement (current: 0.3682, best: 0.3604)
    ‚ö† No improvement for 55 epochs (patience: 150, remaining: 95)

EPOCH 166/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3313
  ‚Ä¢ Validation Loss: 0.3699
  ‚Ä¢ Learning Rate: 0.000710
    No improvement (current: 0.3699, best: 0.3604)
    ‚ö† No improvement for 56 epochs (patience: 150, remaining: 94)

EPOCH 167/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3284
  ‚Ä¢ Validation Loss: 0.3700
  ‚Ä¢ Learning Rate: 0.000704
    No improvement (current: 0.3700, best: 0.3604)
    ‚ö† No improvement for 57 epochs (patience: 150, remaining: 93)

EPOCH 168/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3281
  ‚Ä¢ Validation Loss: 0.3701
  ‚Ä¢ Learning Rate: 0.000697
    No improvement (current: 0.3701, best: 0.3604)
    ‚ö† No improvement for 58 epochs (patience: 150, remaining: 92)

EPOCH 169/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3287
  ‚Ä¢ Validation Loss: 0.3694
  ‚Ä¢ Learning Rate: 0.000690
    No improvement (current: 0.3694, best: 0.3604)
    ‚ö† No improvement for 59 epochs (patience: 150, remaining: 91)

EPOCH 170/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3245
  ‚Ä¢ Validation Loss: 0.3709
  ‚Ä¢ Learning Rate: 0.000683
    No improvement (current: 0.3709, best: 0.3604)
    ‚ö† No improvement for 60 epochs (patience: 150, remaining: 90)

EPOCH 171/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3321
  ‚Ä¢ Validation Loss: 0.3678
  ‚Ä¢ Learning Rate: 0.000676
    No improvement (current: 0.3678, best: 0.3604)
    ‚ö† No improvement for 61 epochs (patience: 150, remaining: 89)

EPOCH 172/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3255
  ‚Ä¢ Validation Loss: 0.3732
  ‚Ä¢ Learning Rate: 0.000669
    No improvement (current: 0.3732, best: 0.3604)
    ‚ö† No improvement for 62 epochs (patience: 150, remaining: 88)

EPOCH 173/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3344
  ‚Ä¢ Validation Loss: 0.3817
  ‚Ä¢ Learning Rate: 0.000662
    No improvement (current: 0.3817, best: 0.3604)
    ‚ö† No improvement for 63 epochs (patience: 150, remaining: 87)

EPOCH 174/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3302
  ‚Ä¢ Validation Loss: 0.3810
  ‚Ä¢ Learning Rate: 0.000655
    No improvement (current: 0.3810, best: 0.3604)
    ‚ö† No improvement for 64 epochs (patience: 150, remaining: 86)

EPOCH 175/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3420
  ‚Ä¢ Validation Loss: 0.3686
  ‚Ä¢ Learning Rate: 0.000648
    No improvement (current: 0.3686, best: 0.3604)
    ‚ö† No improvement for 65 epochs (patience: 150, remaining: 85)

EPOCH 176/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3258
  ‚Ä¢ Validation Loss: 0.3674
  ‚Ä¢ Learning Rate: 0.000641
    No improvement (current: 0.3674, best: 0.3604)
    ‚ö† No improvement for 66 epochs (patience: 150, remaining: 84)

EPOCH 177/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3219
  ‚Ä¢ Validation Loss: 0.3656
  ‚Ä¢ Learning Rate: 0.000633
    No improvement (current: 0.3656, best: 0.3604)
    ‚ö† No improvement for 67 epochs (patience: 150, remaining: 83)

EPOCH 178/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3245
  ‚Ä¢ Validation Loss: 0.3661
  ‚Ä¢ Learning Rate: 0.000626
    No improvement (current: 0.3661, best: 0.3604)
    ‚ö† No improvement for 68 epochs (patience: 150, remaining: 82)

EPOCH 179/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3244
  ‚Ä¢ Validation Loss: 0.3704
  ‚Ä¢ Learning Rate: 0.000619
    No improvement (current: 0.3704, best: 0.3604)
    ‚ö† No improvement for 69 epochs (patience: 150, remaining: 81)

EPOCH 180/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3243
  ‚Ä¢ Validation Loss: 0.3657
  ‚Ä¢ Learning Rate: 0.000612
    No improvement (current: 0.3657, best: 0.3604)
    ‚ö† No improvement for 70 epochs (patience: 150, remaining: 80)

EPOCH 181/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3197
  ‚Ä¢ Validation Loss: 0.3655
  ‚Ä¢ Learning Rate: 0.000604
    No improvement (current: 0.3655, best: 0.3604)
    ‚ö† No improvement for 71 epochs (patience: 150, remaining: 79)

EPOCH 182/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3174
  ‚Ä¢ Validation Loss: 0.3673
  ‚Ä¢ Learning Rate: 0.000597
    No improvement (current: 0.3673, best: 0.3604)
    ‚ö† No improvement for 72 epochs (patience: 150, remaining: 78)

EPOCH 183/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3190
  ‚Ä¢ Validation Loss: 0.3636
  ‚Ä¢ Learning Rate: 0.000590
    No improvement (current: 0.3636, best: 0.3604)
    ‚ö† No improvement for 73 epochs (patience: 150, remaining: 77)

EPOCH 184/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3137
  ‚Ä¢ Validation Loss: 0.3657
  ‚Ä¢ Learning Rate: 0.000582
    No improvement (current: 0.3657, best: 0.3604)
    ‚ö† No improvement for 74 epochs (patience: 150, remaining: 76)

EPOCH 185/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3153
  ‚Ä¢ Validation Loss: 0.3787
  ‚Ä¢ Learning Rate: 0.000575
    No improvement (current: 0.3787, best: 0.3604)
    ‚ö† No improvement for 75 epochs (patience: 150, remaining: 75)

EPOCH 186/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3206
  ‚Ä¢ Validation Loss: 0.3651
  ‚Ä¢ Learning Rate: 0.000567
    No improvement (current: 0.3651, best: 0.3604)
    ‚ö† No improvement for 76 epochs (patience: 150, remaining: 74)

EPOCH 187/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3141
  ‚Ä¢ Validation Loss: 0.3635
  ‚Ä¢ Learning Rate: 0.000560
    No improvement (current: 0.3635, best: 0.3604)
    ‚ö† No improvement for 77 epochs (patience: 150, remaining: 73)

EPOCH 188/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3234
  ‚Ä¢ Validation Loss: 0.3668
  ‚Ä¢ Learning Rate: 0.000553
    No improvement (current: 0.3668, best: 0.3604)
    ‚ö† No improvement for 78 epochs (patience: 150, remaining: 72)

EPOCH 189/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3169
  ‚Ä¢ Validation Loss: 0.3688
  ‚Ä¢ Learning Rate: 0.000545
    No improvement (current: 0.3688, best: 0.3604)
    ‚ö† No improvement for 79 epochs (patience: 150, remaining: 71)

EPOCH 190/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3184
  ‚Ä¢ Validation Loss: 0.3895
  ‚Ä¢ Learning Rate: 0.000538
    No improvement (current: 0.3895, best: 0.3604)
    ‚ö† No improvement for 80 epochs (patience: 150, remaining: 70)

EPOCH 191/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3226
  ‚Ä¢ Validation Loss: 0.3626
  ‚Ä¢ Learning Rate: 0.000530
    No improvement (current: 0.3626, best: 0.3604)
    ‚ö† No improvement for 81 epochs (patience: 150, remaining: 69)

EPOCH 192/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3308
  ‚Ä¢ Validation Loss: 0.4407
  ‚Ä¢ Learning Rate: 0.000523
    No improvement (current: 0.4407, best: 0.3604)
    ‚ö† No improvement for 82 epochs (patience: 150, remaining: 68)

EPOCH 193/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3454
  ‚Ä¢ Validation Loss: 0.3699
  ‚Ä¢ Learning Rate: 0.000515
    No improvement (current: 0.3699, best: 0.3604)
    ‚ö† No improvement for 83 epochs (patience: 150, remaining: 67)

EPOCH 194/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3230
  ‚Ä¢ Validation Loss: 0.3654
  ‚Ä¢ Learning Rate: 0.000508
    No improvement (current: 0.3654, best: 0.3604)
    ‚ö† No improvement for 84 epochs (patience: 150, remaining: 66)

EPOCH 195/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3320
  ‚Ä¢ Validation Loss: 0.3680
  ‚Ä¢ Learning Rate: 0.000500
    No improvement (current: 0.3680, best: 0.3604)
    ‚ö† No improvement for 85 epochs (patience: 150, remaining: 65)

EPOCH 196/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3312
  ‚Ä¢ Validation Loss: 0.3886
  ‚Ä¢ Learning Rate: 0.000493
    No improvement (current: 0.3886, best: 0.3604)
    ‚ö† No improvement for 86 epochs (patience: 150, remaining: 64)

EPOCH 197/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3316
  ‚Ä¢ Validation Loss: 0.3657
  ‚Ä¢ Learning Rate: 0.000486
    No improvement (current: 0.3657, best: 0.3604)
    ‚ö† No improvement for 87 epochs (patience: 150, remaining: 63)

EPOCH 198/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3213
  ‚Ä¢ Validation Loss: 0.3638
  ‚Ä¢ Learning Rate: 0.000478
    No improvement (current: 0.3638, best: 0.3604)
    ‚ö† No improvement for 88 epochs (patience: 150, remaining: 62)

EPOCH 199/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3157
  ‚Ä¢ Validation Loss: 0.3623
  ‚Ä¢ Learning Rate: 0.000471
    No improvement (current: 0.3623, best: 0.3604)
    ‚ö† No improvement for 89 epochs (patience: 150, remaining: 61)

EPOCH 200/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3208
  ‚Ä¢ Validation Loss: 0.3647
  ‚Ä¢ Learning Rate: 0.000463
   üíæ Periodic checkpoint saved: epoch_200.pth
    No improvement (current: 0.3647, best: 0.3604)
    ‚ö† No improvement for 90 epochs (patience: 150, remaining: 60)

EPOCH 201/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3321
  ‚Ä¢ Validation Loss: 0.3857
  ‚Ä¢ Learning Rate: 0.000456
    No improvement (current: 0.3857, best: 0.3604)
    ‚ö† No improvement for 91 epochs (patience: 150, remaining: 59)

EPOCH 202/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3291
  ‚Ä¢ Validation Loss: 0.3651
  ‚Ä¢ Learning Rate: 0.000448
    No improvement (current: 0.3651, best: 0.3604)
    ‚ö† No improvement for 92 epochs (patience: 150, remaining: 58)

EPOCH 203/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3216
  ‚Ä¢ Validation Loss: 0.3623
  ‚Ä¢ Learning Rate: 0.000441
    No improvement (current: 0.3623, best: 0.3604)
    ‚ö† No improvement for 93 epochs (patience: 150, remaining: 57)

EPOCH 204/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3159
  ‚Ä¢ Validation Loss: 0.3625
  ‚Ä¢ Learning Rate: 0.000433
    No improvement (current: 0.3625, best: 0.3604)
    ‚ö† No improvement for 94 epochs (patience: 150, remaining: 56)

EPOCH 205/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3165
  ‚Ä¢ Validation Loss: 0.3618
  ‚Ä¢ Learning Rate: 0.000426
    No improvement (current: 0.3618, best: 0.3604)
    ‚ö† No improvement for 95 epochs (patience: 150, remaining: 55)

EPOCH 206/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3142
  ‚Ä¢ Validation Loss: 0.3621
  ‚Ä¢ Learning Rate: 0.000419
    No improvement (current: 0.3621, best: 0.3604)
    ‚ö† No improvement for 96 epochs (patience: 150, remaining: 54)

EPOCH 207/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3157
  ‚Ä¢ Validation Loss: 0.3616
  ‚Ä¢ Learning Rate: 0.000411
    No improvement (current: 0.3616, best: 0.3604)
    ‚ö† No improvement for 97 epochs (patience: 150, remaining: 53)

EPOCH 208/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3125
  ‚Ä¢ Validation Loss: 0.3620
  ‚Ä¢ Learning Rate: 0.000404
    No improvement (current: 0.3620, best: 0.3604)
    ‚ö† No improvement for 98 epochs (patience: 150, remaining: 52)

EPOCH 209/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3146
  ‚Ä¢ Validation Loss: 0.3617
  ‚Ä¢ Learning Rate: 0.000397
    No improvement (current: 0.3617, best: 0.3604)
    ‚ö† No improvement for 99 epochs (patience: 150, remaining: 51)

EPOCH 210/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3147
  ‚Ä¢ Validation Loss: 0.3616
  ‚Ä¢ Learning Rate: 0.000389
    No improvement (current: 0.3616, best: 0.3604)
    ‚ö† No improvement for 100 epochs (patience: 150, remaining: 50)

EPOCH 211/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3132
  ‚Ä¢ Validation Loss: 0.3615
  ‚Ä¢ Learning Rate: 0.000382
    No improvement (current: 0.3615, best: 0.3604)
    ‚ö† No improvement for 101 epochs (patience: 150, remaining: 49)

EPOCH 212/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3140
  ‚Ä¢ Validation Loss: 0.3612
  ‚Ä¢ Learning Rate: 0.000375
    No improvement (current: 0.3612, best: 0.3604)
    ‚ö† No improvement for 102 epochs (patience: 150, remaining: 48)

EPOCH 213/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3155
  ‚Ä¢ Validation Loss: 0.3613
  ‚Ä¢ Learning Rate: 0.000368
    No improvement (current: 0.3613, best: 0.3604)
    ‚ö† No improvement for 103 epochs (patience: 150, remaining: 47)

EPOCH 214/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3168
  ‚Ä¢ Validation Loss: 0.3612
  ‚Ä¢ Learning Rate: 0.000360
    No improvement (current: 0.3612, best: 0.3604)
    ‚ö† No improvement for 104 epochs (patience: 150, remaining: 46)

EPOCH 215/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3144
  ‚Ä¢ Validation Loss: 0.3609
  ‚Ä¢ Learning Rate: 0.000353
    No improvement (current: 0.3609, best: 0.3604)
    ‚ö† No improvement for 105 epochs (patience: 150, remaining: 45)

EPOCH 216/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3106
  ‚Ä¢ Validation Loss: 0.3609
  ‚Ä¢ Learning Rate: 0.000346
    No improvement (current: 0.3609, best: 0.3604)
    ‚ö† No improvement for 106 epochs (patience: 150, remaining: 44)

EPOCH 217/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3168
  ‚Ä¢ Validation Loss: 0.3610
  ‚Ä¢ Learning Rate: 0.000339
    No improvement (current: 0.3610, best: 0.3604)
    ‚ö† No improvement for 107 epochs (patience: 150, remaining: 43)

EPOCH 218/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3139
  ‚Ä¢ Validation Loss: 0.3610
  ‚Ä¢ Learning Rate: 0.000332
    No improvement (current: 0.3610, best: 0.3604)
    ‚ö† No improvement for 108 epochs (patience: 150, remaining: 42)

EPOCH 219/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3167
  ‚Ä¢ Validation Loss: 0.3610
  ‚Ä¢ Learning Rate: 0.000325
    No improvement (current: 0.3610, best: 0.3604)
    ‚ö† No improvement for 109 epochs (patience: 150, remaining: 41)

EPOCH 220/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3118
  ‚Ä¢ Validation Loss: 0.3610
  ‚Ä¢ Learning Rate: 0.000318
    No improvement (current: 0.3610, best: 0.3604)
    ‚ö† No improvement for 110 epochs (patience: 150, remaining: 40)

EPOCH 221/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3112
  ‚Ä¢ Validation Loss: 0.3616
  ‚Ä¢ Learning Rate: 0.000311
    No improvement (current: 0.3616, best: 0.3604)
    ‚ö† No improvement for 111 epochs (patience: 150, remaining: 39)

EPOCH 222/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3094
  ‚Ä¢ Validation Loss: 0.3607
  ‚Ä¢ Learning Rate: 0.000304
    No improvement (current: 0.3607, best: 0.3604)
    ‚ö† No improvement for 112 epochs (patience: 150, remaining: 38)

EPOCH 223/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3121
  ‚Ä¢ Validation Loss: 0.3606
  ‚Ä¢ Learning Rate: 0.000297
    No improvement (current: 0.3606, best: 0.3604)
    ‚ö† No improvement for 113 epochs (patience: 150, remaining: 37)

EPOCH 224/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3116
  ‚Ä¢ Validation Loss: 0.3605
  ‚Ä¢ Learning Rate: 0.000290
    No improvement (current: 0.3605, best: 0.3604)
    ‚ö† No improvement for 114 epochs (patience: 150, remaining: 36)

EPOCH 225/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3134
  ‚Ä¢ Validation Loss: 0.3608
  ‚Ä¢ Learning Rate: 0.000284
    No improvement (current: 0.3608, best: 0.3604)
    ‚ö† No improvement for 115 epochs (patience: 150, remaining: 35)

EPOCH 226/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3195
  ‚Ä¢ Validation Loss: 0.3606
  ‚Ä¢ Learning Rate: 0.000277
    No improvement (current: 0.3606, best: 0.3604)
    ‚ö† No improvement for 116 epochs (patience: 150, remaining: 34)

EPOCH 227/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3116
  ‚Ä¢ Validation Loss: 0.3607
  ‚Ä¢ Learning Rate: 0.000270
    No improvement (current: 0.3607, best: 0.3604)
    ‚ö† No improvement for 117 epochs (patience: 150, remaining: 33)

EPOCH 228/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3109
  ‚Ä¢ Validation Loss: 0.3607
  ‚Ä¢ Learning Rate: 0.000264
    No improvement (current: 0.3607, best: 0.3604)
    ‚ö† No improvement for 118 epochs (patience: 150, remaining: 32)

EPOCH 229/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3135
  ‚Ä¢ Validation Loss: 0.3609
  ‚Ä¢ Learning Rate: 0.000257
    No improvement (current: 0.3609, best: 0.3604)
    ‚ö† No improvement for 119 epochs (patience: 150, remaining: 31)

EPOCH 230/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3146
  ‚Ä¢ Validation Loss: 0.3678
  ‚Ä¢ Learning Rate: 0.000251
    No improvement (current: 0.3678, best: 0.3604)
    ‚ö† No improvement for 120 epochs (patience: 150, remaining: 30)

EPOCH 231/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3146
  ‚Ä¢ Validation Loss: 0.3606
  ‚Ä¢ Learning Rate: 0.000244
    No improvement (current: 0.3606, best: 0.3604)
    ‚ö† No improvement for 121 epochs (patience: 150, remaining: 29)

EPOCH 232/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3125
  ‚Ä¢ Validation Loss: 0.3672
  ‚Ä¢ Learning Rate: 0.000238
    No improvement (current: 0.3672, best: 0.3604)
    ‚ö† No improvement for 122 epochs (patience: 150, remaining: 28)

EPOCH 233/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3125
  ‚Ä¢ Validation Loss: 0.3708
  ‚Ä¢ Learning Rate: 0.000232
    No improvement (current: 0.3708, best: 0.3604)
    ‚ö† No improvement for 123 epochs (patience: 150, remaining: 27)

EPOCH 234/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3209
  ‚Ä¢ Validation Loss: 0.3625
  ‚Ä¢ Learning Rate: 0.000225
    No improvement (current: 0.3625, best: 0.3604)
    ‚ö† No improvement for 124 epochs (patience: 150, remaining: 26)

EPOCH 235/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3162
  ‚Ä¢ Validation Loss: 0.3609
  ‚Ä¢ Learning Rate: 0.000219
    No improvement (current: 0.3609, best: 0.3604)
    ‚ö† No improvement for 125 epochs (patience: 150, remaining: 25)

EPOCH 236/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3083
  ‚Ä¢ Validation Loss: 0.3623
  ‚Ä¢ Learning Rate: 0.000213
    No improvement (current: 0.3623, best: 0.3604)
    ‚ö† No improvement for 126 epochs (patience: 150, remaining: 24)

EPOCH 237/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3090
  ‚Ä¢ Validation Loss: 0.3610
  ‚Ä¢ Learning Rate: 0.000207
    No improvement (current: 0.3610, best: 0.3604)
    ‚ö† No improvement for 127 epochs (patience: 150, remaining: 23)

EPOCH 238/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3154
  ‚Ä¢ Validation Loss: 0.3618
  ‚Ä¢ Learning Rate: 0.000201
    No improvement (current: 0.3618, best: 0.3604)
    ‚ö† No improvement for 128 epochs (patience: 150, remaining: 22)

EPOCH 239/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3089
  ‚Ä¢ Validation Loss: 0.3607
  ‚Ä¢ Learning Rate: 0.000195
    No improvement (current: 0.3607, best: 0.3604)
    ‚ö† No improvement for 129 epochs (patience: 150, remaining: 21)

EPOCH 240/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3147
  ‚Ä¢ Validation Loss: 0.3606
  ‚Ä¢ Learning Rate: 0.000189
    No improvement (current: 0.3606, best: 0.3604)
    ‚ö† No improvement for 130 epochs (patience: 150, remaining: 20)

EPOCH 241/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3102
  ‚Ä¢ Validation Loss: 0.3623
  ‚Ä¢ Learning Rate: 0.000183
    No improvement (current: 0.3623, best: 0.3604)
    ‚ö† No improvement for 131 epochs (patience: 150, remaining: 19)

EPOCH 242/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3100
  ‚Ä¢ Validation Loss: 0.3598
  ‚Ä¢ Learning Rate: 0.000177
    ‚úì New best checkpoint saved! Val loss: 0.3598
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 243/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3096
  ‚Ä¢ Validation Loss: 0.3600
  ‚Ä¢ Learning Rate: 0.000172
    No improvement (current: 0.3600, best: 0.3598)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 244/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3098
  ‚Ä¢ Validation Loss: 0.3600
  ‚Ä¢ Learning Rate: 0.000166
    No improvement (current: 0.3600, best: 0.3598)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 245/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3095
  ‚Ä¢ Validation Loss: 0.3603
  ‚Ä¢ Learning Rate: 0.000161
    No improvement (current: 0.3603, best: 0.3598)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 246/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3124
  ‚Ä¢ Validation Loss: 0.3599
  ‚Ä¢ Learning Rate: 0.000155
    No improvement (current: 0.3599, best: 0.3598)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 247/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3102
  ‚Ä¢ Validation Loss: 0.3606
  ‚Ä¢ Learning Rate: 0.000150
    No improvement (current: 0.3606, best: 0.3598)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 248/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3149
  ‚Ä¢ Validation Loss: 0.3595
  ‚Ä¢ Learning Rate: 0.000145
    ‚úì New best checkpoint saved! Val loss: 0.3595
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 249/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3134
  ‚Ä¢ Validation Loss: 0.3602
  ‚Ä¢ Learning Rate: 0.000139
    No improvement (current: 0.3602, best: 0.3595)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 250/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3084
  ‚Ä¢ Validation Loss: 0.3592
  ‚Ä¢ Learning Rate: 0.000134
    ‚úì New best checkpoint saved! Val loss: 0.3592
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 251/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3105
  ‚Ä¢ Validation Loss: 0.3603
  ‚Ä¢ Learning Rate: 0.000129
    No improvement (current: 0.3603, best: 0.3592)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 252/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3142
  ‚Ä¢ Validation Loss: 0.3621
  ‚Ä¢ Learning Rate: 0.000124
    No improvement (current: 0.3621, best: 0.3592)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 253/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3086
  ‚Ä¢ Validation Loss: 0.3594
  ‚Ä¢ Learning Rate: 0.000119
    No improvement (current: 0.3594, best: 0.3592)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 254/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3103
  ‚Ä¢ Validation Loss: 0.3603
  ‚Ä¢ Learning Rate: 0.000115
    No improvement (current: 0.3603, best: 0.3592)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 255/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3087
  ‚Ä¢ Validation Loss: 0.3611
  ‚Ä¢ Learning Rate: 0.000110
    No improvement (current: 0.3611, best: 0.3592)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 256/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3102
  ‚Ä¢ Validation Loss: 0.3617
  ‚Ä¢ Learning Rate: 0.000105
    No improvement (current: 0.3617, best: 0.3592)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 257/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3114
  ‚Ä¢ Validation Loss: 0.3599
  ‚Ä¢ Learning Rate: 0.000101
    No improvement (current: 0.3599, best: 0.3592)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 258/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3060
  ‚Ä¢ Validation Loss: 0.3601
  ‚Ä¢ Learning Rate: 0.000096
    No improvement (current: 0.3601, best: 0.3592)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 259/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3065
  ‚Ä¢ Validation Loss: 0.3595
  ‚Ä¢ Learning Rate: 0.000092
    No improvement (current: 0.3595, best: 0.3592)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 260/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3109
  ‚Ä¢ Validation Loss: 0.3595
  ‚Ä¢ Learning Rate: 0.000088
    No improvement (current: 0.3595, best: 0.3592)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 261/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3140
  ‚Ä¢ Validation Loss: 0.3597
  ‚Ä¢ Learning Rate: 0.000084
    No improvement (current: 0.3597, best: 0.3592)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 262/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3089
  ‚Ä¢ Validation Loss: 0.3587
  ‚Ä¢ Learning Rate: 0.000080
    ‚úì New best checkpoint saved! Val loss: 0.3587
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 263/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3016
  ‚Ä¢ Validation Loss: 0.3588
  ‚Ä¢ Learning Rate: 0.000076
    No improvement (current: 0.3588, best: 0.3587)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 264/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3107
  ‚Ä¢ Validation Loss: 0.3605
  ‚Ä¢ Learning Rate: 0.000072
    No improvement (current: 0.3605, best: 0.3587)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 265/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3046
  ‚Ä¢ Validation Loss: 0.3594
  ‚Ä¢ Learning Rate: 0.000068
    No improvement (current: 0.3594, best: 0.3587)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 266/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3097
  ‚Ä¢ Validation Loss: 0.3593
  ‚Ä¢ Learning Rate: 0.000064
    No improvement (current: 0.3593, best: 0.3587)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 267/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3083
  ‚Ä¢ Validation Loss: 0.3589
  ‚Ä¢ Learning Rate: 0.000061
    No improvement (current: 0.3589, best: 0.3587)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 268/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3073
  ‚Ä¢ Validation Loss: 0.3594
  ‚Ä¢ Learning Rate: 0.000057
    No improvement (current: 0.3594, best: 0.3587)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 269/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3050
  ‚Ä¢ Validation Loss: 0.3601
  ‚Ä¢ Learning Rate: 0.000054
    No improvement (current: 0.3601, best: 0.3587)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 270/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3083
  ‚Ä¢ Validation Loss: 0.3613
  ‚Ä¢ Learning Rate: 0.000050
    No improvement (current: 0.3613, best: 0.3587)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 271/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3089
  ‚Ä¢ Validation Loss: 0.3601
  ‚Ä¢ Learning Rate: 0.000047
    No improvement (current: 0.3601, best: 0.3587)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 272/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3119
  ‚Ä¢ Validation Loss: 0.3587
  ‚Ä¢ Learning Rate: 0.000044
    ‚úì New best checkpoint saved! Val loss: 0.3587
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 273/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3078
  ‚Ä¢ Validation Loss: 0.3586
  ‚Ä¢ Learning Rate: 0.000041
    ‚úì New best checkpoint saved! Val loss: 0.3586
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 274/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3118
  ‚Ä¢ Validation Loss: 0.3587
  ‚Ä¢ Learning Rate: 0.000038
    No improvement (current: 0.3587, best: 0.3586)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 275/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3080
  ‚Ä¢ Validation Loss: 0.3585
  ‚Ä¢ Learning Rate: 0.000036
    ‚úì New best checkpoint saved! Val loss: 0.3585
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 276/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3076
  ‚Ä¢ Validation Loss: 0.3586
  ‚Ä¢ Learning Rate: 0.000033
    No improvement (current: 0.3586, best: 0.3585)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 277/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3078
  ‚Ä¢ Validation Loss: 0.3586
  ‚Ä¢ Learning Rate: 0.000030
    No improvement (current: 0.3586, best: 0.3585)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 278/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3067
  ‚Ä¢ Validation Loss: 0.3583
  ‚Ä¢ Learning Rate: 0.000028
    ‚úì New best checkpoint saved! Val loss: 0.3583
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 279/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3058
  ‚Ä¢ Validation Loss: 0.3585
  ‚Ä¢ Learning Rate: 0.000025
    No improvement (current: 0.3585, best: 0.3583)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 280/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3009
  ‚Ä¢ Validation Loss: 0.3582
  ‚Ä¢ Learning Rate: 0.000023
    ‚úì New best checkpoint saved! Val loss: 0.3582
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 281/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3020
  ‚Ä¢ Validation Loss: 0.3584
  ‚Ä¢ Learning Rate: 0.000021
    No improvement (current: 0.3584, best: 0.3582)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 282/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3077
  ‚Ä¢ Validation Loss: 0.3586
  ‚Ä¢ Learning Rate: 0.000019
    No improvement (current: 0.3586, best: 0.3582)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 283/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3048
  ‚Ä¢ Validation Loss: 0.3585
  ‚Ä¢ Learning Rate: 0.000017
    No improvement (current: 0.3585, best: 0.3582)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 284/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3071
  ‚Ä¢ Validation Loss: 0.3584
  ‚Ä¢ Learning Rate: 0.000015
    No improvement (current: 0.3584, best: 0.3582)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 285/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3050
  ‚Ä¢ Validation Loss: 0.3586
  ‚Ä¢ Learning Rate: 0.000014
    No improvement (current: 0.3586, best: 0.3582)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 286/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3035
  ‚Ä¢ Validation Loss: 0.3585
  ‚Ä¢ Learning Rate: 0.000012
    No improvement (current: 0.3585, best: 0.3582)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 287/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3040
  ‚Ä¢ Validation Loss: 0.3584
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3584, best: 0.3582)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 288/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3101
  ‚Ä¢ Validation Loss: 0.3585
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3585, best: 0.3582)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 289/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3085
  ‚Ä¢ Validation Loss: 0.3585
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3585, best: 0.3582)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 290/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3055
  ‚Ä¢ Validation Loss: 0.3584
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3584, best: 0.3582)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 291/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3057
  ‚Ä¢ Validation Loss: 0.3584
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3584, best: 0.3582)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 292/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3065
  ‚Ä¢ Validation Loss: 0.3585
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3585, best: 0.3582)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 293/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3100
  ‚Ä¢ Validation Loss: 0.3586
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3586, best: 0.3582)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 294/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3045
  ‚Ä¢ Validation Loss: 0.3585
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3585, best: 0.3582)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 295/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3040
  ‚Ä¢ Validation Loss: 0.3585
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3585, best: 0.3582)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 296/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3080
  ‚Ä¢ Validation Loss: 0.3584
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3584, best: 0.3582)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 297/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3054
  ‚Ä¢ Validation Loss: 0.3584
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3584, best: 0.3582)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 298/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3119
  ‚Ä¢ Validation Loss: 0.3584
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3584, best: 0.3582)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 299/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3051
  ‚Ä¢ Validation Loss: 0.3585
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3585, best: 0.3582)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 300/300
--------------------------------------------------
‚ö†Ô∏è  Scheduler reached max steps, stopping LR updates.
Results:
  ‚Ä¢ Train Loss: 0.3071
  ‚Ä¢ Validation Loss: 0.3584
  ‚Ä¢ Learning Rate: 0.000001
   üíæ Periodic checkpoint saved: epoch_300.pth
    No improvement (current: 0.3584, best: 0.3582)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

================================================================================
TRAINING COMPLETED
================================================================================
Best Val Loss:  0.3582
Total Epochs:   300
Models Saved:   ./Result/a2/Latin2
TensorBoard:    ./Result/a2/Latin2/tensorboard_logs
================================================================================

[00:00:48] Training completed. Best val loss: 0.3582

=== TRAINING COMPLETED SUCCESSFULLY ===
Training Finished!

========================================================================
Testing Hybrid2 Baseline Model with Smart Skip Connections and Multi-Scale Aggregation: Latin2
========================================================================
=== Historical Document Segmentation Testing ===

Using 6 classes for manuscript: Latin2
Model: Hybrid2
Dataset: UDIADS_BIB
Manuscript: Latin2
Test-Time Augmentation: Enabled
CRF post-processing: Enabled
  - DenseCRF with spatial and color pairwise potentials

================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder for Testing
================================================================================
================================================================================
üöÄ SIMPLE DECODER (Flag-Controlled Enhancements)
================================================================================
  ‚Ä¢ EfficientNet Variant: b4
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Enhancement Flags:
  ‚Ä¢ Deep Supervision: False
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: True
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: True
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Loaded checkpoint from epoch 279
Best validation loss: 0.3582
  ‚úÖ Model checkpoint loaded successfully (exact match)
Loaded checkpoint: best_model_latest.pth
Namespace(cfg=None, output_dir='./Result/a2/Latin2', use_baseline=True, decoder='EfficientNet-B4', efficientnet_variant='b4', use_deep_supervision=False, use_cbam=False, use_smart_skip=True, use_cross_attn=False, use_multiscale_agg=True, use_groupnorm=True, use_batchnorm=False, use_pos_embed=True, dataset='UDIADS_BIB', manuscript='Latin2', udiadsbib_root='../../U-DIADS-Bib-MS_patched', divahisdb_root='../../DivaHisDB', use_patched_data=True, num_classes=6, img_size=224, batch_size=24, is_savenii=True, test_save_dir='../predictions', use_crf=True, deterministic=1, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, use_tta=True)
Testing with checkpoint: best_model_latest.pth
Saving predictions to: ./Result/a2/Latin2/predictions

=== Starting Testing ===
Dataset: UDIADS_BIB
Model: Hybrid2
Manuscript: Latin2
Save predictions: True

Starting inference on UDIADS_BIB dataset
Found 1620 patches for Latin2
Using Test-Time Augmentation (TTA) for improved accuracy
CRF post-processing: Enabled
  - DenseCRF with spatial and color pairwise potentials
Processing: 076 (54 patches)
Applying CRF post-processing to 076
CRF post-processing completed for 076
Completed: 076
Processing: 079 (54 patches)
Applying CRF post-processing to 079
CRF post-processing completed for 079
Completed: 079
Processing: 082 (54 patches)
Applying CRF post-processing to 082
CRF post-processing completed for 082
Completed: 082
Processing: 095 (54 patches)
Applying CRF post-processing to 095
CRF post-processing completed for 095
Completed: 095
Processing: 106 (54 patches)
Applying CRF post-processing to 106
CRF post-processing completed for 106
Completed: 106
Processing: 111 (54 patches)
Applying CRF post-processing to 111
CRF post-processing completed for 111
Completed: 111
Processing: 115 (54 patches)
Applying CRF post-processing to 115
CRF post-processing completed for 115
Completed: 115
Processing: 117 (54 patches)
Applying CRF post-processing to 117
CRF post-processing completed for 117
Completed: 117
Processing: 128 (54 patches)
Applying CRF post-processing to 128
CRF post-processing completed for 128
Completed: 128
Processing: 134 (54 patches)
Applying CRF post-processing to 134
CRF post-processing completed for 134
Completed: 134
Processing: 138 (54 patches)
Applying CRF post-processing to 138
CRF post-processing completed for 138
Completed: 138
Processing: 142 (54 patches)
Applying CRF post-processing to 142
CRF post-processing completed for 142
Completed: 142
Processing: 159 (54 patches)
Applying CRF post-processing to 159
CRF post-processing completed for 159
Completed: 159
Processing: 166 (54 patches)
Applying CRF post-processing to 166
CRF post-processing completed for 166
Completed: 166
Processing: 185 (54 patches)
Applying CRF post-processing to 185
CRF post-processing completed for 185
Completed: 185
Processing: 200 (54 patches)
Applying CRF post-processing to 200
CRF post-processing completed for 200
Completed: 200
Processing: 203 (54 patches)
Applying CRF post-processing to 203
CRF post-processing completed for 203
Completed: 203
Processing: 208 (54 patches)
Applying CRF post-processing to 208
CRF post-processing completed for 208
Completed: 208
Processing: 229 (54 patches)
Applying CRF post-processing to 229
CRF post-processing completed for 229
Completed: 229
Processing: 230 (54 patches)
Applying CRF post-processing to 230
CRF post-processing completed for 230
Completed: 230
Processing: 235 (54 patches)
Applying CRF post-processing to 235
CRF post-processing completed for 235
Completed: 235
Processing: 236 (54 patches)
Applying CRF post-processing to 236
CRF post-processing completed for 236
Completed: 236
Processing: 248 (54 patches)
Applying CRF post-processing to 248
CRF post-processing completed for 248
Completed: 248
Processing: 249 (54 patches)
Applying CRF post-processing to 249
CRF post-processing completed for 249
Completed: 249
Processing: 250 (54 patches)
Applying CRF post-processing to 250
CRF post-processing completed for 250
Completed: 250
Processing: 251 (54 patches)
Applying CRF post-processing to 251
CRF post-processing completed for 251
Completed: 251
Processing: 252 (54 patches)
Applying CRF post-processing to 252
CRF post-processing completed for 252
Completed: 252
Processing: 275 (54 patches)
Applying CRF post-processing to 275
CRF post-processing completed for 275
Completed: 275
Processing: 277 (54 patches)
Applying CRF post-processing to 277
CRF post-processing completed for 277
Completed: 277
Processing: 297 (54 patches)
Applying CRF post-processing to 297
CRF post-processing completed for 297
Completed: 297

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9699, Recall=0.9989, F1=0.9842, IoU=0.9689
Paratext       : Precision=0.8905, Recall=0.4583, F1=0.6052, IoU=0.4339
Decoration     : Precision=0.9037, Recall=0.8693, F1=0.8861, IoU=0.7956
Main Text      : Precision=0.9674, Recall=0.5519, F1=0.7029, IoU=0.5419
Title          : Precision=0.8922, Recall=0.6707, F1=0.7658, IoU=0.6204
Chapter Headings: Precision=0.8607, Recall=0.1729, F1=0.2880, IoU=0.1682

Mean metrics:
----------------------------------------
Mean Precision: 0.9141
Mean Recall: 0.6203
Mean F1-Score: 0.7053
Mean IoU: 0.5881

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9699, Recall=0.9989, F1=0.9842, IoU=0.9689
Paratext       : Precision=0.8905, Recall=0.4583, F1=0.6052, IoU=0.4339
Decoration     : Precision=0.9037, Recall=0.8693, F1=0.8861, IoU=0.7956
Main Text      : Precision=0.9674, Recall=0.5519, F1=0.7029, IoU=0.5419
Title          : Precision=0.8922, Recall=0.6707, F1=0.7658, IoU=0.6204
Chapter Headings: Precision=0.8607, Recall=0.1729, F1=0.2880, IoU=0.1682

Mean metrics:
----------------------------------------
Mean Precision: 0.9141
Mean Recall: 0.6203
Mean F1-Score: 0.7053
Mean IoU: 0.5881
Inference completed on 30 images

=== TESTING COMPLETED SUCCESSFULLY ===
Results saved to: ./Result/a2/Latin2/predictions
==================================================

Calculating average metrics...
Looking for metrics files in: ./Result/a2
  ‚úì Found metrics for Latin2
  ‚úó Metrics file not found: ./Result/a2/metrics_Latin14396.json
  ‚úó Metrics file not found: ./Result/a2/metrics_Latin16746.json
  ‚úó Metrics file not found: ./Result/a2/metrics_Syr341.json

================================================================================
AVERAGE METRICS ACROSS 1 MANUSCRIPT(S)
================================================================================
Manuscripts: Latin2
Missing: Latin14396, Latin16746, Syr341
--------------------------------------------------------------------------------
Mean Precision: 0.9141
Mean Recall:    0.6203
Mean F1-Score:  0.7053
Mean IoU:       0.5881
================================================================================

========================================================================
Training Hybrid2 Baseline Model with Smart Skip Connections and Multi-Scale Aggregation: Latin14396
========================================================================
Dataset: U-DIADS-Bib-MS_patched
Architecture: Swin Transformer Encoder ‚Üí 2 Swin Blocks Bottleneck ‚Üí Simple CNN Decoder
Decoder: Simple Decoder (EfficientNet-b4 channel configuration)

Components Enabled:
  ‚úì Swin Encoder (4 stages: 96‚Üí192‚Üí384‚Üí768 dim)
  ‚úì Bottleneck: 2 Swin Transformer blocks (768 dim, 24 heads)
  ‚úì Simple CNN Decoder (channels: [256, 128, 64, 32])
  ‚úì Smart Skip Connections
  ‚úì Multi-Scale Aggregation
  ‚úì Positional Embeddings (default: enabled)
  ‚úì GroupNorm (default normalization)

Components Disabled (baseline):
  ‚úó CBAM Attention
  ‚úó Smart Skip Connections
  ‚úó Cross-Attention Bottleneck
  ‚úó Multi-Scale Aggregation
  ‚úó BatchNorm
========================================================================
All arguments validated successfully!
Setting random seed to 1234 for reproducible training...
Setting up U-DIADS-Bib dataset...
Using 6 classes for manuscript: Latin14396
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin14396/Image/training
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin14396/mask/training_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin14396/Image/validation
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin14396/mask/validation_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder
================================================================================
================================================================================
üöÄ SIMPLE DECODER (Flag-Controlled Enhancements)
================================================================================
  ‚Ä¢ EfficientNet Variant: b4
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Enhancement Flags:
  ‚Ä¢ Deep Supervision: False
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: True
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: True
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Model moved to CUDA
Model created successfully with 6 classes
DEBUG: args.output_dir = ./Result/a2/Latin14396

=== Starting Training ===
Dataset: UDIADS_BIB
Model: Hybrid2
Batch size: 4
Max epochs: 300
Learning rate: 0.0001


================================================================================
TRAINING CONFIGURATION
================================================================================
Dataset: UDIADS_BIB
Model: Hybrid2
Batch Size: 4
Max Epochs: 300
Learning Rate: 0.0001
Number of Classes: 6
Output Directory: ./Result/a2/Latin14396
Early Stopping Patience: 150 epochs
================================================================================

üìä Dataset Statistics:
   - Training samples: 540
   - Validation samples: 540
   - Batch size: 4
   - Steps per epoch: 135


================================================================================
COMPUTING CLASS WEIGHTS
================================================================================
Raw ENS weights: [9.99999990e-05 1.09839441e-04 9.99999990e-05 9.99999990e-05
 1.00000006e-04 1.00000021e-04]

Class Distribution:
Class                Pixels          Frequency       Weight         
-----------------------------------------------------------------
0                        24,235,884        89.4477%         0.9839
1                            24,125         0.0890%         1.0807
2                           460,965         1.7013%         0.9839
3                         2,056,396         7.5896%         0.9839
4                           164,544         0.6073%         0.9839
5                           153,126         0.5651%         0.9839

Total pixels: 27,095,040.0
Beta: 0.9999
Smoothing: 0.0
Weight range: [0.9839, 1.0807]
================================================================================
üìà Class weights computed with ENS method (smoothing=0.1)
   Final weights: [0.9838655  1.0806724  0.9838655  0.9838655  0.98386556 0.9838657 ]

‚úì Loss functions created: CE (weighted, label_smoothing=0.1), Focal (Œ≥=2.0), Dice
  üìä OneCycleLR: 135 steps/epoch √ó 300 epochs = 40500 total steps
üöÄ Hybrid2 Best Practice: Differential Learning Rates
  üìä Encoder LR:     0.000010 (10x smaller, 119 params)
  üìä Bottleneck LR:  0.000050 (5x smaller, 26 params)
  üìä Decoder LR:     0.000100 (base LR, 84 params)
  ‚öôÔ∏è  Scheduler: OneCycleLR (Peak: 10x, Warmup: 30%, Cosine)
  ‚öôÔ∏è  Weight decay: Encoder=1e-3, Bottleneck=5e-3, Decoder=1e-2

üîç Checking for checkpoint at: ./Result/a2/Latin14396/best_model_latest.pth
   Absolute path: /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid/Result/a2/Latin14396/best_model_latest.pth
   File exists: False

================================================================================
STARTING TRAINING
================================================================================
Early stopping patience: 150 epochs
Learning rate scheduler: OneCycleLR (better convergence for transformers)
================================================================================

EPOCH 1/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5796
  ‚Ä¢ Validation Loss: 0.4983
  ‚Ä¢ Learning Rate: 0.000100
    ‚úì New best checkpoint saved! Val loss: 0.4983
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 2/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4575
  ‚Ä¢ Validation Loss: 0.4442
  ‚Ä¢ Learning Rate: 0.000101
    ‚úì New best checkpoint saved! Val loss: 0.4442
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 3/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4208
  ‚Ä¢ Validation Loss: 0.4148
  ‚Ä¢ Learning Rate: 0.000102
    ‚úì New best checkpoint saved! Val loss: 0.4148
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 4/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3995
  ‚Ä¢ Validation Loss: 0.4019
  ‚Ä¢ Learning Rate: 0.000104
    ‚úì New best checkpoint saved! Val loss: 0.4019
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 5/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3847
  ‚Ä¢ Validation Loss: 0.4014
  ‚Ä¢ Learning Rate: 0.000107
    ‚úì New best checkpoint saved! Val loss: 0.4014
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 6/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3821
  ‚Ä¢ Validation Loss: 0.4060
  ‚Ä¢ Learning Rate: 0.000110
    No improvement (current: 0.4060, best: 0.4014)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 7/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3741
  ‚Ä¢ Validation Loss: 0.3785
  ‚Ä¢ Learning Rate: 0.000113
    ‚úì New best checkpoint saved! Val loss: 0.3785
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 8/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3626
  ‚Ä¢ Validation Loss: 0.3756
  ‚Ä¢ Learning Rate: 0.000117
    ‚úì New best checkpoint saved! Val loss: 0.3756
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 9/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3591
  ‚Ä¢ Validation Loss: 0.3887
  ‚Ä¢ Learning Rate: 0.000122
    No improvement (current: 0.3887, best: 0.3756)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 10/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3639
  ‚Ä¢ Validation Loss: 0.3718
  ‚Ä¢ Learning Rate: 0.000127
    ‚úì New best checkpoint saved! Val loss: 0.3718
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 11/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3599
  ‚Ä¢ Validation Loss: 0.3725
  ‚Ä¢ Learning Rate: 0.000133
    No improvement (current: 0.3725, best: 0.3718)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 12/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3549
  ‚Ä¢ Validation Loss: 0.3659
  ‚Ä¢ Learning Rate: 0.000139
    ‚úì New best checkpoint saved! Val loss: 0.3659
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 13/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3490
  ‚Ä¢ Validation Loss: 0.3659
  ‚Ä¢ Learning Rate: 0.000146
    No improvement (current: 0.3659, best: 0.3659)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 14/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3501
  ‚Ä¢ Validation Loss: 0.3668
  ‚Ä¢ Learning Rate: 0.000153
    No improvement (current: 0.3668, best: 0.3659)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 15/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3495
  ‚Ä¢ Validation Loss: 0.3758
  ‚Ä¢ Learning Rate: 0.000160
    No improvement (current: 0.3758, best: 0.3659)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 16/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3450
  ‚Ä¢ Validation Loss: 0.3739
  ‚Ä¢ Learning Rate: 0.000168
    No improvement (current: 0.3739, best: 0.3659)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 17/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3409
  ‚Ä¢ Validation Loss: 0.3614
  ‚Ä¢ Learning Rate: 0.000177
    ‚úì New best checkpoint saved! Val loss: 0.3614
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 18/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3456
  ‚Ä¢ Validation Loss: 0.3608
  ‚Ä¢ Learning Rate: 0.000186
    ‚úì New best checkpoint saved! Val loss: 0.3608
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 19/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3409
  ‚Ä¢ Validation Loss: 0.3641
  ‚Ä¢ Learning Rate: 0.000195
    No improvement (current: 0.3641, best: 0.3608)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 20/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3420
  ‚Ä¢ Validation Loss: 0.3687
  ‚Ä¢ Learning Rate: 0.000205
    No improvement (current: 0.3687, best: 0.3608)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 21/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3456
  ‚Ä¢ Validation Loss: 0.3602
  ‚Ä¢ Learning Rate: 0.000216
    ‚úì New best checkpoint saved! Val loss: 0.3602
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 22/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3406
  ‚Ä¢ Validation Loss: 0.3750
  ‚Ä¢ Learning Rate: 0.000226
    No improvement (current: 0.3750, best: 0.3602)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 23/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3405
  ‚Ä¢ Validation Loss: 0.3577
  ‚Ä¢ Learning Rate: 0.000237
    ‚úì New best checkpoint saved! Val loss: 0.3577
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 24/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3389
  ‚Ä¢ Validation Loss: 0.3590
  ‚Ä¢ Learning Rate: 0.000249
    No improvement (current: 0.3590, best: 0.3577)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 25/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3340
  ‚Ä¢ Validation Loss: 0.3666
  ‚Ä¢ Learning Rate: 0.000261
    No improvement (current: 0.3666, best: 0.3577)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 26/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3377
  ‚Ä¢ Validation Loss: 0.3594
  ‚Ä¢ Learning Rate: 0.000273
    No improvement (current: 0.3594, best: 0.3577)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 27/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3422
  ‚Ä¢ Validation Loss: 0.3782
  ‚Ä¢ Learning Rate: 0.000286
    No improvement (current: 0.3782, best: 0.3577)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 28/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3369
  ‚Ä¢ Validation Loss: 0.3569
  ‚Ä¢ Learning Rate: 0.000298
    ‚úì New best checkpoint saved! Val loss: 0.3569
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 29/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3380
  ‚Ä¢ Validation Loss: 0.3556
  ‚Ä¢ Learning Rate: 0.000312
    ‚úì New best checkpoint saved! Val loss: 0.3556
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 30/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3362
  ‚Ä¢ Validation Loss: 0.3579
  ‚Ä¢ Learning Rate: 0.000325
    No improvement (current: 0.3579, best: 0.3556)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 31/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3298
  ‚Ä¢ Validation Loss: 0.3550
  ‚Ä¢ Learning Rate: 0.000339
    ‚úì New best checkpoint saved! Val loss: 0.3550
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 32/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3380
  ‚Ä¢ Validation Loss: 0.3747
  ‚Ä¢ Learning Rate: 0.000353
    No improvement (current: 0.3747, best: 0.3550)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 33/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3396
  ‚Ä¢ Validation Loss: 0.3573
  ‚Ä¢ Learning Rate: 0.000367
    No improvement (current: 0.3573, best: 0.3550)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 34/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3363
  ‚Ä¢ Validation Loss: 0.3611
  ‚Ä¢ Learning Rate: 0.000381
    No improvement (current: 0.3611, best: 0.3550)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 35/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3382
  ‚Ä¢ Validation Loss: 0.3550
  ‚Ä¢ Learning Rate: 0.000396
    No improvement (current: 0.3550, best: 0.3550)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 36/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3307
  ‚Ä¢ Validation Loss: 0.3592
  ‚Ä¢ Learning Rate: 0.000411
    No improvement (current: 0.3592, best: 0.3550)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 37/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3374
  ‚Ä¢ Validation Loss: 0.3558
  ‚Ä¢ Learning Rate: 0.000426
    No improvement (current: 0.3558, best: 0.3550)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 38/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3311
  ‚Ä¢ Validation Loss: 0.3538
  ‚Ä¢ Learning Rate: 0.000441
    ‚úì New best checkpoint saved! Val loss: 0.3538
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 39/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3411
  ‚Ä¢ Validation Loss: 0.3614
  ‚Ä¢ Learning Rate: 0.000456
    No improvement (current: 0.3614, best: 0.3538)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 40/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3264
  ‚Ä¢ Validation Loss: 0.3492
  ‚Ä¢ Learning Rate: 0.000472
    ‚úì New best checkpoint saved! Val loss: 0.3492
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 41/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3323
  ‚Ä¢ Validation Loss: 0.3572
  ‚Ä¢ Learning Rate: 0.000487
    No improvement (current: 0.3572, best: 0.3492)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 42/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3345
  ‚Ä¢ Validation Loss: 0.3566
  ‚Ä¢ Learning Rate: 0.000503
    No improvement (current: 0.3566, best: 0.3492)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 43/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3335
  ‚Ä¢ Validation Loss: 0.3603
  ‚Ä¢ Learning Rate: 0.000519
    No improvement (current: 0.3603, best: 0.3492)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 44/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3291
  ‚Ä¢ Validation Loss: 0.3581
  ‚Ä¢ Learning Rate: 0.000534
    No improvement (current: 0.3581, best: 0.3492)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 45/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3274
  ‚Ä¢ Validation Loss: 0.3633
  ‚Ä¢ Learning Rate: 0.000550
    No improvement (current: 0.3633, best: 0.3492)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 46/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3276
  ‚Ä¢ Validation Loss: 0.3546
  ‚Ä¢ Learning Rate: 0.000566
    No improvement (current: 0.3546, best: 0.3492)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 47/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3317
  ‚Ä¢ Validation Loss: 0.3532
  ‚Ä¢ Learning Rate: 0.000581
    No improvement (current: 0.3532, best: 0.3492)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 48/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3337
  ‚Ä¢ Validation Loss: 0.3618
  ‚Ä¢ Learning Rate: 0.000597
    No improvement (current: 0.3618, best: 0.3492)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 49/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3293
  ‚Ä¢ Validation Loss: 0.3555
  ‚Ä¢ Learning Rate: 0.000613
    No improvement (current: 0.3555, best: 0.3492)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 50/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3255
  ‚Ä¢ Validation Loss: 0.3587
  ‚Ä¢ Learning Rate: 0.000628
    No improvement (current: 0.3587, best: 0.3492)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 51/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3397
  ‚Ä¢ Validation Loss: 0.3827
  ‚Ä¢ Learning Rate: 0.000644
    No improvement (current: 0.3827, best: 0.3492)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 52/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3247
  ‚Ä¢ Validation Loss: 0.3477
  ‚Ä¢ Learning Rate: 0.000659
    ‚úì New best checkpoint saved! Val loss: 0.3477
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 53/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3279
  ‚Ä¢ Validation Loss: 0.3532
  ‚Ä¢ Learning Rate: 0.000674
    No improvement (current: 0.3532, best: 0.3477)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 54/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3276
  ‚Ä¢ Validation Loss: 0.3534
  ‚Ä¢ Learning Rate: 0.000689
    No improvement (current: 0.3534, best: 0.3477)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 55/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3271
  ‚Ä¢ Validation Loss: 0.3581
  ‚Ä¢ Learning Rate: 0.000704
    No improvement (current: 0.3581, best: 0.3477)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 56/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3239
  ‚Ä¢ Validation Loss: 0.3507
  ‚Ä¢ Learning Rate: 0.000719
    No improvement (current: 0.3507, best: 0.3477)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 57/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3253
  ‚Ä¢ Validation Loss: 0.3469
  ‚Ä¢ Learning Rate: 0.000733
    ‚úì New best checkpoint saved! Val loss: 0.3469
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 58/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3286
  ‚Ä¢ Validation Loss: 0.3585
  ‚Ä¢ Learning Rate: 0.000747
    No improvement (current: 0.3585, best: 0.3469)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 59/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3305
  ‚Ä¢ Validation Loss: 0.3569
  ‚Ä¢ Learning Rate: 0.000761
    No improvement (current: 0.3569, best: 0.3469)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 60/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3261
  ‚Ä¢ Validation Loss: 0.3560
  ‚Ä¢ Learning Rate: 0.000775
    No improvement (current: 0.3560, best: 0.3469)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 61/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3247
  ‚Ä¢ Validation Loss: 0.3538
  ‚Ä¢ Learning Rate: 0.000789
    No improvement (current: 0.3538, best: 0.3469)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 62/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3281
  ‚Ä¢ Validation Loss: 0.3475
  ‚Ä¢ Learning Rate: 0.000802
    No improvement (current: 0.3475, best: 0.3469)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 63/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3244
  ‚Ä¢ Validation Loss: 0.3465
  ‚Ä¢ Learning Rate: 0.000815
    ‚úì New best checkpoint saved! Val loss: 0.3465
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 64/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3287
  ‚Ä¢ Validation Loss: 0.3472
  ‚Ä¢ Learning Rate: 0.000827
    No improvement (current: 0.3472, best: 0.3465)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 65/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3311
  ‚Ä¢ Validation Loss: 0.3517
  ‚Ä¢ Learning Rate: 0.000839
    No improvement (current: 0.3517, best: 0.3465)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 66/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3270
  ‚Ä¢ Validation Loss: 0.3457
  ‚Ä¢ Learning Rate: 0.000851
    ‚úì New best checkpoint saved! Val loss: 0.3457
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 67/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3197
  ‚Ä¢ Validation Loss: 0.3448
  ‚Ä¢ Learning Rate: 0.000863
    ‚úì New best checkpoint saved! Val loss: 0.3448
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 68/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3176
  ‚Ä¢ Validation Loss: 0.3452
  ‚Ä¢ Learning Rate: 0.000874
    No improvement (current: 0.3452, best: 0.3448)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 69/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3159
  ‚Ä¢ Validation Loss: 0.3442
  ‚Ä¢ Learning Rate: 0.000884
    ‚úì New best checkpoint saved! Val loss: 0.3442
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 70/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3151
  ‚Ä¢ Validation Loss: 0.3439
  ‚Ä¢ Learning Rate: 0.000895
    ‚úì New best checkpoint saved! Val loss: 0.3439
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 71/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3143
  ‚Ä¢ Validation Loss: 0.3439
  ‚Ä¢ Learning Rate: 0.000905
    ‚úì New best checkpoint saved! Val loss: 0.3439
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 72/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3156
  ‚Ä¢ Validation Loss: 0.3438
  ‚Ä¢ Learning Rate: 0.000914
    ‚úì New best checkpoint saved! Val loss: 0.3438
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 73/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3135
  ‚Ä¢ Validation Loss: 0.3434
  ‚Ä¢ Learning Rate: 0.000923
    ‚úì New best checkpoint saved! Val loss: 0.3434
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 74/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3228
  ‚Ä¢ Validation Loss: 0.3825
  ‚Ä¢ Learning Rate: 0.000932
    No improvement (current: 0.3825, best: 0.3434)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 75/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3458
  ‚Ä¢ Validation Loss: 0.3632
  ‚Ä¢ Learning Rate: 0.000940
    No improvement (current: 0.3632, best: 0.3434)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 76/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3336
  ‚Ä¢ Validation Loss: 0.3528
  ‚Ä¢ Learning Rate: 0.000947
    No improvement (current: 0.3528, best: 0.3434)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 77/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3236
  ‚Ä¢ Validation Loss: 0.3503
  ‚Ä¢ Learning Rate: 0.000955
    No improvement (current: 0.3503, best: 0.3434)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 78/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3199
  ‚Ä¢ Validation Loss: 0.3489
  ‚Ä¢ Learning Rate: 0.000961
    No improvement (current: 0.3489, best: 0.3434)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 79/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3176
  ‚Ä¢ Validation Loss: 0.3472
  ‚Ä¢ Learning Rate: 0.000967
    No improvement (current: 0.3472, best: 0.3434)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 80/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3185
  ‚Ä¢ Validation Loss: 0.3455
  ‚Ä¢ Learning Rate: 0.000973
    No improvement (current: 0.3455, best: 0.3434)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 81/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4121
  ‚Ä¢ Validation Loss: 0.3846
  ‚Ä¢ Learning Rate: 0.000978
    No improvement (current: 0.3846, best: 0.3434)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 82/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3423
  ‚Ä¢ Validation Loss: 0.3569
  ‚Ä¢ Learning Rate: 0.000983
    No improvement (current: 0.3569, best: 0.3434)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 83/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3337
  ‚Ä¢ Validation Loss: 0.3522
  ‚Ä¢ Learning Rate: 0.000987
    No improvement (current: 0.3522, best: 0.3434)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 84/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3294
  ‚Ä¢ Validation Loss: 0.3478
  ‚Ä¢ Learning Rate: 0.000990
    No improvement (current: 0.3478, best: 0.3434)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 85/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3257
  ‚Ä¢ Validation Loss: 0.8232
  ‚Ä¢ Learning Rate: 0.000993
    No improvement (current: 0.8232, best: 0.3434)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 86/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3946
  ‚Ä¢ Validation Loss: 0.3798
  ‚Ä¢ Learning Rate: 0.000996
    No improvement (current: 0.3798, best: 0.3434)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 87/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3915
  ‚Ä¢ Validation Loss: 0.4212
  ‚Ä¢ Learning Rate: 0.000998
    No improvement (current: 0.4212, best: 0.3434)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 88/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3829
  ‚Ä¢ Validation Loss: 0.3712
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.3712, best: 0.3434)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 89/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3472
  ‚Ä¢ Validation Loss: 0.3582
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.3582, best: 0.3434)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 90/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3344
  ‚Ä¢ Validation Loss: 0.3622
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.3622, best: 0.3434)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 91/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3422
  ‚Ä¢ Validation Loss: 0.3585
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.3585, best: 0.3434)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 92/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3308
  ‚Ä¢ Validation Loss: 0.3498
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.3498, best: 0.3434)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 93/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3280
  ‚Ä¢ Validation Loss: 0.3492
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.3492, best: 0.3434)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 94/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3293
  ‚Ä¢ Validation Loss: 0.3493
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.3493, best: 0.3434)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 95/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3293
  ‚Ä¢ Validation Loss: 0.3490
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.3490, best: 0.3434)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 96/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3245
  ‚Ä¢ Validation Loss: 0.3488
  ‚Ä¢ Learning Rate: 0.000998
    No improvement (current: 0.3488, best: 0.3434)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 97/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3280
  ‚Ä¢ Validation Loss: 0.3487
  ‚Ä¢ Learning Rate: 0.000997
    No improvement (current: 0.3487, best: 0.3434)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 98/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3260
  ‚Ä¢ Validation Loss: 0.3561
  ‚Ä¢ Learning Rate: 0.000996
    No improvement (current: 0.3561, best: 0.3434)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 99/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3355
  ‚Ä¢ Validation Loss: 0.3557
  ‚Ä¢ Learning Rate: 0.000995
    No improvement (current: 0.3557, best: 0.3434)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 100/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3326
  ‚Ä¢ Validation Loss: 0.3505
  ‚Ä¢ Learning Rate: 0.000994
   üíæ Periodic checkpoint saved: epoch_100.pth
    No improvement (current: 0.3505, best: 0.3434)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 101/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3284
  ‚Ä¢ Validation Loss: 0.3493
  ‚Ä¢ Learning Rate: 0.000993
    No improvement (current: 0.3493, best: 0.3434)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 102/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3210
  ‚Ä¢ Validation Loss: 0.3489
  ‚Ä¢ Learning Rate: 0.000992
    No improvement (current: 0.3489, best: 0.3434)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 103/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3232
  ‚Ä¢ Validation Loss: 0.3485
  ‚Ä¢ Learning Rate: 0.000991
    No improvement (current: 0.3485, best: 0.3434)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 104/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3202
  ‚Ä¢ Validation Loss: 0.3483
  ‚Ä¢ Learning Rate: 0.000989
    No improvement (current: 0.3483, best: 0.3434)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 105/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3218
  ‚Ä¢ Validation Loss: 0.3484
  ‚Ä¢ Learning Rate: 0.000987
    No improvement (current: 0.3484, best: 0.3434)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 106/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3246
  ‚Ä¢ Validation Loss: 0.3480
  ‚Ä¢ Learning Rate: 0.000986
    No improvement (current: 0.3480, best: 0.3434)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 107/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3215
  ‚Ä¢ Validation Loss: 0.3478
  ‚Ä¢ Learning Rate: 0.000984
    No improvement (current: 0.3478, best: 0.3434)
    ‚ö† No improvement for 34 epochs (patience: 150, remaining: 116)

EPOCH 108/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3235
  ‚Ä¢ Validation Loss: 0.3473
  ‚Ä¢ Learning Rate: 0.000982
    No improvement (current: 0.3473, best: 0.3434)
    ‚ö† No improvement for 35 epochs (patience: 150, remaining: 115)

EPOCH 109/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3237
  ‚Ä¢ Validation Loss: 0.3528
  ‚Ä¢ Learning Rate: 0.000980
    No improvement (current: 0.3528, best: 0.3434)
    ‚ö† No improvement for 36 epochs (patience: 150, remaining: 114)

EPOCH 110/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3239
  ‚Ä¢ Validation Loss: 0.3487
  ‚Ä¢ Learning Rate: 0.000978
    No improvement (current: 0.3487, best: 0.3434)
    ‚ö† No improvement for 37 epochs (patience: 150, remaining: 113)

EPOCH 111/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3226
  ‚Ä¢ Validation Loss: 0.3477
  ‚Ä¢ Learning Rate: 0.000976
    No improvement (current: 0.3477, best: 0.3434)
    ‚ö† No improvement for 38 epochs (patience: 150, remaining: 112)

EPOCH 112/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3175
  ‚Ä¢ Validation Loss: 0.3482
  ‚Ä¢ Learning Rate: 0.000973
    No improvement (current: 0.3482, best: 0.3434)
    ‚ö† No improvement for 39 epochs (patience: 150, remaining: 111)

EPOCH 113/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3204
  ‚Ä¢ Validation Loss: 0.3466
  ‚Ä¢ Learning Rate: 0.000971
    No improvement (current: 0.3466, best: 0.3434)
    ‚ö† No improvement for 40 epochs (patience: 150, remaining: 110)

EPOCH 114/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3224
  ‚Ä¢ Validation Loss: 0.3463
  ‚Ä¢ Learning Rate: 0.000968
    No improvement (current: 0.3463, best: 0.3434)
    ‚ö† No improvement for 41 epochs (patience: 150, remaining: 109)

EPOCH 115/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3167
  ‚Ä¢ Validation Loss: 0.3464
  ‚Ä¢ Learning Rate: 0.000965
    No improvement (current: 0.3464, best: 0.3434)
    ‚ö† No improvement for 42 epochs (patience: 150, remaining: 108)

EPOCH 116/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3245
  ‚Ä¢ Validation Loss: 0.3461
  ‚Ä¢ Learning Rate: 0.000963
    No improvement (current: 0.3461, best: 0.3434)
    ‚ö† No improvement for 43 epochs (patience: 150, remaining: 107)

EPOCH 117/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3178
  ‚Ä¢ Validation Loss: 0.3458
  ‚Ä¢ Learning Rate: 0.000960
    No improvement (current: 0.3458, best: 0.3434)
    ‚ö† No improvement for 44 epochs (patience: 150, remaining: 106)

EPOCH 118/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3185
  ‚Ä¢ Validation Loss: 0.3457
  ‚Ä¢ Learning Rate: 0.000957
    No improvement (current: 0.3457, best: 0.3434)
    ‚ö† No improvement for 45 epochs (patience: 150, remaining: 105)

EPOCH 119/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3194
  ‚Ä¢ Validation Loss: 0.3454
  ‚Ä¢ Learning Rate: 0.000954
    No improvement (current: 0.3454, best: 0.3434)
    ‚ö† No improvement for 46 epochs (patience: 150, remaining: 104)

EPOCH 120/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3164
  ‚Ä¢ Validation Loss: 0.3458
  ‚Ä¢ Learning Rate: 0.000951
    No improvement (current: 0.3458, best: 0.3434)
    ‚ö† No improvement for 47 epochs (patience: 150, remaining: 103)

EPOCH 121/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3174
  ‚Ä¢ Validation Loss: 0.3458
  ‚Ä¢ Learning Rate: 0.000947
    No improvement (current: 0.3458, best: 0.3434)
    ‚ö† No improvement for 48 epochs (patience: 150, remaining: 102)

EPOCH 122/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3174
  ‚Ä¢ Validation Loss: 0.3462
  ‚Ä¢ Learning Rate: 0.000944
    No improvement (current: 0.3462, best: 0.3434)
    ‚ö† No improvement for 49 epochs (patience: 150, remaining: 101)

EPOCH 123/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3192
  ‚Ä¢ Validation Loss: 0.3474
  ‚Ä¢ Learning Rate: 0.000940
    No improvement (current: 0.3474, best: 0.3434)
    ‚ö† No improvement for 50 epochs (patience: 150, remaining: 100)

EPOCH 124/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3187
  ‚Ä¢ Validation Loss: 0.3455
  ‚Ä¢ Learning Rate: 0.000937
    No improvement (current: 0.3455, best: 0.3434)
    ‚ö† No improvement for 51 epochs (patience: 150, remaining: 99)

EPOCH 125/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3475
  ‚Ä¢ Validation Loss: 0.4742
  ‚Ä¢ Learning Rate: 0.000933
    No improvement (current: 0.4742, best: 0.3434)
    ‚ö† No improvement for 52 epochs (patience: 150, remaining: 98)

EPOCH 126/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3911
  ‚Ä¢ Validation Loss: 0.3842
  ‚Ä¢ Learning Rate: 0.000929
    No improvement (current: 0.3842, best: 0.3434)
    ‚ö† No improvement for 53 epochs (patience: 150, remaining: 97)

EPOCH 127/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3495
  ‚Ä¢ Validation Loss: 0.3676
  ‚Ä¢ Learning Rate: 0.000925
    No improvement (current: 0.3676, best: 0.3434)
    ‚ö† No improvement for 54 epochs (patience: 150, remaining: 96)

EPOCH 128/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3337
  ‚Ä¢ Validation Loss: 0.3635
  ‚Ä¢ Learning Rate: 0.000921
    No improvement (current: 0.3635, best: 0.3434)
    ‚ö† No improvement for 55 epochs (patience: 150, remaining: 95)

EPOCH 129/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3590
  ‚Ä¢ Validation Loss: 0.3810
  ‚Ä¢ Learning Rate: 0.000917
    No improvement (current: 0.3810, best: 0.3434)
    ‚ö† No improvement for 56 epochs (patience: 150, remaining: 94)

EPOCH 130/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3419
  ‚Ä¢ Validation Loss: 0.3600
  ‚Ä¢ Learning Rate: 0.000913
    No improvement (current: 0.3600, best: 0.3434)
    ‚ö† No improvement for 57 epochs (patience: 150, remaining: 93)

EPOCH 131/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3324
  ‚Ä¢ Validation Loss: 0.3568
  ‚Ä¢ Learning Rate: 0.000909
    No improvement (current: 0.3568, best: 0.3434)
    ‚ö† No improvement for 58 epochs (patience: 150, remaining: 92)

EPOCH 132/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3313
  ‚Ä¢ Validation Loss: 0.3547
  ‚Ä¢ Learning Rate: 0.000905
    No improvement (current: 0.3547, best: 0.3434)
    ‚ö† No improvement for 59 epochs (patience: 150, remaining: 91)

EPOCH 133/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3256
  ‚Ä¢ Validation Loss: 0.3512
  ‚Ä¢ Learning Rate: 0.000900
    No improvement (current: 0.3512, best: 0.3434)
    ‚ö† No improvement for 60 epochs (patience: 150, remaining: 90)

EPOCH 134/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3465
  ‚Ä¢ Validation Loss: 0.3627
  ‚Ä¢ Learning Rate: 0.000896
    No improvement (current: 0.3627, best: 0.3434)
    ‚ö† No improvement for 61 epochs (patience: 150, remaining: 89)

EPOCH 135/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3330
  ‚Ä¢ Validation Loss: 0.3535
  ‚Ä¢ Learning Rate: 0.000891
    No improvement (current: 0.3535, best: 0.3434)
    ‚ö† No improvement for 62 epochs (patience: 150, remaining: 88)

EPOCH 136/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3251
  ‚Ä¢ Validation Loss: 0.3497
  ‚Ä¢ Learning Rate: 0.000886
    No improvement (current: 0.3497, best: 0.3434)
    ‚ö† No improvement for 63 epochs (patience: 150, remaining: 87)

EPOCH 137/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4319
  ‚Ä¢ Validation Loss: 0.4704
  ‚Ä¢ Learning Rate: 0.000881
    No improvement (current: 0.4704, best: 0.3434)
    ‚ö† No improvement for 64 epochs (patience: 150, remaining: 86)

EPOCH 138/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4062
  ‚Ä¢ Validation Loss: 0.3892
  ‚Ä¢ Learning Rate: 0.000877
    No improvement (current: 0.3892, best: 0.3434)
    ‚ö† No improvement for 65 epochs (patience: 150, remaining: 85)

EPOCH 139/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3636
  ‚Ä¢ Validation Loss: 0.3761
  ‚Ä¢ Learning Rate: 0.000872
    No improvement (current: 0.3761, best: 0.3434)
    ‚ö† No improvement for 66 epochs (patience: 150, remaining: 84)

EPOCH 140/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3509
  ‚Ä¢ Validation Loss: 0.3630
  ‚Ä¢ Learning Rate: 0.000867
    No improvement (current: 0.3630, best: 0.3434)
    ‚ö† No improvement for 67 epochs (patience: 150, remaining: 83)

EPOCH 141/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3385
  ‚Ä¢ Validation Loss: 0.3571
  ‚Ä¢ Learning Rate: 0.000861
    No improvement (current: 0.3571, best: 0.3434)
    ‚ö† No improvement for 68 epochs (patience: 150, remaining: 82)

EPOCH 142/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3428
  ‚Ä¢ Validation Loss: 0.3586
  ‚Ä¢ Learning Rate: 0.000856
    No improvement (current: 0.3586, best: 0.3434)
    ‚ö† No improvement for 69 epochs (patience: 150, remaining: 81)

EPOCH 143/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3358
  ‚Ä¢ Validation Loss: 0.3502
  ‚Ä¢ Learning Rate: 0.000851
    No improvement (current: 0.3502, best: 0.3434)
    ‚ö† No improvement for 70 epochs (patience: 150, remaining: 80)

EPOCH 144/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3291
  ‚Ä¢ Validation Loss: 0.3599
  ‚Ä¢ Learning Rate: 0.000846
    No improvement (current: 0.3599, best: 0.3434)
    ‚ö† No improvement for 71 epochs (patience: 150, remaining: 79)

EPOCH 145/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3350
  ‚Ä¢ Validation Loss: 0.3585
  ‚Ä¢ Learning Rate: 0.000840
    No improvement (current: 0.3585, best: 0.3434)
    ‚ö† No improvement for 72 epochs (patience: 150, remaining: 78)

EPOCH 146/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3249
  ‚Ä¢ Validation Loss: 0.3507
  ‚Ä¢ Learning Rate: 0.000835
    No improvement (current: 0.3507, best: 0.3434)
    ‚ö† No improvement for 73 epochs (patience: 150, remaining: 77)

EPOCH 147/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3206
  ‚Ä¢ Validation Loss: 0.3462
  ‚Ä¢ Learning Rate: 0.000829
    No improvement (current: 0.3462, best: 0.3434)
    ‚ö† No improvement for 74 epochs (patience: 150, remaining: 76)

EPOCH 148/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3244
  ‚Ä¢ Validation Loss: 0.3476
  ‚Ä¢ Learning Rate: 0.000823
    No improvement (current: 0.3476, best: 0.3434)
    ‚ö† No improvement for 75 epochs (patience: 150, remaining: 75)

EPOCH 149/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3330
  ‚Ä¢ Validation Loss: 0.3532
  ‚Ä¢ Learning Rate: 0.000818
    No improvement (current: 0.3532, best: 0.3434)
    ‚ö† No improvement for 76 epochs (patience: 150, remaining: 74)

EPOCH 150/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3186
  ‚Ä¢ Validation Loss: 0.3451
  ‚Ä¢ Learning Rate: 0.000812
    No improvement (current: 0.3451, best: 0.3434)
    ‚ö† No improvement for 77 epochs (patience: 150, remaining: 73)

EPOCH 151/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3268
  ‚Ä¢ Validation Loss: 0.3780
  ‚Ä¢ Learning Rate: 0.000806
    No improvement (current: 0.3780, best: 0.3434)
    ‚ö† No improvement for 78 epochs (patience: 150, remaining: 72)

EPOCH 152/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3243
  ‚Ä¢ Validation Loss: 0.3469
  ‚Ä¢ Learning Rate: 0.000800
    No improvement (current: 0.3469, best: 0.3434)
    ‚ö† No improvement for 79 epochs (patience: 150, remaining: 71)

EPOCH 153/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3167
  ‚Ä¢ Validation Loss: 0.3455
  ‚Ä¢ Learning Rate: 0.000794
    No improvement (current: 0.3455, best: 0.3434)
    ‚ö† No improvement for 80 epochs (patience: 150, remaining: 70)

EPOCH 154/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3227
  ‚Ä¢ Validation Loss: 0.3487
  ‚Ä¢ Learning Rate: 0.000788
    No improvement (current: 0.3487, best: 0.3434)
    ‚ö† No improvement for 81 epochs (patience: 150, remaining: 69)

EPOCH 155/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3308
  ‚Ä¢ Validation Loss: 0.3640
  ‚Ä¢ Learning Rate: 0.000782
    No improvement (current: 0.3640, best: 0.3434)
    ‚ö† No improvement for 82 epochs (patience: 150, remaining: 68)

EPOCH 156/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3383
  ‚Ä¢ Validation Loss: 0.3551
  ‚Ä¢ Learning Rate: 0.000776
    No improvement (current: 0.3551, best: 0.3434)
    ‚ö† No improvement for 83 epochs (patience: 150, remaining: 67)

EPOCH 157/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3415
  ‚Ä¢ Validation Loss: 0.3495
  ‚Ä¢ Learning Rate: 0.000769
    No improvement (current: 0.3495, best: 0.3434)
    ‚ö† No improvement for 84 epochs (patience: 150, remaining: 66)

EPOCH 158/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3280
  ‚Ä¢ Validation Loss: 0.3567
  ‚Ä¢ Learning Rate: 0.000763
    No improvement (current: 0.3567, best: 0.3434)
    ‚ö† No improvement for 85 epochs (patience: 150, remaining: 65)

EPOCH 159/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3263
  ‚Ä¢ Validation Loss: 0.3519
  ‚Ä¢ Learning Rate: 0.000757
    No improvement (current: 0.3519, best: 0.3434)
    ‚ö† No improvement for 86 epochs (patience: 150, remaining: 64)

EPOCH 160/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3218
  ‚Ä¢ Validation Loss: 0.3448
  ‚Ä¢ Learning Rate: 0.000750
    No improvement (current: 0.3448, best: 0.3434)
    ‚ö† No improvement for 87 epochs (patience: 150, remaining: 63)

EPOCH 161/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3204
  ‚Ä¢ Validation Loss: 0.3492
  ‚Ä¢ Learning Rate: 0.000744
    No improvement (current: 0.3492, best: 0.3434)
    ‚ö† No improvement for 88 epochs (patience: 150, remaining: 62)

EPOCH 162/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3182
  ‚Ä¢ Validation Loss: 0.3508
  ‚Ä¢ Learning Rate: 0.000737
    No improvement (current: 0.3508, best: 0.3434)
    ‚ö† No improvement for 89 epochs (patience: 150, remaining: 61)

EPOCH 163/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3206
  ‚Ä¢ Validation Loss: 0.3520
  ‚Ä¢ Learning Rate: 0.000731
    No improvement (current: 0.3520, best: 0.3434)
    ‚ö† No improvement for 90 epochs (patience: 150, remaining: 60)

EPOCH 164/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3186
  ‚Ä¢ Validation Loss: 0.3524
  ‚Ä¢ Learning Rate: 0.000724
    No improvement (current: 0.3524, best: 0.3434)
    ‚ö† No improvement for 91 epochs (patience: 150, remaining: 59)

EPOCH 165/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3300
  ‚Ä¢ Validation Loss: 0.5186
  ‚Ä¢ Learning Rate: 0.000717
    No improvement (current: 0.5186, best: 0.3434)
    ‚ö† No improvement for 92 epochs (patience: 150, remaining: 58)

EPOCH 166/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4299
  ‚Ä¢ Validation Loss: 0.3771
  ‚Ä¢ Learning Rate: 0.000710
    No improvement (current: 0.3771, best: 0.3434)
    ‚ö† No improvement for 93 epochs (patience: 150, remaining: 57)

EPOCH 167/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3523
  ‚Ä¢ Validation Loss: 0.3645
  ‚Ä¢ Learning Rate: 0.000704
    No improvement (current: 0.3645, best: 0.3434)
    ‚ö† No improvement for 94 epochs (patience: 150, remaining: 56)

EPOCH 168/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3637
  ‚Ä¢ Validation Loss: 0.3650
  ‚Ä¢ Learning Rate: 0.000697
    No improvement (current: 0.3650, best: 0.3434)
    ‚ö† No improvement for 95 epochs (patience: 150, remaining: 55)

EPOCH 169/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3444
  ‚Ä¢ Validation Loss: 0.3661
  ‚Ä¢ Learning Rate: 0.000690
    No improvement (current: 0.3661, best: 0.3434)
    ‚ö† No improvement for 96 epochs (patience: 150, remaining: 54)

EPOCH 170/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3470
  ‚Ä¢ Validation Loss: 0.3638
  ‚Ä¢ Learning Rate: 0.000683
    No improvement (current: 0.3638, best: 0.3434)
    ‚ö† No improvement for 97 epochs (patience: 150, remaining: 53)

EPOCH 171/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3368
  ‚Ä¢ Validation Loss: 0.3532
  ‚Ä¢ Learning Rate: 0.000676
    No improvement (current: 0.3532, best: 0.3434)
    ‚ö† No improvement for 98 epochs (patience: 150, remaining: 52)

EPOCH 172/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3327
  ‚Ä¢ Validation Loss: 0.3515
  ‚Ä¢ Learning Rate: 0.000669
    No improvement (current: 0.3515, best: 0.3434)
    ‚ö† No improvement for 99 epochs (patience: 150, remaining: 51)

EPOCH 173/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3241
  ‚Ä¢ Validation Loss: 0.3462
  ‚Ä¢ Learning Rate: 0.000662
    No improvement (current: 0.3462, best: 0.3434)
    ‚ö† No improvement for 100 epochs (patience: 150, remaining: 50)

EPOCH 174/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3401
  ‚Ä¢ Validation Loss: 0.3519
  ‚Ä¢ Learning Rate: 0.000655
    No improvement (current: 0.3519, best: 0.3434)
    ‚ö† No improvement for 101 epochs (patience: 150, remaining: 49)

EPOCH 175/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3291
  ‚Ä¢ Validation Loss: 0.3492
  ‚Ä¢ Learning Rate: 0.000648
    No improvement (current: 0.3492, best: 0.3434)
    ‚ö† No improvement for 102 epochs (patience: 150, remaining: 48)

EPOCH 176/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3309
  ‚Ä¢ Validation Loss: 0.4178
  ‚Ä¢ Learning Rate: 0.000641
    No improvement (current: 0.4178, best: 0.3434)
    ‚ö† No improvement for 103 epochs (patience: 150, remaining: 47)

EPOCH 177/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3383
  ‚Ä¢ Validation Loss: 0.3489
  ‚Ä¢ Learning Rate: 0.000633
    No improvement (current: 0.3489, best: 0.3434)
    ‚ö† No improvement for 104 epochs (patience: 150, remaining: 46)

EPOCH 178/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3324
  ‚Ä¢ Validation Loss: 0.3602
  ‚Ä¢ Learning Rate: 0.000626
    No improvement (current: 0.3602, best: 0.3434)
    ‚ö† No improvement for 105 epochs (patience: 150, remaining: 45)

EPOCH 179/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3321
  ‚Ä¢ Validation Loss: 0.3517
  ‚Ä¢ Learning Rate: 0.000619
    No improvement (current: 0.3517, best: 0.3434)
    ‚ö† No improvement for 106 epochs (patience: 150, remaining: 44)

EPOCH 180/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3302
  ‚Ä¢ Validation Loss: 0.4085
  ‚Ä¢ Learning Rate: 0.000612
    No improvement (current: 0.4085, best: 0.3434)
    ‚ö† No improvement for 107 epochs (patience: 150, remaining: 43)

EPOCH 181/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3565
  ‚Ä¢ Validation Loss: 0.3509
  ‚Ä¢ Learning Rate: 0.000604
    No improvement (current: 0.3509, best: 0.3434)
    ‚ö† No improvement for 108 epochs (patience: 150, remaining: 42)

EPOCH 182/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3236
  ‚Ä¢ Validation Loss: 0.3553
  ‚Ä¢ Learning Rate: 0.000597
    No improvement (current: 0.3553, best: 0.3434)
    ‚ö† No improvement for 109 epochs (patience: 150, remaining: 41)

EPOCH 183/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3226
  ‚Ä¢ Validation Loss: 0.3513
  ‚Ä¢ Learning Rate: 0.000590
    No improvement (current: 0.3513, best: 0.3434)
    ‚ö† No improvement for 110 epochs (patience: 150, remaining: 40)

EPOCH 184/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3353
  ‚Ä¢ Validation Loss: 0.3668
  ‚Ä¢ Learning Rate: 0.000582
    No improvement (current: 0.3668, best: 0.3434)
    ‚ö† No improvement for 111 epochs (patience: 150, remaining: 39)

EPOCH 185/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3373
  ‚Ä¢ Validation Loss: 0.3526
  ‚Ä¢ Learning Rate: 0.000575
    No improvement (current: 0.3526, best: 0.3434)
    ‚ö† No improvement for 112 epochs (patience: 150, remaining: 38)

EPOCH 186/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3306
  ‚Ä¢ Validation Loss: 0.3477
  ‚Ä¢ Learning Rate: 0.000567
    No improvement (current: 0.3477, best: 0.3434)
    ‚ö† No improvement for 113 epochs (patience: 150, remaining: 37)

EPOCH 187/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3227
  ‚Ä¢ Validation Loss: 0.3515
  ‚Ä¢ Learning Rate: 0.000560
    No improvement (current: 0.3515, best: 0.3434)
    ‚ö† No improvement for 114 epochs (patience: 150, remaining: 36)

EPOCH 188/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3271
  ‚Ä¢ Validation Loss: 0.3548
  ‚Ä¢ Learning Rate: 0.000553
    No improvement (current: 0.3548, best: 0.3434)
    ‚ö† No improvement for 115 epochs (patience: 150, remaining: 35)

EPOCH 189/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3203
  ‚Ä¢ Validation Loss: 0.3449
  ‚Ä¢ Learning Rate: 0.000545
    No improvement (current: 0.3449, best: 0.3434)
    ‚ö† No improvement for 116 epochs (patience: 150, remaining: 34)

EPOCH 190/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3183
  ‚Ä¢ Validation Loss: 0.3458
  ‚Ä¢ Learning Rate: 0.000538
    No improvement (current: 0.3458, best: 0.3434)
    ‚ö† No improvement for 117 epochs (patience: 150, remaining: 33)

EPOCH 191/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3247
  ‚Ä¢ Validation Loss: 0.3512
  ‚Ä¢ Learning Rate: 0.000530
    No improvement (current: 0.3512, best: 0.3434)
    ‚ö† No improvement for 118 epochs (patience: 150, remaining: 32)

EPOCH 192/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3236
  ‚Ä¢ Validation Loss: 0.3486
  ‚Ä¢ Learning Rate: 0.000523
    No improvement (current: 0.3486, best: 0.3434)
    ‚ö† No improvement for 119 epochs (patience: 150, remaining: 31)

EPOCH 193/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3222
  ‚Ä¢ Validation Loss: 0.3471
  ‚Ä¢ Learning Rate: 0.000515
    No improvement (current: 0.3471, best: 0.3434)
    ‚ö† No improvement for 120 epochs (patience: 150, remaining: 30)

EPOCH 194/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3179
  ‚Ä¢ Validation Loss: 0.3446
  ‚Ä¢ Learning Rate: 0.000508
    No improvement (current: 0.3446, best: 0.3434)
    ‚ö† No improvement for 121 epochs (patience: 150, remaining: 29)

EPOCH 195/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3401
  ‚Ä¢ Validation Loss: 0.3578
  ‚Ä¢ Learning Rate: 0.000500
    No improvement (current: 0.3578, best: 0.3434)
    ‚ö† No improvement for 122 epochs (patience: 150, remaining: 28)

EPOCH 196/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3313
  ‚Ä¢ Validation Loss: 0.3526
  ‚Ä¢ Learning Rate: 0.000493
    No improvement (current: 0.3526, best: 0.3434)
    ‚ö† No improvement for 123 epochs (patience: 150, remaining: 27)

EPOCH 197/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3430
  ‚Ä¢ Validation Loss: 0.3601
  ‚Ä¢ Learning Rate: 0.000486
    No improvement (current: 0.3601, best: 0.3434)
    ‚ö† No improvement for 124 epochs (patience: 150, remaining: 26)

EPOCH 198/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3257
  ‚Ä¢ Validation Loss: 0.3478
  ‚Ä¢ Learning Rate: 0.000478
    No improvement (current: 0.3478, best: 0.3434)
    ‚ö† No improvement for 125 epochs (patience: 150, remaining: 25)

EPOCH 199/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3202
  ‚Ä¢ Validation Loss: 0.3551
  ‚Ä¢ Learning Rate: 0.000471
    No improvement (current: 0.3551, best: 0.3434)
    ‚ö† No improvement for 126 epochs (patience: 150, remaining: 24)

EPOCH 200/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3252
  ‚Ä¢ Validation Loss: 0.3477
  ‚Ä¢ Learning Rate: 0.000463
   üíæ Periodic checkpoint saved: epoch_200.pth
    No improvement (current: 0.3477, best: 0.3434)
    ‚ö† No improvement for 127 epochs (patience: 150, remaining: 23)

EPOCH 201/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3180
  ‚Ä¢ Validation Loss: 0.3500
  ‚Ä¢ Learning Rate: 0.000456
    No improvement (current: 0.3500, best: 0.3434)
    ‚ö† No improvement for 128 epochs (patience: 150, remaining: 22)

EPOCH 202/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3210
  ‚Ä¢ Validation Loss: 0.3462
  ‚Ä¢ Learning Rate: 0.000448
    No improvement (current: 0.3462, best: 0.3434)
    ‚ö† No improvement for 129 epochs (patience: 150, remaining: 21)

EPOCH 203/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3206
  ‚Ä¢ Validation Loss: 0.3448
  ‚Ä¢ Learning Rate: 0.000441
    No improvement (current: 0.3448, best: 0.3434)
    ‚ö† No improvement for 130 epochs (patience: 150, remaining: 20)

EPOCH 204/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3163
  ‚Ä¢ Validation Loss: 0.3478
  ‚Ä¢ Learning Rate: 0.000433
    No improvement (current: 0.3478, best: 0.3434)
    ‚ö† No improvement for 131 epochs (patience: 150, remaining: 19)

EPOCH 205/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3307
  ‚Ä¢ Validation Loss: 0.3462
  ‚Ä¢ Learning Rate: 0.000426
    No improvement (current: 0.3462, best: 0.3434)
    ‚ö† No improvement for 132 epochs (patience: 150, remaining: 18)

EPOCH 206/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3186
  ‚Ä¢ Validation Loss: 0.3526
  ‚Ä¢ Learning Rate: 0.000419
    No improvement (current: 0.3526, best: 0.3434)
    ‚ö† No improvement for 133 epochs (patience: 150, remaining: 17)

EPOCH 207/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3220
  ‚Ä¢ Validation Loss: 0.3494
  ‚Ä¢ Learning Rate: 0.000411
    No improvement (current: 0.3494, best: 0.3434)
    ‚ö† No improvement for 134 epochs (patience: 150, remaining: 16)

EPOCH 208/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3181
  ‚Ä¢ Validation Loss: 0.3451
  ‚Ä¢ Learning Rate: 0.000404
    No improvement (current: 0.3451, best: 0.3434)
    ‚ö† No improvement for 135 epochs (patience: 150, remaining: 15)

EPOCH 209/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3162
  ‚Ä¢ Validation Loss: 0.3492
  ‚Ä¢ Learning Rate: 0.000397
    No improvement (current: 0.3492, best: 0.3434)
    ‚ö† No improvement for 136 epochs (patience: 150, remaining: 14)

EPOCH 210/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3129
  ‚Ä¢ Validation Loss: 0.3459
  ‚Ä¢ Learning Rate: 0.000389
    No improvement (current: 0.3459, best: 0.3434)
    ‚ö† No improvement for 137 epochs (patience: 150, remaining: 13)

EPOCH 211/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3170
  ‚Ä¢ Validation Loss: 0.3445
  ‚Ä¢ Learning Rate: 0.000382
    No improvement (current: 0.3445, best: 0.3434)
    ‚ö† No improvement for 138 epochs (patience: 150, remaining: 12)

EPOCH 212/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3360
  ‚Ä¢ Validation Loss: 0.3546
  ‚Ä¢ Learning Rate: 0.000375
    No improvement (current: 0.3546, best: 0.3434)
    ‚ö† No improvement for 139 epochs (patience: 150, remaining: 11)

EPOCH 213/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3262
  ‚Ä¢ Validation Loss: 0.3522
  ‚Ä¢ Learning Rate: 0.000368
    No improvement (current: 0.3522, best: 0.3434)
    ‚ö† No improvement for 140 epochs (patience: 150, remaining: 10)

EPOCH 214/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3466
  ‚Ä¢ Validation Loss: 0.3662
  ‚Ä¢ Learning Rate: 0.000360
    No improvement (current: 0.3662, best: 0.3434)
    ‚ö† No improvement for 141 epochs (patience: 150, remaining: 9)

EPOCH 215/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3334
  ‚Ä¢ Validation Loss: 0.3554
  ‚Ä¢ Learning Rate: 0.000353
    No improvement (current: 0.3554, best: 0.3434)
    ‚ö† No improvement for 142 epochs (patience: 150, remaining: 8)

EPOCH 216/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3231
  ‚Ä¢ Validation Loss: 0.3458
  ‚Ä¢ Learning Rate: 0.000346
    No improvement (current: 0.3458, best: 0.3434)
    ‚ö† No improvement for 143 epochs (patience: 150, remaining: 7)

EPOCH 217/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3239
  ‚Ä¢ Validation Loss: 0.3479
  ‚Ä¢ Learning Rate: 0.000339
    No improvement (current: 0.3479, best: 0.3434)
    ‚ö† No improvement for 144 epochs (patience: 150, remaining: 6)

EPOCH 218/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3206
  ‚Ä¢ Validation Loss: 0.3446
  ‚Ä¢ Learning Rate: 0.000332
    No improvement (current: 0.3446, best: 0.3434)
    ‚ö† No improvement for 145 epochs (patience: 150, remaining: 5)

EPOCH 219/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3193
  ‚Ä¢ Validation Loss: 0.3488
  ‚Ä¢ Learning Rate: 0.000325
    No improvement (current: 0.3488, best: 0.3434)
    ‚ö† No improvement for 146 epochs (patience: 150, remaining: 4)

EPOCH 220/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3212
  ‚Ä¢ Validation Loss: 0.3500
  ‚Ä¢ Learning Rate: 0.000318
    No improvement (current: 0.3500, best: 0.3434)
    ‚ö† No improvement for 147 epochs (patience: 150, remaining: 3)

EPOCH 221/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3162
  ‚Ä¢ Validation Loss: 0.3450
  ‚Ä¢ Learning Rate: 0.000311
    No improvement (current: 0.3450, best: 0.3434)
    ‚ö† No improvement for 148 epochs (patience: 150, remaining: 2)

EPOCH 222/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3239
  ‚Ä¢ Validation Loss: 0.3770
  ‚Ä¢ Learning Rate: 0.000304
    No improvement (current: 0.3770, best: 0.3434)
    ‚ö† No improvement for 149 epochs (patience: 150, remaining: 1)

EPOCH 223/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3360
  ‚Ä¢ Validation Loss: 0.3486
  ‚Ä¢ Learning Rate: 0.000297
    No improvement (current: 0.3486, best: 0.3434)
    ‚ö† No improvement for 150 epochs (patience: 150, remaining: 0)

================================================================================
EARLY STOPPING TRIGGERED!
================================================================================
Model has not improved for 150 consecutive epochs.
Stopping training at epoch 223.
Best validation loss achieved: 0.3434
================================================================================


================================================================================
TRAINING COMPLETED
================================================================================
Best Val Loss:  0.3434
Total Epochs:   223
Models Saved:   ./Result/a2/Latin14396
TensorBoard:    ./Result/a2/Latin14396/tensorboard_logs
================================================================================

[01:07:14] Training completed. Best val loss: 0.3434

=== TRAINING COMPLETED SUCCESSFULLY ===
Training Finished!

========================================================================
Testing Hybrid2 Baseline Model with Smart Skip Connections and Multi-Scale Aggregation: Latin14396
========================================================================
=== Historical Document Segmentation Testing ===

Using 6 classes for manuscript: Latin14396
Model: Hybrid2
Dataset: UDIADS_BIB
Manuscript: Latin14396
Test-Time Augmentation: Enabled
CRF post-processing: Enabled
  - DenseCRF with spatial and color pairwise potentials

================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder for Testing
================================================================================
================================================================================
üöÄ SIMPLE DECODER (Flag-Controlled Enhancements)
================================================================================
  ‚Ä¢ EfficientNet Variant: b4
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Enhancement Flags:
  ‚Ä¢ Deep Supervision: False
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: True
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: True
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Loaded checkpoint from epoch 72
Best validation loss: 0.3434
  ‚úÖ Model checkpoint loaded successfully (exact match)
Loaded checkpoint: best_model_latest.pth
Namespace(cfg=None, output_dir='./Result/a2/Latin14396', use_baseline=True, decoder='EfficientNet-B4', efficientnet_variant='b4', use_deep_supervision=False, use_cbam=False, use_smart_skip=True, use_cross_attn=False, use_multiscale_agg=True, use_groupnorm=True, use_batchnorm=False, use_pos_embed=True, dataset='UDIADS_BIB', manuscript='Latin14396', udiadsbib_root='../../U-DIADS-Bib-MS_patched', divahisdb_root='../../DivaHisDB', use_patched_data=True, num_classes=6, img_size=224, batch_size=24, is_savenii=True, test_save_dir='../predictions', use_crf=True, deterministic=1, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, use_tta=True)
Testing with checkpoint: best_model_latest.pth
Saving predictions to: ./Result/a2/Latin14396/predictions

=== Starting Testing ===
Dataset: UDIADS_BIB
Model: Hybrid2
Manuscript: Latin14396
Save predictions: True

Starting inference on UDIADS_BIB dataset
Found 1620 patches for Latin14396
Using Test-Time Augmentation (TTA) for improved accuracy
CRF post-processing: Enabled
  - DenseCRF with spatial and color pairwise potentials
Processing: 014 (54 patches)
Applying CRF post-processing to 014
CRF post-processing completed for 014
Completed: 014
Processing: 032 (54 patches)
Applying CRF post-processing to 032
CRF post-processing completed for 032
Completed: 032
Processing: 034 (54 patches)
Applying CRF post-processing to 034
CRF post-processing completed for 034
Completed: 034
Processing: 036 (54 patches)
Applying CRF post-processing to 036
CRF post-processing completed for 036
Completed: 036
Processing: 038 (54 patches)
Applying CRF post-processing to 038
CRF post-processing completed for 038
Completed: 038
Processing: 047 (54 patches)
Applying CRF post-processing to 047
CRF post-processing completed for 047
Completed: 047
Processing: 060 (54 patches)
Applying CRF post-processing to 060
CRF post-processing completed for 060
Completed: 060
Processing: 085 (54 patches)
Applying CRF post-processing to 085
CRF post-processing completed for 085
Completed: 085
Processing: 087 (54 patches)
Applying CRF post-processing to 087
CRF post-processing completed for 087
Completed: 087
Processing: 104 (54 patches)
Applying CRF post-processing to 104
CRF post-processing completed for 104
Completed: 104
Processing: 105 (54 patches)
Applying CRF post-processing to 105
CRF post-processing completed for 105
Completed: 105
Processing: 108 (54 patches)
Applying CRF post-processing to 108
CRF post-processing completed for 108
Completed: 108
Processing: 110 (54 patches)
Applying CRF post-processing to 110
CRF post-processing completed for 110
Completed: 110
Processing: 136 (54 patches)
Applying CRF post-processing to 136
CRF post-processing completed for 136
Completed: 136
Processing: 169 (54 patches)
Applying CRF post-processing to 169
CRF post-processing completed for 169
Completed: 169
Processing: 195 (54 patches)
Applying CRF post-processing to 195
CRF post-processing completed for 195
Completed: 195
Processing: 196 (54 patches)
Applying CRF post-processing to 196
CRF post-processing completed for 196
Completed: 196
Processing: 198 (54 patches)
Applying CRF post-processing to 198
CRF post-processing completed for 198
Completed: 198
Processing: 204 (54 patches)
Applying CRF post-processing to 204
CRF post-processing completed for 204
Completed: 204
Processing: 223 (54 patches)
Applying CRF post-processing to 223
CRF post-processing completed for 223
Completed: 223
Processing: 225 (54 patches)
Applying CRF post-processing to 225
CRF post-processing completed for 225
Completed: 225
Processing: 227 (54 patches)
Applying CRF post-processing to 227
CRF post-processing completed for 227
Completed: 227
Processing: 229 (54 patches)
Applying CRF post-processing to 229
CRF post-processing completed for 229
Completed: 229
Processing: 251 (54 patches)
Applying CRF post-processing to 251
CRF post-processing completed for 251
Completed: 251
Processing: 253 (54 patches)
Applying CRF post-processing to 253
CRF post-processing completed for 253
Completed: 253
Processing: 255 (54 patches)
Applying CRF post-processing to 255
CRF post-processing completed for 255
Completed: 255
Processing: 264 (54 patches)
Applying CRF post-processing to 264
CRF post-processing completed for 264
Completed: 264
Processing: 270 (54 patches)
Applying CRF post-processing to 270
CRF post-processing completed for 270
Completed: 270
Processing: 276 (54 patches)
Applying CRF post-processing to 276
CRF post-processing completed for 276
Completed: 276
Processing: 325 (54 patches)
Applying CRF post-processing to 325
CRF post-processing completed for 325
Completed: 325

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9799, Recall=0.9992, F1=0.9895, IoU=0.9792
Paratext       : Precision=0.7355, Recall=0.3631, F1=0.4862, IoU=0.3212
Decoration     : Precision=0.9550, Recall=0.9553, F1=0.9551, IoU=0.9141
Main Text      : Precision=0.9771, Recall=0.7912, F1=0.8744, IoU=0.7768
Title          : Precision=0.8917, Recall=0.7879, F1=0.8366, IoU=0.7191
Chapter Headings: Precision=0.9321, Recall=0.5859, F1=0.7195, IoU=0.5619

Mean metrics:
----------------------------------------
Mean Precision: 0.9119
Mean Recall: 0.7471
Mean F1-Score: 0.8102
Mean IoU: 0.7120

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9799, Recall=0.9992, F1=0.9895, IoU=0.9792
Paratext       : Precision=0.7355, Recall=0.3631, F1=0.4862, IoU=0.3212
Decoration     : Precision=0.9550, Recall=0.9553, F1=0.9551, IoU=0.9141
Main Text      : Precision=0.9771, Recall=0.7912, F1=0.8744, IoU=0.7768
Title          : Precision=0.8917, Recall=0.7879, F1=0.8366, IoU=0.7191
Chapter Headings: Precision=0.9321, Recall=0.5859, F1=0.7195, IoU=0.5619

Mean metrics:
----------------------------------------
Mean Precision: 0.9119
Mean Recall: 0.7471
Mean F1-Score: 0.8102
Mean IoU: 0.7120
Inference completed on 30 images

=== TESTING COMPLETED SUCCESSFULLY ===
Results saved to: ./Result/a2/Latin14396/predictions
==================================================

Calculating average metrics...
Looking for metrics files in: ./Result/a2
  ‚úó Metrics file not found: ./Result/a2/metrics_Latin2.json
  ‚úì Found metrics for Latin14396
  ‚úó Metrics file not found: ./Result/a2/metrics_Latin16746.json
  ‚úó Metrics file not found: ./Result/a2/metrics_Syr341.json

================================================================================
AVERAGE METRICS ACROSS 1 MANUSCRIPT(S)
================================================================================
Manuscripts: Latin14396
Missing: Latin2, Latin16746, Syr341
--------------------------------------------------------------------------------
Mean Precision: 0.9119
Mean Recall:    0.7471
Mean F1-Score:  0.8102
Mean IoU:       0.7120
================================================================================

========================================================================
Training Hybrid2 Baseline Model with Smart Skip Connections and Multi-Scale Aggregation: Latin16746
========================================================================
Dataset: U-DIADS-Bib-MS_patched
Architecture: Swin Transformer Encoder ‚Üí 2 Swin Blocks Bottleneck ‚Üí Simple CNN Decoder
Decoder: Simple Decoder (EfficientNet-b4 channel configuration)

Components Enabled:
  ‚úì Swin Encoder (4 stages: 96‚Üí192‚Üí384‚Üí768 dim)
  ‚úì Bottleneck: 2 Swin Transformer blocks (768 dim, 24 heads)
  ‚úì Simple CNN Decoder (channels: [256, 128, 64, 32])
  ‚úì Smart Skip Connections
  ‚úì Multi-Scale Aggregation
  ‚úì Positional Embeddings (default: enabled)
  ‚úì GroupNorm (default normalization)

Components Disabled (baseline):
  ‚úó CBAM Attention
  ‚úó Smart Skip Connections
  ‚úó Cross-Attention Bottleneck
  ‚úó Multi-Scale Aggregation
  ‚úó BatchNorm
========================================================================
All arguments validated successfully!
Setting random seed to 1234 for reproducible training...
Setting up U-DIADS-Bib dataset...
Using 6 classes for manuscript: Latin16746
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin16746/Image/training
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin16746/mask/training_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin16746/Image/validation
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin16746/mask/validation_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder
================================================================================
================================================================================
üöÄ SIMPLE DECODER (Flag-Controlled Enhancements)
================================================================================
  ‚Ä¢ EfficientNet Variant: b4
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Enhancement Flags:
  ‚Ä¢ Deep Supervision: False
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: True
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: True
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Model moved to CUDA
Model created successfully with 6 classes
DEBUG: args.output_dir = ./Result/a2/Latin16746

=== Starting Training ===
Dataset: UDIADS_BIB
Model: Hybrid2
Batch size: 4
Max epochs: 300
Learning rate: 0.0001


================================================================================
TRAINING CONFIGURATION
================================================================================
Dataset: UDIADS_BIB
Model: Hybrid2
Batch Size: 4
Max Epochs: 300
Learning Rate: 0.0001
Number of Classes: 6
Output Directory: ./Result/a2/Latin16746
Early Stopping Patience: 150 epochs
================================================================================

üìä Dataset Statistics:
   - Training samples: 540
   - Validation samples: 540
   - Batch size: 4
   - Steps per epoch: 135


================================================================================
COMPUTING CLASS WEIGHTS
================================================================================
Raw ENS weights: [9.99999990e-05 1.00009434e-04 9.99999990e-05 9.99999990e-05
 1.00760331e-04 9.99999990e-05]

Class Distribution:
Class                Pixels          Frequency       Weight         
-----------------------------------------------------------------
0                        23,958,162        88.4227%         0.9987
1                            92,681         0.3421%         0.9988
2                           683,272         2.5218%         0.9987
3                         2,030,719         7.4948%         0.9987
4                            48,865         0.1803%         1.0063
5                           281,341         1.0383%         0.9987

Total pixels: 27,095,040.0
Beta: 0.9999
Smoothing: 0.0
Weight range: [0.9987, 1.0063]
================================================================================
üìà Class weights computed with ENS method (smoothing=0.1)
   Final weights: [0.9987187 0.9988129 0.9987187 0.9987187 1.0063123 0.9987187]

‚úì Loss functions created: CE (weighted, label_smoothing=0.1), Focal (Œ≥=2.0), Dice
  üìä OneCycleLR: 135 steps/epoch √ó 300 epochs = 40500 total steps
üöÄ Hybrid2 Best Practice: Differential Learning Rates
  üìä Encoder LR:     0.000010 (10x smaller, 119 params)
  üìä Bottleneck LR:  0.000050 (5x smaller, 26 params)
  üìä Decoder LR:     0.000100 (base LR, 84 params)
  ‚öôÔ∏è  Scheduler: OneCycleLR (Peak: 10x, Warmup: 30%, Cosine)
  ‚öôÔ∏è  Weight decay: Encoder=1e-3, Bottleneck=5e-3, Decoder=1e-2

üîç Checking for checkpoint at: ./Result/a2/Latin16746/best_model_latest.pth
   Absolute path: /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid/Result/a2/Latin16746/best_model_latest.pth
   File exists: False

================================================================================
STARTING TRAINING
================================================================================
Early stopping patience: 150 epochs
Learning rate scheduler: OneCycleLR (better convergence for transformers)
================================================================================

EPOCH 1/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5805
  ‚Ä¢ Validation Loss: 0.4851
  ‚Ä¢ Learning Rate: 0.000100
    ‚úì New best checkpoint saved! Val loss: 0.4851
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 2/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4501
  ‚Ä¢ Validation Loss: 0.4313
  ‚Ä¢ Learning Rate: 0.000101
    ‚úì New best checkpoint saved! Val loss: 0.4313
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 3/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4050
  ‚Ä¢ Validation Loss: 0.4074
  ‚Ä¢ Learning Rate: 0.000102
    ‚úì New best checkpoint saved! Val loss: 0.4074
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 4/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3814
  ‚Ä¢ Validation Loss: 0.3942
  ‚Ä¢ Learning Rate: 0.000104
    ‚úì New best checkpoint saved! Val loss: 0.3942
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 5/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3661
  ‚Ä¢ Validation Loss: 0.3930
  ‚Ä¢ Learning Rate: 0.000107
    ‚úì New best checkpoint saved! Val loss: 0.3930
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 6/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3542
  ‚Ä¢ Validation Loss: 0.3834
  ‚Ä¢ Learning Rate: 0.000110
    ‚úì New best checkpoint saved! Val loss: 0.3834
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 7/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3464
  ‚Ä¢ Validation Loss: 0.3749
  ‚Ä¢ Learning Rate: 0.000113
    ‚úì New best checkpoint saved! Val loss: 0.3749
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 8/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3377
  ‚Ä¢ Validation Loss: 0.3795
  ‚Ä¢ Learning Rate: 0.000117
    No improvement (current: 0.3795, best: 0.3749)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 9/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3441
  ‚Ä¢ Validation Loss: 0.3720
  ‚Ä¢ Learning Rate: 0.000122
    ‚úì New best checkpoint saved! Val loss: 0.3720
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 10/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3347
  ‚Ä¢ Validation Loss: 0.3679
  ‚Ä¢ Learning Rate: 0.000127
    ‚úì New best checkpoint saved! Val loss: 0.3679
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 11/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3387
  ‚Ä¢ Validation Loss: 0.3682
  ‚Ä¢ Learning Rate: 0.000133
    No improvement (current: 0.3682, best: 0.3679)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 12/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3283
  ‚Ä¢ Validation Loss: 0.3735
  ‚Ä¢ Learning Rate: 0.000139
    No improvement (current: 0.3735, best: 0.3679)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 13/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3262
  ‚Ä¢ Validation Loss: 0.3632
  ‚Ä¢ Learning Rate: 0.000146
    ‚úì New best checkpoint saved! Val loss: 0.3632
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 14/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3327
  ‚Ä¢ Validation Loss: 0.3697
  ‚Ä¢ Learning Rate: 0.000153
    No improvement (current: 0.3697, best: 0.3632)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 15/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3251
  ‚Ä¢ Validation Loss: 0.3636
  ‚Ä¢ Learning Rate: 0.000160
    No improvement (current: 0.3636, best: 0.3632)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 16/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3148
  ‚Ä¢ Validation Loss: 0.3635
  ‚Ä¢ Learning Rate: 0.000168
    No improvement (current: 0.3635, best: 0.3632)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 17/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3265
  ‚Ä¢ Validation Loss: 0.3631
  ‚Ä¢ Learning Rate: 0.000177
    ‚úì New best checkpoint saved! Val loss: 0.3631
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 18/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3144
  ‚Ä¢ Validation Loss: 0.3664
  ‚Ä¢ Learning Rate: 0.000186
    No improvement (current: 0.3664, best: 0.3631)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 19/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3103
  ‚Ä¢ Validation Loss: 0.3672
  ‚Ä¢ Learning Rate: 0.000195
    No improvement (current: 0.3672, best: 0.3631)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 20/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3160
  ‚Ä¢ Validation Loss: 0.3646
  ‚Ä¢ Learning Rate: 0.000205
    No improvement (current: 0.3646, best: 0.3631)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 21/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3160
  ‚Ä¢ Validation Loss: 0.3637
  ‚Ä¢ Learning Rate: 0.000216
    No improvement (current: 0.3637, best: 0.3631)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 22/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3175
  ‚Ä¢ Validation Loss: 0.3664
  ‚Ä¢ Learning Rate: 0.000226
    No improvement (current: 0.3664, best: 0.3631)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 23/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3188
  ‚Ä¢ Validation Loss: 0.3540
  ‚Ä¢ Learning Rate: 0.000237
    ‚úì New best checkpoint saved! Val loss: 0.3540
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 24/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3139
  ‚Ä¢ Validation Loss: 0.3525
  ‚Ä¢ Learning Rate: 0.000249
    ‚úì New best checkpoint saved! Val loss: 0.3525
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 25/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3136
  ‚Ä¢ Validation Loss: 0.3546
  ‚Ä¢ Learning Rate: 0.000261
    No improvement (current: 0.3546, best: 0.3525)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 26/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3115
  ‚Ä¢ Validation Loss: 0.3607
  ‚Ä¢ Learning Rate: 0.000273
    No improvement (current: 0.3607, best: 0.3525)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 27/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3111
  ‚Ä¢ Validation Loss: 0.3560
  ‚Ä¢ Learning Rate: 0.000286
    No improvement (current: 0.3560, best: 0.3525)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 28/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3051
  ‚Ä¢ Validation Loss: 0.3925
  ‚Ä¢ Learning Rate: 0.000298
    No improvement (current: 0.3925, best: 0.3525)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 29/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3082
  ‚Ä¢ Validation Loss: 0.3500
  ‚Ä¢ Learning Rate: 0.000312
    ‚úì New best checkpoint saved! Val loss: 0.3500
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 30/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3156
  ‚Ä¢ Validation Loss: 0.3522
  ‚Ä¢ Learning Rate: 0.000325
    No improvement (current: 0.3522, best: 0.3500)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 31/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3101
  ‚Ä¢ Validation Loss: 0.3604
  ‚Ä¢ Learning Rate: 0.000339
    No improvement (current: 0.3604, best: 0.3500)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 32/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3126
  ‚Ä¢ Validation Loss: 0.3585
  ‚Ä¢ Learning Rate: 0.000353
    No improvement (current: 0.3585, best: 0.3500)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 33/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3069
  ‚Ä¢ Validation Loss: 0.3516
  ‚Ä¢ Learning Rate: 0.000367
    No improvement (current: 0.3516, best: 0.3500)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 34/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3056
  ‚Ä¢ Validation Loss: 0.3575
  ‚Ä¢ Learning Rate: 0.000381
    No improvement (current: 0.3575, best: 0.3500)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 35/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3087
  ‚Ä¢ Validation Loss: 0.3566
  ‚Ä¢ Learning Rate: 0.000396
    No improvement (current: 0.3566, best: 0.3500)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 36/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3072
  ‚Ä¢ Validation Loss: 0.3564
  ‚Ä¢ Learning Rate: 0.000411
    No improvement (current: 0.3564, best: 0.3500)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 37/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3139
  ‚Ä¢ Validation Loss: 0.3531
  ‚Ä¢ Learning Rate: 0.000426
    No improvement (current: 0.3531, best: 0.3500)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 38/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3010
  ‚Ä¢ Validation Loss: 0.3572
  ‚Ä¢ Learning Rate: 0.000441
    No improvement (current: 0.3572, best: 0.3500)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 39/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3149
  ‚Ä¢ Validation Loss: 0.3599
  ‚Ä¢ Learning Rate: 0.000456
    No improvement (current: 0.3599, best: 0.3500)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 40/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3049
  ‚Ä¢ Validation Loss: 0.3638
  ‚Ä¢ Learning Rate: 0.000472
    No improvement (current: 0.3638, best: 0.3500)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 41/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3227
  ‚Ä¢ Validation Loss: 0.3684
  ‚Ä¢ Learning Rate: 0.000487
    No improvement (current: 0.3684, best: 0.3500)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 42/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3059
  ‚Ä¢ Validation Loss: 0.3532
  ‚Ä¢ Learning Rate: 0.000503
    No improvement (current: 0.3532, best: 0.3500)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 43/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3043
  ‚Ä¢ Validation Loss: 0.3486
  ‚Ä¢ Learning Rate: 0.000519
    ‚úì New best checkpoint saved! Val loss: 0.3486
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 44/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3078
  ‚Ä¢ Validation Loss: 0.3473
  ‚Ä¢ Learning Rate: 0.000534
    ‚úì New best checkpoint saved! Val loss: 0.3473
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 45/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3000
  ‚Ä¢ Validation Loss: 0.3494
  ‚Ä¢ Learning Rate: 0.000550
    No improvement (current: 0.3494, best: 0.3473)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 46/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3020
  ‚Ä¢ Validation Loss: 0.3498
  ‚Ä¢ Learning Rate: 0.000566
    No improvement (current: 0.3498, best: 0.3473)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 47/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3001
  ‚Ä¢ Validation Loss: 0.3462
  ‚Ä¢ Learning Rate: 0.000581
    ‚úì New best checkpoint saved! Val loss: 0.3462
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 48/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3092
  ‚Ä¢ Validation Loss: 0.3526
  ‚Ä¢ Learning Rate: 0.000597
    No improvement (current: 0.3526, best: 0.3462)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 49/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2981
  ‚Ä¢ Validation Loss: 0.3561
  ‚Ä¢ Learning Rate: 0.000613
    No improvement (current: 0.3561, best: 0.3462)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 50/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3049
  ‚Ä¢ Validation Loss: 0.3517
  ‚Ä¢ Learning Rate: 0.000628
    No improvement (current: 0.3517, best: 0.3462)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 51/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3034
  ‚Ä¢ Validation Loss: 0.3484
  ‚Ä¢ Learning Rate: 0.000644
    No improvement (current: 0.3484, best: 0.3462)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 52/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3040
  ‚Ä¢ Validation Loss: 0.3627
  ‚Ä¢ Learning Rate: 0.000659
    No improvement (current: 0.3627, best: 0.3462)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 53/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3191
  ‚Ä¢ Validation Loss: 0.3614
  ‚Ä¢ Learning Rate: 0.000674
    No improvement (current: 0.3614, best: 0.3462)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 54/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3019
  ‚Ä¢ Validation Loss: 0.3512
  ‚Ä¢ Learning Rate: 0.000689
    No improvement (current: 0.3512, best: 0.3462)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 55/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3057
  ‚Ä¢ Validation Loss: 0.3494
  ‚Ä¢ Learning Rate: 0.000704
    No improvement (current: 0.3494, best: 0.3462)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 56/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3020
  ‚Ä¢ Validation Loss: 0.3512
  ‚Ä¢ Learning Rate: 0.000719
    No improvement (current: 0.3512, best: 0.3462)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 57/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3022
  ‚Ä¢ Validation Loss: 0.3556
  ‚Ä¢ Learning Rate: 0.000733
    No improvement (current: 0.3556, best: 0.3462)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 58/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3056
  ‚Ä¢ Validation Loss: 0.3657
  ‚Ä¢ Learning Rate: 0.000747
    No improvement (current: 0.3657, best: 0.3462)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 59/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3027
  ‚Ä¢ Validation Loss: 0.3467
  ‚Ä¢ Learning Rate: 0.000761
    No improvement (current: 0.3467, best: 0.3462)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 60/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3026
  ‚Ä¢ Validation Loss: 0.3466
  ‚Ä¢ Learning Rate: 0.000775
    No improvement (current: 0.3466, best: 0.3462)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 61/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3035
  ‚Ä¢ Validation Loss: 0.3476
  ‚Ä¢ Learning Rate: 0.000789
    No improvement (current: 0.3476, best: 0.3462)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 62/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3093
  ‚Ä¢ Validation Loss: 0.3571
  ‚Ä¢ Learning Rate: 0.000802
    No improvement (current: 0.3571, best: 0.3462)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 63/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2998
  ‚Ä¢ Validation Loss: 0.3650
  ‚Ä¢ Learning Rate: 0.000815
    No improvement (current: 0.3650, best: 0.3462)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 64/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2996
  ‚Ä¢ Validation Loss: 0.3523
  ‚Ä¢ Learning Rate: 0.000827
    No improvement (current: 0.3523, best: 0.3462)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 65/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3028
  ‚Ä¢ Validation Loss: 0.3464
  ‚Ä¢ Learning Rate: 0.000839
    No improvement (current: 0.3464, best: 0.3462)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 66/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2991
  ‚Ä¢ Validation Loss: 0.3426
  ‚Ä¢ Learning Rate: 0.000851
    ‚úì New best checkpoint saved! Val loss: 0.3426
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 67/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2987
  ‚Ä¢ Validation Loss: 0.3608
  ‚Ä¢ Learning Rate: 0.000863
    No improvement (current: 0.3608, best: 0.3426)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 68/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3046
  ‚Ä¢ Validation Loss: 0.3478
  ‚Ä¢ Learning Rate: 0.000874
    No improvement (current: 0.3478, best: 0.3426)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 69/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2976
  ‚Ä¢ Validation Loss: 0.3461
  ‚Ä¢ Learning Rate: 0.000884
    No improvement (current: 0.3461, best: 0.3426)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 70/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3029
  ‚Ä¢ Validation Loss: 0.3440
  ‚Ä¢ Learning Rate: 0.000895
    No improvement (current: 0.3440, best: 0.3426)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 71/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2959
  ‚Ä¢ Validation Loss: 0.3450
  ‚Ä¢ Learning Rate: 0.000905
    No improvement (current: 0.3450, best: 0.3426)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 72/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2999
  ‚Ä¢ Validation Loss: 0.3444
  ‚Ä¢ Learning Rate: 0.000914
    No improvement (current: 0.3444, best: 0.3426)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 73/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2964
  ‚Ä¢ Validation Loss: 0.3411
  ‚Ä¢ Learning Rate: 0.000923
    ‚úì New best checkpoint saved! Val loss: 0.3411
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 74/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2995
  ‚Ä¢ Validation Loss: 0.3612
  ‚Ä¢ Learning Rate: 0.000932
    No improvement (current: 0.3612, best: 0.3411)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 75/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2934
  ‚Ä¢ Validation Loss: 0.3486
  ‚Ä¢ Learning Rate: 0.000940
    No improvement (current: 0.3486, best: 0.3411)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 76/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2914
  ‚Ä¢ Validation Loss: 0.3438
  ‚Ä¢ Learning Rate: 0.000947
    No improvement (current: 0.3438, best: 0.3411)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 77/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2946
  ‚Ä¢ Validation Loss: 0.3455
  ‚Ä¢ Learning Rate: 0.000955
    No improvement (current: 0.3455, best: 0.3411)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 78/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2949
  ‚Ä¢ Validation Loss: 0.3408
  ‚Ä¢ Learning Rate: 0.000961
    ‚úì New best checkpoint saved! Val loss: 0.3408
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 79/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2884
  ‚Ä¢ Validation Loss: 0.3457
  ‚Ä¢ Learning Rate: 0.000967
    No improvement (current: 0.3457, best: 0.3408)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 80/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2975
  ‚Ä¢ Validation Loss: 0.3431
  ‚Ä¢ Learning Rate: 0.000973
    No improvement (current: 0.3431, best: 0.3408)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 81/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2861
  ‚Ä¢ Validation Loss: 0.3427
  ‚Ä¢ Learning Rate: 0.000978
    No improvement (current: 0.3427, best: 0.3408)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 82/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2851
  ‚Ä¢ Validation Loss: 0.3377
  ‚Ä¢ Learning Rate: 0.000983
    ‚úì New best checkpoint saved! Val loss: 0.3377
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 83/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2808
  ‚Ä¢ Validation Loss: 0.3395
  ‚Ä¢ Learning Rate: 0.000987
    No improvement (current: 0.3395, best: 0.3377)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 84/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2830
  ‚Ä¢ Validation Loss: 0.3384
  ‚Ä¢ Learning Rate: 0.000990
    No improvement (current: 0.3384, best: 0.3377)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 85/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2797
  ‚Ä¢ Validation Loss: 0.3407
  ‚Ä¢ Learning Rate: 0.000993
    No improvement (current: 0.3407, best: 0.3377)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 86/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2786
  ‚Ä¢ Validation Loss: 0.3398
  ‚Ä¢ Learning Rate: 0.000996
    No improvement (current: 0.3398, best: 0.3377)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 87/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2865
  ‚Ä¢ Validation Loss: 0.3394
  ‚Ä¢ Learning Rate: 0.000998
    No improvement (current: 0.3394, best: 0.3377)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 88/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2833
  ‚Ä¢ Validation Loss: 0.3361
  ‚Ä¢ Learning Rate: 0.000999
    ‚úì New best checkpoint saved! Val loss: 0.3361
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 89/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2816
  ‚Ä¢ Validation Loss: 0.3369
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.3369, best: 0.3361)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 90/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2802
  ‚Ä¢ Validation Loss: 0.3407
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.3407, best: 0.3361)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 91/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2774
  ‚Ä¢ Validation Loss: 0.3393
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.3393, best: 0.3361)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 92/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2818
  ‚Ä¢ Validation Loss: 0.3378
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.3378, best: 0.3361)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 93/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2855
  ‚Ä¢ Validation Loss: 0.3381
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.3381, best: 0.3361)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 94/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2820
  ‚Ä¢ Validation Loss: 0.3380
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.3380, best: 0.3361)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 95/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2791
  ‚Ä¢ Validation Loss: 0.3377
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.3377, best: 0.3361)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 96/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2817
  ‚Ä¢ Validation Loss: 0.3377
  ‚Ä¢ Learning Rate: 0.000998
    No improvement (current: 0.3377, best: 0.3361)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 97/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2847
  ‚Ä¢ Validation Loss: 0.3370
  ‚Ä¢ Learning Rate: 0.000997
    No improvement (current: 0.3370, best: 0.3361)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 98/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2794
  ‚Ä¢ Validation Loss: 0.3380
  ‚Ä¢ Learning Rate: 0.000996
    No improvement (current: 0.3380, best: 0.3361)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 99/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2789
  ‚Ä¢ Validation Loss: 0.3377
  ‚Ä¢ Learning Rate: 0.000995
    No improvement (current: 0.3377, best: 0.3361)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 100/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2824
  ‚Ä¢ Validation Loss: 0.3380
  ‚Ä¢ Learning Rate: 0.000994
   üíæ Periodic checkpoint saved: epoch_100.pth
    No improvement (current: 0.3380, best: 0.3361)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 101/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2818
  ‚Ä¢ Validation Loss: 0.3372
  ‚Ä¢ Learning Rate: 0.000993
    No improvement (current: 0.3372, best: 0.3361)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 102/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2782
  ‚Ä¢ Validation Loss: 0.3412
  ‚Ä¢ Learning Rate: 0.000992
    No improvement (current: 0.3412, best: 0.3361)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 103/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2778
  ‚Ä¢ Validation Loss: 0.3388
  ‚Ä¢ Learning Rate: 0.000991
    No improvement (current: 0.3388, best: 0.3361)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 104/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2767
  ‚Ä¢ Validation Loss: 0.3425
  ‚Ä¢ Learning Rate: 0.000989
    No improvement (current: 0.3425, best: 0.3361)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 105/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2794
  ‚Ä¢ Validation Loss: 0.3404
  ‚Ä¢ Learning Rate: 0.000987
    No improvement (current: 0.3404, best: 0.3361)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 106/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2752
  ‚Ä¢ Validation Loss: 0.3396
  ‚Ä¢ Learning Rate: 0.000986
    No improvement (current: 0.3396, best: 0.3361)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 107/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2758
  ‚Ä¢ Validation Loss: 0.3358
  ‚Ä¢ Learning Rate: 0.000984
    ‚úì New best checkpoint saved! Val loss: 0.3358
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 108/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2757
  ‚Ä¢ Validation Loss: 0.3365
  ‚Ä¢ Learning Rate: 0.000982
    No improvement (current: 0.3365, best: 0.3358)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 109/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2910
  ‚Ä¢ Validation Loss: 0.3474
  ‚Ä¢ Learning Rate: 0.000980
    No improvement (current: 0.3474, best: 0.3358)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 110/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2878
  ‚Ä¢ Validation Loss: 0.3440
  ‚Ä¢ Learning Rate: 0.000978
    No improvement (current: 0.3440, best: 0.3358)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 111/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2818
  ‚Ä¢ Validation Loss: 0.3397
  ‚Ä¢ Learning Rate: 0.000976
    No improvement (current: 0.3397, best: 0.3358)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 112/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2776
  ‚Ä¢ Validation Loss: 0.3383
  ‚Ä¢ Learning Rate: 0.000973
    No improvement (current: 0.3383, best: 0.3358)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 113/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2787
  ‚Ä¢ Validation Loss: 0.3378
  ‚Ä¢ Learning Rate: 0.000971
    No improvement (current: 0.3378, best: 0.3358)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 114/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2813
  ‚Ä¢ Validation Loss: 0.3372
  ‚Ä¢ Learning Rate: 0.000968
    No improvement (current: 0.3372, best: 0.3358)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 115/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2809
  ‚Ä¢ Validation Loss: 0.3368
  ‚Ä¢ Learning Rate: 0.000965
    No improvement (current: 0.3368, best: 0.3358)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 116/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2816
  ‚Ä¢ Validation Loss: 0.3380
  ‚Ä¢ Learning Rate: 0.000963
    No improvement (current: 0.3380, best: 0.3358)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 117/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2821
  ‚Ä¢ Validation Loss: 0.3366
  ‚Ä¢ Learning Rate: 0.000960
    No improvement (current: 0.3366, best: 0.3358)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 118/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3965
  ‚Ä¢ Validation Loss: 0.4748
  ‚Ä¢ Learning Rate: 0.000957
    No improvement (current: 0.4748, best: 0.3358)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 119/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4763
  ‚Ä¢ Validation Loss: 0.4625
  ‚Ä¢ Learning Rate: 0.000954
    No improvement (current: 0.4625, best: 0.3358)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 120/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4560
  ‚Ä¢ Validation Loss: 0.4523
  ‚Ä¢ Learning Rate: 0.000951
    No improvement (current: 0.4523, best: 0.3358)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 121/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4437
  ‚Ä¢ Validation Loss: 0.4432
  ‚Ä¢ Learning Rate: 0.000947
    No improvement (current: 0.4432, best: 0.3358)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 122/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4285
  ‚Ä¢ Validation Loss: 0.4320
  ‚Ä¢ Learning Rate: 0.000944
    No improvement (current: 0.4320, best: 0.3358)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 123/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4177
  ‚Ä¢ Validation Loss: 0.4258
  ‚Ä¢ Learning Rate: 0.000940
    No improvement (current: 0.4258, best: 0.3358)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 124/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4044
  ‚Ä¢ Validation Loss: 0.4181
  ‚Ä¢ Learning Rate: 0.000937
    No improvement (current: 0.4181, best: 0.3358)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 125/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3926
  ‚Ä¢ Validation Loss: 0.4113
  ‚Ä¢ Learning Rate: 0.000933
    No improvement (current: 0.4113, best: 0.3358)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 126/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3803
  ‚Ä¢ Validation Loss: 0.4050
  ‚Ä¢ Learning Rate: 0.000929
    No improvement (current: 0.4050, best: 0.3358)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 127/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3738
  ‚Ä¢ Validation Loss: 0.3979
  ‚Ä¢ Learning Rate: 0.000925
    No improvement (current: 0.3979, best: 0.3358)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 128/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3660
  ‚Ä¢ Validation Loss: 0.3935
  ‚Ä¢ Learning Rate: 0.000921
    No improvement (current: 0.3935, best: 0.3358)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 129/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3597
  ‚Ä¢ Validation Loss: 0.3892
  ‚Ä¢ Learning Rate: 0.000917
    No improvement (current: 0.3892, best: 0.3358)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 130/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3550
  ‚Ä¢ Validation Loss: 0.3852
  ‚Ä¢ Learning Rate: 0.000913
    No improvement (current: 0.3852, best: 0.3358)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 131/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3516
  ‚Ä¢ Validation Loss: 0.3811
  ‚Ä¢ Learning Rate: 0.000909
    No improvement (current: 0.3811, best: 0.3358)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 132/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3464
  ‚Ä¢ Validation Loss: 0.3783
  ‚Ä¢ Learning Rate: 0.000905
    No improvement (current: 0.3783, best: 0.3358)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 133/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3436
  ‚Ä¢ Validation Loss: 0.3755
  ‚Ä¢ Learning Rate: 0.000900
    No improvement (current: 0.3755, best: 0.3358)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 134/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3392
  ‚Ä¢ Validation Loss: 0.3747
  ‚Ä¢ Learning Rate: 0.000896
    No improvement (current: 0.3747, best: 0.3358)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 135/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3359
  ‚Ä¢ Validation Loss: 0.3719
  ‚Ä¢ Learning Rate: 0.000891
    No improvement (current: 0.3719, best: 0.3358)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 136/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3287
  ‚Ä¢ Validation Loss: 0.3708
  ‚Ä¢ Learning Rate: 0.000886
    No improvement (current: 0.3708, best: 0.3358)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 137/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3285
  ‚Ä¢ Validation Loss: 0.3689
  ‚Ä¢ Learning Rate: 0.000881
    No improvement (current: 0.3689, best: 0.3358)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 138/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3300
  ‚Ä¢ Validation Loss: 0.3675
  ‚Ä¢ Learning Rate: 0.000877
    No improvement (current: 0.3675, best: 0.3358)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 139/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3222
  ‚Ä¢ Validation Loss: 0.3662
  ‚Ä¢ Learning Rate: 0.000872
    No improvement (current: 0.3662, best: 0.3358)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 140/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3207
  ‚Ä¢ Validation Loss: 0.3648
  ‚Ä¢ Learning Rate: 0.000867
    No improvement (current: 0.3648, best: 0.3358)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 141/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3188
  ‚Ä¢ Validation Loss: 0.3635
  ‚Ä¢ Learning Rate: 0.000861
    No improvement (current: 0.3635, best: 0.3358)
    ‚ö† No improvement for 34 epochs (patience: 150, remaining: 116)

EPOCH 142/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3204
  ‚Ä¢ Validation Loss: 0.3636
  ‚Ä¢ Learning Rate: 0.000856
    No improvement (current: 0.3636, best: 0.3358)
    ‚ö† No improvement for 35 epochs (patience: 150, remaining: 115)

EPOCH 143/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3127
  ‚Ä¢ Validation Loss: 0.3606
  ‚Ä¢ Learning Rate: 0.000851
    No improvement (current: 0.3606, best: 0.3358)
    ‚ö† No improvement for 36 epochs (patience: 150, remaining: 114)

EPOCH 144/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3089
  ‚Ä¢ Validation Loss: 0.3598
  ‚Ä¢ Learning Rate: 0.000846
    No improvement (current: 0.3598, best: 0.3358)
    ‚ö† No improvement for 37 epochs (patience: 150, remaining: 113)

EPOCH 145/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3116
  ‚Ä¢ Validation Loss: 0.3593
  ‚Ä¢ Learning Rate: 0.000840
    No improvement (current: 0.3593, best: 0.3358)
    ‚ö† No improvement for 38 epochs (patience: 150, remaining: 112)

EPOCH 146/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3104
  ‚Ä¢ Validation Loss: 0.3577
  ‚Ä¢ Learning Rate: 0.000835
    No improvement (current: 0.3577, best: 0.3358)
    ‚ö† No improvement for 39 epochs (patience: 150, remaining: 111)

EPOCH 147/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3051
  ‚Ä¢ Validation Loss: 0.3565
  ‚Ä¢ Learning Rate: 0.000829
    No improvement (current: 0.3565, best: 0.3358)
    ‚ö† No improvement for 40 epochs (patience: 150, remaining: 110)

EPOCH 148/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3098
  ‚Ä¢ Validation Loss: 0.3550
  ‚Ä¢ Learning Rate: 0.000823
    No improvement (current: 0.3550, best: 0.3358)
    ‚ö† No improvement for 41 epochs (patience: 150, remaining: 109)

EPOCH 149/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3052
  ‚Ä¢ Validation Loss: 0.3535
  ‚Ä¢ Learning Rate: 0.000818
    No improvement (current: 0.3535, best: 0.3358)
    ‚ö† No improvement for 42 epochs (patience: 150, remaining: 108)

EPOCH 150/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3051
  ‚Ä¢ Validation Loss: 0.3533
  ‚Ä¢ Learning Rate: 0.000812
    No improvement (current: 0.3533, best: 0.3358)
    ‚ö† No improvement for 43 epochs (patience: 150, remaining: 107)

EPOCH 151/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2972
  ‚Ä¢ Validation Loss: 0.3523
  ‚Ä¢ Learning Rate: 0.000806
    No improvement (current: 0.3523, best: 0.3358)
    ‚ö† No improvement for 44 epochs (patience: 150, remaining: 106)

EPOCH 152/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2973
  ‚Ä¢ Validation Loss: 0.3523
  ‚Ä¢ Learning Rate: 0.000800
    No improvement (current: 0.3523, best: 0.3358)
    ‚ö† No improvement for 45 epochs (patience: 150, remaining: 105)

EPOCH 153/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2960
  ‚Ä¢ Validation Loss: 0.3508
  ‚Ä¢ Learning Rate: 0.000794
    No improvement (current: 0.3508, best: 0.3358)
    ‚ö† No improvement for 46 epochs (patience: 150, remaining: 104)

EPOCH 154/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2969
  ‚Ä¢ Validation Loss: 0.3497
  ‚Ä¢ Learning Rate: 0.000788
    No improvement (current: 0.3497, best: 0.3358)
    ‚ö† No improvement for 47 epochs (patience: 150, remaining: 103)

EPOCH 155/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2972
  ‚Ä¢ Validation Loss: 0.3494
  ‚Ä¢ Learning Rate: 0.000782
    No improvement (current: 0.3494, best: 0.3358)
    ‚ö† No improvement for 48 epochs (patience: 150, remaining: 102)

EPOCH 156/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2928
  ‚Ä¢ Validation Loss: 0.3492
  ‚Ä¢ Learning Rate: 0.000776
    No improvement (current: 0.3492, best: 0.3358)
    ‚ö† No improvement for 49 epochs (patience: 150, remaining: 101)

EPOCH 157/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2944
  ‚Ä¢ Validation Loss: 0.3498
  ‚Ä¢ Learning Rate: 0.000769
    No improvement (current: 0.3498, best: 0.3358)
    ‚ö† No improvement for 50 epochs (patience: 150, remaining: 100)

EPOCH 158/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2923
  ‚Ä¢ Validation Loss: 0.3490
  ‚Ä¢ Learning Rate: 0.000763
    No improvement (current: 0.3490, best: 0.3358)
    ‚ö† No improvement for 51 epochs (patience: 150, remaining: 99)

EPOCH 159/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2964
  ‚Ä¢ Validation Loss: 0.3458
  ‚Ä¢ Learning Rate: 0.000757
    No improvement (current: 0.3458, best: 0.3358)
    ‚ö† No improvement for 52 epochs (patience: 150, remaining: 98)

EPOCH 160/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2886
  ‚Ä¢ Validation Loss: 0.3495
  ‚Ä¢ Learning Rate: 0.000750
    No improvement (current: 0.3495, best: 0.3358)
    ‚ö† No improvement for 53 epochs (patience: 150, remaining: 97)

EPOCH 161/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2929
  ‚Ä¢ Validation Loss: 0.3479
  ‚Ä¢ Learning Rate: 0.000744
    No improvement (current: 0.3479, best: 0.3358)
    ‚ö† No improvement for 54 epochs (patience: 150, remaining: 96)

EPOCH 162/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2958
  ‚Ä¢ Validation Loss: 0.3455
  ‚Ä¢ Learning Rate: 0.000737
    No improvement (current: 0.3455, best: 0.3358)
    ‚ö† No improvement for 55 epochs (patience: 150, remaining: 95)

EPOCH 163/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2953
  ‚Ä¢ Validation Loss: 0.3504
  ‚Ä¢ Learning Rate: 0.000731
    No improvement (current: 0.3504, best: 0.3358)
    ‚ö† No improvement for 56 epochs (patience: 150, remaining: 94)

EPOCH 164/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2921
  ‚Ä¢ Validation Loss: 0.3484
  ‚Ä¢ Learning Rate: 0.000724
    No improvement (current: 0.3484, best: 0.3358)
    ‚ö† No improvement for 57 epochs (patience: 150, remaining: 93)

EPOCH 165/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2937
  ‚Ä¢ Validation Loss: 0.4314
  ‚Ä¢ Learning Rate: 0.000717
    No improvement (current: 0.4314, best: 0.3358)
    ‚ö† No improvement for 58 epochs (patience: 150, remaining: 92)

EPOCH 166/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.0738
  ‚Ä¢ Validation Loss: 0.5683
  ‚Ä¢ Learning Rate: 0.000710
    No improvement (current: 0.5683, best: 0.3358)
    ‚ö† No improvement for 59 epochs (patience: 150, remaining: 91)

EPOCH 167/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5409
  ‚Ä¢ Validation Loss: 0.4872
  ‚Ä¢ Learning Rate: 0.000704
    No improvement (current: 0.4872, best: 0.3358)
    ‚ö† No improvement for 60 epochs (patience: 150, remaining: 90)

EPOCH 168/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4832
  ‚Ä¢ Validation Loss: 0.4504
  ‚Ä¢ Learning Rate: 0.000697
    No improvement (current: 0.4504, best: 0.3358)
    ‚ö† No improvement for 61 epochs (patience: 150, remaining: 89)

EPOCH 169/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4536
  ‚Ä¢ Validation Loss: 0.4653
  ‚Ä¢ Learning Rate: 0.000690
    No improvement (current: 0.4653, best: 0.3358)
    ‚ö† No improvement for 62 epochs (patience: 150, remaining: 88)

EPOCH 170/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4400
  ‚Ä¢ Validation Loss: 0.4230
  ‚Ä¢ Learning Rate: 0.000683
    No improvement (current: 0.4230, best: 0.3358)
    ‚ö† No improvement for 63 epochs (patience: 150, remaining: 87)

EPOCH 171/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4207
  ‚Ä¢ Validation Loss: 0.4222
  ‚Ä¢ Learning Rate: 0.000676
    No improvement (current: 0.4222, best: 0.3358)
    ‚ö† No improvement for 64 epochs (patience: 150, remaining: 86)

EPOCH 172/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4267
  ‚Ä¢ Validation Loss: 0.4332
  ‚Ä¢ Learning Rate: 0.000669
    No improvement (current: 0.4332, best: 0.3358)
    ‚ö† No improvement for 65 epochs (patience: 150, remaining: 85)

EPOCH 173/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4294
  ‚Ä¢ Validation Loss: 0.4138
  ‚Ä¢ Learning Rate: 0.000662
    No improvement (current: 0.4138, best: 0.3358)
    ‚ö† No improvement for 66 epochs (patience: 150, remaining: 84)

EPOCH 174/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4056
  ‚Ä¢ Validation Loss: 0.4121
  ‚Ä¢ Learning Rate: 0.000655
    No improvement (current: 0.4121, best: 0.3358)
    ‚ö† No improvement for 67 epochs (patience: 150, remaining: 83)

EPOCH 175/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3961
  ‚Ä¢ Validation Loss: 0.4011
  ‚Ä¢ Learning Rate: 0.000648
    No improvement (current: 0.4011, best: 0.3358)
    ‚ö† No improvement for 68 epochs (patience: 150, remaining: 82)

EPOCH 176/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4289
  ‚Ä¢ Validation Loss: 0.4054
  ‚Ä¢ Learning Rate: 0.000641
    No improvement (current: 0.4054, best: 0.3358)
    ‚ö† No improvement for 69 epochs (patience: 150, remaining: 81)

EPOCH 177/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3903
  ‚Ä¢ Validation Loss: 0.4028
  ‚Ä¢ Learning Rate: 0.000633
    No improvement (current: 0.4028, best: 0.3358)
    ‚ö† No improvement for 70 epochs (patience: 150, remaining: 80)

EPOCH 178/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3854
  ‚Ä¢ Validation Loss: 0.3970
  ‚Ä¢ Learning Rate: 0.000626
    No improvement (current: 0.3970, best: 0.3358)
    ‚ö† No improvement for 71 epochs (patience: 150, remaining: 79)

EPOCH 179/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3894
  ‚Ä¢ Validation Loss: 0.3923
  ‚Ä¢ Learning Rate: 0.000619
    No improvement (current: 0.3923, best: 0.3358)
    ‚ö† No improvement for 72 epochs (patience: 150, remaining: 78)

EPOCH 180/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3792
  ‚Ä¢ Validation Loss: 0.3920
  ‚Ä¢ Learning Rate: 0.000612
    No improvement (current: 0.3920, best: 0.3358)
    ‚ö† No improvement for 73 epochs (patience: 150, remaining: 77)

EPOCH 181/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3732
  ‚Ä¢ Validation Loss: 0.3973
  ‚Ä¢ Learning Rate: 0.000604
    No improvement (current: 0.3973, best: 0.3358)
    ‚ö† No improvement for 74 epochs (patience: 150, remaining: 76)

EPOCH 182/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3611
  ‚Ä¢ Validation Loss: 0.3810
  ‚Ä¢ Learning Rate: 0.000597
    No improvement (current: 0.3810, best: 0.3358)
    ‚ö† No improvement for 75 epochs (patience: 150, remaining: 75)

EPOCH 183/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3604
  ‚Ä¢ Validation Loss: 0.3863
  ‚Ä¢ Learning Rate: 0.000590
    No improvement (current: 0.3863, best: 0.3358)
    ‚ö† No improvement for 76 epochs (patience: 150, remaining: 74)

EPOCH 184/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3591
  ‚Ä¢ Validation Loss: 0.3904
  ‚Ä¢ Learning Rate: 0.000582
    No improvement (current: 0.3904, best: 0.3358)
    ‚ö† No improvement for 77 epochs (patience: 150, remaining: 73)

EPOCH 185/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3603
  ‚Ä¢ Validation Loss: 0.4486
  ‚Ä¢ Learning Rate: 0.000575
    No improvement (current: 0.4486, best: 0.3358)
    ‚ö† No improvement for 78 epochs (patience: 150, remaining: 72)

EPOCH 186/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3732
  ‚Ä¢ Validation Loss: 0.3797
  ‚Ä¢ Learning Rate: 0.000567
    No improvement (current: 0.3797, best: 0.3358)
    ‚ö† No improvement for 79 epochs (patience: 150, remaining: 71)

EPOCH 187/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3669
  ‚Ä¢ Validation Loss: 0.3750
  ‚Ä¢ Learning Rate: 0.000560
    No improvement (current: 0.3750, best: 0.3358)
    ‚ö† No improvement for 80 epochs (patience: 150, remaining: 70)

EPOCH 188/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3687
  ‚Ä¢ Validation Loss: 0.3753
  ‚Ä¢ Learning Rate: 0.000553
    No improvement (current: 0.3753, best: 0.3358)
    ‚ö† No improvement for 81 epochs (patience: 150, remaining: 69)

EPOCH 189/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3486
  ‚Ä¢ Validation Loss: 0.3769
  ‚Ä¢ Learning Rate: 0.000545
    No improvement (current: 0.3769, best: 0.3358)
    ‚ö† No improvement for 82 epochs (patience: 150, remaining: 68)

EPOCH 190/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3434
  ‚Ä¢ Validation Loss: 0.3878
  ‚Ä¢ Learning Rate: 0.000538
    No improvement (current: 0.3878, best: 0.3358)
    ‚ö† No improvement for 83 epochs (patience: 150, remaining: 67)

EPOCH 191/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4116
  ‚Ä¢ Validation Loss: 0.5623
  ‚Ä¢ Learning Rate: 0.000530
    No improvement (current: 0.5623, best: 0.3358)
    ‚ö† No improvement for 84 epochs (patience: 150, remaining: 66)

EPOCH 192/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5923
  ‚Ä¢ Validation Loss: 0.5502
  ‚Ä¢ Learning Rate: 0.000523
    No improvement (current: 0.5502, best: 0.3358)
    ‚ö† No improvement for 85 epochs (patience: 150, remaining: 65)

EPOCH 193/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5727
  ‚Ä¢ Validation Loss: 0.5256
  ‚Ä¢ Learning Rate: 0.000515
    No improvement (current: 0.5256, best: 0.3358)
    ‚ö† No improvement for 86 epochs (patience: 150, remaining: 64)

EPOCH 194/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5277
  ‚Ä¢ Validation Loss: 0.4803
  ‚Ä¢ Learning Rate: 0.000508
    No improvement (current: 0.4803, best: 0.3358)
    ‚ö† No improvement for 87 epochs (patience: 150, remaining: 63)

EPOCH 195/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5403
  ‚Ä¢ Validation Loss: 0.5389
  ‚Ä¢ Learning Rate: 0.000500
    No improvement (current: 0.5389, best: 0.3358)
    ‚ö† No improvement for 88 epochs (patience: 150, remaining: 62)

EPOCH 196/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5372
  ‚Ä¢ Validation Loss: 0.4945
  ‚Ä¢ Learning Rate: 0.000493
    No improvement (current: 0.4945, best: 0.3358)
    ‚ö† No improvement for 89 epochs (patience: 150, remaining: 61)

EPOCH 197/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4997
  ‚Ä¢ Validation Loss: 0.4621
  ‚Ä¢ Learning Rate: 0.000486
    No improvement (current: 0.4621, best: 0.3358)
    ‚ö† No improvement for 90 epochs (patience: 150, remaining: 60)

EPOCH 198/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4697
  ‚Ä¢ Validation Loss: 0.4600
  ‚Ä¢ Learning Rate: 0.000478
    No improvement (current: 0.4600, best: 0.3358)
    ‚ö† No improvement for 91 epochs (patience: 150, remaining: 59)

EPOCH 199/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4633
  ‚Ä¢ Validation Loss: 0.4501
  ‚Ä¢ Learning Rate: 0.000471
    No improvement (current: 0.4501, best: 0.3358)
    ‚ö† No improvement for 92 epochs (patience: 150, remaining: 58)

EPOCH 200/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4558
  ‚Ä¢ Validation Loss: 0.4406
  ‚Ä¢ Learning Rate: 0.000463
   üíæ Periodic checkpoint saved: epoch_200.pth
    No improvement (current: 0.4406, best: 0.3358)
    ‚ö† No improvement for 93 epochs (patience: 150, remaining: 57)

EPOCH 201/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4435
  ‚Ä¢ Validation Loss: 0.4309
  ‚Ä¢ Learning Rate: 0.000456
    No improvement (current: 0.4309, best: 0.3358)
    ‚ö† No improvement for 94 epochs (patience: 150, remaining: 56)

EPOCH 202/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4197
  ‚Ä¢ Validation Loss: 0.4139
  ‚Ä¢ Learning Rate: 0.000448
    No improvement (current: 0.4139, best: 0.3358)
    ‚ö† No improvement for 95 epochs (patience: 150, remaining: 55)

EPOCH 203/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4025
  ‚Ä¢ Validation Loss: 0.4117
  ‚Ä¢ Learning Rate: 0.000441
    No improvement (current: 0.4117, best: 0.3358)
    ‚ö† No improvement for 96 epochs (patience: 150, remaining: 54)

EPOCH 204/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3963
  ‚Ä¢ Validation Loss: 0.4065
  ‚Ä¢ Learning Rate: 0.000433
    No improvement (current: 0.4065, best: 0.3358)
    ‚ö† No improvement for 97 epochs (patience: 150, remaining: 53)

EPOCH 205/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3880
  ‚Ä¢ Validation Loss: 0.3975
  ‚Ä¢ Learning Rate: 0.000426
    No improvement (current: 0.3975, best: 0.3358)
    ‚ö† No improvement for 98 epochs (patience: 150, remaining: 52)

EPOCH 206/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3763
  ‚Ä¢ Validation Loss: 0.3935
  ‚Ä¢ Learning Rate: 0.000419
    No improvement (current: 0.3935, best: 0.3358)
    ‚ö† No improvement for 99 epochs (patience: 150, remaining: 51)

EPOCH 207/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3723
  ‚Ä¢ Validation Loss: 0.3964
  ‚Ä¢ Learning Rate: 0.000411
    No improvement (current: 0.3964, best: 0.3358)
    ‚ö† No improvement for 100 epochs (patience: 150, remaining: 50)

EPOCH 208/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3793
  ‚Ä¢ Validation Loss: 0.4002
  ‚Ä¢ Learning Rate: 0.000404
    No improvement (current: 0.4002, best: 0.3358)
    ‚ö† No improvement for 101 epochs (patience: 150, remaining: 49)

EPOCH 209/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3780
  ‚Ä¢ Validation Loss: 0.3861
  ‚Ä¢ Learning Rate: 0.000397
    No improvement (current: 0.3861, best: 0.3358)
    ‚ö† No improvement for 102 epochs (patience: 150, remaining: 48)

EPOCH 210/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3676
  ‚Ä¢ Validation Loss: 0.4193
  ‚Ä¢ Learning Rate: 0.000389
    No improvement (current: 0.4193, best: 0.3358)
    ‚ö† No improvement for 103 epochs (patience: 150, remaining: 47)

EPOCH 211/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3715
  ‚Ä¢ Validation Loss: 0.3844
  ‚Ä¢ Learning Rate: 0.000382
    No improvement (current: 0.3844, best: 0.3358)
    ‚ö† No improvement for 104 epochs (patience: 150, remaining: 46)

EPOCH 212/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3518
  ‚Ä¢ Validation Loss: 0.3920
  ‚Ä¢ Learning Rate: 0.000375
    No improvement (current: 0.3920, best: 0.3358)
    ‚ö† No improvement for 105 epochs (patience: 150, remaining: 45)

EPOCH 213/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3540
  ‚Ä¢ Validation Loss: 0.4249
  ‚Ä¢ Learning Rate: 0.000368
    No improvement (current: 0.4249, best: 0.3358)
    ‚ö† No improvement for 106 epochs (patience: 150, remaining: 44)

EPOCH 214/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3803
  ‚Ä¢ Validation Loss: 0.3832
  ‚Ä¢ Learning Rate: 0.000360
    No improvement (current: 0.3832, best: 0.3358)
    ‚ö† No improvement for 107 epochs (patience: 150, remaining: 43)

EPOCH 215/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3527
  ‚Ä¢ Validation Loss: 0.3758
  ‚Ä¢ Learning Rate: 0.000353
    No improvement (current: 0.3758, best: 0.3358)
    ‚ö† No improvement for 108 epochs (patience: 150, remaining: 42)

EPOCH 216/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3474
  ‚Ä¢ Validation Loss: 0.3741
  ‚Ä¢ Learning Rate: 0.000346
    No improvement (current: 0.3741, best: 0.3358)
    ‚ö† No improvement for 109 epochs (patience: 150, remaining: 41)

EPOCH 217/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3401
  ‚Ä¢ Validation Loss: 0.3694
  ‚Ä¢ Learning Rate: 0.000339
    No improvement (current: 0.3694, best: 0.3358)
    ‚ö† No improvement for 110 epochs (patience: 150, remaining: 40)

EPOCH 218/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3596
  ‚Ä¢ Validation Loss: 0.3893
  ‚Ä¢ Learning Rate: 0.000332
    No improvement (current: 0.3893, best: 0.3358)
    ‚ö† No improvement for 111 epochs (patience: 150, remaining: 39)

EPOCH 219/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3541
  ‚Ä¢ Validation Loss: 0.3752
  ‚Ä¢ Learning Rate: 0.000325
    No improvement (current: 0.3752, best: 0.3358)
    ‚ö† No improvement for 112 epochs (patience: 150, remaining: 38)

EPOCH 220/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3363
  ‚Ä¢ Validation Loss: 0.3680
  ‚Ä¢ Learning Rate: 0.000318
    No improvement (current: 0.3680, best: 0.3358)
    ‚ö† No improvement for 113 epochs (patience: 150, remaining: 37)

EPOCH 221/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3374
  ‚Ä¢ Validation Loss: 0.3807
  ‚Ä¢ Learning Rate: 0.000311
    No improvement (current: 0.3807, best: 0.3358)
    ‚ö† No improvement for 114 epochs (patience: 150, remaining: 36)

EPOCH 222/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3337
  ‚Ä¢ Validation Loss: 0.3687
  ‚Ä¢ Learning Rate: 0.000304
    No improvement (current: 0.3687, best: 0.3358)
    ‚ö† No improvement for 115 epochs (patience: 150, remaining: 35)

EPOCH 223/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3315
  ‚Ä¢ Validation Loss: 0.3702
  ‚Ä¢ Learning Rate: 0.000297
    No improvement (current: 0.3702, best: 0.3358)
    ‚ö† No improvement for 116 epochs (patience: 150, remaining: 34)

EPOCH 224/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3472
  ‚Ä¢ Validation Loss: 0.4147
  ‚Ä¢ Learning Rate: 0.000290
    No improvement (current: 0.4147, best: 0.3358)
    ‚ö† No improvement for 117 epochs (patience: 150, remaining: 33)

EPOCH 225/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3443
  ‚Ä¢ Validation Loss: 0.3721
  ‚Ä¢ Learning Rate: 0.000284
    No improvement (current: 0.3721, best: 0.3358)
    ‚ö† No improvement for 118 epochs (patience: 150, remaining: 32)

EPOCH 226/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3824
  ‚Ä¢ Validation Loss: 0.4097
  ‚Ä¢ Learning Rate: 0.000277
    No improvement (current: 0.4097, best: 0.3358)
    ‚ö† No improvement for 119 epochs (patience: 150, remaining: 31)

EPOCH 227/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3609
  ‚Ä¢ Validation Loss: 0.3698
  ‚Ä¢ Learning Rate: 0.000270
    No improvement (current: 0.3698, best: 0.3358)
    ‚ö† No improvement for 120 epochs (patience: 150, remaining: 30)

EPOCH 228/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3297
  ‚Ä¢ Validation Loss: 0.3722
  ‚Ä¢ Learning Rate: 0.000264
    No improvement (current: 0.3722, best: 0.3358)
    ‚ö† No improvement for 121 epochs (patience: 150, remaining: 29)

EPOCH 229/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3460
  ‚Ä¢ Validation Loss: 0.3611
  ‚Ä¢ Learning Rate: 0.000257
    No improvement (current: 0.3611, best: 0.3358)
    ‚ö† No improvement for 122 epochs (patience: 150, remaining: 28)

EPOCH 230/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3251
  ‚Ä¢ Validation Loss: 0.3678
  ‚Ä¢ Learning Rate: 0.000251
    No improvement (current: 0.3678, best: 0.3358)
    ‚ö† No improvement for 123 epochs (patience: 150, remaining: 27)

EPOCH 231/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3249
  ‚Ä¢ Validation Loss: 0.3569
  ‚Ä¢ Learning Rate: 0.000244
    No improvement (current: 0.3569, best: 0.3358)
    ‚ö† No improvement for 124 epochs (patience: 150, remaining: 26)

EPOCH 232/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4213
  ‚Ä¢ Validation Loss: 0.4011
  ‚Ä¢ Learning Rate: 0.000238
    No improvement (current: 0.4011, best: 0.3358)
    ‚ö† No improvement for 125 epochs (patience: 150, remaining: 25)

EPOCH 233/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3691
  ‚Ä¢ Validation Loss: 0.3834
  ‚Ä¢ Learning Rate: 0.000232
    No improvement (current: 0.3834, best: 0.3358)
    ‚ö† No improvement for 126 epochs (patience: 150, remaining: 24)

EPOCH 234/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3541
  ‚Ä¢ Validation Loss: 0.3762
  ‚Ä¢ Learning Rate: 0.000225
    No improvement (current: 0.3762, best: 0.3358)
    ‚ö† No improvement for 127 epochs (patience: 150, remaining: 23)

EPOCH 235/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3523
  ‚Ä¢ Validation Loss: 0.3754
  ‚Ä¢ Learning Rate: 0.000219
    No improvement (current: 0.3754, best: 0.3358)
    ‚ö† No improvement for 128 epochs (patience: 150, remaining: 22)

EPOCH 236/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3346
  ‚Ä¢ Validation Loss: 0.3898
  ‚Ä¢ Learning Rate: 0.000213
    No improvement (current: 0.3898, best: 0.3358)
    ‚ö† No improvement for 129 epochs (patience: 150, remaining: 21)

EPOCH 237/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3615
  ‚Ä¢ Validation Loss: 0.3662
  ‚Ä¢ Learning Rate: 0.000207
    No improvement (current: 0.3662, best: 0.3358)
    ‚ö† No improvement for 130 epochs (patience: 150, remaining: 20)

EPOCH 238/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3340
  ‚Ä¢ Validation Loss: 0.3620
  ‚Ä¢ Learning Rate: 0.000201
    No improvement (current: 0.3620, best: 0.3358)
    ‚ö† No improvement for 131 epochs (patience: 150, remaining: 19)

EPOCH 239/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3273
  ‚Ä¢ Validation Loss: 0.3637
  ‚Ä¢ Learning Rate: 0.000195
    No improvement (current: 0.3637, best: 0.3358)
    ‚ö† No improvement for 132 epochs (patience: 150, remaining: 18)

EPOCH 240/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3645
  ‚Ä¢ Validation Loss: 0.4565
  ‚Ä¢ Learning Rate: 0.000189
    No improvement (current: 0.4565, best: 0.3358)
    ‚ö† No improvement for 133 epochs (patience: 150, remaining: 17)

EPOCH 241/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3561
  ‚Ä¢ Validation Loss: 0.3662
  ‚Ä¢ Learning Rate: 0.000183
    No improvement (current: 0.3662, best: 0.3358)
    ‚ö† No improvement for 134 epochs (patience: 150, remaining: 16)

EPOCH 242/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3336
  ‚Ä¢ Validation Loss: 0.3595
  ‚Ä¢ Learning Rate: 0.000177
    No improvement (current: 0.3595, best: 0.3358)
    ‚ö† No improvement for 135 epochs (patience: 150, remaining: 15)

EPOCH 243/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3248
  ‚Ä¢ Validation Loss: 0.3574
  ‚Ä¢ Learning Rate: 0.000172
    No improvement (current: 0.3574, best: 0.3358)
    ‚ö† No improvement for 136 epochs (patience: 150, remaining: 14)

EPOCH 244/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3268
  ‚Ä¢ Validation Loss: 0.3586
  ‚Ä¢ Learning Rate: 0.000166
    No improvement (current: 0.3586, best: 0.3358)
    ‚ö† No improvement for 137 epochs (patience: 150, remaining: 13)

EPOCH 245/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3235
  ‚Ä¢ Validation Loss: 0.3567
  ‚Ä¢ Learning Rate: 0.000161
    No improvement (current: 0.3567, best: 0.3358)
    ‚ö† No improvement for 138 epochs (patience: 150, remaining: 12)

EPOCH 246/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3216
  ‚Ä¢ Validation Loss: 0.3561
  ‚Ä¢ Learning Rate: 0.000155
    No improvement (current: 0.3561, best: 0.3358)
    ‚ö† No improvement for 139 epochs (patience: 150, remaining: 11)

EPOCH 247/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3221
  ‚Ä¢ Validation Loss: 0.3554
  ‚Ä¢ Learning Rate: 0.000150
    No improvement (current: 0.3554, best: 0.3358)
    ‚ö† No improvement for 140 epochs (patience: 150, remaining: 10)

EPOCH 248/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3196
  ‚Ä¢ Validation Loss: 0.3617
  ‚Ä¢ Learning Rate: 0.000145
    No improvement (current: 0.3617, best: 0.3358)
    ‚ö† No improvement for 141 epochs (patience: 150, remaining: 9)

EPOCH 249/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3184
  ‚Ä¢ Validation Loss: 0.3562
  ‚Ä¢ Learning Rate: 0.000139
    No improvement (current: 0.3562, best: 0.3358)
    ‚ö† No improvement for 142 epochs (patience: 150, remaining: 8)

EPOCH 250/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3162
  ‚Ä¢ Validation Loss: 0.3542
  ‚Ä¢ Learning Rate: 0.000134
    No improvement (current: 0.3542, best: 0.3358)
    ‚ö† No improvement for 143 epochs (patience: 150, remaining: 7)

EPOCH 251/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3186
  ‚Ä¢ Validation Loss: 0.3550
  ‚Ä¢ Learning Rate: 0.000129
    No improvement (current: 0.3550, best: 0.3358)
    ‚ö† No improvement for 144 epochs (patience: 150, remaining: 6)

EPOCH 252/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3144
  ‚Ä¢ Validation Loss: 0.3532
  ‚Ä¢ Learning Rate: 0.000124
    No improvement (current: 0.3532, best: 0.3358)
    ‚ö† No improvement for 145 epochs (patience: 150, remaining: 5)

EPOCH 253/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3151
  ‚Ä¢ Validation Loss: 0.3532
  ‚Ä¢ Learning Rate: 0.000119
    No improvement (current: 0.3532, best: 0.3358)
    ‚ö† No improvement for 146 epochs (patience: 150, remaining: 4)

EPOCH 254/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3118
  ‚Ä¢ Validation Loss: 0.3525
  ‚Ä¢ Learning Rate: 0.000115
    No improvement (current: 0.3525, best: 0.3358)
    ‚ö† No improvement for 147 epochs (patience: 150, remaining: 3)

EPOCH 255/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3145
  ‚Ä¢ Validation Loss: 0.3555
  ‚Ä¢ Learning Rate: 0.000110
    No improvement (current: 0.3555, best: 0.3358)
    ‚ö† No improvement for 148 epochs (patience: 150, remaining: 2)

EPOCH 256/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3064
  ‚Ä¢ Validation Loss: 0.3519
  ‚Ä¢ Learning Rate: 0.000105
    No improvement (current: 0.3519, best: 0.3358)
    ‚ö† No improvement for 149 epochs (patience: 150, remaining: 1)

EPOCH 257/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3088
  ‚Ä¢ Validation Loss: 0.3525
  ‚Ä¢ Learning Rate: 0.000101
    No improvement (current: 0.3525, best: 0.3358)
    ‚ö† No improvement for 150 epochs (patience: 150, remaining: 0)

================================================================================
EARLY STOPPING TRIGGERED!
================================================================================
Model has not improved for 150 consecutive epochs.
Stopping training at epoch 257.
Best validation loss achieved: 0.3358
================================================================================


================================================================================
TRAINING COMPLETED
================================================================================
Best Val Loss:  0.3358
Total Epochs:   257
Models Saved:   ./Result/a2/Latin16746
TensorBoard:    ./Result/a2/Latin16746/tensorboard_logs
================================================================================

[02:22:39] Training completed. Best val loss: 0.3358

=== TRAINING COMPLETED SUCCESSFULLY ===
Training Finished!

========================================================================
Testing Hybrid2 Baseline Model with Smart Skip Connections and Multi-Scale Aggregation: Latin16746
========================================================================
=== Historical Document Segmentation Testing ===

Using 6 classes for manuscript: Latin16746
Model: Hybrid2
Dataset: UDIADS_BIB
Manuscript: Latin16746
Test-Time Augmentation: Enabled
CRF post-processing: Enabled
  - DenseCRF with spatial and color pairwise potentials

================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder for Testing
================================================================================
================================================================================
üöÄ SIMPLE DECODER (Flag-Controlled Enhancements)
================================================================================
  ‚Ä¢ EfficientNet Variant: b4
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Enhancement Flags:
  ‚Ä¢ Deep Supervision: False
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: True
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: True
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Loaded checkpoint from epoch 106
Best validation loss: 0.3358
  ‚úÖ Model checkpoint loaded successfully (exact match)
Loaded checkpoint: best_model_latest.pth
Namespace(cfg=None, output_dir='./Result/a2/Latin16746', use_baseline=True, decoder='EfficientNet-B4', efficientnet_variant='b4', use_deep_supervision=False, use_cbam=False, use_smart_skip=True, use_cross_attn=False, use_multiscale_agg=True, use_groupnorm=True, use_batchnorm=False, use_pos_embed=True, dataset='UDIADS_BIB', manuscript='Latin16746', udiadsbib_root='../../U-DIADS-Bib-MS_patched', divahisdb_root='../../DivaHisDB', use_patched_data=True, num_classes=6, img_size=224, batch_size=24, is_savenii=True, test_save_dir='../predictions', use_crf=True, deterministic=1, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, use_tta=True)
Testing with checkpoint: best_model_latest.pth
Saving predictions to: ./Result/a2/Latin16746/predictions

=== Starting Testing ===
Dataset: UDIADS_BIB
Model: Hybrid2
Manuscript: Latin16746
Save predictions: True

Starting inference on UDIADS_BIB dataset
Found 1620 patches for Latin16746
Using Test-Time Augmentation (TTA) for improved accuracy
CRF post-processing: Enabled
  - DenseCRF with spatial and color pairwise potentials
Processing: 009 (54 patches)
Applying CRF post-processing to 009
CRF post-processing completed for 009
Completed: 009
Processing: 020 (54 patches)
Applying CRF post-processing to 020
CRF post-processing completed for 020
Completed: 020
Processing: 022 (54 patches)
Applying CRF post-processing to 022
CRF post-processing completed for 022
Completed: 022
Processing: 029 (54 patches)
Applying CRF post-processing to 029
CRF post-processing completed for 029
Completed: 029
Processing: 035 (54 patches)
Applying CRF post-processing to 035
CRF post-processing completed for 035
Completed: 035
Processing: 048 (54 patches)
Applying CRF post-processing to 048
CRF post-processing completed for 048
Completed: 048
Processing: 069 (54 patches)
Applying CRF post-processing to 069
CRF post-processing completed for 069
Completed: 069
Processing: 082 (54 patches)
Applying CRF post-processing to 082
CRF post-processing completed for 082
Completed: 082
Processing: 088 (54 patches)
Applying CRF post-processing to 088
CRF post-processing completed for 088
Completed: 088
Processing: 089 (54 patches)
Applying CRF post-processing to 089
CRF post-processing completed for 089
Completed: 089
Processing: 091 (54 patches)
Applying CRF post-processing to 091
CRF post-processing completed for 091
Completed: 091
Processing: 100 (54 patches)
Applying CRF post-processing to 100
CRF post-processing completed for 100
Completed: 100
Processing: 106 (54 patches)
Applying CRF post-processing to 106
CRF post-processing completed for 106
Completed: 106
Processing: 117 (54 patches)
Applying CRF post-processing to 117
CRF post-processing completed for 117
Completed: 117
Processing: 123 (54 patches)
Applying CRF post-processing to 123
CRF post-processing completed for 123
Completed: 123
Processing: 125 (54 patches)
Applying CRF post-processing to 125
CRF post-processing completed for 125
Completed: 125
Processing: 130 (54 patches)
Applying CRF post-processing to 130
CRF post-processing completed for 130
Completed: 130
Processing: 133 (54 patches)
Applying CRF post-processing to 133
CRF post-processing completed for 133
Completed: 133
Processing: 137 (54 patches)
Applying CRF post-processing to 137
CRF post-processing completed for 137
Completed: 137
Processing: 146 (54 patches)
Applying CRF post-processing to 146
CRF post-processing completed for 146
Completed: 146
Processing: 166 (54 patches)
Applying CRF post-processing to 166
CRF post-processing completed for 166
Completed: 166
Processing: 184 (54 patches)
Applying CRF post-processing to 184
CRF post-processing completed for 184
Completed: 184
Processing: 215 (54 patches)
Applying CRF post-processing to 215
CRF post-processing completed for 215
Completed: 215
Processing: 237 (54 patches)
Applying CRF post-processing to 237
CRF post-processing completed for 237
Completed: 237
Processing: 243 (54 patches)
Applying CRF post-processing to 243
CRF post-processing completed for 243
Completed: 243
Processing: 255 (54 patches)
Applying CRF post-processing to 255
CRF post-processing completed for 255
Completed: 255
Processing: 258 (54 patches)
Applying CRF post-processing to 258
CRF post-processing completed for 258
Completed: 258
Processing: 284 (54 patches)
Applying CRF post-processing to 284
CRF post-processing completed for 284
Completed: 284
Processing: 325 (54 patches)
Applying CRF post-processing to 325
CRF post-processing completed for 325
Completed: 325
Processing: 357 (54 patches)
Applying CRF post-processing to 357
CRF post-processing completed for 357
Completed: 357

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9834, Recall=0.9983, F1=0.9908, IoU=0.9817
Paratext       : Precision=0.9221, Recall=0.5929, F1=0.7218, IoU=0.5646
Decoration     : Precision=0.9933, Recall=0.8898, F1=0.9387, IoU=0.8845
Main Text      : Precision=0.9587, Recall=0.8880, F1=0.9220, IoU=0.8553
Title          : Precision=0.8747, Recall=0.6821, F1=0.7665, IoU=0.6214
Chapter Headings: Precision=0.9651, Recall=0.6047, F1=0.7435, IoU=0.5918

Mean metrics:
----------------------------------------
Mean Precision: 0.9495
Mean Recall: 0.7760
Mean F1-Score: 0.8472
Mean IoU: 0.7499

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9834, Recall=0.9983, F1=0.9908, IoU=0.9817
Paratext       : Precision=0.9221, Recall=0.5929, F1=0.7218, IoU=0.5646
Decoration     : Precision=0.9933, Recall=0.8898, F1=0.9387, IoU=0.8845
Main Text      : Precision=0.9587, Recall=0.8880, F1=0.9220, IoU=0.8553
Title          : Precision=0.8747, Recall=0.6821, F1=0.7665, IoU=0.6214
Chapter Headings: Precision=0.9651, Recall=0.6047, F1=0.7435, IoU=0.5918

Mean metrics:
----------------------------------------
Mean Precision: 0.9495
Mean Recall: 0.7760
Mean F1-Score: 0.8472
Mean IoU: 0.7499
Inference completed on 30 images

=== TESTING COMPLETED SUCCESSFULLY ===
Results saved to: ./Result/a2/Latin16746/predictions
==================================================

Calculating average metrics...
Looking for metrics files in: ./Result/a2
  ‚úó Metrics file not found: ./Result/a2/metrics_Latin2.json
  ‚úó Metrics file not found: ./Result/a2/metrics_Latin14396.json
  ‚úì Found metrics for Latin16746
  ‚úó Metrics file not found: ./Result/a2/metrics_Syr341.json

================================================================================
AVERAGE METRICS ACROSS 1 MANUSCRIPT(S)
================================================================================
Manuscripts: Latin16746
Missing: Latin2, Latin14396, Syr341
--------------------------------------------------------------------------------
Mean Precision: 0.9495
Mean Recall:    0.7760
Mean F1-Score:  0.8472
Mean IoU:       0.7499
================================================================================

========================================================================
Training Hybrid2 Baseline Model with Smart Skip Connections and Multi-Scale Aggregation: Syr341
========================================================================
Dataset: U-DIADS-Bib-MS_patched
Architecture: Swin Transformer Encoder ‚Üí 2 Swin Blocks Bottleneck ‚Üí Simple CNN Decoder
Decoder: Simple Decoder (EfficientNet-b4 channel configuration)

Components Enabled:
  ‚úì Swin Encoder (4 stages: 96‚Üí192‚Üí384‚Üí768 dim)
  ‚úì Bottleneck: 2 Swin Transformer blocks (768 dim, 24 heads)
  ‚úì Simple CNN Decoder (channels: [256, 128, 64, 32])
  ‚úì Smart Skip Connections
  ‚úì Multi-Scale Aggregation
  ‚úì Positional Embeddings (default: enabled)
  ‚úì GroupNorm (default normalization)

Components Disabled (baseline):
  ‚úó CBAM Attention
  ‚úó Smart Skip Connections
  ‚úó Cross-Attention Bottleneck
  ‚úó Multi-Scale Aggregation
  ‚úó BatchNorm
========================================================================
All arguments validated successfully!
Setting random seed to 1234 for reproducible training...
Setting up U-DIADS-Bib dataset...
Detected Syriaque341 manuscript: using 5 classes (no Chapter Headings)
Looking for images in: ../../U-DIADS-Bib-MS_patched/Syr341/Image/training
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Syr341/mask/training_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
Looking for images in: ../../U-DIADS-Bib-MS_patched/Syr341/Image/validation
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Syr341/mask/validation_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder
================================================================================
================================================================================
üöÄ SIMPLE DECODER (Flag-Controlled Enhancements)
================================================================================
  ‚Ä¢ EfficientNet Variant: b4
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Enhancement Flags:
  ‚Ä¢ Deep Supervision: False
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: True
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: True
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Model moved to CUDA
Model created successfully with 5 classes
DEBUG: args.output_dir = ./Result/a2/Syr341

=== Starting Training ===
Dataset: UDIADS_BIB
Model: Hybrid2
Batch size: 4
Max epochs: 300
Learning rate: 0.0001


================================================================================
TRAINING CONFIGURATION
================================================================================
Dataset: UDIADS_BIB
Model: Hybrid2
Batch Size: 4
Max Epochs: 300
Learning Rate: 0.0001
Number of Classes: 5
Output Directory: ./Result/a2/Syr341
Early Stopping Patience: 150 epochs
================================================================================

üìä Dataset Statistics:
   - Training samples: 540
   - Validation samples: 540
   - Batch size: 4
   - Steps per epoch: 135


================================================================================
COMPUTING CLASS WEIGHTS
================================================================================
Raw ENS weights: [9.99999990e-05 1.00964968e-04 9.99999990e-05 9.99999990e-05
 1.03734323e-04]

Class Distribution:
Class                Pixels          Frequency       Weight         
-----------------------------------------------------------------
0                        22,747,305        83.9538%         0.9907
1                            46,502         0.1716%         1.0002
2                         1,252,058         4.6210%         0.9907
3                         3,015,934        11.1309%         0.9907
4                            33,241         0.1227%         1.0277

Total pixels: 27,095,040.0
Beta: 0.9999
Smoothing: 0.0
Weight range: [0.9907, 1.0277]
================================================================================
üìà Class weights computed with ENS method (smoothing=0.1)
   Final weights: [0.9906889 1.0002488 0.9906889 0.9906889 1.0276845]

‚úì Loss functions created: CE (weighted, label_smoothing=0.1), Focal (Œ≥=2.0), Dice
  üìä OneCycleLR: 135 steps/epoch √ó 300 epochs = 40500 total steps
üöÄ Hybrid2 Best Practice: Differential Learning Rates
  üìä Encoder LR:     0.000010 (10x smaller, 119 params)
  üìä Bottleneck LR:  0.000050 (5x smaller, 26 params)
  üìä Decoder LR:     0.000100 (base LR, 84 params)
  ‚öôÔ∏è  Scheduler: OneCycleLR (Peak: 10x, Warmup: 30%, Cosine)
  ‚öôÔ∏è  Weight decay: Encoder=1e-3, Bottleneck=5e-3, Decoder=1e-2

üîç Checking for checkpoint at: ./Result/a2/Syr341/best_model_latest.pth
   Absolute path: /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid/Result/a2/Syr341/best_model_latest.pth
   File exists: False

================================================================================
STARTING TRAINING
================================================================================
Early stopping patience: 150 epochs
Learning rate scheduler: OneCycleLR (better convergence for transformers)
================================================================================

EPOCH 1/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5653
  ‚Ä¢ Validation Loss: 0.4698
  ‚Ä¢ Learning Rate: 0.000100
    ‚úì New best checkpoint saved! Val loss: 0.4698
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 2/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4563
  ‚Ä¢ Validation Loss: 0.4432
  ‚Ä¢ Learning Rate: 0.000101
    ‚úì New best checkpoint saved! Val loss: 0.4432
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 3/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4104
  ‚Ä¢ Validation Loss: 0.4012
  ‚Ä¢ Learning Rate: 0.000102
    ‚úì New best checkpoint saved! Val loss: 0.4012
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 4/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3949
  ‚Ä¢ Validation Loss: 0.3939
  ‚Ä¢ Learning Rate: 0.000104
    ‚úì New best checkpoint saved! Val loss: 0.3939
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 5/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3822
  ‚Ä¢ Validation Loss: 0.3862
  ‚Ä¢ Learning Rate: 0.000107
    ‚úì New best checkpoint saved! Val loss: 0.3862
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 6/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3844
  ‚Ä¢ Validation Loss: 0.3906
  ‚Ä¢ Learning Rate: 0.000110
    No improvement (current: 0.3906, best: 0.3862)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 7/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3750
  ‚Ä¢ Validation Loss: 0.3816
  ‚Ä¢ Learning Rate: 0.000113
    ‚úì New best checkpoint saved! Val loss: 0.3816
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 8/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3707
  ‚Ä¢ Validation Loss: 0.3810
  ‚Ä¢ Learning Rate: 0.000117
    ‚úì New best checkpoint saved! Val loss: 0.3810
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 9/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3695
  ‚Ä¢ Validation Loss: 0.3949
  ‚Ä¢ Learning Rate: 0.000122
    No improvement (current: 0.3949, best: 0.3810)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 10/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3671
  ‚Ä¢ Validation Loss: 0.3767
  ‚Ä¢ Learning Rate: 0.000127
    ‚úì New best checkpoint saved! Val loss: 0.3767
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 11/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3652
  ‚Ä¢ Validation Loss: 0.3748
  ‚Ä¢ Learning Rate: 0.000133
    ‚úì New best checkpoint saved! Val loss: 0.3748
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 12/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3578
  ‚Ä¢ Validation Loss: 0.3733
  ‚Ä¢ Learning Rate: 0.000139
    ‚úì New best checkpoint saved! Val loss: 0.3733
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 13/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3615
  ‚Ä¢ Validation Loss: 0.3759
  ‚Ä¢ Learning Rate: 0.000146
    No improvement (current: 0.3759, best: 0.3733)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 14/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3553
  ‚Ä¢ Validation Loss: 0.3764
  ‚Ä¢ Learning Rate: 0.000153
    No improvement (current: 0.3764, best: 0.3733)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 15/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3533
  ‚Ä¢ Validation Loss: 0.3688
  ‚Ä¢ Learning Rate: 0.000160
    ‚úì New best checkpoint saved! Val loss: 0.3688
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 16/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3524
  ‚Ä¢ Validation Loss: 0.3722
  ‚Ä¢ Learning Rate: 0.000168
    No improvement (current: 0.3722, best: 0.3688)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 17/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3561
  ‚Ä¢ Validation Loss: 0.3734
  ‚Ä¢ Learning Rate: 0.000177
    No improvement (current: 0.3734, best: 0.3688)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 18/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3542
  ‚Ä¢ Validation Loss: 0.3749
  ‚Ä¢ Learning Rate: 0.000186
    No improvement (current: 0.3749, best: 0.3688)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 19/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3543
  ‚Ä¢ Validation Loss: 0.3828
  ‚Ä¢ Learning Rate: 0.000195
    No improvement (current: 0.3828, best: 0.3688)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 20/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3511
  ‚Ä¢ Validation Loss: 0.3661
  ‚Ä¢ Learning Rate: 0.000205
    ‚úì New best checkpoint saved! Val loss: 0.3661
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 21/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3491
  ‚Ä¢ Validation Loss: 0.3665
  ‚Ä¢ Learning Rate: 0.000216
    No improvement (current: 0.3665, best: 0.3661)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 22/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3502
  ‚Ä¢ Validation Loss: 0.3655
  ‚Ä¢ Learning Rate: 0.000226
    ‚úì New best checkpoint saved! Val loss: 0.3655
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 23/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3440
  ‚Ä¢ Validation Loss: 0.3658
  ‚Ä¢ Learning Rate: 0.000237
    No improvement (current: 0.3658, best: 0.3655)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 24/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3399
  ‚Ä¢ Validation Loss: 0.3683
  ‚Ä¢ Learning Rate: 0.000249
    No improvement (current: 0.3683, best: 0.3655)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 25/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3434
  ‚Ä¢ Validation Loss: 0.3630
  ‚Ä¢ Learning Rate: 0.000261
    ‚úì New best checkpoint saved! Val loss: 0.3630
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 26/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3462
  ‚Ä¢ Validation Loss: 0.3629
  ‚Ä¢ Learning Rate: 0.000273
    ‚úì New best checkpoint saved! Val loss: 0.3629
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 27/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3447
  ‚Ä¢ Validation Loss: 0.3745
  ‚Ä¢ Learning Rate: 0.000286
    No improvement (current: 0.3745, best: 0.3629)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 28/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3442
  ‚Ä¢ Validation Loss: 0.3696
  ‚Ä¢ Learning Rate: 0.000298
    No improvement (current: 0.3696, best: 0.3629)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 29/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3436
  ‚Ä¢ Validation Loss: 0.3633
  ‚Ä¢ Learning Rate: 0.000312
    No improvement (current: 0.3633, best: 0.3629)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 30/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3438
  ‚Ä¢ Validation Loss: 0.3689
  ‚Ä¢ Learning Rate: 0.000325
    No improvement (current: 0.3689, best: 0.3629)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 31/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3421
  ‚Ä¢ Validation Loss: 0.3610
  ‚Ä¢ Learning Rate: 0.000339
    ‚úì New best checkpoint saved! Val loss: 0.3610
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 32/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3389
  ‚Ä¢ Validation Loss: 0.3641
  ‚Ä¢ Learning Rate: 0.000353
    No improvement (current: 0.3641, best: 0.3610)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 33/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3442
  ‚Ä¢ Validation Loss: 0.3623
  ‚Ä¢ Learning Rate: 0.000367
    No improvement (current: 0.3623, best: 0.3610)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 34/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3402
  ‚Ä¢ Validation Loss: 0.3667
  ‚Ä¢ Learning Rate: 0.000381
    No improvement (current: 0.3667, best: 0.3610)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 35/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3388
  ‚Ä¢ Validation Loss: 0.3615
  ‚Ä¢ Learning Rate: 0.000396
    No improvement (current: 0.3615, best: 0.3610)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 36/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3434
  ‚Ä¢ Validation Loss: 0.3611
  ‚Ä¢ Learning Rate: 0.000411
    No improvement (current: 0.3611, best: 0.3610)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 37/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3361
  ‚Ä¢ Validation Loss: 0.3645
  ‚Ä¢ Learning Rate: 0.000426
    No improvement (current: 0.3645, best: 0.3610)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 38/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3388
  ‚Ä¢ Validation Loss: 0.3690
  ‚Ä¢ Learning Rate: 0.000441
    No improvement (current: 0.3690, best: 0.3610)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 39/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3450
  ‚Ä¢ Validation Loss: 0.3618
  ‚Ä¢ Learning Rate: 0.000456
    No improvement (current: 0.3618, best: 0.3610)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 40/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3412
  ‚Ä¢ Validation Loss: 0.3618
  ‚Ä¢ Learning Rate: 0.000472
    No improvement (current: 0.3618, best: 0.3610)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 41/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3379
  ‚Ä¢ Validation Loss: 0.3670
  ‚Ä¢ Learning Rate: 0.000487
    No improvement (current: 0.3670, best: 0.3610)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 42/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3399
  ‚Ä¢ Validation Loss: 0.3659
  ‚Ä¢ Learning Rate: 0.000503
    No improvement (current: 0.3659, best: 0.3610)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 43/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3357
  ‚Ä¢ Validation Loss: 0.3644
  ‚Ä¢ Learning Rate: 0.000519
    No improvement (current: 0.3644, best: 0.3610)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 44/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3399
  ‚Ä¢ Validation Loss: 0.3653
  ‚Ä¢ Learning Rate: 0.000534
    No improvement (current: 0.3653, best: 0.3610)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 45/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3399
  ‚Ä¢ Validation Loss: 0.3650
  ‚Ä¢ Learning Rate: 0.000550
    No improvement (current: 0.3650, best: 0.3610)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 46/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3444
  ‚Ä¢ Validation Loss: 0.3713
  ‚Ä¢ Learning Rate: 0.000566
    No improvement (current: 0.3713, best: 0.3610)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 47/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3342
  ‚Ä¢ Validation Loss: 0.3615
  ‚Ä¢ Learning Rate: 0.000581
    No improvement (current: 0.3615, best: 0.3610)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 48/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3322
  ‚Ä¢ Validation Loss: 0.3640
  ‚Ä¢ Learning Rate: 0.000597
    No improvement (current: 0.3640, best: 0.3610)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 49/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3308
  ‚Ä¢ Validation Loss: 0.3622
  ‚Ä¢ Learning Rate: 0.000613
    No improvement (current: 0.3622, best: 0.3610)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 50/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3359
  ‚Ä¢ Validation Loss: 0.3665
  ‚Ä¢ Learning Rate: 0.000628
    No improvement (current: 0.3665, best: 0.3610)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 51/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3339
  ‚Ä¢ Validation Loss: 0.3611
  ‚Ä¢ Learning Rate: 0.000644
    No improvement (current: 0.3611, best: 0.3610)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 52/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3343
  ‚Ä¢ Validation Loss: 0.3587
  ‚Ä¢ Learning Rate: 0.000659
    ‚úì New best checkpoint saved! Val loss: 0.3587
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 53/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3347
  ‚Ä¢ Validation Loss: 0.3583
  ‚Ä¢ Learning Rate: 0.000674
    ‚úì New best checkpoint saved! Val loss: 0.3583
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 54/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3353
  ‚Ä¢ Validation Loss: 0.3687
  ‚Ä¢ Learning Rate: 0.000689
    No improvement (current: 0.3687, best: 0.3583)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 55/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3407
  ‚Ä¢ Validation Loss: 0.3630
  ‚Ä¢ Learning Rate: 0.000704
    No improvement (current: 0.3630, best: 0.3583)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 56/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3361
  ‚Ä¢ Validation Loss: 0.3607
  ‚Ä¢ Learning Rate: 0.000719
    No improvement (current: 0.3607, best: 0.3583)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 57/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3342
  ‚Ä¢ Validation Loss: 0.3604
  ‚Ä¢ Learning Rate: 0.000733
    No improvement (current: 0.3604, best: 0.3583)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 58/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3359
  ‚Ä¢ Validation Loss: 0.3620
  ‚Ä¢ Learning Rate: 0.000747
    No improvement (current: 0.3620, best: 0.3583)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 59/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3357
  ‚Ä¢ Validation Loss: 0.3662
  ‚Ä¢ Learning Rate: 0.000761
    No improvement (current: 0.3662, best: 0.3583)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 60/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3349
  ‚Ä¢ Validation Loss: 0.3604
  ‚Ä¢ Learning Rate: 0.000775
    No improvement (current: 0.3604, best: 0.3583)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 61/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3296
  ‚Ä¢ Validation Loss: 0.3619
  ‚Ä¢ Learning Rate: 0.000789
    No improvement (current: 0.3619, best: 0.3583)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 62/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3345
  ‚Ä¢ Validation Loss: 0.3616
  ‚Ä¢ Learning Rate: 0.000802
    No improvement (current: 0.3616, best: 0.3583)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 63/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3264
  ‚Ä¢ Validation Loss: 0.3588
  ‚Ä¢ Learning Rate: 0.000815
    No improvement (current: 0.3588, best: 0.3583)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 64/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3321
  ‚Ä¢ Validation Loss: 0.3616
  ‚Ä¢ Learning Rate: 0.000827
    No improvement (current: 0.3616, best: 0.3583)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 65/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3323
  ‚Ä¢ Validation Loss: 0.3581
  ‚Ä¢ Learning Rate: 0.000839
    ‚úì New best checkpoint saved! Val loss: 0.3581
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 66/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3285
  ‚Ä¢ Validation Loss: 0.3631
  ‚Ä¢ Learning Rate: 0.000851
    No improvement (current: 0.3631, best: 0.3581)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 67/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3363
  ‚Ä¢ Validation Loss: 0.3594
  ‚Ä¢ Learning Rate: 0.000863
    No improvement (current: 0.3594, best: 0.3581)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 68/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3269
  ‚Ä¢ Validation Loss: 0.3712
  ‚Ä¢ Learning Rate: 0.000874
    No improvement (current: 0.3712, best: 0.3581)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 69/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3308
  ‚Ä¢ Validation Loss: 0.3569
  ‚Ä¢ Learning Rate: 0.000884
    ‚úì New best checkpoint saved! Val loss: 0.3569
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 70/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3325
  ‚Ä¢ Validation Loss: 0.3605
  ‚Ä¢ Learning Rate: 0.000895
    No improvement (current: 0.3605, best: 0.3569)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 71/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3254
  ‚Ä¢ Validation Loss: 0.3577
  ‚Ä¢ Learning Rate: 0.000905
    No improvement (current: 0.3577, best: 0.3569)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 72/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3266
  ‚Ä¢ Validation Loss: 0.3592
  ‚Ä¢ Learning Rate: 0.000914
    No improvement (current: 0.3592, best: 0.3569)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 73/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3299
  ‚Ä¢ Validation Loss: 0.3605
  ‚Ä¢ Learning Rate: 0.000923
    No improvement (current: 0.3605, best: 0.3569)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 74/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3258
  ‚Ä¢ Validation Loss: 0.3582
  ‚Ä¢ Learning Rate: 0.000932
    No improvement (current: 0.3582, best: 0.3569)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 75/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3226
  ‚Ä¢ Validation Loss: 0.3580
  ‚Ä¢ Learning Rate: 0.000940
    No improvement (current: 0.3580, best: 0.3569)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 76/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3221
  ‚Ä¢ Validation Loss: 0.3605
  ‚Ä¢ Learning Rate: 0.000947
    No improvement (current: 0.3605, best: 0.3569)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 77/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3285
  ‚Ä¢ Validation Loss: 0.3597
  ‚Ä¢ Learning Rate: 0.000955
    No improvement (current: 0.3597, best: 0.3569)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 78/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3253
  ‚Ä¢ Validation Loss: 0.3653
  ‚Ä¢ Learning Rate: 0.000961
    No improvement (current: 0.3653, best: 0.3569)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 79/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3250
  ‚Ä¢ Validation Loss: 0.3547
  ‚Ä¢ Learning Rate: 0.000967
    ‚úì New best checkpoint saved! Val loss: 0.3547
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 80/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3202
  ‚Ä¢ Validation Loss: 0.3548
  ‚Ä¢ Learning Rate: 0.000973
    No improvement (current: 0.3548, best: 0.3547)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 81/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3190
  ‚Ä¢ Validation Loss: 0.3545
  ‚Ä¢ Learning Rate: 0.000978
    ‚úì New best checkpoint saved! Val loss: 0.3545
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 82/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3186
  ‚Ä¢ Validation Loss: 0.3545
  ‚Ä¢ Learning Rate: 0.000983
    ‚úì New best checkpoint saved! Val loss: 0.3545
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 83/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3183
  ‚Ä¢ Validation Loss: 0.3544
  ‚Ä¢ Learning Rate: 0.000987
    ‚úì New best checkpoint saved! Val loss: 0.3544
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 84/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3181
  ‚Ä¢ Validation Loss: 0.3544
  ‚Ä¢ Learning Rate: 0.000990
    ‚úì New best checkpoint saved! Val loss: 0.3544
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 85/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3168
  ‚Ä¢ Validation Loss: 0.3543
  ‚Ä¢ Learning Rate: 0.000993
    ‚úì New best checkpoint saved! Val loss: 0.3543
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 86/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3173
  ‚Ä¢ Validation Loss: 0.3543
  ‚Ä¢ Learning Rate: 0.000996
    No improvement (current: 0.3543, best: 0.3543)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 87/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3156
  ‚Ä¢ Validation Loss: 0.3543
  ‚Ä¢ Learning Rate: 0.000998
    No improvement (current: 0.3543, best: 0.3543)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 88/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3182
  ‚Ä¢ Validation Loss: 0.3543
  ‚Ä¢ Learning Rate: 0.000999
    ‚úì New best checkpoint saved! Val loss: 0.3543
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 89/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3181
  ‚Ä¢ Validation Loss: 0.3543
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.3543, best: 0.3543)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 90/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3186
  ‚Ä¢ Validation Loss: 0.3543
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.3543, best: 0.3543)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 91/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3318
  ‚Ä¢ Validation Loss: 0.4062
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.4062, best: 0.3543)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 92/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3584
  ‚Ä¢ Validation Loss: 0.3666
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.3666, best: 0.3543)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 93/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3376
  ‚Ä¢ Validation Loss: 0.3582
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.3582, best: 0.3543)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 94/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3332
  ‚Ä¢ Validation Loss: 0.3682
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.3682, best: 0.3543)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 95/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3285
  ‚Ä¢ Validation Loss: 0.3579
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.3579, best: 0.3543)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 96/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3254
  ‚Ä¢ Validation Loss: 0.3613
  ‚Ä¢ Learning Rate: 0.000998
    No improvement (current: 0.3613, best: 0.3543)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 97/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3253
  ‚Ä¢ Validation Loss: 0.3555
  ‚Ä¢ Learning Rate: 0.000997
    No improvement (current: 0.3555, best: 0.3543)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 98/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3246
  ‚Ä¢ Validation Loss: 0.3571
  ‚Ä¢ Learning Rate: 0.000996
    No improvement (current: 0.3571, best: 0.3543)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 99/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3254
  ‚Ä¢ Validation Loss: 0.3566
  ‚Ä¢ Learning Rate: 0.000995
    No improvement (current: 0.3566, best: 0.3543)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 100/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3415
  ‚Ä¢ Validation Loss: 0.3614
  ‚Ä¢ Learning Rate: 0.000994
   üíæ Periodic checkpoint saved: epoch_100.pth
    No improvement (current: 0.3614, best: 0.3543)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 101/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3202
  ‚Ä¢ Validation Loss: 0.3573
  ‚Ä¢ Learning Rate: 0.000993
    No improvement (current: 0.3573, best: 0.3543)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 102/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3253
  ‚Ä¢ Validation Loss: 0.3591
  ‚Ä¢ Learning Rate: 0.000992
    No improvement (current: 0.3591, best: 0.3543)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 103/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3307
  ‚Ä¢ Validation Loss: 0.3750
  ‚Ä¢ Learning Rate: 0.000991
    No improvement (current: 0.3750, best: 0.3543)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 104/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3683
  ‚Ä¢ Validation Loss: 0.3609
  ‚Ä¢ Learning Rate: 0.000989
    No improvement (current: 0.3609, best: 0.3543)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 105/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3251
  ‚Ä¢ Validation Loss: 0.3584
  ‚Ä¢ Learning Rate: 0.000987
    No improvement (current: 0.3584, best: 0.3543)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 106/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3211
  ‚Ä¢ Validation Loss: 0.3555
  ‚Ä¢ Learning Rate: 0.000986
    No improvement (current: 0.3555, best: 0.3543)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 107/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3189
  ‚Ä¢ Validation Loss: 0.3569
  ‚Ä¢ Learning Rate: 0.000984
    No improvement (current: 0.3569, best: 0.3543)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 108/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3152
  ‚Ä¢ Validation Loss: 0.3580
  ‚Ä¢ Learning Rate: 0.000982
    No improvement (current: 0.3580, best: 0.3543)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 109/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3306
  ‚Ä¢ Validation Loss: 0.3572
  ‚Ä¢ Learning Rate: 0.000980
    No improvement (current: 0.3572, best: 0.3543)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 110/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3503
  ‚Ä¢ Validation Loss: 0.3577
  ‚Ä¢ Learning Rate: 0.000978
    No improvement (current: 0.3577, best: 0.3543)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 111/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3243
  ‚Ä¢ Validation Loss: 0.3619
  ‚Ä¢ Learning Rate: 0.000976
    No improvement (current: 0.3619, best: 0.3543)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 112/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3347
  ‚Ä¢ Validation Loss: 0.3649
  ‚Ä¢ Learning Rate: 0.000973
    No improvement (current: 0.3649, best: 0.3543)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 113/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4395
  ‚Ä¢ Validation Loss: 0.3778
  ‚Ä¢ Learning Rate: 0.000971
    No improvement (current: 0.3778, best: 0.3543)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 114/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3543
  ‚Ä¢ Validation Loss: 0.3803
  ‚Ä¢ Learning Rate: 0.000968
    No improvement (current: 0.3803, best: 0.3543)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 115/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3528
  ‚Ä¢ Validation Loss: 0.3633
  ‚Ä¢ Learning Rate: 0.000965
    No improvement (current: 0.3633, best: 0.3543)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 116/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3363
  ‚Ä¢ Validation Loss: 0.3615
  ‚Ä¢ Learning Rate: 0.000963
    No improvement (current: 0.3615, best: 0.3543)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 117/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3296
  ‚Ä¢ Validation Loss: 0.3605
  ‚Ä¢ Learning Rate: 0.000960
    No improvement (current: 0.3605, best: 0.3543)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 118/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3323
  ‚Ä¢ Validation Loss: 0.3601
  ‚Ä¢ Learning Rate: 0.000957
    No improvement (current: 0.3601, best: 0.3543)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 119/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3284
  ‚Ä¢ Validation Loss: 0.3598
  ‚Ä¢ Learning Rate: 0.000954
    No improvement (current: 0.3598, best: 0.3543)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 120/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3310
  ‚Ä¢ Validation Loss: 0.3596
  ‚Ä¢ Learning Rate: 0.000951
    No improvement (current: 0.3596, best: 0.3543)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 121/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3304
  ‚Ä¢ Validation Loss: 0.3593
  ‚Ä¢ Learning Rate: 0.000947
    No improvement (current: 0.3593, best: 0.3543)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 122/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3267
  ‚Ä¢ Validation Loss: 0.3592
  ‚Ä¢ Learning Rate: 0.000944
    No improvement (current: 0.3592, best: 0.3543)
    ‚ö† No improvement for 34 epochs (patience: 150, remaining: 116)

EPOCH 123/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3299
  ‚Ä¢ Validation Loss: 0.3590
  ‚Ä¢ Learning Rate: 0.000940
    No improvement (current: 0.3590, best: 0.3543)
    ‚ö† No improvement for 35 epochs (patience: 150, remaining: 115)

EPOCH 124/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3316
  ‚Ä¢ Validation Loss: 0.3588
  ‚Ä¢ Learning Rate: 0.000937
    No improvement (current: 0.3588, best: 0.3543)
    ‚ö† No improvement for 36 epochs (patience: 150, remaining: 114)

EPOCH 125/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3295
  ‚Ä¢ Validation Loss: 0.3590
  ‚Ä¢ Learning Rate: 0.000933
    No improvement (current: 0.3590, best: 0.3543)
    ‚ö† No improvement for 37 epochs (patience: 150, remaining: 113)

EPOCH 126/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3292
  ‚Ä¢ Validation Loss: 0.3587
  ‚Ä¢ Learning Rate: 0.000929
    No improvement (current: 0.3587, best: 0.3543)
    ‚ö† No improvement for 38 epochs (patience: 150, remaining: 112)

EPOCH 127/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3284
  ‚Ä¢ Validation Loss: 0.3587
  ‚Ä¢ Learning Rate: 0.000925
    No improvement (current: 0.3587, best: 0.3543)
    ‚ö† No improvement for 39 epochs (patience: 150, remaining: 111)

EPOCH 128/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3279
  ‚Ä¢ Validation Loss: 0.3586
  ‚Ä¢ Learning Rate: 0.000921
    No improvement (current: 0.3586, best: 0.3543)
    ‚ö† No improvement for 40 epochs (patience: 150, remaining: 110)

EPOCH 129/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3289
  ‚Ä¢ Validation Loss: 0.3581
  ‚Ä¢ Learning Rate: 0.000917
    No improvement (current: 0.3581, best: 0.3543)
    ‚ö† No improvement for 41 epochs (patience: 150, remaining: 109)

EPOCH 130/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3304
  ‚Ä¢ Validation Loss: 0.3580
  ‚Ä¢ Learning Rate: 0.000913
    No improvement (current: 0.3580, best: 0.3543)
    ‚ö† No improvement for 42 epochs (patience: 150, remaining: 108)

EPOCH 131/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3291
  ‚Ä¢ Validation Loss: 0.3578
  ‚Ä¢ Learning Rate: 0.000909
    No improvement (current: 0.3578, best: 0.3543)
    ‚ö† No improvement for 43 epochs (patience: 150, remaining: 107)

EPOCH 132/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3249
  ‚Ä¢ Validation Loss: 0.3577
  ‚Ä¢ Learning Rate: 0.000905
    No improvement (current: 0.3577, best: 0.3543)
    ‚ö† No improvement for 44 epochs (patience: 150, remaining: 106)

EPOCH 133/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3269
  ‚Ä¢ Validation Loss: 0.3575
  ‚Ä¢ Learning Rate: 0.000900
    No improvement (current: 0.3575, best: 0.3543)
    ‚ö† No improvement for 45 epochs (patience: 150, remaining: 105)

EPOCH 134/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3273
  ‚Ä¢ Validation Loss: 0.3575
  ‚Ä¢ Learning Rate: 0.000896
    No improvement (current: 0.3575, best: 0.3543)
    ‚ö† No improvement for 46 epochs (patience: 150, remaining: 104)

EPOCH 135/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3278
  ‚Ä¢ Validation Loss: 0.3574
  ‚Ä¢ Learning Rate: 0.000891
    No improvement (current: 0.3574, best: 0.3543)
    ‚ö† No improvement for 47 epochs (patience: 150, remaining: 103)

EPOCH 136/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3270
  ‚Ä¢ Validation Loss: 0.3573
  ‚Ä¢ Learning Rate: 0.000886
    No improvement (current: 0.3573, best: 0.3543)
    ‚ö† No improvement for 48 epochs (patience: 150, remaining: 102)

EPOCH 137/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3245
  ‚Ä¢ Validation Loss: 0.3573
  ‚Ä¢ Learning Rate: 0.000881
    No improvement (current: 0.3573, best: 0.3543)
    ‚ö† No improvement for 49 epochs (patience: 150, remaining: 101)

EPOCH 138/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3273
  ‚Ä¢ Validation Loss: 0.3572
  ‚Ä¢ Learning Rate: 0.000877
    No improvement (current: 0.3572, best: 0.3543)
    ‚ö† No improvement for 50 epochs (patience: 150, remaining: 100)

EPOCH 139/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3239
  ‚Ä¢ Validation Loss: 0.3572
  ‚Ä¢ Learning Rate: 0.000872
    No improvement (current: 0.3572, best: 0.3543)
    ‚ö† No improvement for 51 epochs (patience: 150, remaining: 99)

EPOCH 140/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3266
  ‚Ä¢ Validation Loss: 0.3571
  ‚Ä¢ Learning Rate: 0.000867
    No improvement (current: 0.3571, best: 0.3543)
    ‚ö† No improvement for 52 epochs (patience: 150, remaining: 98)

EPOCH 141/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3288
  ‚Ä¢ Validation Loss: 0.3568
  ‚Ä¢ Learning Rate: 0.000861
    No improvement (current: 0.3568, best: 0.3543)
    ‚ö† No improvement for 53 epochs (patience: 150, remaining: 97)

EPOCH 142/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3275
  ‚Ä¢ Validation Loss: 0.3568
  ‚Ä¢ Learning Rate: 0.000856
    No improvement (current: 0.3568, best: 0.3543)
    ‚ö† No improvement for 54 epochs (patience: 150, remaining: 96)

EPOCH 143/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3266
  ‚Ä¢ Validation Loss: 0.3570
  ‚Ä¢ Learning Rate: 0.000851
    No improvement (current: 0.3570, best: 0.3543)
    ‚ö† No improvement for 55 epochs (patience: 150, remaining: 95)

EPOCH 144/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3226
  ‚Ä¢ Validation Loss: 0.3565
  ‚Ä¢ Learning Rate: 0.000846
    No improvement (current: 0.3565, best: 0.3543)
    ‚ö† No improvement for 56 epochs (patience: 150, remaining: 94)

EPOCH 145/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3240
  ‚Ä¢ Validation Loss: 0.3563
  ‚Ä¢ Learning Rate: 0.000840
    No improvement (current: 0.3563, best: 0.3543)
    ‚ö† No improvement for 57 epochs (patience: 150, remaining: 93)

EPOCH 146/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3222
  ‚Ä¢ Validation Loss: 0.3565
  ‚Ä¢ Learning Rate: 0.000835
    No improvement (current: 0.3565, best: 0.3543)
    ‚ö† No improvement for 58 epochs (patience: 150, remaining: 92)

EPOCH 147/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3229
  ‚Ä¢ Validation Loss: 0.3560
  ‚Ä¢ Learning Rate: 0.000829
    No improvement (current: 0.3560, best: 0.3543)
    ‚ö† No improvement for 59 epochs (patience: 150, remaining: 91)

EPOCH 148/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3222
  ‚Ä¢ Validation Loss: 0.3562
  ‚Ä¢ Learning Rate: 0.000823
    No improvement (current: 0.3562, best: 0.3543)
    ‚ö† No improvement for 60 epochs (patience: 150, remaining: 90)

EPOCH 149/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3233
  ‚Ä¢ Validation Loss: 0.3560
  ‚Ä¢ Learning Rate: 0.000818
    No improvement (current: 0.3560, best: 0.3543)
    ‚ö† No improvement for 61 epochs (patience: 150, remaining: 89)

EPOCH 150/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4996
  ‚Ä¢ Validation Loss: 0.5061
  ‚Ä¢ Learning Rate: 0.000812
    No improvement (current: 0.5061, best: 0.3543)
    ‚ö† No improvement for 62 epochs (patience: 150, remaining: 88)

EPOCH 151/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5310
  ‚Ä¢ Validation Loss: 0.4915
  ‚Ä¢ Learning Rate: 0.000806
    No improvement (current: 0.4915, best: 0.3543)
    ‚ö† No improvement for 63 epochs (patience: 150, remaining: 87)

EPOCH 152/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5075
  ‚Ä¢ Validation Loss: 0.4756
  ‚Ä¢ Learning Rate: 0.000800
    No improvement (current: 0.4756, best: 0.3543)
    ‚ö† No improvement for 64 epochs (patience: 150, remaining: 86)

EPOCH 153/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4953
  ‚Ä¢ Validation Loss: 0.4682
  ‚Ä¢ Learning Rate: 0.000794
    No improvement (current: 0.4682, best: 0.3543)
    ‚ö† No improvement for 65 epochs (patience: 150, remaining: 85)

EPOCH 154/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4866
  ‚Ä¢ Validation Loss: 0.4625
  ‚Ä¢ Learning Rate: 0.000788
    No improvement (current: 0.4625, best: 0.3543)
    ‚ö† No improvement for 66 epochs (patience: 150, remaining: 84)

EPOCH 155/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4763
  ‚Ä¢ Validation Loss: 0.4558
  ‚Ä¢ Learning Rate: 0.000782
    No improvement (current: 0.4558, best: 0.3543)
    ‚ö† No improvement for 67 epochs (patience: 150, remaining: 83)

EPOCH 156/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4650
  ‚Ä¢ Validation Loss: 0.4495
  ‚Ä¢ Learning Rate: 0.000776
    No improvement (current: 0.4495, best: 0.3543)
    ‚ö† No improvement for 68 epochs (patience: 150, remaining: 82)

EPOCH 157/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4608
  ‚Ä¢ Validation Loss: 0.4475
  ‚Ä¢ Learning Rate: 0.000769
    No improvement (current: 0.4475, best: 0.3543)
    ‚ö† No improvement for 69 epochs (patience: 150, remaining: 81)

EPOCH 158/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4663
  ‚Ä¢ Validation Loss: 0.4387
  ‚Ä¢ Learning Rate: 0.000763
    No improvement (current: 0.4387, best: 0.3543)
    ‚ö† No improvement for 70 epochs (patience: 150, remaining: 80)

EPOCH 159/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4400
  ‚Ä¢ Validation Loss: 0.4335
  ‚Ä¢ Learning Rate: 0.000757
    No improvement (current: 0.4335, best: 0.3543)
    ‚ö† No improvement for 71 epochs (patience: 150, remaining: 79)

EPOCH 160/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4313
  ‚Ä¢ Validation Loss: 0.4276
  ‚Ä¢ Learning Rate: 0.000750
    No improvement (current: 0.4276, best: 0.3543)
    ‚ö† No improvement for 72 epochs (patience: 150, remaining: 78)

EPOCH 161/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4292
  ‚Ä¢ Validation Loss: 0.4242
  ‚Ä¢ Learning Rate: 0.000744
    No improvement (current: 0.4242, best: 0.3543)
    ‚ö† No improvement for 73 epochs (patience: 150, remaining: 77)

EPOCH 162/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4240
  ‚Ä¢ Validation Loss: 0.4220
  ‚Ä¢ Learning Rate: 0.000737
    No improvement (current: 0.4220, best: 0.3543)
    ‚ö† No improvement for 74 epochs (patience: 150, remaining: 76)

EPOCH 163/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4194
  ‚Ä¢ Validation Loss: 0.4179
  ‚Ä¢ Learning Rate: 0.000731
    No improvement (current: 0.4179, best: 0.3543)
    ‚ö† No improvement for 75 epochs (patience: 150, remaining: 75)

EPOCH 164/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4180
  ‚Ä¢ Validation Loss: 0.4166
  ‚Ä¢ Learning Rate: 0.000724
    No improvement (current: 0.4166, best: 0.3543)
    ‚ö† No improvement for 76 epochs (patience: 150, remaining: 74)

EPOCH 165/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4108
  ‚Ä¢ Validation Loss: 0.4125
  ‚Ä¢ Learning Rate: 0.000717
    No improvement (current: 0.4125, best: 0.3543)
    ‚ö† No improvement for 77 epochs (patience: 150, remaining: 73)

EPOCH 166/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4072
  ‚Ä¢ Validation Loss: 0.4104
  ‚Ä¢ Learning Rate: 0.000710
    No improvement (current: 0.4104, best: 0.3543)
    ‚ö† No improvement for 78 epochs (patience: 150, remaining: 72)

EPOCH 167/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4050
  ‚Ä¢ Validation Loss: 0.4071
  ‚Ä¢ Learning Rate: 0.000704
    No improvement (current: 0.4071, best: 0.3543)
    ‚ö† No improvement for 79 epochs (patience: 150, remaining: 71)

EPOCH 168/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4020
  ‚Ä¢ Validation Loss: 0.4059
  ‚Ä¢ Learning Rate: 0.000697
    No improvement (current: 0.4059, best: 0.3543)
    ‚ö† No improvement for 80 epochs (patience: 150, remaining: 70)

EPOCH 169/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3962
  ‚Ä¢ Validation Loss: 0.4067
  ‚Ä¢ Learning Rate: 0.000690
    No improvement (current: 0.4067, best: 0.3543)
    ‚ö† No improvement for 81 epochs (patience: 150, remaining: 69)

EPOCH 170/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3947
  ‚Ä¢ Validation Loss: 0.4016
  ‚Ä¢ Learning Rate: 0.000683
    No improvement (current: 0.4016, best: 0.3543)
    ‚ö† No improvement for 82 epochs (patience: 150, remaining: 68)

EPOCH 171/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3925
  ‚Ä¢ Validation Loss: 0.3976
  ‚Ä¢ Learning Rate: 0.000676
    No improvement (current: 0.3976, best: 0.3543)
    ‚ö† No improvement for 83 epochs (patience: 150, remaining: 67)

EPOCH 172/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3897
  ‚Ä¢ Validation Loss: 0.3969
  ‚Ä¢ Learning Rate: 0.000669
    No improvement (current: 0.3969, best: 0.3543)
    ‚ö† No improvement for 84 epochs (patience: 150, remaining: 66)

EPOCH 173/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3864
  ‚Ä¢ Validation Loss: 0.3937
  ‚Ä¢ Learning Rate: 0.000662
    No improvement (current: 0.3937, best: 0.3543)
    ‚ö† No improvement for 85 epochs (patience: 150, remaining: 65)

EPOCH 174/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3844
  ‚Ä¢ Validation Loss: 0.3914
  ‚Ä¢ Learning Rate: 0.000655
    No improvement (current: 0.3914, best: 0.3543)
    ‚ö† No improvement for 86 epochs (patience: 150, remaining: 64)

EPOCH 175/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3804
  ‚Ä¢ Validation Loss: 0.3897
  ‚Ä¢ Learning Rate: 0.000648
    No improvement (current: 0.3897, best: 0.3543)
    ‚ö† No improvement for 87 epochs (patience: 150, remaining: 63)

EPOCH 176/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3792
  ‚Ä¢ Validation Loss: 0.3897
  ‚Ä¢ Learning Rate: 0.000641
    No improvement (current: 0.3897, best: 0.3543)
    ‚ö† No improvement for 88 epochs (patience: 150, remaining: 62)

EPOCH 177/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3778
  ‚Ä¢ Validation Loss: 0.3868
  ‚Ä¢ Learning Rate: 0.000633
    No improvement (current: 0.3868, best: 0.3543)
    ‚ö† No improvement for 89 epochs (patience: 150, remaining: 61)

EPOCH 178/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3762
  ‚Ä¢ Validation Loss: 0.3857
  ‚Ä¢ Learning Rate: 0.000626
    No improvement (current: 0.3857, best: 0.3543)
    ‚ö† No improvement for 90 epochs (patience: 150, remaining: 60)

EPOCH 179/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3694
  ‚Ä¢ Validation Loss: 0.3824
  ‚Ä¢ Learning Rate: 0.000619
    No improvement (current: 0.3824, best: 0.3543)
    ‚ö† No improvement for 91 epochs (patience: 150, remaining: 59)

EPOCH 180/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3726
  ‚Ä¢ Validation Loss: 0.3806
  ‚Ä¢ Learning Rate: 0.000612
    No improvement (current: 0.3806, best: 0.3543)
    ‚ö† No improvement for 92 epochs (patience: 150, remaining: 58)

EPOCH 181/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3698
  ‚Ä¢ Validation Loss: 0.3793
  ‚Ä¢ Learning Rate: 0.000604
    No improvement (current: 0.3793, best: 0.3543)
    ‚ö† No improvement for 93 epochs (patience: 150, remaining: 57)

EPOCH 182/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3914
  ‚Ä¢ Validation Loss: 0.3869
  ‚Ä¢ Learning Rate: 0.000597
    No improvement (current: 0.3869, best: 0.3543)
    ‚ö† No improvement for 94 epochs (patience: 150, remaining: 56)

EPOCH 183/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3687
  ‚Ä¢ Validation Loss: 0.3855
  ‚Ä¢ Learning Rate: 0.000590
    No improvement (current: 0.3855, best: 0.3543)
    ‚ö† No improvement for 95 epochs (patience: 150, remaining: 55)

EPOCH 184/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3761
  ‚Ä¢ Validation Loss: 0.3795
  ‚Ä¢ Learning Rate: 0.000582
    No improvement (current: 0.3795, best: 0.3543)
    ‚ö† No improvement for 96 epochs (patience: 150, remaining: 54)

EPOCH 185/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3582
  ‚Ä¢ Validation Loss: 0.3752
  ‚Ä¢ Learning Rate: 0.000575
    No improvement (current: 0.3752, best: 0.3543)
    ‚ö† No improvement for 97 epochs (patience: 150, remaining: 53)

EPOCH 186/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3646
  ‚Ä¢ Validation Loss: 0.3747
  ‚Ä¢ Learning Rate: 0.000567
    No improvement (current: 0.3747, best: 0.3543)
    ‚ö† No improvement for 98 epochs (patience: 150, remaining: 52)

EPOCH 187/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3558
  ‚Ä¢ Validation Loss: 0.3720
  ‚Ä¢ Learning Rate: 0.000560
    No improvement (current: 0.3720, best: 0.3543)
    ‚ö† No improvement for 99 epochs (patience: 150, remaining: 51)

EPOCH 188/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3522
  ‚Ä¢ Validation Loss: 0.3695
  ‚Ä¢ Learning Rate: 0.000553
    No improvement (current: 0.3695, best: 0.3543)
    ‚ö† No improvement for 100 epochs (patience: 150, remaining: 50)

EPOCH 189/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3551
  ‚Ä¢ Validation Loss: 0.3753
  ‚Ä¢ Learning Rate: 0.000545
    No improvement (current: 0.3753, best: 0.3543)
    ‚ö† No improvement for 101 epochs (patience: 150, remaining: 49)

EPOCH 190/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3518
  ‚Ä¢ Validation Loss: 0.3728
  ‚Ä¢ Learning Rate: 0.000538
    No improvement (current: 0.3728, best: 0.3543)
    ‚ö† No improvement for 102 epochs (patience: 150, remaining: 48)

EPOCH 191/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3537
  ‚Ä¢ Validation Loss: 0.3651
  ‚Ä¢ Learning Rate: 0.000530
    No improvement (current: 0.3651, best: 0.3543)
    ‚ö† No improvement for 103 epochs (patience: 150, remaining: 47)

EPOCH 192/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3461
  ‚Ä¢ Validation Loss: 0.3653
  ‚Ä¢ Learning Rate: 0.000523
    No improvement (current: 0.3653, best: 0.3543)
    ‚ö† No improvement for 104 epochs (patience: 150, remaining: 46)

EPOCH 193/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3513
  ‚Ä¢ Validation Loss: 0.3647
  ‚Ä¢ Learning Rate: 0.000515
    No improvement (current: 0.3647, best: 0.3543)
    ‚ö† No improvement for 105 epochs (patience: 150, remaining: 45)

EPOCH 194/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3621
  ‚Ä¢ Validation Loss: 0.3848
  ‚Ä¢ Learning Rate: 0.000508
    No improvement (current: 0.3848, best: 0.3543)
    ‚ö† No improvement for 106 epochs (patience: 150, remaining: 44)

EPOCH 195/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3587
  ‚Ä¢ Validation Loss: 0.3655
  ‚Ä¢ Learning Rate: 0.000500
    No improvement (current: 0.3655, best: 0.3543)
    ‚ö† No improvement for 107 epochs (patience: 150, remaining: 43)

EPOCH 196/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3417
  ‚Ä¢ Validation Loss: 0.3626
  ‚Ä¢ Learning Rate: 0.000493
    No improvement (current: 0.3626, best: 0.3543)
    ‚ö† No improvement for 108 epochs (patience: 150, remaining: 42)

EPOCH 197/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3387
  ‚Ä¢ Validation Loss: 0.3632
  ‚Ä¢ Learning Rate: 0.000486
    No improvement (current: 0.3632, best: 0.3543)
    ‚ö† No improvement for 109 epochs (patience: 150, remaining: 41)

EPOCH 198/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3398
  ‚Ä¢ Validation Loss: 0.3611
  ‚Ä¢ Learning Rate: 0.000478
    No improvement (current: 0.3611, best: 0.3543)
    ‚ö† No improvement for 110 epochs (patience: 150, remaining: 40)

EPOCH 199/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3389
  ‚Ä¢ Validation Loss: 0.3603
  ‚Ä¢ Learning Rate: 0.000471
    No improvement (current: 0.3603, best: 0.3543)
    ‚ö† No improvement for 111 epochs (patience: 150, remaining: 39)

EPOCH 200/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3372
  ‚Ä¢ Validation Loss: 0.3616
  ‚Ä¢ Learning Rate: 0.000463
   üíæ Periodic checkpoint saved: epoch_200.pth
    No improvement (current: 0.3616, best: 0.3543)
    ‚ö† No improvement for 112 epochs (patience: 150, remaining: 38)

EPOCH 201/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3455
  ‚Ä¢ Validation Loss: 0.3670
  ‚Ä¢ Learning Rate: 0.000456
    No improvement (current: 0.3670, best: 0.3543)
    ‚ö† No improvement for 113 epochs (patience: 150, remaining: 37)

EPOCH 202/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3364
  ‚Ä¢ Validation Loss: 0.3590
  ‚Ä¢ Learning Rate: 0.000448
    No improvement (current: 0.3590, best: 0.3543)
    ‚ö† No improvement for 114 epochs (patience: 150, remaining: 36)

EPOCH 203/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3376
  ‚Ä¢ Validation Loss: 0.3613
  ‚Ä¢ Learning Rate: 0.000441
    No improvement (current: 0.3613, best: 0.3543)
    ‚ö† No improvement for 115 epochs (patience: 150, remaining: 35)

EPOCH 204/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3361
  ‚Ä¢ Validation Loss: 0.3597
  ‚Ä¢ Learning Rate: 0.000433
    No improvement (current: 0.3597, best: 0.3543)
    ‚ö† No improvement for 116 epochs (patience: 150, remaining: 34)

EPOCH 205/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3365
  ‚Ä¢ Validation Loss: 0.3678
  ‚Ä¢ Learning Rate: 0.000426
    No improvement (current: 0.3678, best: 0.3543)
    ‚ö† No improvement for 117 epochs (patience: 150, remaining: 33)

EPOCH 206/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3382
  ‚Ä¢ Validation Loss: 0.3590
  ‚Ä¢ Learning Rate: 0.000419
    No improvement (current: 0.3590, best: 0.3543)
    ‚ö† No improvement for 118 epochs (patience: 150, remaining: 32)

EPOCH 207/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3376
  ‚Ä¢ Validation Loss: 0.3588
  ‚Ä¢ Learning Rate: 0.000411
    No improvement (current: 0.3588, best: 0.3543)
    ‚ö† No improvement for 119 epochs (patience: 150, remaining: 31)

EPOCH 208/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3333
  ‚Ä¢ Validation Loss: 0.3722
  ‚Ä¢ Learning Rate: 0.000404
    No improvement (current: 0.3722, best: 0.3543)
    ‚ö† No improvement for 120 epochs (patience: 150, remaining: 30)

EPOCH 209/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3365
  ‚Ä¢ Validation Loss: 0.3632
  ‚Ä¢ Learning Rate: 0.000397
    No improvement (current: 0.3632, best: 0.3543)
    ‚ö† No improvement for 121 epochs (patience: 150, remaining: 29)

EPOCH 210/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3319
  ‚Ä¢ Validation Loss: 0.3581
  ‚Ä¢ Learning Rate: 0.000389
    No improvement (current: 0.3581, best: 0.3543)
    ‚ö† No improvement for 122 epochs (patience: 150, remaining: 28)

EPOCH 211/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3349
  ‚Ä¢ Validation Loss: 0.3653
  ‚Ä¢ Learning Rate: 0.000382
    No improvement (current: 0.3653, best: 0.3543)
    ‚ö† No improvement for 123 epochs (patience: 150, remaining: 27)

EPOCH 212/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3338
  ‚Ä¢ Validation Loss: 0.3581
  ‚Ä¢ Learning Rate: 0.000375
    No improvement (current: 0.3581, best: 0.3543)
    ‚ö† No improvement for 124 epochs (patience: 150, remaining: 26)

EPOCH 213/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3338
  ‚Ä¢ Validation Loss: 0.3622
  ‚Ä¢ Learning Rate: 0.000368
    No improvement (current: 0.3622, best: 0.3543)
    ‚ö† No improvement for 125 epochs (patience: 150, remaining: 25)

EPOCH 214/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3306
  ‚Ä¢ Validation Loss: 0.3644
  ‚Ä¢ Learning Rate: 0.000360
    No improvement (current: 0.3644, best: 0.3543)
    ‚ö† No improvement for 126 epochs (patience: 150, remaining: 24)

EPOCH 215/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3339
  ‚Ä¢ Validation Loss: 0.3574
  ‚Ä¢ Learning Rate: 0.000353
    No improvement (current: 0.3574, best: 0.3543)
    ‚ö† No improvement for 127 epochs (patience: 150, remaining: 23)

EPOCH 216/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3278
  ‚Ä¢ Validation Loss: 0.3682
  ‚Ä¢ Learning Rate: 0.000346
    No improvement (current: 0.3682, best: 0.3543)
    ‚ö† No improvement for 128 epochs (patience: 150, remaining: 22)

EPOCH 217/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3351
  ‚Ä¢ Validation Loss: 0.3571
  ‚Ä¢ Learning Rate: 0.000339
    No improvement (current: 0.3571, best: 0.3543)
    ‚ö† No improvement for 129 epochs (patience: 150, remaining: 21)

EPOCH 218/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3345
  ‚Ä¢ Validation Loss: 0.3621
  ‚Ä¢ Learning Rate: 0.000332
    No improvement (current: 0.3621, best: 0.3543)
    ‚ö† No improvement for 130 epochs (patience: 150, remaining: 20)

EPOCH 219/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3297
  ‚Ä¢ Validation Loss: 0.3610
  ‚Ä¢ Learning Rate: 0.000325
    No improvement (current: 0.3610, best: 0.3543)
    ‚ö† No improvement for 131 epochs (patience: 150, remaining: 19)

EPOCH 220/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3319
  ‚Ä¢ Validation Loss: 0.3563
  ‚Ä¢ Learning Rate: 0.000318
    No improvement (current: 0.3563, best: 0.3543)
    ‚ö† No improvement for 132 epochs (patience: 150, remaining: 18)

EPOCH 221/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3253
  ‚Ä¢ Validation Loss: 0.3585
  ‚Ä¢ Learning Rate: 0.000311
    No improvement (current: 0.3585, best: 0.3543)
    ‚ö† No improvement for 133 epochs (patience: 150, remaining: 17)

EPOCH 222/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3274
  ‚Ä¢ Validation Loss: 0.3579
  ‚Ä¢ Learning Rate: 0.000304
    No improvement (current: 0.3579, best: 0.3543)
    ‚ö† No improvement for 134 epochs (patience: 150, remaining: 16)

EPOCH 223/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3258
  ‚Ä¢ Validation Loss: 0.3565
  ‚Ä¢ Learning Rate: 0.000297
    No improvement (current: 0.3565, best: 0.3543)
    ‚ö† No improvement for 135 epochs (patience: 150, remaining: 15)

EPOCH 224/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3225
  ‚Ä¢ Validation Loss: 0.3591
  ‚Ä¢ Learning Rate: 0.000290
    No improvement (current: 0.3591, best: 0.3543)
    ‚ö† No improvement for 136 epochs (patience: 150, remaining: 14)

EPOCH 225/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3248
  ‚Ä¢ Validation Loss: 0.3635
  ‚Ä¢ Learning Rate: 0.000284
    No improvement (current: 0.3635, best: 0.3543)
    ‚ö† No improvement for 137 epochs (patience: 150, remaining: 13)

EPOCH 226/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3233
  ‚Ä¢ Validation Loss: 0.3554
  ‚Ä¢ Learning Rate: 0.000277
    No improvement (current: 0.3554, best: 0.3543)
    ‚ö† No improvement for 138 epochs (patience: 150, remaining: 12)

EPOCH 227/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3285
  ‚Ä¢ Validation Loss: 0.3557
  ‚Ä¢ Learning Rate: 0.000270
    No improvement (current: 0.3557, best: 0.3543)
    ‚ö† No improvement for 139 epochs (patience: 150, remaining: 11)

EPOCH 228/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3270
  ‚Ä¢ Validation Loss: 0.3564
  ‚Ä¢ Learning Rate: 0.000264
    No improvement (current: 0.3564, best: 0.3543)
    ‚ö† No improvement for 140 epochs (patience: 150, remaining: 10)

EPOCH 229/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3277
  ‚Ä¢ Validation Loss: 0.3559
  ‚Ä¢ Learning Rate: 0.000257
    No improvement (current: 0.3559, best: 0.3543)
    ‚ö† No improvement for 141 epochs (patience: 150, remaining: 9)

EPOCH 230/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3275
  ‚Ä¢ Validation Loss: 0.3563
  ‚Ä¢ Learning Rate: 0.000251
    No improvement (current: 0.3563, best: 0.3543)
    ‚ö† No improvement for 142 epochs (patience: 150, remaining: 8)

EPOCH 231/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3221
  ‚Ä¢ Validation Loss: 0.3555
  ‚Ä¢ Learning Rate: 0.000244
    No improvement (current: 0.3555, best: 0.3543)
    ‚ö† No improvement for 143 epochs (patience: 150, remaining: 7)

EPOCH 232/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3223
  ‚Ä¢ Validation Loss: 0.3567
  ‚Ä¢ Learning Rate: 0.000238
    No improvement (current: 0.3567, best: 0.3543)
    ‚ö† No improvement for 144 epochs (patience: 150, remaining: 6)

EPOCH 233/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3220
  ‚Ä¢ Validation Loss: 0.3550
  ‚Ä¢ Learning Rate: 0.000232
    No improvement (current: 0.3550, best: 0.3543)
    ‚ö† No improvement for 145 epochs (patience: 150, remaining: 5)

EPOCH 234/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3190
  ‚Ä¢ Validation Loss: 0.3542
  ‚Ä¢ Learning Rate: 0.000225
    ‚úì New best checkpoint saved! Val loss: 0.3542
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 235/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3237
  ‚Ä¢ Validation Loss: 0.3556
  ‚Ä¢ Learning Rate: 0.000219
    No improvement (current: 0.3556, best: 0.3542)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 236/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3205
  ‚Ä¢ Validation Loss: 0.3561
  ‚Ä¢ Learning Rate: 0.000213
    No improvement (current: 0.3561, best: 0.3542)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 237/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3222
  ‚Ä¢ Validation Loss: 0.3576
  ‚Ä¢ Learning Rate: 0.000207
    No improvement (current: 0.3576, best: 0.3542)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 238/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3231
  ‚Ä¢ Validation Loss: 0.3540
  ‚Ä¢ Learning Rate: 0.000201
    ‚úì New best checkpoint saved! Val loss: 0.3540
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 239/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3177
  ‚Ä¢ Validation Loss: 0.3531
  ‚Ä¢ Learning Rate: 0.000195
    ‚úì New best checkpoint saved! Val loss: 0.3531
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 240/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3229
  ‚Ä¢ Validation Loss: 0.3535
  ‚Ä¢ Learning Rate: 0.000189
    No improvement (current: 0.3535, best: 0.3531)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 241/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3188
  ‚Ä¢ Validation Loss: 0.3593
  ‚Ä¢ Learning Rate: 0.000183
    No improvement (current: 0.3593, best: 0.3531)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 242/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3204
  ‚Ä¢ Validation Loss: 0.3534
  ‚Ä¢ Learning Rate: 0.000177
    No improvement (current: 0.3534, best: 0.3531)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 243/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3215
  ‚Ä¢ Validation Loss: 0.3542
  ‚Ä¢ Learning Rate: 0.000172
    No improvement (current: 0.3542, best: 0.3531)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 244/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3179
  ‚Ä¢ Validation Loss: 0.3541
  ‚Ä¢ Learning Rate: 0.000166
    No improvement (current: 0.3541, best: 0.3531)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 245/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3125
  ‚Ä¢ Validation Loss: 0.3546
  ‚Ä¢ Learning Rate: 0.000161
    No improvement (current: 0.3546, best: 0.3531)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 246/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3143
  ‚Ä¢ Validation Loss: 0.3544
  ‚Ä¢ Learning Rate: 0.000155
    No improvement (current: 0.3544, best: 0.3531)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 247/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3159
  ‚Ä¢ Validation Loss: 0.3540
  ‚Ä¢ Learning Rate: 0.000150
    No improvement (current: 0.3540, best: 0.3531)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 248/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3130
  ‚Ä¢ Validation Loss: 0.3534
  ‚Ä¢ Learning Rate: 0.000145
    No improvement (current: 0.3534, best: 0.3531)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 249/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3126
  ‚Ä¢ Validation Loss: 0.3542
  ‚Ä¢ Learning Rate: 0.000139
    No improvement (current: 0.3542, best: 0.3531)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 250/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3166
  ‚Ä¢ Validation Loss: 0.3536
  ‚Ä¢ Learning Rate: 0.000134
    No improvement (current: 0.3536, best: 0.3531)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 251/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3157
  ‚Ä¢ Validation Loss: 0.3529
  ‚Ä¢ Learning Rate: 0.000129
    ‚úì New best checkpoint saved! Val loss: 0.3529
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 252/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3119
  ‚Ä¢ Validation Loss: 0.3540
  ‚Ä¢ Learning Rate: 0.000124
    No improvement (current: 0.3540, best: 0.3529)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 253/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3129
  ‚Ä¢ Validation Loss: 0.3541
  ‚Ä¢ Learning Rate: 0.000119
    No improvement (current: 0.3541, best: 0.3529)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 254/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3145
  ‚Ä¢ Validation Loss: 0.3536
  ‚Ä¢ Learning Rate: 0.000115
    No improvement (current: 0.3536, best: 0.3529)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 255/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3184
  ‚Ä¢ Validation Loss: 0.3524
  ‚Ä¢ Learning Rate: 0.000110
    ‚úì New best checkpoint saved! Val loss: 0.3524
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 256/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3154
  ‚Ä¢ Validation Loss: 0.3560
  ‚Ä¢ Learning Rate: 0.000105
    No improvement (current: 0.3560, best: 0.3524)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 257/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3112
  ‚Ä¢ Validation Loss: 0.3530
  ‚Ä¢ Learning Rate: 0.000101
    No improvement (current: 0.3530, best: 0.3524)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 258/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3125
  ‚Ä¢ Validation Loss: 0.3539
  ‚Ä¢ Learning Rate: 0.000096
    No improvement (current: 0.3539, best: 0.3524)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 259/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3143
  ‚Ä¢ Validation Loss: 0.3531
  ‚Ä¢ Learning Rate: 0.000092
    No improvement (current: 0.3531, best: 0.3524)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 260/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3188
  ‚Ä¢ Validation Loss: 0.3543
  ‚Ä¢ Learning Rate: 0.000088
    No improvement (current: 0.3543, best: 0.3524)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 261/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3167
  ‚Ä¢ Validation Loss: 0.3543
  ‚Ä¢ Learning Rate: 0.000084
    No improvement (current: 0.3543, best: 0.3524)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 262/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3127
  ‚Ä¢ Validation Loss: 0.3525
  ‚Ä¢ Learning Rate: 0.000080
    No improvement (current: 0.3525, best: 0.3524)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 263/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3132
  ‚Ä¢ Validation Loss: 0.3536
  ‚Ä¢ Learning Rate: 0.000076
    No improvement (current: 0.3536, best: 0.3524)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 264/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3156
  ‚Ä¢ Validation Loss: 0.3524
  ‚Ä¢ Learning Rate: 0.000072
    No improvement (current: 0.3524, best: 0.3524)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 265/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3120
  ‚Ä¢ Validation Loss: 0.3528
  ‚Ä¢ Learning Rate: 0.000068
    No improvement (current: 0.3528, best: 0.3524)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 266/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3114
  ‚Ä¢ Validation Loss: 0.3554
  ‚Ä¢ Learning Rate: 0.000064
    No improvement (current: 0.3554, best: 0.3524)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 267/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3131
  ‚Ä¢ Validation Loss: 0.3548
  ‚Ä¢ Learning Rate: 0.000061
    No improvement (current: 0.3548, best: 0.3524)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 268/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3113
  ‚Ä¢ Validation Loss: 0.3533
  ‚Ä¢ Learning Rate: 0.000057
    No improvement (current: 0.3533, best: 0.3524)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 269/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3108
  ‚Ä¢ Validation Loss: 0.3534
  ‚Ä¢ Learning Rate: 0.000054
    No improvement (current: 0.3534, best: 0.3524)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 270/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3112
  ‚Ä¢ Validation Loss: 0.3534
  ‚Ä¢ Learning Rate: 0.000050
    No improvement (current: 0.3534, best: 0.3524)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 271/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3124
  ‚Ä¢ Validation Loss: 0.3549
  ‚Ä¢ Learning Rate: 0.000047
    No improvement (current: 0.3549, best: 0.3524)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 272/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3141
  ‚Ä¢ Validation Loss: 0.3529
  ‚Ä¢ Learning Rate: 0.000044
    No improvement (current: 0.3529, best: 0.3524)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 273/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3113
  ‚Ä¢ Validation Loss: 0.3550
  ‚Ä¢ Learning Rate: 0.000041
    No improvement (current: 0.3550, best: 0.3524)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 274/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3085
  ‚Ä¢ Validation Loss: 0.3533
  ‚Ä¢ Learning Rate: 0.000038
    No improvement (current: 0.3533, best: 0.3524)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 275/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3128
  ‚Ä¢ Validation Loss: 0.3534
  ‚Ä¢ Learning Rate: 0.000036
    No improvement (current: 0.3534, best: 0.3524)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 276/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3094
  ‚Ä¢ Validation Loss: 0.3533
  ‚Ä¢ Learning Rate: 0.000033
    No improvement (current: 0.3533, best: 0.3524)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 277/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3109
  ‚Ä¢ Validation Loss: 0.3531
  ‚Ä¢ Learning Rate: 0.000030
    No improvement (current: 0.3531, best: 0.3524)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 278/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3071
  ‚Ä¢ Validation Loss: 0.3526
  ‚Ä¢ Learning Rate: 0.000028
    No improvement (current: 0.3526, best: 0.3524)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 279/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3082
  ‚Ä¢ Validation Loss: 0.3530
  ‚Ä¢ Learning Rate: 0.000025
    No improvement (current: 0.3530, best: 0.3524)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 280/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3122
  ‚Ä¢ Validation Loss: 0.3533
  ‚Ä¢ Learning Rate: 0.000023
    No improvement (current: 0.3533, best: 0.3524)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 281/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3123
  ‚Ä¢ Validation Loss: 0.3523
  ‚Ä¢ Learning Rate: 0.000021
    ‚úì New best checkpoint saved! Val loss: 0.3523
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 282/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3110
  ‚Ä¢ Validation Loss: 0.3528
  ‚Ä¢ Learning Rate: 0.000019
    No improvement (current: 0.3528, best: 0.3523)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 283/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3067
  ‚Ä¢ Validation Loss: 0.3533
  ‚Ä¢ Learning Rate: 0.000017
    No improvement (current: 0.3533, best: 0.3523)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 284/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3104
  ‚Ä¢ Validation Loss: 0.3528
  ‚Ä¢ Learning Rate: 0.000015
    No improvement (current: 0.3528, best: 0.3523)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 285/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3100
  ‚Ä¢ Validation Loss: 0.3532
  ‚Ä¢ Learning Rate: 0.000014
    No improvement (current: 0.3532, best: 0.3523)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 286/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3084
  ‚Ä¢ Validation Loss: 0.3531
  ‚Ä¢ Learning Rate: 0.000012
    No improvement (current: 0.3531, best: 0.3523)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 287/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3099
  ‚Ä¢ Validation Loss: 0.3533
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3533, best: 0.3523)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 288/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3126
  ‚Ä¢ Validation Loss: 0.3527
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3527, best: 0.3523)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 289/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3076
  ‚Ä¢ Validation Loss: 0.3528
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3528, best: 0.3523)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 290/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3122
  ‚Ä¢ Validation Loss: 0.3531
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3531, best: 0.3523)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 291/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3100
  ‚Ä¢ Validation Loss: 0.3529
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3529, best: 0.3523)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 292/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3100
  ‚Ä¢ Validation Loss: 0.3530
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3530, best: 0.3523)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 293/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3102
  ‚Ä¢ Validation Loss: 0.3530
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3530, best: 0.3523)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 294/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3125
  ‚Ä¢ Validation Loss: 0.3530
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3530, best: 0.3523)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 295/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3107
  ‚Ä¢ Validation Loss: 0.3530
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3530, best: 0.3523)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 296/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3101
  ‚Ä¢ Validation Loss: 0.3529
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3529, best: 0.3523)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 297/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3133
  ‚Ä¢ Validation Loss: 0.3529
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3529, best: 0.3523)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 298/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3114
  ‚Ä¢ Validation Loss: 0.3529
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3529, best: 0.3523)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 299/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3099
  ‚Ä¢ Validation Loss: 0.3529
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3529, best: 0.3523)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 300/300
--------------------------------------------------
‚ö†Ô∏è  Scheduler reached max steps, stopping LR updates.
Results:
  ‚Ä¢ Train Loss: 0.3111
  ‚Ä¢ Validation Loss: 0.3529
  ‚Ä¢ Learning Rate: 0.000001
   üíæ Periodic checkpoint saved: epoch_300.pth
    No improvement (current: 0.3529, best: 0.3523)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

================================================================================
TRAINING COMPLETED
================================================================================
Best Val Loss:  0.3523
Total Epochs:   300
Models Saved:   ./Result/a2/Syr341
TensorBoard:    ./Result/a2/Syr341/tensorboard_logs
================================================================================

[03:48:40] Training completed. Best val loss: 0.3523

=== TRAINING COMPLETED SUCCESSFULLY ===
Training Finished!

========================================================================
Testing Hybrid2 Baseline Model with Smart Skip Connections and Multi-Scale Aggregation: Syr341
========================================================================
=== Historical Document Segmentation Testing ===

Detected Syriaque341 manuscript: using 5 classes (no Chapter Headings)
Model: Hybrid2
Dataset: UDIADS_BIB
Manuscript: Syr341
Test-Time Augmentation: Enabled
CRF post-processing: Enabled
  - DenseCRF with spatial and color pairwise potentials

================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder for Testing
================================================================================
================================================================================
üöÄ SIMPLE DECODER (Flag-Controlled Enhancements)
================================================================================
  ‚Ä¢ EfficientNet Variant: b4
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Enhancement Flags:
  ‚Ä¢ Deep Supervision: False
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: True
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: True
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Loaded checkpoint from epoch 280
Best validation loss: 0.3523
  ‚úÖ Model checkpoint loaded successfully (exact match)
Loaded checkpoint: best_model_latest.pth
Namespace(cfg=None, output_dir='./Result/a2/Syr341', use_baseline=True, decoder='EfficientNet-B4', efficientnet_variant='b4', use_deep_supervision=False, use_cbam=False, use_smart_skip=True, use_cross_attn=False, use_multiscale_agg=True, use_groupnorm=True, use_batchnorm=False, use_pos_embed=True, dataset='UDIADS_BIB', manuscript='Syr341', udiadsbib_root='../../U-DIADS-Bib-MS_patched', divahisdb_root='../../DivaHisDB', use_patched_data=True, num_classes=5, img_size=224, batch_size=24, is_savenii=True, test_save_dir='../predictions', use_crf=True, deterministic=1, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, use_tta=True)
Testing with checkpoint: best_model_latest.pth
Saving predictions to: ./Result/a2/Syr341/predictions

=== Starting Testing ===
Dataset: UDIADS_BIB
Model: Hybrid2
Manuscript: Syr341
Save predictions: True

Starting inference on UDIADS_BIB dataset
Found 1620 patches for Syr341
Using Test-Time Augmentation (TTA) for improved accuracy
CRF post-processing: Enabled
  - DenseCRF with spatial and color pairwise potentials
Processing: 031 (54 patches)
Applying CRF post-processing to 031
CRF post-processing completed for 031
Completed: 031
Processing: 053 (54 patches)
Applying CRF post-processing to 053
CRF post-processing completed for 053
Completed: 053
Processing: 054 (54 patches)
Applying CRF post-processing to 054
CRF post-processing completed for 054
Completed: 054
Processing: 071 (54 patches)
Applying CRF post-processing to 071
CRF post-processing completed for 071
Completed: 071
Processing: 073 (54 patches)
Applying CRF post-processing to 073
CRF post-processing completed for 073
Completed: 073
Processing: 075 (54 patches)
Applying CRF post-processing to 075
CRF post-processing completed for 075
Completed: 075
Processing: 100 (54 patches)
Applying CRF post-processing to 100
CRF post-processing completed for 100
Completed: 100
Processing: 137 (54 patches)
Applying CRF post-processing to 137
CRF post-processing completed for 137
Completed: 137
Processing: 150 (54 patches)
Applying CRF post-processing to 150
CRF post-processing completed for 150
Completed: 150
Processing: 160 (54 patches)
Applying CRF post-processing to 160
CRF post-processing completed for 160
Completed: 160
Processing: 167 (54 patches)
Applying CRF post-processing to 167
CRF post-processing completed for 167
Completed: 167
Processing: 184 (54 patches)
Applying CRF post-processing to 184
CRF post-processing completed for 184
Completed: 184
Processing: 190 (54 patches)
Applying CRF post-processing to 190
CRF post-processing completed for 190
Completed: 190
Processing: 201 (54 patches)
Applying CRF post-processing to 201
CRF post-processing completed for 201
Completed: 201
Processing: 210 (54 patches)
Applying CRF post-processing to 210
CRF post-processing completed for 210
Completed: 210
Processing: 222 (54 patches)
Applying CRF post-processing to 222
CRF post-processing completed for 222
Completed: 222
Processing: 224 (54 patches)
Applying CRF post-processing to 224
CRF post-processing completed for 224
Completed: 224
Processing: 231 (54 patches)
Applying CRF post-processing to 231
CRF post-processing completed for 231
Completed: 231
Processing: 241 (54 patches)
Applying CRF post-processing to 241
CRF post-processing completed for 241
Completed: 241
Processing: 249 (54 patches)
Applying CRF post-processing to 249
CRF post-processing completed for 249
Completed: 249
Processing: 252 (54 patches)
Applying CRF post-processing to 252
CRF post-processing completed for 252
Completed: 252
Processing: 267 (54 patches)
Applying CRF post-processing to 267
CRF post-processing completed for 267
Completed: 267
Processing: 281 (54 patches)
Applying CRF post-processing to 281
CRF post-processing completed for 281
Completed: 281
Processing: 286 (54 patches)
Applying CRF post-processing to 286
CRF post-processing completed for 286
Completed: 286
Processing: 290 (54 patches)
Applying CRF post-processing to 290
CRF post-processing completed for 290
Completed: 290
Processing: 313 (54 patches)
Applying CRF post-processing to 313
CRF post-processing completed for 313
Completed: 313
Processing: 362 (54 patches)
Applying CRF post-processing to 362
CRF post-processing completed for 362
Completed: 362
Processing: 368 (54 patches)
Applying CRF post-processing to 368
CRF post-processing completed for 368
Completed: 368
Processing: 376 (54 patches)
Applying CRF post-processing to 376
CRF post-processing completed for 376
Completed: 376
Processing: 446 (54 patches)
Applying CRF post-processing to 446
CRF post-processing completed for 446
Completed: 446

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9384, Recall=0.9925, F1=0.9647, IoU=0.9318
Paratext       : Precision=0.6037, Recall=0.2934, F1=0.3949, IoU=0.2460
Decoration     : Precision=0.9684, Recall=0.8013, F1=0.8770, IoU=0.7809
Main Text      : Precision=0.9219, Recall=0.5883, F1=0.7182, IoU=0.5603
Title          : Precision=0.5996, Recall=0.5442, F1=0.5706, IoU=0.3991

Mean metrics:
----------------------------------------
Mean Precision: 0.8064
Mean Recall: 0.6439
Mean F1-Score: 0.7051
Mean IoU: 0.5836

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9384, Recall=0.9925, F1=0.9647, IoU=0.9318
Paratext       : Precision=0.6037, Recall=0.2934, F1=0.3949, IoU=0.2460
Decoration     : Precision=0.9684, Recall=0.8013, F1=0.8770, IoU=0.7809
Main Text      : Precision=0.9219, Recall=0.5883, F1=0.7182, IoU=0.5603
Title          : Precision=0.5996, Recall=0.5442, F1=0.5706, IoU=0.3991

Mean metrics:
----------------------------------------
Mean Precision: 0.8064
Mean Recall: 0.6439
Mean F1-Score: 0.7051
Mean IoU: 0.5836
Inference completed on 30 images

=== TESTING COMPLETED SUCCESSFULLY ===
Results saved to: ./Result/a2/Syr341/predictions
==================================================

Calculating average metrics...
Looking for metrics files in: ./Result/a2
  ‚úó Metrics file not found: ./Result/a2/metrics_Latin2.json
  ‚úó Metrics file not found: ./Result/a2/metrics_Latin14396.json
  ‚úó Metrics file not found: ./Result/a2/metrics_Latin16746.json
  ‚úì Found metrics for Syr341

================================================================================
AVERAGE METRICS ACROSS 1 MANUSCRIPT(S)
================================================================================
Manuscripts: Syr341
Missing: Latin2, Latin14396, Latin16746
--------------------------------------------------------------------------------
Mean Precision: 0.8064
Mean Recall:    0.6439
Mean F1-Score:  0.7051
Mean IoU:       0.5836
================================================================================

========================================================================
ALL MANUSCRIPTS COMPLETED - HYBRID2 BASELINE MODEL WITH SMART SKIP CONNECTIONS AND MULTI-SCALE AGGREGATION
========================================================================
Model: Hybrid2 Baseline (Swin Encoder + Simple Decoder with Smart Skip Connections and Multi-Scale Aggregation)
Results saved in: ./Result/a2/


========================================================================
AGGREGATING RESULTS ACROSS ALL MANUSCRIPTS
========================================================================

================================================================================
PARSING MANUSCRIPT RESULTS
================================================================================

Processing: Latin2
  Directory: ./Result/a2/Latin2
  ‚úó Could not find metrics for Latin2
    Please ensure testing has completed and output files exist

Processing: Latin14396
  Directory: ./Result/a2/Latin14396
  ‚úó Could not find metrics for Latin14396
    Please ensure testing has completed and output files exist

Processing: Latin16746
  Directory: ./Result/a2/Latin16746
  ‚úó Could not find metrics for Latin16746
    Please ensure testing has completed and output files exist

Processing: Syr341
  Directory: ./Result/a2/Syr341
  ‚úó Could not find metrics for Syr341
    Please ensure testing has completed and output files exist

================================================================================
ERROR: No metrics found!
================================================================================
Please ensure that:
  1. Testing has completed for all manuscripts
  2. Output files (.out or .txt) exist in the results directory
  3. The results_dir path is correct
================================================================================

========================================================================
AGGREGATION COMPLETE
========================================================================
Aggregated metrics saved to: ./Result/a2/aggregated_metrics.txt

=== JOB_STATISTICS ===
=== current date     : Fri Nov 14 03:56:59 AM CET 2025
= Job-ID             : 1321764 on tinygpu
= Job-Name           : r2
= Job-Command        : /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid/run2.sh
= Initial workdir    : /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid
= Queue/Partition    : work
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 22:00:00
= Elapsed runtime    : 05:14:30
= Total RAM usage    : 8.6 GiB of requested  GiB (%)   
= Node list          : tg067
= Subm/Elig/Start/End: 2025-11-13T22:42:39 / 2025-11-13T22:42:39 / 2025-11-13T22:42:41 / 2025-11-14T03:57:11
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc              68.5G   104.9G   209.7G        N/A     236K     500K   1,000K        N/A    
    /home/woody             0.0K  1000.0G  1500.0G        N/A       1    5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA GeForce RTX 2080 Ti, 00000000:AF:00.0, 333462, 8 %, 7 %, 9532 MiB, 47612 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:AF:00.0, 334317, 53 %, 27 %, 1708 MiB, 4682367 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:AF:00.0, 345727, 7 %, 2 %, 434 MiB, 473036 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:AF:00.0, 345812, 53 %, 27 %, 1706 MiB, 3493696 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:AF:00.0, 354370, 7 %, 1 %, 434 MiB, 476761 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:AF:00.0, 354449, 53 %, 27 %, 1708 MiB, 4032269 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:AF:00.0, 364267, 7 %, 1 %, 434 MiB, 486046 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:AF:00.0, 364346, 53 %, 27 %, 1686 MiB, 4659459 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:AF:00.0, 375788, 8 %, 1 %, 438 MiB, 489995 ms
