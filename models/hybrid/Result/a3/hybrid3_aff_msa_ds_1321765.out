### Starting TaskPrologue of job 1321765 on tg068 at Thu Nov 13 10:42:34 PM CET 2025
Running on cores 2-3,10-11,18-19,26-27 with governor ondemand
Thu Nov 13 22:42:34 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 2080 Ti     On  |   00000000:3B:00.0 Off |                  N/A |
| 29%   32C    P8             13W /  250W |       1MiB /  11264MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue


========================================================================
Training Hybrid2 Baseline Model with Smart Skip Connections and Multi-Scale Aggregation and Deep Supervision: Latin2
========================================================================
Dataset: U-DIADS-Bib-MS_patched
Architecture: Swin Transformer Encoder ‚Üí 2 Swin Blocks Bottleneck ‚Üí Simple CNN Decoder
Decoder: Simple Decoder (EfficientNet-b4 channel configuration)

Components Enabled:
  ‚úì Swin Encoder (4 stages: 96‚Üí192‚Üí384‚Üí768 dim)
  ‚úì Bottleneck: 2 Swin Transformer blocks (768 dim, 24 heads)
  ‚úì Simple CNN Decoder (channels: [256, 128, 64, 32])
  ‚úì Smart Skip Connections
  ‚úì Multi-Scale Aggregation
  ‚úì Deep Supervision
  ‚úì Positional Embeddings (default: enabled)
  ‚úì GroupNorm (default normalization)

Components Disabled (baseline):
  ‚úó CBAM Attention
  ‚úó Cross-Attention Bottleneck
  ‚úó BatchNorm
========================================================================
All arguments validated successfully!
Setting random seed to 1234 for reproducible training...
Setting up U-DIADS-Bib dataset...
Using 6 classes for manuscript: Latin2
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin2/Image/training
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin2/mask/training_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin2/Image/validation
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin2/mask/validation_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder
================================================================================
================================================================================
üöÄ SIMPLE DECODER (Flag-Controlled Enhancements)
================================================================================
  ‚Ä¢ EfficientNet Variant: b4
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Enhancement Flags:
  ‚Ä¢ Deep Supervision: True
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: True
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: True
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Model moved to CUDA
Model created successfully with 6 classes

=== Starting Training ===
Dataset: UDIADS_BIB
Model: Hybrid2
Batch size: 4
Max epochs: 300
Learning rate: 0.0001


================================================================================
TRAINING CONFIGURATION
================================================================================
Dataset: UDIADS_BIB
Model: Hybrid2
Batch Size: 4
Max Epochs: 300
Learning Rate: 0.0001
Number of Classes: 6
Output Directory: ./Result/a3/Latin2
Early Stopping Patience: 150 epochs
================================================================================

üìä Dataset Statistics:
   - Training samples: 540
   - Validation samples: 540
   - Batch size: 4
   - Steps per epoch: 135


================================================================================
COMPUTING CLASS WEIGHTS
================================================================================
Raw ENS weights: [9.99999990e-05 1.03287895e-04 9.99999990e-05 9.99999990e-05
 1.00003115e-04 1.00000103e-04]

Class Distribution:
Class                Pixels          Frequency       Weight         
-----------------------------------------------------------------
0                        25,105,103        92.6557%         0.9945
1                            34,471         0.1272%         1.0272
2                           638,823         2.3577%         0.9945
3                         1,075,139         3.9680%         0.9945
4                           103,758         0.3829%         0.9946
5                           137,746         0.5084%         0.9945

Total pixels: 27,095,040.0
Beta: 0.9999
Smoothing: 0.0
Weight range: [0.9945, 1.0272]
================================================================================
üìà Class weights computed with ENS method (smoothing=0.1)
   Final weights: [0.99454474 1.0272443  0.99454474 0.99454474 0.99457574 0.99454576]

‚úì Loss functions created: CE (weighted, label_smoothing=0.1), Focal (Œ≥=2.0), Dice
  üìä OneCycleLR: 135 steps/epoch √ó 300 epochs = 40500 total steps
üöÄ Hybrid2 Best Practice: Differential Learning Rates
  üìä Encoder LR:     0.000010 (10x smaller, 119 params)
  üìä Bottleneck LR:  0.000050 (5x smaller, 26 params)
  üìä Decoder LR:     0.000100 (base LR, 90 params)
  ‚öôÔ∏è  Scheduler: OneCycleLR (Peak: 10x, Warmup: 30%, Cosine)
  ‚öôÔ∏è  Weight decay: Encoder=1e-3, Bottleneck=5e-3, Decoder=1e-2

üîç Checking for checkpoint at: ./Result/a3/Latin2/best_model_latest.pth
   Absolute path: /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid/Result/a3/Latin2/best_model_latest.pth
   File exists: False

================================================================================
STARTING TRAINING
================================================================================
Early stopping patience: 150 epochs
Learning rate scheduler: OneCycleLR (better convergence for transformers)
================================================================================

EPOCH 1/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.1512
  ‚Ä¢ Validation Loss: 1.0281
  ‚Ä¢ Learning Rate: 0.000100
    ‚úì New best checkpoint saved! Val loss: 1.0281
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 2/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.9473
  ‚Ä¢ Validation Loss: 0.9312
  ‚Ä¢ Learning Rate: 0.000101
    ‚úì New best checkpoint saved! Val loss: 0.9312
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 3/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8863
  ‚Ä¢ Validation Loss: 0.8940
  ‚Ä¢ Learning Rate: 0.000102
    ‚úì New best checkpoint saved! Val loss: 0.8940
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 4/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8415
  ‚Ä¢ Validation Loss: 0.8643
  ‚Ä¢ Learning Rate: 0.000104
    ‚úì New best checkpoint saved! Val loss: 0.8643
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 5/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8099
  ‚Ä¢ Validation Loss: 0.8402
  ‚Ä¢ Learning Rate: 0.000107
    ‚úì New best checkpoint saved! Val loss: 0.8402
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 6/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7925
  ‚Ä¢ Validation Loss: 0.8259
  ‚Ä¢ Learning Rate: 0.000110
    ‚úì New best checkpoint saved! Val loss: 0.8259
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 7/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7783
  ‚Ä¢ Validation Loss: 0.8172
  ‚Ä¢ Learning Rate: 0.000113
    ‚úì New best checkpoint saved! Val loss: 0.8172
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 8/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7645
  ‚Ä¢ Validation Loss: 0.8260
  ‚Ä¢ Learning Rate: 0.000117
    No improvement (current: 0.8260, best: 0.8172)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 9/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7613
  ‚Ä¢ Validation Loss: 0.8091
  ‚Ä¢ Learning Rate: 0.000122
    ‚úì New best checkpoint saved! Val loss: 0.8091
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 10/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7533
  ‚Ä¢ Validation Loss: 0.8108
  ‚Ä¢ Learning Rate: 0.000127
    No improvement (current: 0.8108, best: 0.8091)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 11/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7486
  ‚Ä¢ Validation Loss: 0.8112
  ‚Ä¢ Learning Rate: 0.000133
    No improvement (current: 0.8112, best: 0.8091)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 12/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7289
  ‚Ä¢ Validation Loss: 0.7982
  ‚Ä¢ Learning Rate: 0.000139
    ‚úì New best checkpoint saved! Val loss: 0.7982
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 13/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7349
  ‚Ä¢ Validation Loss: 0.8046
  ‚Ä¢ Learning Rate: 0.000146
    No improvement (current: 0.8046, best: 0.7982)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 14/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7270
  ‚Ä¢ Validation Loss: 0.7883
  ‚Ä¢ Learning Rate: 0.000153
    ‚úì New best checkpoint saved! Val loss: 0.7883
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 15/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7346
  ‚Ä¢ Validation Loss: 0.8134
  ‚Ä¢ Learning Rate: 0.000160
    No improvement (current: 0.8134, best: 0.7883)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 16/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7272
  ‚Ä¢ Validation Loss: 0.8040
  ‚Ä¢ Learning Rate: 0.000168
    No improvement (current: 0.8040, best: 0.7883)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 17/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7160
  ‚Ä¢ Validation Loss: 0.7898
  ‚Ä¢ Learning Rate: 0.000177
    No improvement (current: 0.7898, best: 0.7883)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 18/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7170
  ‚Ä¢ Validation Loss: 0.7927
  ‚Ä¢ Learning Rate: 0.000186
    No improvement (current: 0.7927, best: 0.7883)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 19/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7253
  ‚Ä¢ Validation Loss: 0.7914
  ‚Ä¢ Learning Rate: 0.000195
    No improvement (current: 0.7914, best: 0.7883)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 20/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7135
  ‚Ä¢ Validation Loss: 0.8152
  ‚Ä¢ Learning Rate: 0.000205
    No improvement (current: 0.8152, best: 0.7883)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 21/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7133
  ‚Ä¢ Validation Loss: 0.7950
  ‚Ä¢ Learning Rate: 0.000216
    No improvement (current: 0.7950, best: 0.7883)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 22/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7143
  ‚Ä¢ Validation Loss: 0.7897
  ‚Ä¢ Learning Rate: 0.000226
    No improvement (current: 0.7897, best: 0.7883)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 23/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7168
  ‚Ä¢ Validation Loss: 0.7856
  ‚Ä¢ Learning Rate: 0.000237
    ‚úì New best checkpoint saved! Val loss: 0.7856
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 24/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7107
  ‚Ä¢ Validation Loss: 0.7781
  ‚Ä¢ Learning Rate: 0.000249
    ‚úì New best checkpoint saved! Val loss: 0.7781
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 25/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7074
  ‚Ä¢ Validation Loss: 0.7824
  ‚Ä¢ Learning Rate: 0.000261
    No improvement (current: 0.7824, best: 0.7781)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 26/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7023
  ‚Ä¢ Validation Loss: 0.7920
  ‚Ä¢ Learning Rate: 0.000273
    No improvement (current: 0.7920, best: 0.7781)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 27/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7098
  ‚Ä¢ Validation Loss: 0.7772
  ‚Ä¢ Learning Rate: 0.000286
    ‚úì New best checkpoint saved! Val loss: 0.7772
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 28/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7003
  ‚Ä¢ Validation Loss: 0.7774
  ‚Ä¢ Learning Rate: 0.000298
    No improvement (current: 0.7774, best: 0.7772)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 29/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7158
  ‚Ä¢ Validation Loss: 0.7938
  ‚Ä¢ Learning Rate: 0.000312
    No improvement (current: 0.7938, best: 0.7772)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 30/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6963
  ‚Ä¢ Validation Loss: 0.7729
  ‚Ä¢ Learning Rate: 0.000325
    ‚úì New best checkpoint saved! Val loss: 0.7729
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 31/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6952
  ‚Ä¢ Validation Loss: 0.7730
  ‚Ä¢ Learning Rate: 0.000339
    No improvement (current: 0.7730, best: 0.7729)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 32/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6998
  ‚Ä¢ Validation Loss: 0.7923
  ‚Ä¢ Learning Rate: 0.000353
    No improvement (current: 0.7923, best: 0.7729)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 33/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7096
  ‚Ä¢ Validation Loss: 0.7826
  ‚Ä¢ Learning Rate: 0.000367
    No improvement (current: 0.7826, best: 0.7729)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 34/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6983
  ‚Ä¢ Validation Loss: 0.7865
  ‚Ä¢ Learning Rate: 0.000381
    No improvement (current: 0.7865, best: 0.7729)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 35/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7069
  ‚Ä¢ Validation Loss: 0.7788
  ‚Ä¢ Learning Rate: 0.000396
    No improvement (current: 0.7788, best: 0.7729)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 36/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7069
  ‚Ä¢ Validation Loss: 0.7711
  ‚Ä¢ Learning Rate: 0.000411
    ‚úì New best checkpoint saved! Val loss: 0.7711
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 37/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7122
  ‚Ä¢ Validation Loss: 0.7915
  ‚Ä¢ Learning Rate: 0.000426
    No improvement (current: 0.7915, best: 0.7711)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 38/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7076
  ‚Ä¢ Validation Loss: 0.7707
  ‚Ä¢ Learning Rate: 0.000441
    ‚úì New best checkpoint saved! Val loss: 0.7707
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 39/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7098
  ‚Ä¢ Validation Loss: 0.7923
  ‚Ä¢ Learning Rate: 0.000456
    No improvement (current: 0.7923, best: 0.7707)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 40/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7055
  ‚Ä¢ Validation Loss: 0.7799
  ‚Ä¢ Learning Rate: 0.000472
    No improvement (current: 0.7799, best: 0.7707)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 41/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7037
  ‚Ä¢ Validation Loss: 0.8240
  ‚Ä¢ Learning Rate: 0.000487
    No improvement (current: 0.8240, best: 0.7707)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 42/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7230
  ‚Ä¢ Validation Loss: 0.7795
  ‚Ä¢ Learning Rate: 0.000503
    No improvement (current: 0.7795, best: 0.7707)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 43/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7108
  ‚Ä¢ Validation Loss: 0.7815
  ‚Ä¢ Learning Rate: 0.000519
    No improvement (current: 0.7815, best: 0.7707)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 44/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7026
  ‚Ä¢ Validation Loss: 0.7743
  ‚Ä¢ Learning Rate: 0.000534
    No improvement (current: 0.7743, best: 0.7707)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 45/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7012
  ‚Ä¢ Validation Loss: 0.7766
  ‚Ä¢ Learning Rate: 0.000550
    No improvement (current: 0.7766, best: 0.7707)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 46/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7004
  ‚Ä¢ Validation Loss: 0.7765
  ‚Ä¢ Learning Rate: 0.000566
    No improvement (current: 0.7765, best: 0.7707)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 47/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6915
  ‚Ä¢ Validation Loss: 0.7806
  ‚Ä¢ Learning Rate: 0.000581
    No improvement (current: 0.7806, best: 0.7707)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 48/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7053
  ‚Ä¢ Validation Loss: 0.7788
  ‚Ä¢ Learning Rate: 0.000597
    No improvement (current: 0.7788, best: 0.7707)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 49/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6931
  ‚Ä¢ Validation Loss: 0.7723
  ‚Ä¢ Learning Rate: 0.000613
    No improvement (current: 0.7723, best: 0.7707)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 50/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6995
  ‚Ä¢ Validation Loss: 0.7756
  ‚Ä¢ Learning Rate: 0.000628
    No improvement (current: 0.7756, best: 0.7707)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 51/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6927
  ‚Ä¢ Validation Loss: 0.7854
  ‚Ä¢ Learning Rate: 0.000644
    No improvement (current: 0.7854, best: 0.7707)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 52/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7047
  ‚Ä¢ Validation Loss: 0.7733
  ‚Ä¢ Learning Rate: 0.000659
    No improvement (current: 0.7733, best: 0.7707)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 53/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7105
  ‚Ä¢ Validation Loss: 0.7948
  ‚Ä¢ Learning Rate: 0.000674
    No improvement (current: 0.7948, best: 0.7707)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 54/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6881
  ‚Ä¢ Validation Loss: 0.7788
  ‚Ä¢ Learning Rate: 0.000689
    No improvement (current: 0.7788, best: 0.7707)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 55/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6937
  ‚Ä¢ Validation Loss: 0.7724
  ‚Ä¢ Learning Rate: 0.000704
    No improvement (current: 0.7724, best: 0.7707)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 56/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6976
  ‚Ä¢ Validation Loss: 0.7783
  ‚Ä¢ Learning Rate: 0.000719
    No improvement (current: 0.7783, best: 0.7707)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 57/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6992
  ‚Ä¢ Validation Loss: 0.7817
  ‚Ä¢ Learning Rate: 0.000733
    No improvement (current: 0.7817, best: 0.7707)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 58/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7044
  ‚Ä¢ Validation Loss: 0.7689
  ‚Ä¢ Learning Rate: 0.000747
    ‚úì New best checkpoint saved! Val loss: 0.7689
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 59/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7103
  ‚Ä¢ Validation Loss: 0.8007
  ‚Ä¢ Learning Rate: 0.000761
    No improvement (current: 0.8007, best: 0.7689)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 60/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7009
  ‚Ä¢ Validation Loss: 0.7825
  ‚Ä¢ Learning Rate: 0.000775
    No improvement (current: 0.7825, best: 0.7689)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 61/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7149
  ‚Ä¢ Validation Loss: 0.7846
  ‚Ä¢ Learning Rate: 0.000789
    No improvement (current: 0.7846, best: 0.7689)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 62/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6908
  ‚Ä¢ Validation Loss: 0.7741
  ‚Ä¢ Learning Rate: 0.000802
    No improvement (current: 0.7741, best: 0.7689)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 63/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6898
  ‚Ä¢ Validation Loss: 0.7862
  ‚Ä¢ Learning Rate: 0.000815
    No improvement (current: 0.7862, best: 0.7689)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 64/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6883
  ‚Ä¢ Validation Loss: 0.7731
  ‚Ä¢ Learning Rate: 0.000827
    No improvement (current: 0.7731, best: 0.7689)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 65/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6837
  ‚Ä¢ Validation Loss: 0.7677
  ‚Ä¢ Learning Rate: 0.000839
    ‚úì New best checkpoint saved! Val loss: 0.7677
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 66/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7039
  ‚Ä¢ Validation Loss: 0.7792
  ‚Ä¢ Learning Rate: 0.000851
    No improvement (current: 0.7792, best: 0.7677)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 67/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6938
  ‚Ä¢ Validation Loss: 0.7759
  ‚Ä¢ Learning Rate: 0.000863
    No improvement (current: 0.7759, best: 0.7677)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 68/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6953
  ‚Ä¢ Validation Loss: 0.7958
  ‚Ä¢ Learning Rate: 0.000874
    No improvement (current: 0.7958, best: 0.7677)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 69/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7115
  ‚Ä¢ Validation Loss: 0.7940
  ‚Ä¢ Learning Rate: 0.000884
    No improvement (current: 0.7940, best: 0.7677)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 70/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6945
  ‚Ä¢ Validation Loss: 0.7704
  ‚Ä¢ Learning Rate: 0.000895
    No improvement (current: 0.7704, best: 0.7677)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 71/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6968
  ‚Ä¢ Validation Loss: 0.7754
  ‚Ä¢ Learning Rate: 0.000905
    No improvement (current: 0.7754, best: 0.7677)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 72/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6883
  ‚Ä¢ Validation Loss: 0.7731
  ‚Ä¢ Learning Rate: 0.000914
    No improvement (current: 0.7731, best: 0.7677)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 73/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6850
  ‚Ä¢ Validation Loss: 0.7899
  ‚Ä¢ Learning Rate: 0.000923
    No improvement (current: 0.7899, best: 0.7677)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 74/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6961
  ‚Ä¢ Validation Loss: 0.7764
  ‚Ä¢ Learning Rate: 0.000932
    No improvement (current: 0.7764, best: 0.7677)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 75/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6866
  ‚Ä¢ Validation Loss: 0.7787
  ‚Ä¢ Learning Rate: 0.000940
    No improvement (current: 0.7787, best: 0.7677)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 76/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7122
  ‚Ä¢ Validation Loss: 0.7754
  ‚Ä¢ Learning Rate: 0.000947
    No improvement (current: 0.7754, best: 0.7677)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 77/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7350
  ‚Ä¢ Validation Loss: 0.9205
  ‚Ä¢ Learning Rate: 0.000955
    No improvement (current: 0.9205, best: 0.7677)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 78/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7867
  ‚Ä¢ Validation Loss: 0.8293
  ‚Ä¢ Learning Rate: 0.000961
    No improvement (current: 0.8293, best: 0.7677)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 79/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7684
  ‚Ä¢ Validation Loss: 0.8283
  ‚Ä¢ Learning Rate: 0.000967
    No improvement (current: 0.8283, best: 0.7677)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 80/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7697
  ‚Ä¢ Validation Loss: 0.8281
  ‚Ä¢ Learning Rate: 0.000973
    No improvement (current: 0.8281, best: 0.7677)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 81/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7656
  ‚Ä¢ Validation Loss: 0.8276
  ‚Ä¢ Learning Rate: 0.000978
    No improvement (current: 0.8276, best: 0.7677)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 82/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7682
  ‚Ä¢ Validation Loss: 0.8289
  ‚Ä¢ Learning Rate: 0.000983
    No improvement (current: 0.8289, best: 0.7677)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 83/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7661
  ‚Ä¢ Validation Loss: 0.8297
  ‚Ä¢ Learning Rate: 0.000987
    No improvement (current: 0.8297, best: 0.7677)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 84/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7693
  ‚Ä¢ Validation Loss: 0.8286
  ‚Ä¢ Learning Rate: 0.000990
    No improvement (current: 0.8286, best: 0.7677)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 85/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7669
  ‚Ä¢ Validation Loss: 0.8277
  ‚Ä¢ Learning Rate: 0.000993
    No improvement (current: 0.8277, best: 0.7677)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 86/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7630
  ‚Ä¢ Validation Loss: 0.8275
  ‚Ä¢ Learning Rate: 0.000996
    No improvement (current: 0.8275, best: 0.7677)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 87/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7636
  ‚Ä¢ Validation Loss: 0.8282
  ‚Ä¢ Learning Rate: 0.000998
    No improvement (current: 0.8282, best: 0.7677)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 88/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7614
  ‚Ä¢ Validation Loss: 0.8280
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.8280, best: 0.7677)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 89/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7651
  ‚Ä¢ Validation Loss: 0.8277
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.8277, best: 0.7677)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 90/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7672
  ‚Ä¢ Validation Loss: 0.8281
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.8281, best: 0.7677)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 91/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7664
  ‚Ä¢ Validation Loss: 0.8275
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.8275, best: 0.7677)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 92/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7673
  ‚Ä¢ Validation Loss: 0.8289
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.8289, best: 0.7677)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 93/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7664
  ‚Ä¢ Validation Loss: 0.8291
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.8291, best: 0.7677)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 94/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7671
  ‚Ä¢ Validation Loss: 0.8289
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.8289, best: 0.7677)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 95/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7686
  ‚Ä¢ Validation Loss: 0.8293
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.8293, best: 0.7677)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 96/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7741
  ‚Ä¢ Validation Loss: 0.8312
  ‚Ä¢ Learning Rate: 0.000998
    No improvement (current: 0.8312, best: 0.7677)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 97/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7702
  ‚Ä¢ Validation Loss: 0.8290
  ‚Ä¢ Learning Rate: 0.000997
    No improvement (current: 0.8290, best: 0.7677)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 98/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7736
  ‚Ä¢ Validation Loss: 0.8303
  ‚Ä¢ Learning Rate: 0.000996
    No improvement (current: 0.8303, best: 0.7677)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 99/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7681
  ‚Ä¢ Validation Loss: 0.8301
  ‚Ä¢ Learning Rate: 0.000995
    No improvement (current: 0.8301, best: 0.7677)
    ‚ö† No improvement for 34 epochs (patience: 150, remaining: 116)

EPOCH 100/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7666
  ‚Ä¢ Validation Loss: 0.8293
  ‚Ä¢ Learning Rate: 0.000994
   üíæ Periodic checkpoint saved: epoch_100.pth
    No improvement (current: 0.8293, best: 0.7677)
    ‚ö† No improvement for 35 epochs (patience: 150, remaining: 115)

EPOCH 101/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7663
  ‚Ä¢ Validation Loss: 0.8300
  ‚Ä¢ Learning Rate: 0.000993
    No improvement (current: 0.8300, best: 0.7677)
    ‚ö† No improvement for 36 epochs (patience: 150, remaining: 114)

EPOCH 102/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7662
  ‚Ä¢ Validation Loss: 0.8285
  ‚Ä¢ Learning Rate: 0.000992
    No improvement (current: 0.8285, best: 0.7677)
    ‚ö† No improvement for 37 epochs (patience: 150, remaining: 113)

EPOCH 103/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7707
  ‚Ä¢ Validation Loss: 0.8307
  ‚Ä¢ Learning Rate: 0.000991
    No improvement (current: 0.8307, best: 0.7677)
    ‚ö† No improvement for 38 epochs (patience: 150, remaining: 112)

EPOCH 104/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7660
  ‚Ä¢ Validation Loss: 0.8327
  ‚Ä¢ Learning Rate: 0.000989
    No improvement (current: 0.8327, best: 0.7677)
    ‚ö† No improvement for 39 epochs (patience: 150, remaining: 111)

EPOCH 105/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7713
  ‚Ä¢ Validation Loss: 0.8331
  ‚Ä¢ Learning Rate: 0.000987
    No improvement (current: 0.8331, best: 0.7677)
    ‚ö† No improvement for 40 epochs (patience: 150, remaining: 110)

EPOCH 106/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7725
  ‚Ä¢ Validation Loss: 0.8305
  ‚Ä¢ Learning Rate: 0.000986
    No improvement (current: 0.8305, best: 0.7677)
    ‚ö† No improvement for 41 epochs (patience: 150, remaining: 109)

EPOCH 107/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7688
  ‚Ä¢ Validation Loss: 0.8315
  ‚Ä¢ Learning Rate: 0.000984
    No improvement (current: 0.8315, best: 0.7677)
    ‚ö† No improvement for 42 epochs (patience: 150, remaining: 108)

EPOCH 108/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7666
  ‚Ä¢ Validation Loss: 0.8334
  ‚Ä¢ Learning Rate: 0.000982
    No improvement (current: 0.8334, best: 0.7677)
    ‚ö† No improvement for 43 epochs (patience: 150, remaining: 107)

EPOCH 109/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7680
  ‚Ä¢ Validation Loss: 0.8269
  ‚Ä¢ Learning Rate: 0.000980
    No improvement (current: 0.8269, best: 0.7677)
    ‚ö† No improvement for 44 epochs (patience: 150, remaining: 106)

EPOCH 110/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7626
  ‚Ä¢ Validation Loss: 0.8308
  ‚Ä¢ Learning Rate: 0.000978
    No improvement (current: 0.8308, best: 0.7677)
    ‚ö† No improvement for 45 epochs (patience: 150, remaining: 105)

EPOCH 111/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7659
  ‚Ä¢ Validation Loss: 0.8318
  ‚Ä¢ Learning Rate: 0.000976
    No improvement (current: 0.8318, best: 0.7677)
    ‚ö† No improvement for 46 epochs (patience: 150, remaining: 104)

EPOCH 112/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7656
  ‚Ä¢ Validation Loss: 0.8319
  ‚Ä¢ Learning Rate: 0.000973
    No improvement (current: 0.8319, best: 0.7677)
    ‚ö† No improvement for 47 epochs (patience: 150, remaining: 103)

EPOCH 113/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7660
  ‚Ä¢ Validation Loss: 0.8308
  ‚Ä¢ Learning Rate: 0.000971
    No improvement (current: 0.8308, best: 0.7677)
    ‚ö† No improvement for 48 epochs (patience: 150, remaining: 102)

EPOCH 114/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7686
  ‚Ä¢ Validation Loss: 0.8286
  ‚Ä¢ Learning Rate: 0.000968
    No improvement (current: 0.8286, best: 0.7677)
    ‚ö† No improvement for 49 epochs (patience: 150, remaining: 101)

EPOCH 115/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7742
  ‚Ä¢ Validation Loss: 0.8304
  ‚Ä¢ Learning Rate: 0.000965
    No improvement (current: 0.8304, best: 0.7677)
    ‚ö† No improvement for 50 epochs (patience: 150, remaining: 100)

EPOCH 116/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7612
  ‚Ä¢ Validation Loss: 0.8296
  ‚Ä¢ Learning Rate: 0.000963
    No improvement (current: 0.8296, best: 0.7677)
    ‚ö† No improvement for 51 epochs (patience: 150, remaining: 99)

EPOCH 117/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7709
  ‚Ä¢ Validation Loss: 0.8300
  ‚Ä¢ Learning Rate: 0.000960
    No improvement (current: 0.8300, best: 0.7677)
    ‚ö† No improvement for 52 epochs (patience: 150, remaining: 98)

EPOCH 118/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7696
  ‚Ä¢ Validation Loss: 0.8326
  ‚Ä¢ Learning Rate: 0.000957
    No improvement (current: 0.8326, best: 0.7677)
    ‚ö† No improvement for 53 epochs (patience: 150, remaining: 97)

EPOCH 119/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7717
  ‚Ä¢ Validation Loss: 0.8307
  ‚Ä¢ Learning Rate: 0.000954
    No improvement (current: 0.8307, best: 0.7677)
    ‚ö† No improvement for 54 epochs (patience: 150, remaining: 96)

EPOCH 120/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7702
  ‚Ä¢ Validation Loss: 0.8313
  ‚Ä¢ Learning Rate: 0.000951
    No improvement (current: 0.8313, best: 0.7677)
    ‚ö† No improvement for 55 epochs (patience: 150, remaining: 95)

EPOCH 121/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7662
  ‚Ä¢ Validation Loss: 0.8288
  ‚Ä¢ Learning Rate: 0.000947
    No improvement (current: 0.8288, best: 0.7677)
    ‚ö† No improvement for 56 epochs (patience: 150, remaining: 94)

EPOCH 122/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7711
  ‚Ä¢ Validation Loss: 0.8305
  ‚Ä¢ Learning Rate: 0.000944
    No improvement (current: 0.8305, best: 0.7677)
    ‚ö† No improvement for 57 epochs (patience: 150, remaining: 93)

EPOCH 123/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7680
  ‚Ä¢ Validation Loss: 0.8305
  ‚Ä¢ Learning Rate: 0.000940
    No improvement (current: 0.8305, best: 0.7677)
    ‚ö† No improvement for 58 epochs (patience: 150, remaining: 92)

EPOCH 124/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7678
  ‚Ä¢ Validation Loss: 0.8261
  ‚Ä¢ Learning Rate: 0.000937
    No improvement (current: 0.8261, best: 0.7677)
    ‚ö† No improvement for 59 epochs (patience: 150, remaining: 91)

EPOCH 125/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7609
  ‚Ä¢ Validation Loss: 0.8288
  ‚Ä¢ Learning Rate: 0.000933
    No improvement (current: 0.8288, best: 0.7677)
    ‚ö† No improvement for 60 epochs (patience: 150, remaining: 90)

EPOCH 126/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7614
  ‚Ä¢ Validation Loss: 0.8280
  ‚Ä¢ Learning Rate: 0.000929
    No improvement (current: 0.8280, best: 0.7677)
    ‚ö† No improvement for 61 epochs (patience: 150, remaining: 89)

EPOCH 127/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7666
  ‚Ä¢ Validation Loss: 0.8276
  ‚Ä¢ Learning Rate: 0.000925
    No improvement (current: 0.8276, best: 0.7677)
    ‚ö† No improvement for 62 epochs (patience: 150, remaining: 88)

EPOCH 128/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7637
  ‚Ä¢ Validation Loss: 0.8244
  ‚Ä¢ Learning Rate: 0.000921
    No improvement (current: 0.8244, best: 0.7677)
    ‚ö† No improvement for 63 epochs (patience: 150, remaining: 87)

EPOCH 129/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7622
  ‚Ä¢ Validation Loss: 0.8233
  ‚Ä¢ Learning Rate: 0.000917
    No improvement (current: 0.8233, best: 0.7677)
    ‚ö† No improvement for 64 epochs (patience: 150, remaining: 86)

EPOCH 130/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7634
  ‚Ä¢ Validation Loss: 0.8234
  ‚Ä¢ Learning Rate: 0.000913
    No improvement (current: 0.8234, best: 0.7677)
    ‚ö† No improvement for 65 epochs (patience: 150, remaining: 85)

EPOCH 131/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7565
  ‚Ä¢ Validation Loss: 0.8226
  ‚Ä¢ Learning Rate: 0.000909
    No improvement (current: 0.8226, best: 0.7677)
    ‚ö† No improvement for 66 epochs (patience: 150, remaining: 84)

EPOCH 132/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7565
  ‚Ä¢ Validation Loss: 0.8211
  ‚Ä¢ Learning Rate: 0.000905
    No improvement (current: 0.8211, best: 0.7677)
    ‚ö† No improvement for 67 epochs (patience: 150, remaining: 83)

EPOCH 133/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7539
  ‚Ä¢ Validation Loss: 0.8198
  ‚Ä¢ Learning Rate: 0.000900
    No improvement (current: 0.8198, best: 0.7677)
    ‚ö† No improvement for 68 epochs (patience: 150, remaining: 82)

EPOCH 134/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7587
  ‚Ä¢ Validation Loss: 0.8201
  ‚Ä¢ Learning Rate: 0.000896
    No improvement (current: 0.8201, best: 0.7677)
    ‚ö† No improvement for 69 epochs (patience: 150, remaining: 81)

EPOCH 135/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7616
  ‚Ä¢ Validation Loss: 0.8211
  ‚Ä¢ Learning Rate: 0.000891
    No improvement (current: 0.8211, best: 0.7677)
    ‚ö† No improvement for 70 epochs (patience: 150, remaining: 80)

EPOCH 136/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7565
  ‚Ä¢ Validation Loss: 0.8211
  ‚Ä¢ Learning Rate: 0.000886
    No improvement (current: 0.8211, best: 0.7677)
    ‚ö† No improvement for 71 epochs (patience: 150, remaining: 79)

EPOCH 137/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7564
  ‚Ä¢ Validation Loss: 0.8167
  ‚Ä¢ Learning Rate: 0.000881
    No improvement (current: 0.8167, best: 0.7677)
    ‚ö† No improvement for 72 epochs (patience: 150, remaining: 78)

EPOCH 138/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7553
  ‚Ä¢ Validation Loss: 0.8156
  ‚Ä¢ Learning Rate: 0.000877
    No improvement (current: 0.8156, best: 0.7677)
    ‚ö† No improvement for 73 epochs (patience: 150, remaining: 77)

EPOCH 139/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7595
  ‚Ä¢ Validation Loss: 0.8172
  ‚Ä¢ Learning Rate: 0.000872
    No improvement (current: 0.8172, best: 0.7677)
    ‚ö† No improvement for 74 epochs (patience: 150, remaining: 76)

EPOCH 140/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7607
  ‚Ä¢ Validation Loss: 0.8174
  ‚Ä¢ Learning Rate: 0.000867
    No improvement (current: 0.8174, best: 0.7677)
    ‚ö† No improvement for 75 epochs (patience: 150, remaining: 75)

EPOCH 141/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7526
  ‚Ä¢ Validation Loss: 0.8162
  ‚Ä¢ Learning Rate: 0.000861
    No improvement (current: 0.8162, best: 0.7677)
    ‚ö† No improvement for 76 epochs (patience: 150, remaining: 74)

EPOCH 142/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7451
  ‚Ä¢ Validation Loss: 0.8164
  ‚Ä¢ Learning Rate: 0.000856
    No improvement (current: 0.8164, best: 0.7677)
    ‚ö† No improvement for 77 epochs (patience: 150, remaining: 73)

EPOCH 143/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7483
  ‚Ä¢ Validation Loss: 0.8150
  ‚Ä¢ Learning Rate: 0.000851
    No improvement (current: 0.8150, best: 0.7677)
    ‚ö† No improvement for 78 epochs (patience: 150, remaining: 72)

EPOCH 144/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7525
  ‚Ä¢ Validation Loss: 0.8120
  ‚Ä¢ Learning Rate: 0.000846
    No improvement (current: 0.8120, best: 0.7677)
    ‚ö† No improvement for 79 epochs (patience: 150, remaining: 71)

EPOCH 145/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7431
  ‚Ä¢ Validation Loss: 0.8092
  ‚Ä¢ Learning Rate: 0.000840
    No improvement (current: 0.8092, best: 0.7677)
    ‚ö† No improvement for 80 epochs (patience: 150, remaining: 70)

EPOCH 146/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.2951
  ‚Ä¢ Validation Loss: 1.9963
  ‚Ä¢ Learning Rate: 0.000835
    No improvement (current: 1.9963, best: 0.7677)
    ‚ö† No improvement for 81 epochs (patience: 150, remaining: 69)

EPOCH 147/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.1332
  ‚Ä¢ Validation Loss: 0.8327
  ‚Ä¢ Learning Rate: 0.000829
    No improvement (current: 0.8327, best: 0.7677)
    ‚ö† No improvement for 82 epochs (patience: 150, remaining: 68)

EPOCH 148/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7604
  ‚Ä¢ Validation Loss: 0.8113
  ‚Ä¢ Learning Rate: 0.000823
    No improvement (current: 0.8113, best: 0.7677)
    ‚ö† No improvement for 83 epochs (patience: 150, remaining: 67)

EPOCH 149/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7864
  ‚Ä¢ Validation Loss: 0.8434
  ‚Ä¢ Learning Rate: 0.000818
    No improvement (current: 0.8434, best: 0.7677)
    ‚ö† No improvement for 84 epochs (patience: 150, remaining: 66)

EPOCH 150/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7707
  ‚Ä¢ Validation Loss: 0.8321
  ‚Ä¢ Learning Rate: 0.000812
    No improvement (current: 0.8321, best: 0.7677)
    ‚ö† No improvement for 85 epochs (patience: 150, remaining: 65)

EPOCH 151/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7677
  ‚Ä¢ Validation Loss: 0.8267
  ‚Ä¢ Learning Rate: 0.000806
    No improvement (current: 0.8267, best: 0.7677)
    ‚ö† No improvement for 86 epochs (patience: 150, remaining: 64)

EPOCH 152/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7630
  ‚Ä¢ Validation Loss: 0.8237
  ‚Ä¢ Learning Rate: 0.000800
    No improvement (current: 0.8237, best: 0.7677)
    ‚ö† No improvement for 87 epochs (patience: 150, remaining: 63)

EPOCH 153/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7600
  ‚Ä¢ Validation Loss: 0.8183
  ‚Ä¢ Learning Rate: 0.000794
    No improvement (current: 0.8183, best: 0.7677)
    ‚ö† No improvement for 88 epochs (patience: 150, remaining: 62)

EPOCH 154/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7556
  ‚Ä¢ Validation Loss: 0.8213
  ‚Ä¢ Learning Rate: 0.000788
    No improvement (current: 0.8213, best: 0.7677)
    ‚ö† No improvement for 89 epochs (patience: 150, remaining: 61)

EPOCH 155/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7464
  ‚Ä¢ Validation Loss: 0.8189
  ‚Ä¢ Learning Rate: 0.000782
    No improvement (current: 0.8189, best: 0.7677)
    ‚ö† No improvement for 90 epochs (patience: 150, remaining: 60)

EPOCH 156/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7484
  ‚Ä¢ Validation Loss: 0.8117
  ‚Ä¢ Learning Rate: 0.000776
    No improvement (current: 0.8117, best: 0.7677)
    ‚ö† No improvement for 91 epochs (patience: 150, remaining: 59)

EPOCH 157/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7424
  ‚Ä¢ Validation Loss: 0.8116
  ‚Ä¢ Learning Rate: 0.000769
    No improvement (current: 0.8116, best: 0.7677)
    ‚ö† No improvement for 92 epochs (patience: 150, remaining: 58)

EPOCH 158/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7466
  ‚Ä¢ Validation Loss: 0.8102
  ‚Ä¢ Learning Rate: 0.000763
    No improvement (current: 0.8102, best: 0.7677)
    ‚ö† No improvement for 93 epochs (patience: 150, remaining: 57)

EPOCH 159/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7415
  ‚Ä¢ Validation Loss: 0.8101
  ‚Ä¢ Learning Rate: 0.000757
    No improvement (current: 0.8101, best: 0.7677)
    ‚ö† No improvement for 94 epochs (patience: 150, remaining: 56)

EPOCH 160/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7975
  ‚Ä¢ Validation Loss: 1.4973
  ‚Ä¢ Learning Rate: 0.000750
    No improvement (current: 1.4973, best: 0.7677)
    ‚ö† No improvement for 95 epochs (patience: 150, remaining: 55)

EPOCH 161/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.0977
  ‚Ä¢ Validation Loss: 1.0398
  ‚Ä¢ Learning Rate: 0.000744
    No improvement (current: 1.0398, best: 0.7677)
    ‚ö† No improvement for 96 epochs (patience: 150, remaining: 54)

EPOCH 162/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.0078
  ‚Ä¢ Validation Loss: 1.0062
  ‚Ä¢ Learning Rate: 0.000737
    No improvement (current: 1.0062, best: 0.7677)
    ‚ö† No improvement for 97 epochs (patience: 150, remaining: 53)

EPOCH 163/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.9763
  ‚Ä¢ Validation Loss: 0.9920
  ‚Ä¢ Learning Rate: 0.000731
    No improvement (current: 0.9920, best: 0.7677)
    ‚ö† No improvement for 98 epochs (patience: 150, remaining: 52)

EPOCH 164/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.9886
  ‚Ä¢ Validation Loss: 1.2355
  ‚Ä¢ Learning Rate: 0.000724
    No improvement (current: 1.2355, best: 0.7677)
    ‚ö† No improvement for 99 epochs (patience: 150, remaining: 51)

EPOCH 165/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.1520
  ‚Ä¢ Validation Loss: 1.1064
  ‚Ä¢ Learning Rate: 0.000717
    No improvement (current: 1.1064, best: 0.7677)
    ‚ö† No improvement for 100 epochs (patience: 150, remaining: 50)

EPOCH 166/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.0633
  ‚Ä¢ Validation Loss: 1.0470
  ‚Ä¢ Learning Rate: 0.000710
    No improvement (current: 1.0470, best: 0.7677)
    ‚ö† No improvement for 101 epochs (patience: 150, remaining: 49)

EPOCH 167/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.0201
  ‚Ä¢ Validation Loss: 1.0274
  ‚Ä¢ Learning Rate: 0.000704
    No improvement (current: 1.0274, best: 0.7677)
    ‚ö† No improvement for 102 epochs (patience: 150, remaining: 48)

EPOCH 168/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.1578
  ‚Ä¢ Validation Loss: 1.2135
  ‚Ä¢ Learning Rate: 0.000697
    No improvement (current: 1.2135, best: 0.7677)
    ‚ö† No improvement for 103 epochs (patience: 150, remaining: 47)

EPOCH 169/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.1503
  ‚Ä¢ Validation Loss: 1.1256
  ‚Ä¢ Learning Rate: 0.000690
    No improvement (current: 1.1256, best: 0.7677)
    ‚ö† No improvement for 104 epochs (patience: 150, remaining: 46)

EPOCH 170/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.0997
  ‚Ä¢ Validation Loss: 1.1028
  ‚Ä¢ Learning Rate: 0.000683
    No improvement (current: 1.1028, best: 0.7677)
    ‚ö† No improvement for 105 epochs (patience: 150, remaining: 45)

EPOCH 171/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.0712
  ‚Ä¢ Validation Loss: 1.0852
  ‚Ä¢ Learning Rate: 0.000676
    No improvement (current: 1.0852, best: 0.7677)
    ‚ö† No improvement for 106 epochs (patience: 150, remaining: 44)

EPOCH 172/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.0581
  ‚Ä¢ Validation Loss: 1.0472
  ‚Ä¢ Learning Rate: 0.000669
    No improvement (current: 1.0472, best: 0.7677)
    ‚ö† No improvement for 107 epochs (patience: 150, remaining: 43)

EPOCH 173/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.0322
  ‚Ä¢ Validation Loss: 1.0300
  ‚Ä¢ Learning Rate: 0.000662
    No improvement (current: 1.0300, best: 0.7677)
    ‚ö† No improvement for 108 epochs (patience: 150, remaining: 42)

EPOCH 174/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.0056
  ‚Ä¢ Validation Loss: 1.0084
  ‚Ä¢ Learning Rate: 0.000655
    No improvement (current: 1.0084, best: 0.7677)
    ‚ö† No improvement for 109 epochs (patience: 150, remaining: 41)

EPOCH 175/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.9950
  ‚Ä¢ Validation Loss: 1.0900
  ‚Ä¢ Learning Rate: 0.000648
    No improvement (current: 1.0900, best: 0.7677)
    ‚ö† No improvement for 110 epochs (patience: 150, remaining: 40)

EPOCH 176/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.0129
  ‚Ä¢ Validation Loss: 1.0004
  ‚Ä¢ Learning Rate: 0.000641
    No improvement (current: 1.0004, best: 0.7677)
    ‚ö† No improvement for 111 epochs (patience: 150, remaining: 39)

EPOCH 177/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.9882
  ‚Ä¢ Validation Loss: 0.9990
  ‚Ä¢ Learning Rate: 0.000633
    No improvement (current: 0.9990, best: 0.7677)
    ‚ö† No improvement for 112 epochs (patience: 150, remaining: 38)

EPOCH 178/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.9836
  ‚Ä¢ Validation Loss: 0.9848
  ‚Ä¢ Learning Rate: 0.000626
    No improvement (current: 0.9848, best: 0.7677)
    ‚ö† No improvement for 113 epochs (patience: 150, remaining: 37)

EPOCH 179/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.9698
  ‚Ä¢ Validation Loss: 0.9835
  ‚Ä¢ Learning Rate: 0.000619
    No improvement (current: 0.9835, best: 0.7677)
    ‚ö† No improvement for 114 epochs (patience: 150, remaining: 36)

EPOCH 180/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.9735
  ‚Ä¢ Validation Loss: 0.9771
  ‚Ä¢ Learning Rate: 0.000612
    No improvement (current: 0.9771, best: 0.7677)
    ‚ö† No improvement for 115 epochs (patience: 150, remaining: 35)

EPOCH 181/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.9531
  ‚Ä¢ Validation Loss: 0.9658
  ‚Ä¢ Learning Rate: 0.000604
    No improvement (current: 0.9658, best: 0.7677)
    ‚ö† No improvement for 116 epochs (patience: 150, remaining: 34)

EPOCH 182/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.9680
  ‚Ä¢ Validation Loss: 0.9835
  ‚Ä¢ Learning Rate: 0.000597
    No improvement (current: 0.9835, best: 0.7677)
    ‚ö† No improvement for 117 epochs (patience: 150, remaining: 33)

EPOCH 183/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.9473
  ‚Ä¢ Validation Loss: 0.9559
  ‚Ä¢ Learning Rate: 0.000590
    No improvement (current: 0.9559, best: 0.7677)
    ‚ö† No improvement for 118 epochs (patience: 150, remaining: 32)

EPOCH 184/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.9200
  ‚Ä¢ Validation Loss: 0.9351
  ‚Ä¢ Learning Rate: 0.000582
    No improvement (current: 0.9351, best: 0.7677)
    ‚ö† No improvement for 119 epochs (patience: 150, remaining: 31)

EPOCH 185/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.9023
  ‚Ä¢ Validation Loss: 0.9383
  ‚Ä¢ Learning Rate: 0.000575
    No improvement (current: 0.9383, best: 0.7677)
    ‚ö† No improvement for 120 epochs (patience: 150, remaining: 30)

EPOCH 186/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8870
  ‚Ä¢ Validation Loss: 0.9184
  ‚Ä¢ Learning Rate: 0.000567
    No improvement (current: 0.9184, best: 0.7677)
    ‚ö† No improvement for 121 epochs (patience: 150, remaining: 29)

EPOCH 187/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8809
  ‚Ä¢ Validation Loss: 0.9144
  ‚Ä¢ Learning Rate: 0.000560
    No improvement (current: 0.9144, best: 0.7677)
    ‚ö† No improvement for 122 epochs (patience: 150, remaining: 28)

EPOCH 188/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8819
  ‚Ä¢ Validation Loss: 0.9239
  ‚Ä¢ Learning Rate: 0.000553
    No improvement (current: 0.9239, best: 0.7677)
    ‚ö† No improvement for 123 epochs (patience: 150, remaining: 27)

EPOCH 189/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8769
  ‚Ä¢ Validation Loss: 0.9310
  ‚Ä¢ Learning Rate: 0.000545
    No improvement (current: 0.9310, best: 0.7677)
    ‚ö† No improvement for 124 epochs (patience: 150, remaining: 26)

EPOCH 190/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8725
  ‚Ä¢ Validation Loss: 0.9065
  ‚Ä¢ Learning Rate: 0.000538
    No improvement (current: 0.9065, best: 0.7677)
    ‚ö† No improvement for 125 epochs (patience: 150, remaining: 25)

EPOCH 191/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8665
  ‚Ä¢ Validation Loss: 0.9031
  ‚Ä¢ Learning Rate: 0.000530
    No improvement (current: 0.9031, best: 0.7677)
    ‚ö† No improvement for 126 epochs (patience: 150, remaining: 24)

EPOCH 192/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8726
  ‚Ä¢ Validation Loss: 0.9102
  ‚Ä¢ Learning Rate: 0.000523
    No improvement (current: 0.9102, best: 0.7677)
    ‚ö† No improvement for 127 epochs (patience: 150, remaining: 23)

EPOCH 193/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8599
  ‚Ä¢ Validation Loss: 0.9015
  ‚Ä¢ Learning Rate: 0.000515
    No improvement (current: 0.9015, best: 0.7677)
    ‚ö† No improvement for 128 epochs (patience: 150, remaining: 22)

EPOCH 194/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8693
  ‚Ä¢ Validation Loss: 0.9041
  ‚Ä¢ Learning Rate: 0.000508
    No improvement (current: 0.9041, best: 0.7677)
    ‚ö† No improvement for 129 epochs (patience: 150, remaining: 21)

EPOCH 195/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8615
  ‚Ä¢ Validation Loss: 0.9053
  ‚Ä¢ Learning Rate: 0.000500
    No improvement (current: 0.9053, best: 0.7677)
    ‚ö† No improvement for 130 epochs (patience: 150, remaining: 20)

EPOCH 196/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8418
  ‚Ä¢ Validation Loss: 0.8870
  ‚Ä¢ Learning Rate: 0.000493
    No improvement (current: 0.8870, best: 0.7677)
    ‚ö† No improvement for 131 epochs (patience: 150, remaining: 19)

EPOCH 197/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8471
  ‚Ä¢ Validation Loss: 0.8854
  ‚Ä¢ Learning Rate: 0.000486
    No improvement (current: 0.8854, best: 0.7677)
    ‚ö† No improvement for 132 epochs (patience: 150, remaining: 18)

EPOCH 198/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8354
  ‚Ä¢ Validation Loss: 0.8899
  ‚Ä¢ Learning Rate: 0.000478
    No improvement (current: 0.8899, best: 0.7677)
    ‚ö† No improvement for 133 epochs (patience: 150, remaining: 17)

EPOCH 199/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8522
  ‚Ä¢ Validation Loss: 0.8894
  ‚Ä¢ Learning Rate: 0.000471
    No improvement (current: 0.8894, best: 0.7677)
    ‚ö† No improvement for 134 epochs (patience: 150, remaining: 16)

EPOCH 200/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8478
  ‚Ä¢ Validation Loss: 0.8917
  ‚Ä¢ Learning Rate: 0.000463
   üíæ Periodic checkpoint saved: epoch_200.pth
    No improvement (current: 0.8917, best: 0.7677)
    ‚ö† No improvement for 135 epochs (patience: 150, remaining: 15)

EPOCH 201/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8468
  ‚Ä¢ Validation Loss: 0.8854
  ‚Ä¢ Learning Rate: 0.000456
    No improvement (current: 0.8854, best: 0.7677)
    ‚ö† No improvement for 136 epochs (patience: 150, remaining: 14)

EPOCH 202/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8415
  ‚Ä¢ Validation Loss: 0.8854
  ‚Ä¢ Learning Rate: 0.000448
    No improvement (current: 0.8854, best: 0.7677)
    ‚ö† No improvement for 137 epochs (patience: 150, remaining: 13)

EPOCH 203/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8541
  ‚Ä¢ Validation Loss: 0.8870
  ‚Ä¢ Learning Rate: 0.000441
    No improvement (current: 0.8870, best: 0.7677)
    ‚ö† No improvement for 138 epochs (patience: 150, remaining: 12)

EPOCH 204/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8380
  ‚Ä¢ Validation Loss: 0.8780
  ‚Ä¢ Learning Rate: 0.000433
    No improvement (current: 0.8780, best: 0.7677)
    ‚ö† No improvement for 139 epochs (patience: 150, remaining: 11)

EPOCH 205/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8356
  ‚Ä¢ Validation Loss: 0.8973
  ‚Ä¢ Learning Rate: 0.000426
    No improvement (current: 0.8973, best: 0.7677)
    ‚ö† No improvement for 140 epochs (patience: 150, remaining: 10)

EPOCH 206/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8238
  ‚Ä¢ Validation Loss: 0.8832
  ‚Ä¢ Learning Rate: 0.000419
    No improvement (current: 0.8832, best: 0.7677)
    ‚ö† No improvement for 141 epochs (patience: 150, remaining: 9)

EPOCH 207/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8292
  ‚Ä¢ Validation Loss: 0.8826
  ‚Ä¢ Learning Rate: 0.000411
    No improvement (current: 0.8826, best: 0.7677)
    ‚ö† No improvement for 142 epochs (patience: 150, remaining: 8)

EPOCH 208/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8297
  ‚Ä¢ Validation Loss: 0.8815
  ‚Ä¢ Learning Rate: 0.000404
    No improvement (current: 0.8815, best: 0.7677)
    ‚ö† No improvement for 143 epochs (patience: 150, remaining: 7)

EPOCH 209/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8423
  ‚Ä¢ Validation Loss: 0.8844
  ‚Ä¢ Learning Rate: 0.000397
    No improvement (current: 0.8844, best: 0.7677)
    ‚ö† No improvement for 144 epochs (patience: 150, remaining: 6)

EPOCH 210/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8248
  ‚Ä¢ Validation Loss: 0.8843
  ‚Ä¢ Learning Rate: 0.000389
    No improvement (current: 0.8843, best: 0.7677)
    ‚ö† No improvement for 145 epochs (patience: 150, remaining: 5)

EPOCH 211/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8205
  ‚Ä¢ Validation Loss: 0.8777
  ‚Ä¢ Learning Rate: 0.000382
    No improvement (current: 0.8777, best: 0.7677)
    ‚ö† No improvement for 146 epochs (patience: 150, remaining: 4)

EPOCH 212/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8338
  ‚Ä¢ Validation Loss: 0.8846
  ‚Ä¢ Learning Rate: 0.000375
    No improvement (current: 0.8846, best: 0.7677)
    ‚ö† No improvement for 147 epochs (patience: 150, remaining: 3)

EPOCH 213/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8201
  ‚Ä¢ Validation Loss: 0.8790
  ‚Ä¢ Learning Rate: 0.000368
    No improvement (current: 0.8790, best: 0.7677)
    ‚ö† No improvement for 148 epochs (patience: 150, remaining: 2)

EPOCH 214/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8325
  ‚Ä¢ Validation Loss: 0.8769
  ‚Ä¢ Learning Rate: 0.000360
    No improvement (current: 0.8769, best: 0.7677)
    ‚ö† No improvement for 149 epochs (patience: 150, remaining: 1)

EPOCH 215/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8275
  ‚Ä¢ Validation Loss: 0.8806
  ‚Ä¢ Learning Rate: 0.000353
    No improvement (current: 0.8806, best: 0.7677)
    ‚ö† No improvement for 150 epochs (patience: 150, remaining: 0)

================================================================================
EARLY STOPPING TRIGGERED!
================================================================================
Model has not improved for 150 consecutive epochs.
Stopping training at epoch 215.
Best validation loss achieved: 0.7677
================================================================================


================================================================================
TRAINING COMPLETED
================================================================================
Best Val Loss:  0.7677
Total Epochs:   215
Models Saved:   ./Result/a3/Latin2
TensorBoard:    ./Result/a3/Latin2/tensorboard_logs
================================================================================

[23:48:46] Training completed. Best val loss: 0.7677

=== TRAINING COMPLETED SUCCESSFULLY ===
Training Finished!

========================================================================
Testing Hybrid2 Baseline Model with Smart Skip Connections and Multi-Scale Aggregation and Deep Supervision: Latin2
========================================================================
=== Historical Document Segmentation Testing ===

Using 6 classes for manuscript: Latin2
Model: Hybrid2
Dataset: UDIADS_BIB
Manuscript: Latin2
Test-Time Augmentation: Enabled
CRF post-processing: Enabled
  - DenseCRF with spatial and color pairwise potentials

================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder for Testing
================================================================================
================================================================================
üöÄ SIMPLE DECODER (Flag-Controlled Enhancements)
================================================================================
  ‚Ä¢ EfficientNet Variant: b4
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Enhancement Flags:
  ‚Ä¢ Deep Supervision: True
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: True
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: True
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Loaded checkpoint from epoch 64
Best validation loss: 0.7677
  ‚úÖ Model checkpoint loaded successfully (exact match)
Loaded checkpoint: best_model_latest.pth
Namespace(cfg=None, output_dir='./Result/a3/Latin2', use_baseline=True, decoder='EfficientNet-B4', efficientnet_variant='b4', use_deep_supervision=True, use_cbam=False, use_smart_skip=True, use_cross_attn=False, use_multiscale_agg=True, use_groupnorm=True, use_batchnorm=False, use_pos_embed=True, dataset='UDIADS_BIB', manuscript='Latin2', udiadsbib_root='../../U-DIADS-Bib-MS_patched', divahisdb_root='../../DivaHisDB', use_patched_data=True, num_classes=6, img_size=224, batch_size=24, is_savenii=True, test_save_dir='../predictions', use_crf=True, deterministic=1, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, use_tta=True)
Testing with checkpoint: best_model_latest.pth
Saving predictions to: ./Result/a3/Latin2/predictions

=== Starting Testing ===
Dataset: UDIADS_BIB
Model: Hybrid2
Manuscript: Latin2
Save predictions: True

Starting inference on UDIADS_BIB dataset
Found 1620 patches for Latin2
Using Test-Time Augmentation (TTA) for improved accuracy
CRF post-processing: Enabled
  - DenseCRF with spatial and color pairwise potentials
Processing: 076 (54 patches)
Applying CRF post-processing to 076
CRF post-processing completed for 076
Completed: 076
Processing: 079 (54 patches)
Applying CRF post-processing to 079
CRF post-processing completed for 079
Completed: 079
Processing: 082 (54 patches)
Applying CRF post-processing to 082
CRF post-processing completed for 082
Completed: 082
Processing: 095 (54 patches)
Applying CRF post-processing to 095
CRF post-processing completed for 095
Completed: 095
Processing: 106 (54 patches)
Applying CRF post-processing to 106
CRF post-processing completed for 106
Completed: 106
Processing: 111 (54 patches)
Applying CRF post-processing to 111
CRF post-processing completed for 111
Completed: 111
Processing: 115 (54 patches)
Applying CRF post-processing to 115
CRF post-processing completed for 115
Completed: 115
Processing: 117 (54 patches)
Applying CRF post-processing to 117
CRF post-processing completed for 117
Completed: 117
Processing: 128 (54 patches)
Applying CRF post-processing to 128
CRF post-processing completed for 128
Completed: 128
Processing: 134 (54 patches)
Applying CRF post-processing to 134
CRF post-processing completed for 134
Completed: 134
Processing: 138 (54 patches)
Applying CRF post-processing to 138
CRF post-processing completed for 138
Completed: 138
Processing: 142 (54 patches)
Applying CRF post-processing to 142
CRF post-processing completed for 142
Completed: 142
Processing: 159 (54 patches)
Applying CRF post-processing to 159
CRF post-processing completed for 159
Completed: 159
Processing: 166 (54 patches)
Applying CRF post-processing to 166
CRF post-processing completed for 166
Completed: 166
Processing: 185 (54 patches)
Applying CRF post-processing to 185
CRF post-processing completed for 185
Completed: 185
Processing: 200 (54 patches)
Applying CRF post-processing to 200
CRF post-processing completed for 200
Completed: 200
Processing: 203 (54 patches)
Applying CRF post-processing to 203
CRF post-processing completed for 203
Completed: 203
Processing: 208 (54 patches)
Applying CRF post-processing to 208
CRF post-processing completed for 208
Completed: 208
Processing: 229 (54 patches)
Applying CRF post-processing to 229
CRF post-processing completed for 229
Completed: 229
Processing: 230 (54 patches)
Applying CRF post-processing to 230
CRF post-processing completed for 230
Completed: 230
Processing: 235 (54 patches)
Applying CRF post-processing to 235
CRF post-processing completed for 235
Completed: 235
Processing: 236 (54 patches)
Applying CRF post-processing to 236
CRF post-processing completed for 236
Completed: 236
Processing: 248 (54 patches)
Applying CRF post-processing to 248
CRF post-processing completed for 248
Completed: 248
Processing: 249 (54 patches)
Applying CRF post-processing to 249
CRF post-processing completed for 249
Completed: 249
Processing: 250 (54 patches)
Applying CRF post-processing to 250
CRF post-processing completed for 250
Completed: 250
Processing: 251 (54 patches)
Applying CRF post-processing to 251
CRF post-processing completed for 251
Completed: 251
Processing: 252 (54 patches)
Applying CRF post-processing to 252
CRF post-processing completed for 252
Completed: 252
Processing: 275 (54 patches)
Applying CRF post-processing to 275
CRF post-processing completed for 275
Completed: 275
Processing: 277 (54 patches)
Applying CRF post-processing to 277
CRF post-processing completed for 277
Completed: 277
Processing: 297 (54 patches)
Applying CRF post-processing to 297
CRF post-processing completed for 297
Completed: 297

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9699, Recall=0.9990, F1=0.9843, IoU=0.9690
Paratext       : Precision=0.7965, Recall=0.4628, F1=0.5855, IoU=0.4139
Decoration     : Precision=0.9243, Recall=0.8551, F1=0.8883, IoU=0.7991
Main Text      : Precision=0.9601, Recall=0.5506, F1=0.6998, IoU=0.5383
Title          : Precision=0.9080, Recall=0.7178, F1=0.8018, IoU=0.6692
Chapter Headings: Precision=0.8463, Recall=0.1666, F1=0.2785, IoU=0.1617

Mean metrics:
----------------------------------------
Mean Precision: 0.9009
Mean Recall: 0.6253
Mean F1-Score: 0.7064
Mean IoU: 0.5919

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9699, Recall=0.9990, F1=0.9843, IoU=0.9690
Paratext       : Precision=0.7965, Recall=0.4628, F1=0.5855, IoU=0.4139
Decoration     : Precision=0.9243, Recall=0.8551, F1=0.8883, IoU=0.7991
Main Text      : Precision=0.9601, Recall=0.5506, F1=0.6998, IoU=0.5383
Title          : Precision=0.9080, Recall=0.7178, F1=0.8018, IoU=0.6692
Chapter Headings: Precision=0.8463, Recall=0.1666, F1=0.2785, IoU=0.1617

Mean metrics:
----------------------------------------
Mean Precision: 0.9009
Mean Recall: 0.6253
Mean F1-Score: 0.7064
Mean IoU: 0.5919
Inference completed on 30 images

=== TESTING COMPLETED SUCCESSFULLY ===
Results saved to: ./Result/a3/Latin2/predictions
==================================================

Calculating average metrics...
Looking for metrics files in: ./Result/a3
  ‚úì Found metrics for Latin2
  ‚úó Metrics file not found: ./Result/a3/metrics_Latin14396.json
  ‚úó Metrics file not found: ./Result/a3/metrics_Latin16746.json
  ‚úó Metrics file not found: ./Result/a3/metrics_Syr341.json

================================================================================
AVERAGE METRICS ACROSS 1 MANUSCRIPT(S)
================================================================================
Manuscripts: Latin2
Missing: Latin14396, Latin16746, Syr341
--------------------------------------------------------------------------------
Mean Precision: 0.9009
Mean Recall:    0.6253
Mean F1-Score:  0.7064
Mean IoU:       0.5919
================================================================================

========================================================================
Training Hybrid2 Baseline Model with Smart Skip Connections and Multi-Scale Aggregation and Deep Supervision: Latin14396
========================================================================
Dataset: U-DIADS-Bib-MS_patched
Architecture: Swin Transformer Encoder ‚Üí 2 Swin Blocks Bottleneck ‚Üí Simple CNN Decoder
Decoder: Simple Decoder (EfficientNet-b4 channel configuration)

Components Enabled:
  ‚úì Swin Encoder (4 stages: 96‚Üí192‚Üí384‚Üí768 dim)
  ‚úì Bottleneck: 2 Swin Transformer blocks (768 dim, 24 heads)
  ‚úì Simple CNN Decoder (channels: [256, 128, 64, 32])
  ‚úì Smart Skip Connections
  ‚úì Multi-Scale Aggregation
  ‚úì Deep Supervision
  ‚úì Positional Embeddings (default: enabled)
  ‚úì GroupNorm (default normalization)

Components Disabled (baseline):
  ‚úó CBAM Attention
  ‚úó Cross-Attention Bottleneck
  ‚úó BatchNorm
========================================================================
All arguments validated successfully!
Setting random seed to 1234 for reproducible training...
Setting up U-DIADS-Bib dataset...
Using 6 classes for manuscript: Latin14396
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin14396/Image/training
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin14396/mask/training_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin14396/Image/validation
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin14396/mask/validation_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder
================================================================================
================================================================================
üöÄ SIMPLE DECODER (Flag-Controlled Enhancements)
================================================================================
  ‚Ä¢ EfficientNet Variant: b4
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Enhancement Flags:
  ‚Ä¢ Deep Supervision: True
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: True
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: True
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Model moved to CUDA
Model created successfully with 6 classes
DEBUG: args.output_dir = ./Result/a3/Latin14396

=== Starting Training ===
Dataset: UDIADS_BIB
Model: Hybrid2
Batch size: 4
Max epochs: 300
Learning rate: 0.0001


================================================================================
TRAINING CONFIGURATION
================================================================================
Dataset: UDIADS_BIB
Model: Hybrid2
Batch Size: 4
Max Epochs: 300
Learning Rate: 0.0001
Number of Classes: 6
Output Directory: ./Result/a3/Latin14396
Early Stopping Patience: 150 epochs
================================================================================

üìä Dataset Statistics:
   - Training samples: 540
   - Validation samples: 540
   - Batch size: 4
   - Steps per epoch: 135


================================================================================
COMPUTING CLASS WEIGHTS
================================================================================
Raw ENS weights: [9.99999990e-05 1.09839441e-04 9.99999990e-05 9.99999990e-05
 1.00000006e-04 1.00000021e-04]

Class Distribution:
Class                Pixels          Frequency       Weight         
-----------------------------------------------------------------
0                        24,235,884        89.4477%         0.9839
1                            24,125         0.0890%         1.0807
2                           460,965         1.7013%         0.9839
3                         2,056,396         7.5896%         0.9839
4                           164,544         0.6073%         0.9839
5                           153,126         0.5651%         0.9839

Total pixels: 27,095,040.0
Beta: 0.9999
Smoothing: 0.0
Weight range: [0.9839, 1.0807]
================================================================================
üìà Class weights computed with ENS method (smoothing=0.1)
   Final weights: [0.9838655  1.0806724  0.9838655  0.9838655  0.98386556 0.9838657 ]

‚úì Loss functions created: CE (weighted, label_smoothing=0.1), Focal (Œ≥=2.0), Dice
  üìä OneCycleLR: 135 steps/epoch √ó 300 epochs = 40500 total steps
üöÄ Hybrid2 Best Practice: Differential Learning Rates
  üìä Encoder LR:     0.000010 (10x smaller, 119 params)
  üìä Bottleneck LR:  0.000050 (5x smaller, 26 params)
  üìä Decoder LR:     0.000100 (base LR, 90 params)
  ‚öôÔ∏è  Scheduler: OneCycleLR (Peak: 10x, Warmup: 30%, Cosine)
  ‚öôÔ∏è  Weight decay: Encoder=1e-3, Bottleneck=5e-3, Decoder=1e-2

üîç Checking for checkpoint at: ./Result/a3/Latin14396/best_model_latest.pth
   Absolute path: /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid/Result/a3/Latin14396/best_model_latest.pth
   File exists: False

================================================================================
STARTING TRAINING
================================================================================
Early stopping patience: 150 epochs
Learning rate scheduler: OneCycleLR (better convergence for transformers)
================================================================================

EPOCH 1/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.1622
  ‚Ä¢ Validation Loss: 1.0069
  ‚Ä¢ Learning Rate: 0.000100
    ‚úì New best checkpoint saved! Val loss: 1.0069
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 2/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.9406
  ‚Ä¢ Validation Loss: 0.9008
  ‚Ä¢ Learning Rate: 0.000101
    ‚úì New best checkpoint saved! Val loss: 0.9008
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 3/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8686
  ‚Ä¢ Validation Loss: 0.8619
  ‚Ä¢ Learning Rate: 0.000102
    ‚úì New best checkpoint saved! Val loss: 0.8619
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 4/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8352
  ‚Ä¢ Validation Loss: 0.8419
  ‚Ä¢ Learning Rate: 0.000104
    ‚úì New best checkpoint saved! Val loss: 0.8419
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 5/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8117
  ‚Ä¢ Validation Loss: 0.8194
  ‚Ä¢ Learning Rate: 0.000107
    ‚úì New best checkpoint saved! Val loss: 0.8194
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 6/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8007
  ‚Ä¢ Validation Loss: 0.8261
  ‚Ä¢ Learning Rate: 0.000110
    No improvement (current: 0.8261, best: 0.8194)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 7/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7847
  ‚Ä¢ Validation Loss: 0.8226
  ‚Ä¢ Learning Rate: 0.000113
    No improvement (current: 0.8226, best: 0.8194)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 8/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7642
  ‚Ä¢ Validation Loss: 0.8039
  ‚Ä¢ Learning Rate: 0.000117
    ‚úì New best checkpoint saved! Val loss: 0.8039
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 9/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7655
  ‚Ä¢ Validation Loss: 0.7859
  ‚Ä¢ Learning Rate: 0.000122
    ‚úì New best checkpoint saved! Val loss: 0.7859
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 10/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7527
  ‚Ä¢ Validation Loss: 0.7838
  ‚Ä¢ Learning Rate: 0.000127
    ‚úì New best checkpoint saved! Val loss: 0.7838
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 11/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7461
  ‚Ä¢ Validation Loss: 0.7773
  ‚Ä¢ Learning Rate: 0.000133
    ‚úì New best checkpoint saved! Val loss: 0.7773
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 12/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7351
  ‚Ä¢ Validation Loss: 0.7698
  ‚Ä¢ Learning Rate: 0.000139
    ‚úì New best checkpoint saved! Val loss: 0.7698
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 13/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7412
  ‚Ä¢ Validation Loss: 0.7670
  ‚Ä¢ Learning Rate: 0.000146
    ‚úì New best checkpoint saved! Val loss: 0.7670
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 14/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7355
  ‚Ä¢ Validation Loss: 0.7648
  ‚Ä¢ Learning Rate: 0.000153
    ‚úì New best checkpoint saved! Val loss: 0.7648
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 15/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7309
  ‚Ä¢ Validation Loss: 0.7707
  ‚Ä¢ Learning Rate: 0.000160
    No improvement (current: 0.7707, best: 0.7648)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 16/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7210
  ‚Ä¢ Validation Loss: 0.7638
  ‚Ä¢ Learning Rate: 0.000168
    ‚úì New best checkpoint saved! Val loss: 0.7638
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 17/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7226
  ‚Ä¢ Validation Loss: 0.7608
  ‚Ä¢ Learning Rate: 0.000177
    ‚úì New best checkpoint saved! Val loss: 0.7608
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 18/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7243
  ‚Ä¢ Validation Loss: 0.7652
  ‚Ä¢ Learning Rate: 0.000186
    No improvement (current: 0.7652, best: 0.7608)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 19/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7185
  ‚Ä¢ Validation Loss: 0.7576
  ‚Ä¢ Learning Rate: 0.000195
    ‚úì New best checkpoint saved! Val loss: 0.7576
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 20/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7144
  ‚Ä¢ Validation Loss: 0.7639
  ‚Ä¢ Learning Rate: 0.000205
    No improvement (current: 0.7639, best: 0.7576)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 21/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7212
  ‚Ä¢ Validation Loss: 0.7568
  ‚Ä¢ Learning Rate: 0.000216
    ‚úì New best checkpoint saved! Val loss: 0.7568
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 22/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7155
  ‚Ä¢ Validation Loss: 0.7626
  ‚Ä¢ Learning Rate: 0.000226
    No improvement (current: 0.7626, best: 0.7568)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 23/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7201
  ‚Ä¢ Validation Loss: 0.7498
  ‚Ä¢ Learning Rate: 0.000237
    ‚úì New best checkpoint saved! Val loss: 0.7498
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 24/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7131
  ‚Ä¢ Validation Loss: 0.7615
  ‚Ä¢ Learning Rate: 0.000249
    No improvement (current: 0.7615, best: 0.7498)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 25/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7137
  ‚Ä¢ Validation Loss: 0.7491
  ‚Ä¢ Learning Rate: 0.000261
    ‚úì New best checkpoint saved! Val loss: 0.7491
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 26/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7222
  ‚Ä¢ Validation Loss: 0.7599
  ‚Ä¢ Learning Rate: 0.000273
    No improvement (current: 0.7599, best: 0.7491)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 27/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7029
  ‚Ä¢ Validation Loss: 0.7586
  ‚Ä¢ Learning Rate: 0.000286
    No improvement (current: 0.7586, best: 0.7491)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 28/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7109
  ‚Ä¢ Validation Loss: 0.7583
  ‚Ä¢ Learning Rate: 0.000298
    No improvement (current: 0.7583, best: 0.7491)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 29/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7037
  ‚Ä¢ Validation Loss: 0.7856
  ‚Ä¢ Learning Rate: 0.000312
    No improvement (current: 0.7856, best: 0.7491)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 30/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7191
  ‚Ä¢ Validation Loss: 0.7648
  ‚Ä¢ Learning Rate: 0.000325
    No improvement (current: 0.7648, best: 0.7491)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 31/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7125
  ‚Ä¢ Validation Loss: 0.7577
  ‚Ä¢ Learning Rate: 0.000339
    No improvement (current: 0.7577, best: 0.7491)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 32/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7173
  ‚Ä¢ Validation Loss: 0.7543
  ‚Ä¢ Learning Rate: 0.000353
    No improvement (current: 0.7543, best: 0.7491)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 33/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7024
  ‚Ä¢ Validation Loss: 0.7573
  ‚Ä¢ Learning Rate: 0.000367
    No improvement (current: 0.7573, best: 0.7491)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 34/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7010
  ‚Ä¢ Validation Loss: 0.7724
  ‚Ä¢ Learning Rate: 0.000381
    No improvement (current: 0.7724, best: 0.7491)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 35/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7261
  ‚Ä¢ Validation Loss: 0.7486
  ‚Ä¢ Learning Rate: 0.000396
    ‚úì New best checkpoint saved! Val loss: 0.7486
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 36/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7124
  ‚Ä¢ Validation Loss: 0.7450
  ‚Ä¢ Learning Rate: 0.000411
    ‚úì New best checkpoint saved! Val loss: 0.7450
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 37/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7064
  ‚Ä¢ Validation Loss: 0.7446
  ‚Ä¢ Learning Rate: 0.000426
    ‚úì New best checkpoint saved! Val loss: 0.7446
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 38/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7052
  ‚Ä¢ Validation Loss: 0.7693
  ‚Ä¢ Learning Rate: 0.000441
    No improvement (current: 0.7693, best: 0.7446)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 39/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7029
  ‚Ä¢ Validation Loss: 0.7933
  ‚Ä¢ Learning Rate: 0.000456
    No improvement (current: 0.7933, best: 0.7446)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 40/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7000
  ‚Ä¢ Validation Loss: 0.7491
  ‚Ä¢ Learning Rate: 0.000472
    No improvement (current: 0.7491, best: 0.7446)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 41/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6898
  ‚Ä¢ Validation Loss: 0.7595
  ‚Ä¢ Learning Rate: 0.000487
    No improvement (current: 0.7595, best: 0.7446)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 42/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7180
  ‚Ä¢ Validation Loss: 0.7558
  ‚Ä¢ Learning Rate: 0.000503
    No improvement (current: 0.7558, best: 0.7446)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 43/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6968
  ‚Ä¢ Validation Loss: 0.7419
  ‚Ä¢ Learning Rate: 0.000519
    ‚úì New best checkpoint saved! Val loss: 0.7419
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 44/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6986
  ‚Ä¢ Validation Loss: 0.7714
  ‚Ä¢ Learning Rate: 0.000534
    No improvement (current: 0.7714, best: 0.7419)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 45/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6970
  ‚Ä¢ Validation Loss: 0.7512
  ‚Ä¢ Learning Rate: 0.000550
    No improvement (current: 0.7512, best: 0.7419)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 46/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7052
  ‚Ä¢ Validation Loss: 0.7494
  ‚Ä¢ Learning Rate: 0.000566
    No improvement (current: 0.7494, best: 0.7419)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 47/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7094
  ‚Ä¢ Validation Loss: 0.7515
  ‚Ä¢ Learning Rate: 0.000581
    No improvement (current: 0.7515, best: 0.7419)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 48/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6922
  ‚Ä¢ Validation Loss: 0.7416
  ‚Ä¢ Learning Rate: 0.000597
    ‚úì New best checkpoint saved! Val loss: 0.7416
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 49/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7100
  ‚Ä¢ Validation Loss: 0.7438
  ‚Ä¢ Learning Rate: 0.000613
    No improvement (current: 0.7438, best: 0.7416)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 50/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6915
  ‚Ä¢ Validation Loss: 0.7551
  ‚Ä¢ Learning Rate: 0.000628
    No improvement (current: 0.7551, best: 0.7416)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 51/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6978
  ‚Ä¢ Validation Loss: 0.7425
  ‚Ä¢ Learning Rate: 0.000644
    No improvement (current: 0.7425, best: 0.7416)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 52/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6897
  ‚Ä¢ Validation Loss: 0.7496
  ‚Ä¢ Learning Rate: 0.000659
    No improvement (current: 0.7496, best: 0.7416)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 53/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6935
  ‚Ä¢ Validation Loss: 0.7475
  ‚Ä¢ Learning Rate: 0.000674
    No improvement (current: 0.7475, best: 0.7416)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 54/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6944
  ‚Ä¢ Validation Loss: 0.7472
  ‚Ä¢ Learning Rate: 0.000689
    No improvement (current: 0.7472, best: 0.7416)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 55/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7080
  ‚Ä¢ Validation Loss: 0.7801
  ‚Ä¢ Learning Rate: 0.000704
    No improvement (current: 0.7801, best: 0.7416)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 56/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7130
  ‚Ä¢ Validation Loss: 0.7594
  ‚Ä¢ Learning Rate: 0.000719
    No improvement (current: 0.7594, best: 0.7416)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 57/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6976
  ‚Ä¢ Validation Loss: 0.7673
  ‚Ä¢ Learning Rate: 0.000733
    No improvement (current: 0.7673, best: 0.7416)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 58/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7053
  ‚Ä¢ Validation Loss: 0.7497
  ‚Ä¢ Learning Rate: 0.000747
    No improvement (current: 0.7497, best: 0.7416)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 59/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7022
  ‚Ä¢ Validation Loss: 0.7464
  ‚Ä¢ Learning Rate: 0.000761
    No improvement (current: 0.7464, best: 0.7416)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 60/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7068
  ‚Ä¢ Validation Loss: 0.7767
  ‚Ä¢ Learning Rate: 0.000775
    No improvement (current: 0.7767, best: 0.7416)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 61/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7070
  ‚Ä¢ Validation Loss: 0.7429
  ‚Ä¢ Learning Rate: 0.000789
    No improvement (current: 0.7429, best: 0.7416)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 62/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6929
  ‚Ä¢ Validation Loss: 0.7564
  ‚Ä¢ Learning Rate: 0.000802
    No improvement (current: 0.7564, best: 0.7416)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 63/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6960
  ‚Ä¢ Validation Loss: 0.7504
  ‚Ä¢ Learning Rate: 0.000815
    No improvement (current: 0.7504, best: 0.7416)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 64/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6892
  ‚Ä¢ Validation Loss: 0.7409
  ‚Ä¢ Learning Rate: 0.000827
    ‚úì New best checkpoint saved! Val loss: 0.7409
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 65/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6960
  ‚Ä¢ Validation Loss: 0.7708
  ‚Ä¢ Learning Rate: 0.000839
    No improvement (current: 0.7708, best: 0.7409)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 66/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7007
  ‚Ä¢ Validation Loss: 0.7627
  ‚Ä¢ Learning Rate: 0.000851
    No improvement (current: 0.7627, best: 0.7409)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 67/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6993
  ‚Ä¢ Validation Loss: 0.7565
  ‚Ä¢ Learning Rate: 0.000863
    No improvement (current: 0.7565, best: 0.7409)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 68/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6967
  ‚Ä¢ Validation Loss: 0.7452
  ‚Ä¢ Learning Rate: 0.000874
    No improvement (current: 0.7452, best: 0.7409)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 69/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6921
  ‚Ä¢ Validation Loss: 0.7485
  ‚Ä¢ Learning Rate: 0.000884
    No improvement (current: 0.7485, best: 0.7409)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 70/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6952
  ‚Ä¢ Validation Loss: 0.7570
  ‚Ä¢ Learning Rate: 0.000895
    No improvement (current: 0.7570, best: 0.7409)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 71/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6937
  ‚Ä¢ Validation Loss: 0.7444
  ‚Ä¢ Learning Rate: 0.000905
    No improvement (current: 0.7444, best: 0.7409)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 72/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6918
  ‚Ä¢ Validation Loss: 0.7404
  ‚Ä¢ Learning Rate: 0.000914
    ‚úì New best checkpoint saved! Val loss: 0.7404
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 73/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7180
  ‚Ä¢ Validation Loss: 0.7445
  ‚Ä¢ Learning Rate: 0.000923
    No improvement (current: 0.7445, best: 0.7404)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 74/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6919
  ‚Ä¢ Validation Loss: 0.7422
  ‚Ä¢ Learning Rate: 0.000932
    No improvement (current: 0.7422, best: 0.7404)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 75/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6776
  ‚Ä¢ Validation Loss: 0.7428
  ‚Ä¢ Learning Rate: 0.000940
    No improvement (current: 0.7428, best: 0.7404)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 76/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7021
  ‚Ä¢ Validation Loss: 0.7384
  ‚Ä¢ Learning Rate: 0.000947
    ‚úì New best checkpoint saved! Val loss: 0.7384
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 77/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6843
  ‚Ä¢ Validation Loss: 0.7521
  ‚Ä¢ Learning Rate: 0.000955
    No improvement (current: 0.7521, best: 0.7384)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 78/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6803
  ‚Ä¢ Validation Loss: 0.7550
  ‚Ä¢ Learning Rate: 0.000961
    No improvement (current: 0.7550, best: 0.7384)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 79/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6883
  ‚Ä¢ Validation Loss: 0.7463
  ‚Ä¢ Learning Rate: 0.000967
    No improvement (current: 0.7463, best: 0.7384)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 80/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6866
  ‚Ä¢ Validation Loss: 0.7677
  ‚Ä¢ Learning Rate: 0.000973
    No improvement (current: 0.7677, best: 0.7384)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 81/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6914
  ‚Ä¢ Validation Loss: 0.7433
  ‚Ä¢ Learning Rate: 0.000978
    No improvement (current: 0.7433, best: 0.7384)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 82/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6920
  ‚Ä¢ Validation Loss: 0.7443
  ‚Ä¢ Learning Rate: 0.000983
    No improvement (current: 0.7443, best: 0.7384)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 83/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6846
  ‚Ä¢ Validation Loss: 0.7349
  ‚Ä¢ Learning Rate: 0.000987
    ‚úì New best checkpoint saved! Val loss: 0.7349
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 84/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6804
  ‚Ä¢ Validation Loss: 0.7403
  ‚Ä¢ Learning Rate: 0.000990
    No improvement (current: 0.7403, best: 0.7349)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 85/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6810
  ‚Ä¢ Validation Loss: 0.7411
  ‚Ä¢ Learning Rate: 0.000993
    No improvement (current: 0.7411, best: 0.7349)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 86/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6751
  ‚Ä¢ Validation Loss: 0.7533
  ‚Ä¢ Learning Rate: 0.000996
    No improvement (current: 0.7533, best: 0.7349)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 87/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6818
  ‚Ä¢ Validation Loss: 0.7546
  ‚Ä¢ Learning Rate: 0.000998
    No improvement (current: 0.7546, best: 0.7349)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 88/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6743
  ‚Ä¢ Validation Loss: 0.7331
  ‚Ä¢ Learning Rate: 0.000999
    ‚úì New best checkpoint saved! Val loss: 0.7331
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 89/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6706
  ‚Ä¢ Validation Loss: 0.7557
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.7557, best: 0.7331)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 90/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6719
  ‚Ä¢ Validation Loss: 0.7361
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.7361, best: 0.7331)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 91/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6715
  ‚Ä¢ Validation Loss: 0.7785
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.7785, best: 0.7331)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 92/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6858
  ‚Ä¢ Validation Loss: 0.7376
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.7376, best: 0.7331)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 93/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6737
  ‚Ä¢ Validation Loss: 0.7445
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.7445, best: 0.7331)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 94/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6766
  ‚Ä¢ Validation Loss: 0.7427
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.7427, best: 0.7331)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 95/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6916
  ‚Ä¢ Validation Loss: 0.7518
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.7518, best: 0.7331)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 96/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6900
  ‚Ä¢ Validation Loss: 0.7626
  ‚Ä¢ Learning Rate: 0.000998
    No improvement (current: 0.7626, best: 0.7331)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 97/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6984
  ‚Ä¢ Validation Loss: 0.7347
  ‚Ä¢ Learning Rate: 0.000997
    No improvement (current: 0.7347, best: 0.7331)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 98/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6865
  ‚Ä¢ Validation Loss: 0.7727
  ‚Ä¢ Learning Rate: 0.000996
    No improvement (current: 0.7727, best: 0.7331)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 99/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6748
  ‚Ä¢ Validation Loss: 0.7320
  ‚Ä¢ Learning Rate: 0.000995
    ‚úì New best checkpoint saved! Val loss: 0.7320
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 100/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6678
  ‚Ä¢ Validation Loss: 0.7465
  ‚Ä¢ Learning Rate: 0.000994
   üíæ Periodic checkpoint saved: epoch_100.pth
    No improvement (current: 0.7465, best: 0.7320)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 101/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6731
  ‚Ä¢ Validation Loss: 0.7406
  ‚Ä¢ Learning Rate: 0.000993
    No improvement (current: 0.7406, best: 0.7320)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 102/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6796
  ‚Ä¢ Validation Loss: 0.7591
  ‚Ä¢ Learning Rate: 0.000992
    No improvement (current: 0.7591, best: 0.7320)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 103/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6630
  ‚Ä¢ Validation Loss: 0.7420
  ‚Ä¢ Learning Rate: 0.000991
    No improvement (current: 0.7420, best: 0.7320)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 104/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6691
  ‚Ä¢ Validation Loss: 0.7521
  ‚Ä¢ Learning Rate: 0.000989
    No improvement (current: 0.7521, best: 0.7320)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 105/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6793
  ‚Ä¢ Validation Loss: 0.7386
  ‚Ä¢ Learning Rate: 0.000987
    No improvement (current: 0.7386, best: 0.7320)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 106/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6830
  ‚Ä¢ Validation Loss: 0.7324
  ‚Ä¢ Learning Rate: 0.000986
    No improvement (current: 0.7324, best: 0.7320)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 107/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6617
  ‚Ä¢ Validation Loss: 0.7398
  ‚Ä¢ Learning Rate: 0.000984
    No improvement (current: 0.7398, best: 0.7320)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 108/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6681
  ‚Ä¢ Validation Loss: 0.7433
  ‚Ä¢ Learning Rate: 0.000982
    No improvement (current: 0.7433, best: 0.7320)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 109/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6705
  ‚Ä¢ Validation Loss: 0.7385
  ‚Ä¢ Learning Rate: 0.000980
    No improvement (current: 0.7385, best: 0.7320)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 110/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6583
  ‚Ä¢ Validation Loss: 0.7388
  ‚Ä¢ Learning Rate: 0.000978
    No improvement (current: 0.7388, best: 0.7320)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 111/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6628
  ‚Ä¢ Validation Loss: 0.7334
  ‚Ä¢ Learning Rate: 0.000976
    No improvement (current: 0.7334, best: 0.7320)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 112/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6640
  ‚Ä¢ Validation Loss: 0.7589
  ‚Ä¢ Learning Rate: 0.000973
    No improvement (current: 0.7589, best: 0.7320)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 113/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6822
  ‚Ä¢ Validation Loss: 0.7425
  ‚Ä¢ Learning Rate: 0.000971
    No improvement (current: 0.7425, best: 0.7320)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 114/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6744
  ‚Ä¢ Validation Loss: 0.7316
  ‚Ä¢ Learning Rate: 0.000968
    ‚úì New best checkpoint saved! Val loss: 0.7316
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 115/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6588
  ‚Ä¢ Validation Loss: 0.7287
  ‚Ä¢ Learning Rate: 0.000965
    ‚úì New best checkpoint saved! Val loss: 0.7287
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 116/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6551
  ‚Ä¢ Validation Loss: 0.7279
  ‚Ä¢ Learning Rate: 0.000963
    ‚úì New best checkpoint saved! Val loss: 0.7279
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 117/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6569
  ‚Ä¢ Validation Loss: 0.7449
  ‚Ä¢ Learning Rate: 0.000960
    No improvement (current: 0.7449, best: 0.7279)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 118/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6649
  ‚Ä¢ Validation Loss: 0.7322
  ‚Ä¢ Learning Rate: 0.000957
    No improvement (current: 0.7322, best: 0.7279)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 119/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6615
  ‚Ä¢ Validation Loss: 0.7297
  ‚Ä¢ Learning Rate: 0.000954
    No improvement (current: 0.7297, best: 0.7279)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 120/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6539
  ‚Ä¢ Validation Loss: 0.7337
  ‚Ä¢ Learning Rate: 0.000951
    No improvement (current: 0.7337, best: 0.7279)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 121/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6642
  ‚Ä¢ Validation Loss: 0.7503
  ‚Ä¢ Learning Rate: 0.000947
    No improvement (current: 0.7503, best: 0.7279)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 122/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6701
  ‚Ä¢ Validation Loss: 0.7409
  ‚Ä¢ Learning Rate: 0.000944
    No improvement (current: 0.7409, best: 0.7279)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 123/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6670
  ‚Ä¢ Validation Loss: 0.7415
  ‚Ä¢ Learning Rate: 0.000940
    No improvement (current: 0.7415, best: 0.7279)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 124/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6582
  ‚Ä¢ Validation Loss: 0.7376
  ‚Ä¢ Learning Rate: 0.000937
    No improvement (current: 0.7376, best: 0.7279)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 125/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6628
  ‚Ä¢ Validation Loss: 0.7314
  ‚Ä¢ Learning Rate: 0.000933
    No improvement (current: 0.7314, best: 0.7279)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 126/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6551
  ‚Ä¢ Validation Loss: 0.7305
  ‚Ä¢ Learning Rate: 0.000929
    No improvement (current: 0.7305, best: 0.7279)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 127/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6529
  ‚Ä¢ Validation Loss: 0.7289
  ‚Ä¢ Learning Rate: 0.000925
    No improvement (current: 0.7289, best: 0.7279)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 128/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6583
  ‚Ä¢ Validation Loss: 0.7612
  ‚Ä¢ Learning Rate: 0.000921
    No improvement (current: 0.7612, best: 0.7279)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 129/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6583
  ‚Ä¢ Validation Loss: 0.7319
  ‚Ä¢ Learning Rate: 0.000917
    No improvement (current: 0.7319, best: 0.7279)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 130/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6630
  ‚Ä¢ Validation Loss: 0.7301
  ‚Ä¢ Learning Rate: 0.000913
    No improvement (current: 0.7301, best: 0.7279)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 131/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6539
  ‚Ä¢ Validation Loss: 0.7313
  ‚Ä¢ Learning Rate: 0.000909
    No improvement (current: 0.7313, best: 0.7279)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 132/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6533
  ‚Ä¢ Validation Loss: 0.7320
  ‚Ä¢ Learning Rate: 0.000905
    No improvement (current: 0.7320, best: 0.7279)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 133/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6665
  ‚Ä¢ Validation Loss: 0.7469
  ‚Ä¢ Learning Rate: 0.000900
    No improvement (current: 0.7469, best: 0.7279)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 134/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6681
  ‚Ä¢ Validation Loss: 0.7333
  ‚Ä¢ Learning Rate: 0.000896
    No improvement (current: 0.7333, best: 0.7279)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 135/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6562
  ‚Ä¢ Validation Loss: 0.7291
  ‚Ä¢ Learning Rate: 0.000891
    No improvement (current: 0.7291, best: 0.7279)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 136/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6577
  ‚Ä¢ Validation Loss: 0.7268
  ‚Ä¢ Learning Rate: 0.000886
    ‚úì New best checkpoint saved! Val loss: 0.7268
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 137/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6542
  ‚Ä¢ Validation Loss: 0.7266
  ‚Ä¢ Learning Rate: 0.000881
    ‚úì New best checkpoint saved! Val loss: 0.7266
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 138/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6575
  ‚Ä¢ Validation Loss: 0.7338
  ‚Ä¢ Learning Rate: 0.000877
    No improvement (current: 0.7338, best: 0.7266)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 139/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6527
  ‚Ä¢ Validation Loss: 0.7310
  ‚Ä¢ Learning Rate: 0.000872
    No improvement (current: 0.7310, best: 0.7266)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 140/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6518
  ‚Ä¢ Validation Loss: 0.7392
  ‚Ä¢ Learning Rate: 0.000867
    No improvement (current: 0.7392, best: 0.7266)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 141/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6631
  ‚Ä¢ Validation Loss: 0.7474
  ‚Ä¢ Learning Rate: 0.000861
    No improvement (current: 0.7474, best: 0.7266)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 142/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6563
  ‚Ä¢ Validation Loss: 0.7311
  ‚Ä¢ Learning Rate: 0.000856
    No improvement (current: 0.7311, best: 0.7266)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 143/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6588
  ‚Ä¢ Validation Loss: 0.7277
  ‚Ä¢ Learning Rate: 0.000851
    No improvement (current: 0.7277, best: 0.7266)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 144/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6586
  ‚Ä¢ Validation Loss: 0.7319
  ‚Ä¢ Learning Rate: 0.000846
    No improvement (current: 0.7319, best: 0.7266)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 145/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6577
  ‚Ä¢ Validation Loss: 0.7277
  ‚Ä¢ Learning Rate: 0.000840
    No improvement (current: 0.7277, best: 0.7266)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 146/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6466
  ‚Ä¢ Validation Loss: 0.7305
  ‚Ä¢ Learning Rate: 0.000835
    No improvement (current: 0.7305, best: 0.7266)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 147/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6522
  ‚Ä¢ Validation Loss: 0.7288
  ‚Ä¢ Learning Rate: 0.000829
    No improvement (current: 0.7288, best: 0.7266)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 148/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6565
  ‚Ä¢ Validation Loss: 0.7265
  ‚Ä¢ Learning Rate: 0.000823
    ‚úì New best checkpoint saved! Val loss: 0.7265
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 149/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6568
  ‚Ä¢ Validation Loss: 0.7314
  ‚Ä¢ Learning Rate: 0.000818
    No improvement (current: 0.7314, best: 0.7265)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 150/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6518
  ‚Ä¢ Validation Loss: 0.7327
  ‚Ä¢ Learning Rate: 0.000812
    No improvement (current: 0.7327, best: 0.7265)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 151/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6581
  ‚Ä¢ Validation Loss: 0.7392
  ‚Ä¢ Learning Rate: 0.000806
    No improvement (current: 0.7392, best: 0.7265)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 152/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6619
  ‚Ä¢ Validation Loss: 0.7280
  ‚Ä¢ Learning Rate: 0.000800
    No improvement (current: 0.7280, best: 0.7265)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 153/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6497
  ‚Ä¢ Validation Loss: 0.7288
  ‚Ä¢ Learning Rate: 0.000794
    No improvement (current: 0.7288, best: 0.7265)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 154/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6547
  ‚Ä¢ Validation Loss: 0.7288
  ‚Ä¢ Learning Rate: 0.000788
    No improvement (current: 0.7288, best: 0.7265)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 155/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6548
  ‚Ä¢ Validation Loss: 0.7286
  ‚Ä¢ Learning Rate: 0.000782
    No improvement (current: 0.7286, best: 0.7265)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 156/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6481
  ‚Ä¢ Validation Loss: 0.7266
  ‚Ä¢ Learning Rate: 0.000776
    No improvement (current: 0.7266, best: 0.7265)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 157/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6485
  ‚Ä¢ Validation Loss: 0.7280
  ‚Ä¢ Learning Rate: 0.000769
    No improvement (current: 0.7280, best: 0.7265)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 158/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6486
  ‚Ä¢ Validation Loss: 0.7277
  ‚Ä¢ Learning Rate: 0.000763
    No improvement (current: 0.7277, best: 0.7265)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 159/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6510
  ‚Ä¢ Validation Loss: 0.7234
  ‚Ä¢ Learning Rate: 0.000757
    ‚úì New best checkpoint saved! Val loss: 0.7234
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 160/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6447
  ‚Ä¢ Validation Loss: 0.7266
  ‚Ä¢ Learning Rate: 0.000750
    No improvement (current: 0.7266, best: 0.7234)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 161/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6467
  ‚Ä¢ Validation Loss: 0.7255
  ‚Ä¢ Learning Rate: 0.000744
    No improvement (current: 0.7255, best: 0.7234)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 162/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6477
  ‚Ä¢ Validation Loss: 0.7278
  ‚Ä¢ Learning Rate: 0.000737
    No improvement (current: 0.7278, best: 0.7234)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 163/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6571
  ‚Ä¢ Validation Loss: 0.7303
  ‚Ä¢ Learning Rate: 0.000731
    No improvement (current: 0.7303, best: 0.7234)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 164/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6527
  ‚Ä¢ Validation Loss: 0.7284
  ‚Ä¢ Learning Rate: 0.000724
    No improvement (current: 0.7284, best: 0.7234)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 165/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6472
  ‚Ä¢ Validation Loss: 0.7270
  ‚Ä¢ Learning Rate: 0.000717
    No improvement (current: 0.7270, best: 0.7234)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 166/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6457
  ‚Ä¢ Validation Loss: 0.7233
  ‚Ä¢ Learning Rate: 0.000710
    ‚úì New best checkpoint saved! Val loss: 0.7233
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 167/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6431
  ‚Ä¢ Validation Loss: 0.7232
  ‚Ä¢ Learning Rate: 0.000704
    ‚úì New best checkpoint saved! Val loss: 0.7232
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 168/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6390
  ‚Ä¢ Validation Loss: 0.7241
  ‚Ä¢ Learning Rate: 0.000697
    No improvement (current: 0.7241, best: 0.7232)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 169/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6394
  ‚Ä¢ Validation Loss: 0.7232
  ‚Ä¢ Learning Rate: 0.000690
    ‚úì New best checkpoint saved! Val loss: 0.7232
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 170/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6393
  ‚Ä¢ Validation Loss: 0.7233
  ‚Ä¢ Learning Rate: 0.000683
    No improvement (current: 0.7233, best: 0.7232)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 171/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6428
  ‚Ä¢ Validation Loss: 0.7252
  ‚Ä¢ Learning Rate: 0.000676
    No improvement (current: 0.7252, best: 0.7232)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 172/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6386
  ‚Ä¢ Validation Loss: 0.7274
  ‚Ä¢ Learning Rate: 0.000669
    No improvement (current: 0.7274, best: 0.7232)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 173/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6385
  ‚Ä¢ Validation Loss: 0.7261
  ‚Ä¢ Learning Rate: 0.000662
    No improvement (current: 0.7261, best: 0.7232)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 174/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6390
  ‚Ä¢ Validation Loss: 0.7256
  ‚Ä¢ Learning Rate: 0.000655
    No improvement (current: 0.7256, best: 0.7232)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 175/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6434
  ‚Ä¢ Validation Loss: 0.7251
  ‚Ä¢ Learning Rate: 0.000648
    No improvement (current: 0.7251, best: 0.7232)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 176/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6408
  ‚Ä¢ Validation Loss: 0.7222
  ‚Ä¢ Learning Rate: 0.000641
    ‚úì New best checkpoint saved! Val loss: 0.7222
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 177/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6526
  ‚Ä¢ Validation Loss: 0.7433
  ‚Ä¢ Learning Rate: 0.000633
    No improvement (current: 0.7433, best: 0.7222)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 178/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6676
  ‚Ä¢ Validation Loss: 0.7388
  ‚Ä¢ Learning Rate: 0.000626
    No improvement (current: 0.7388, best: 0.7222)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 179/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6523
  ‚Ä¢ Validation Loss: 0.7326
  ‚Ä¢ Learning Rate: 0.000619
    No improvement (current: 0.7326, best: 0.7222)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 180/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6423
  ‚Ä¢ Validation Loss: 0.7258
  ‚Ä¢ Learning Rate: 0.000612
    No improvement (current: 0.7258, best: 0.7222)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 181/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6438
  ‚Ä¢ Validation Loss: 0.7230
  ‚Ä¢ Learning Rate: 0.000604
    No improvement (current: 0.7230, best: 0.7222)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 182/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6420
  ‚Ä¢ Validation Loss: 0.7238
  ‚Ä¢ Learning Rate: 0.000597
    No improvement (current: 0.7238, best: 0.7222)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 183/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6434
  ‚Ä¢ Validation Loss: 0.7254
  ‚Ä¢ Learning Rate: 0.000590
    No improvement (current: 0.7254, best: 0.7222)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 184/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6482
  ‚Ä¢ Validation Loss: 0.7232
  ‚Ä¢ Learning Rate: 0.000582
    No improvement (current: 0.7232, best: 0.7222)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 185/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6415
  ‚Ä¢ Validation Loss: 0.7277
  ‚Ä¢ Learning Rate: 0.000575
    No improvement (current: 0.7277, best: 0.7222)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 186/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6426
  ‚Ä¢ Validation Loss: 0.7236
  ‚Ä¢ Learning Rate: 0.000567
    No improvement (current: 0.7236, best: 0.7222)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 187/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6442
  ‚Ä¢ Validation Loss: 0.7261
  ‚Ä¢ Learning Rate: 0.000560
    No improvement (current: 0.7261, best: 0.7222)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 188/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6455
  ‚Ä¢ Validation Loss: 0.7278
  ‚Ä¢ Learning Rate: 0.000553
    No improvement (current: 0.7278, best: 0.7222)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 189/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6366
  ‚Ä¢ Validation Loss: 0.7237
  ‚Ä¢ Learning Rate: 0.000545
    No improvement (current: 0.7237, best: 0.7222)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 190/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6362
  ‚Ä¢ Validation Loss: 0.7238
  ‚Ä¢ Learning Rate: 0.000538
    No improvement (current: 0.7238, best: 0.7222)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 191/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6427
  ‚Ä¢ Validation Loss: 0.7296
  ‚Ä¢ Learning Rate: 0.000530
    No improvement (current: 0.7296, best: 0.7222)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 192/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6420
  ‚Ä¢ Validation Loss: 0.7270
  ‚Ä¢ Learning Rate: 0.000523
    No improvement (current: 0.7270, best: 0.7222)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 193/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6431
  ‚Ä¢ Validation Loss: 0.7257
  ‚Ä¢ Learning Rate: 0.000515
    No improvement (current: 0.7257, best: 0.7222)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 194/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6424
  ‚Ä¢ Validation Loss: 0.7224
  ‚Ä¢ Learning Rate: 0.000508
    No improvement (current: 0.7224, best: 0.7222)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 195/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6520
  ‚Ä¢ Validation Loss: 0.7225
  ‚Ä¢ Learning Rate: 0.000500
    No improvement (current: 0.7225, best: 0.7222)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 196/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6391
  ‚Ä¢ Validation Loss: 0.7231
  ‚Ä¢ Learning Rate: 0.000493
    No improvement (current: 0.7231, best: 0.7222)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 197/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6414
  ‚Ä¢ Validation Loss: 0.7312
  ‚Ä¢ Learning Rate: 0.000486
    No improvement (current: 0.7312, best: 0.7222)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 198/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6374
  ‚Ä¢ Validation Loss: 0.7271
  ‚Ä¢ Learning Rate: 0.000478
    No improvement (current: 0.7271, best: 0.7222)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 199/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6452
  ‚Ä¢ Validation Loss: 0.7244
  ‚Ä¢ Learning Rate: 0.000471
    No improvement (current: 0.7244, best: 0.7222)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 200/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6500
  ‚Ä¢ Validation Loss: 0.7257
  ‚Ä¢ Learning Rate: 0.000463
   üíæ Periodic checkpoint saved: epoch_200.pth
    No improvement (current: 0.7257, best: 0.7222)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 201/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6405
  ‚Ä¢ Validation Loss: 0.7230
  ‚Ä¢ Learning Rate: 0.000456
    No improvement (current: 0.7230, best: 0.7222)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 202/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6383
  ‚Ä¢ Validation Loss: 0.7253
  ‚Ä¢ Learning Rate: 0.000448
    No improvement (current: 0.7253, best: 0.7222)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 203/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6408
  ‚Ä¢ Validation Loss: 0.7248
  ‚Ä¢ Learning Rate: 0.000441
    No improvement (current: 0.7248, best: 0.7222)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 204/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6380
  ‚Ä¢ Validation Loss: 0.7227
  ‚Ä¢ Learning Rate: 0.000433
    No improvement (current: 0.7227, best: 0.7222)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 205/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6408
  ‚Ä¢ Validation Loss: 0.7237
  ‚Ä¢ Learning Rate: 0.000426
    No improvement (current: 0.7237, best: 0.7222)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 206/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6441
  ‚Ä¢ Validation Loss: 0.7225
  ‚Ä¢ Learning Rate: 0.000419
    No improvement (current: 0.7225, best: 0.7222)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 207/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6386
  ‚Ä¢ Validation Loss: 0.7243
  ‚Ä¢ Learning Rate: 0.000411
    No improvement (current: 0.7243, best: 0.7222)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 208/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6388
  ‚Ä¢ Validation Loss: 0.7224
  ‚Ä¢ Learning Rate: 0.000404
    No improvement (current: 0.7224, best: 0.7222)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 209/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6408
  ‚Ä¢ Validation Loss: 0.7225
  ‚Ä¢ Learning Rate: 0.000397
    No improvement (current: 0.7225, best: 0.7222)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 210/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6415
  ‚Ä¢ Validation Loss: 0.7215
  ‚Ä¢ Learning Rate: 0.000389
    ‚úì New best checkpoint saved! Val loss: 0.7215
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 211/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6343
  ‚Ä¢ Validation Loss: 0.7225
  ‚Ä¢ Learning Rate: 0.000382
    No improvement (current: 0.7225, best: 0.7215)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 212/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6439
  ‚Ä¢ Validation Loss: 0.7222
  ‚Ä¢ Learning Rate: 0.000375
    No improvement (current: 0.7222, best: 0.7215)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 213/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6388
  ‚Ä¢ Validation Loss: 0.7218
  ‚Ä¢ Learning Rate: 0.000368
    No improvement (current: 0.7218, best: 0.7215)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 214/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6346
  ‚Ä¢ Validation Loss: 0.7224
  ‚Ä¢ Learning Rate: 0.000360
    No improvement (current: 0.7224, best: 0.7215)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 215/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6400
  ‚Ä¢ Validation Loss: 0.7245
  ‚Ä¢ Learning Rate: 0.000353
    No improvement (current: 0.7245, best: 0.7215)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 216/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6377
  ‚Ä¢ Validation Loss: 0.7233
  ‚Ä¢ Learning Rate: 0.000346
    No improvement (current: 0.7233, best: 0.7215)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 217/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6367
  ‚Ä¢ Validation Loss: 0.7232
  ‚Ä¢ Learning Rate: 0.000339
    No improvement (current: 0.7232, best: 0.7215)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 218/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6428
  ‚Ä¢ Validation Loss: 0.7219
  ‚Ä¢ Learning Rate: 0.000332
    No improvement (current: 0.7219, best: 0.7215)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 219/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6374
  ‚Ä¢ Validation Loss: 0.7223
  ‚Ä¢ Learning Rate: 0.000325
    No improvement (current: 0.7223, best: 0.7215)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 220/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6355
  ‚Ä¢ Validation Loss: 0.7226
  ‚Ä¢ Learning Rate: 0.000318
    No improvement (current: 0.7226, best: 0.7215)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 221/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6347
  ‚Ä¢ Validation Loss: 0.7222
  ‚Ä¢ Learning Rate: 0.000311
    No improvement (current: 0.7222, best: 0.7215)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 222/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6407
  ‚Ä¢ Validation Loss: 0.7222
  ‚Ä¢ Learning Rate: 0.000304
    No improvement (current: 0.7222, best: 0.7215)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 223/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6335
  ‚Ä¢ Validation Loss: 0.7232
  ‚Ä¢ Learning Rate: 0.000297
    No improvement (current: 0.7232, best: 0.7215)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 224/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6399
  ‚Ä¢ Validation Loss: 0.7224
  ‚Ä¢ Learning Rate: 0.000290
    No improvement (current: 0.7224, best: 0.7215)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 225/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6375
  ‚Ä¢ Validation Loss: 0.7228
  ‚Ä¢ Learning Rate: 0.000284
    No improvement (current: 0.7228, best: 0.7215)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 226/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6374
  ‚Ä¢ Validation Loss: 0.7221
  ‚Ä¢ Learning Rate: 0.000277
    No improvement (current: 0.7221, best: 0.7215)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 227/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6365
  ‚Ä¢ Validation Loss: 0.7223
  ‚Ä¢ Learning Rate: 0.000270
    No improvement (current: 0.7223, best: 0.7215)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 228/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6308
  ‚Ä¢ Validation Loss: 0.7226
  ‚Ä¢ Learning Rate: 0.000264
    No improvement (current: 0.7226, best: 0.7215)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 229/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6346
  ‚Ä¢ Validation Loss: 0.7224
  ‚Ä¢ Learning Rate: 0.000257
    No improvement (current: 0.7224, best: 0.7215)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 230/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6332
  ‚Ä¢ Validation Loss: 0.7227
  ‚Ä¢ Learning Rate: 0.000251
    No improvement (current: 0.7227, best: 0.7215)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 231/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6347
  ‚Ä¢ Validation Loss: 0.7225
  ‚Ä¢ Learning Rate: 0.000244
    No improvement (current: 0.7225, best: 0.7215)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 232/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6343
  ‚Ä¢ Validation Loss: 0.7238
  ‚Ä¢ Learning Rate: 0.000238
    No improvement (current: 0.7238, best: 0.7215)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 233/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6412
  ‚Ä¢ Validation Loss: 0.7222
  ‚Ä¢ Learning Rate: 0.000232
    No improvement (current: 0.7222, best: 0.7215)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 234/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6347
  ‚Ä¢ Validation Loss: 0.7226
  ‚Ä¢ Learning Rate: 0.000225
    No improvement (current: 0.7226, best: 0.7215)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 235/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6383
  ‚Ä¢ Validation Loss: 0.7208
  ‚Ä¢ Learning Rate: 0.000219
    ‚úì New best checkpoint saved! Val loss: 0.7208
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 236/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6308
  ‚Ä¢ Validation Loss: 0.7219
  ‚Ä¢ Learning Rate: 0.000213
    No improvement (current: 0.7219, best: 0.7208)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 237/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6387
  ‚Ä¢ Validation Loss: 0.7218
  ‚Ä¢ Learning Rate: 0.000207
    No improvement (current: 0.7218, best: 0.7208)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 238/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6283
  ‚Ä¢ Validation Loss: 0.7222
  ‚Ä¢ Learning Rate: 0.000201
    No improvement (current: 0.7222, best: 0.7208)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 239/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6394
  ‚Ä¢ Validation Loss: 0.7218
  ‚Ä¢ Learning Rate: 0.000195
    No improvement (current: 0.7218, best: 0.7208)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 240/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6362
  ‚Ä¢ Validation Loss: 0.7217
  ‚Ä¢ Learning Rate: 0.000189
    No improvement (current: 0.7217, best: 0.7208)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 241/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6344
  ‚Ä¢ Validation Loss: 0.7216
  ‚Ä¢ Learning Rate: 0.000183
    No improvement (current: 0.7216, best: 0.7208)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 242/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6329
  ‚Ä¢ Validation Loss: 0.7222
  ‚Ä¢ Learning Rate: 0.000177
    No improvement (current: 0.7222, best: 0.7208)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 243/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6371
  ‚Ä¢ Validation Loss: 0.7221
  ‚Ä¢ Learning Rate: 0.000172
    No improvement (current: 0.7221, best: 0.7208)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 244/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6338
  ‚Ä¢ Validation Loss: 0.7219
  ‚Ä¢ Learning Rate: 0.000166
    No improvement (current: 0.7219, best: 0.7208)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 245/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6294
  ‚Ä¢ Validation Loss: 0.7221
  ‚Ä¢ Learning Rate: 0.000161
    No improvement (current: 0.7221, best: 0.7208)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 246/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6337
  ‚Ä¢ Validation Loss: 0.7220
  ‚Ä¢ Learning Rate: 0.000155
    No improvement (current: 0.7220, best: 0.7208)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 247/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6335
  ‚Ä¢ Validation Loss: 0.7225
  ‚Ä¢ Learning Rate: 0.000150
    No improvement (current: 0.7225, best: 0.7208)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 248/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6353
  ‚Ä¢ Validation Loss: 0.7221
  ‚Ä¢ Learning Rate: 0.000145
    No improvement (current: 0.7221, best: 0.7208)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 249/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6280
  ‚Ä¢ Validation Loss: 0.7219
  ‚Ä¢ Learning Rate: 0.000139
    No improvement (current: 0.7219, best: 0.7208)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 250/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6364
  ‚Ä¢ Validation Loss: 0.7216
  ‚Ä¢ Learning Rate: 0.000134
    No improvement (current: 0.7216, best: 0.7208)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 251/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6323
  ‚Ä¢ Validation Loss: 0.7223
  ‚Ä¢ Learning Rate: 0.000129
    No improvement (current: 0.7223, best: 0.7208)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 252/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6280
  ‚Ä¢ Validation Loss: 0.7218
  ‚Ä¢ Learning Rate: 0.000124
    No improvement (current: 0.7218, best: 0.7208)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 253/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6329
  ‚Ä¢ Validation Loss: 0.7213
  ‚Ä¢ Learning Rate: 0.000119
    No improvement (current: 0.7213, best: 0.7208)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 254/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6289
  ‚Ä¢ Validation Loss: 0.7219
  ‚Ä¢ Learning Rate: 0.000115
    No improvement (current: 0.7219, best: 0.7208)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 255/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6340
  ‚Ä¢ Validation Loss: 0.7221
  ‚Ä¢ Learning Rate: 0.000110
    No improvement (current: 0.7221, best: 0.7208)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 256/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6300
  ‚Ä¢ Validation Loss: 0.7225
  ‚Ä¢ Learning Rate: 0.000105
    No improvement (current: 0.7225, best: 0.7208)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 257/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6325
  ‚Ä¢ Validation Loss: 0.7222
  ‚Ä¢ Learning Rate: 0.000101
    No improvement (current: 0.7222, best: 0.7208)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 258/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6331
  ‚Ä¢ Validation Loss: 0.7219
  ‚Ä¢ Learning Rate: 0.000096
    No improvement (current: 0.7219, best: 0.7208)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 259/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6310
  ‚Ä¢ Validation Loss: 0.7224
  ‚Ä¢ Learning Rate: 0.000092
    No improvement (current: 0.7224, best: 0.7208)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 260/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6305
  ‚Ä¢ Validation Loss: 0.7220
  ‚Ä¢ Learning Rate: 0.000088
    No improvement (current: 0.7220, best: 0.7208)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 261/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6372
  ‚Ä¢ Validation Loss: 0.7221
  ‚Ä¢ Learning Rate: 0.000084
    No improvement (current: 0.7221, best: 0.7208)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 262/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6301
  ‚Ä¢ Validation Loss: 0.7221
  ‚Ä¢ Learning Rate: 0.000080
    No improvement (current: 0.7221, best: 0.7208)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 263/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6340
  ‚Ä¢ Validation Loss: 0.7226
  ‚Ä¢ Learning Rate: 0.000076
    No improvement (current: 0.7226, best: 0.7208)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 264/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6292
  ‚Ä¢ Validation Loss: 0.7228
  ‚Ä¢ Learning Rate: 0.000072
    No improvement (current: 0.7228, best: 0.7208)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 265/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6345
  ‚Ä¢ Validation Loss: 0.7222
  ‚Ä¢ Learning Rate: 0.000068
    No improvement (current: 0.7222, best: 0.7208)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 266/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6344
  ‚Ä¢ Validation Loss: 0.7222
  ‚Ä¢ Learning Rate: 0.000064
    No improvement (current: 0.7222, best: 0.7208)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 267/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6316
  ‚Ä¢ Validation Loss: 0.7227
  ‚Ä¢ Learning Rate: 0.000061
    No improvement (current: 0.7227, best: 0.7208)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 268/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6294
  ‚Ä¢ Validation Loss: 0.7220
  ‚Ä¢ Learning Rate: 0.000057
    No improvement (current: 0.7220, best: 0.7208)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 269/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6320
  ‚Ä¢ Validation Loss: 0.7220
  ‚Ä¢ Learning Rate: 0.000054
    No improvement (current: 0.7220, best: 0.7208)
    ‚ö† No improvement for 34 epochs (patience: 150, remaining: 116)

EPOCH 270/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6327
  ‚Ä¢ Validation Loss: 0.7218
  ‚Ä¢ Learning Rate: 0.000050
    No improvement (current: 0.7218, best: 0.7208)
    ‚ö† No improvement for 35 epochs (patience: 150, remaining: 115)

EPOCH 271/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6271
  ‚Ä¢ Validation Loss: 0.7223
  ‚Ä¢ Learning Rate: 0.000047
    No improvement (current: 0.7223, best: 0.7208)
    ‚ö† No improvement for 36 epochs (patience: 150, remaining: 114)

EPOCH 272/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6314
  ‚Ä¢ Validation Loss: 0.7222
  ‚Ä¢ Learning Rate: 0.000044
    No improvement (current: 0.7222, best: 0.7208)
    ‚ö† No improvement for 37 epochs (patience: 150, remaining: 113)

EPOCH 273/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6278
  ‚Ä¢ Validation Loss: 0.7222
  ‚Ä¢ Learning Rate: 0.000041
    No improvement (current: 0.7222, best: 0.7208)
    ‚ö† No improvement for 38 epochs (patience: 150, remaining: 112)

EPOCH 274/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6319
  ‚Ä¢ Validation Loss: 0.7221
  ‚Ä¢ Learning Rate: 0.000038
    No improvement (current: 0.7221, best: 0.7208)
    ‚ö† No improvement for 39 epochs (patience: 150, remaining: 111)

EPOCH 275/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6299
  ‚Ä¢ Validation Loss: 0.7222
  ‚Ä¢ Learning Rate: 0.000036
    No improvement (current: 0.7222, best: 0.7208)
    ‚ö† No improvement for 40 epochs (patience: 150, remaining: 110)

EPOCH 276/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6282
  ‚Ä¢ Validation Loss: 0.7222
  ‚Ä¢ Learning Rate: 0.000033
    No improvement (current: 0.7222, best: 0.7208)
    ‚ö† No improvement for 41 epochs (patience: 150, remaining: 109)

EPOCH 277/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6390
  ‚Ä¢ Validation Loss: 0.7223
  ‚Ä¢ Learning Rate: 0.000030
    No improvement (current: 0.7223, best: 0.7208)
    ‚ö† No improvement for 42 epochs (patience: 150, remaining: 108)

EPOCH 278/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6288
  ‚Ä¢ Validation Loss: 0.7222
  ‚Ä¢ Learning Rate: 0.000028
    No improvement (current: 0.7222, best: 0.7208)
    ‚ö† No improvement for 43 epochs (patience: 150, remaining: 107)

EPOCH 279/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6334
  ‚Ä¢ Validation Loss: 0.7221
  ‚Ä¢ Learning Rate: 0.000025
    No improvement (current: 0.7221, best: 0.7208)
    ‚ö† No improvement for 44 epochs (patience: 150, remaining: 106)

EPOCH 280/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6357
  ‚Ä¢ Validation Loss: 0.7222
  ‚Ä¢ Learning Rate: 0.000023
    No improvement (current: 0.7222, best: 0.7208)
    ‚ö† No improvement for 45 epochs (patience: 150, remaining: 105)

EPOCH 281/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6308
  ‚Ä¢ Validation Loss: 0.7220
  ‚Ä¢ Learning Rate: 0.000021
    No improvement (current: 0.7220, best: 0.7208)
    ‚ö† No improvement for 46 epochs (patience: 150, remaining: 104)

EPOCH 282/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6320
  ‚Ä¢ Validation Loss: 0.7221
  ‚Ä¢ Learning Rate: 0.000019
    No improvement (current: 0.7221, best: 0.7208)
    ‚ö† No improvement for 47 epochs (patience: 150, remaining: 103)

EPOCH 283/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6352
  ‚Ä¢ Validation Loss: 0.7223
  ‚Ä¢ Learning Rate: 0.000017
    No improvement (current: 0.7223, best: 0.7208)
    ‚ö† No improvement for 48 epochs (patience: 150, remaining: 102)

EPOCH 284/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6344
  ‚Ä¢ Validation Loss: 0.7222
  ‚Ä¢ Learning Rate: 0.000015
    No improvement (current: 0.7222, best: 0.7208)
    ‚ö† No improvement for 49 epochs (patience: 150, remaining: 101)

EPOCH 285/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6331
  ‚Ä¢ Validation Loss: 0.7221
  ‚Ä¢ Learning Rate: 0.000014
    No improvement (current: 0.7221, best: 0.7208)
    ‚ö† No improvement for 50 epochs (patience: 150, remaining: 100)

EPOCH 286/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6337
  ‚Ä¢ Validation Loss: 0.7221
  ‚Ä¢ Learning Rate: 0.000012
    No improvement (current: 0.7221, best: 0.7208)
    ‚ö† No improvement for 51 epochs (patience: 150, remaining: 99)

EPOCH 287/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6281
  ‚Ä¢ Validation Loss: 0.7220
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.7220, best: 0.7208)
    ‚ö† No improvement for 52 epochs (patience: 150, remaining: 98)

EPOCH 288/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6328
  ‚Ä¢ Validation Loss: 0.7219
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.7219, best: 0.7208)
    ‚ö† No improvement for 53 epochs (patience: 150, remaining: 97)

EPOCH 289/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6307
  ‚Ä¢ Validation Loss: 0.7220
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.7220, best: 0.7208)
    ‚ö† No improvement for 54 epochs (patience: 150, remaining: 96)

EPOCH 290/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6261
  ‚Ä¢ Validation Loss: 0.7219
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.7219, best: 0.7208)
    ‚ö† No improvement for 55 epochs (patience: 150, remaining: 95)

EPOCH 291/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6376
  ‚Ä¢ Validation Loss: 0.7220
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.7220, best: 0.7208)
    ‚ö† No improvement for 56 epochs (patience: 150, remaining: 94)

EPOCH 292/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6309
  ‚Ä¢ Validation Loss: 0.7220
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.7220, best: 0.7208)
    ‚ö† No improvement for 57 epochs (patience: 150, remaining: 93)

EPOCH 293/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6302
  ‚Ä¢ Validation Loss: 0.7220
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.7220, best: 0.7208)
    ‚ö† No improvement for 58 epochs (patience: 150, remaining: 92)

EPOCH 294/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6320
  ‚Ä¢ Validation Loss: 0.7221
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.7221, best: 0.7208)
    ‚ö† No improvement for 59 epochs (patience: 150, remaining: 91)

EPOCH 295/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6353
  ‚Ä¢ Validation Loss: 0.7220
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.7220, best: 0.7208)
    ‚ö† No improvement for 60 epochs (patience: 150, remaining: 90)

EPOCH 296/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6301
  ‚Ä¢ Validation Loss: 0.7220
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.7220, best: 0.7208)
    ‚ö† No improvement for 61 epochs (patience: 150, remaining: 89)

EPOCH 297/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6328
  ‚Ä¢ Validation Loss: 0.7220
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.7220, best: 0.7208)
    ‚ö† No improvement for 62 epochs (patience: 150, remaining: 88)

EPOCH 298/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6344
  ‚Ä¢ Validation Loss: 0.7220
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.7220, best: 0.7208)
    ‚ö† No improvement for 63 epochs (patience: 150, remaining: 87)

EPOCH 299/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6305
  ‚Ä¢ Validation Loss: 0.7220
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.7220, best: 0.7208)
    ‚ö† No improvement for 64 epochs (patience: 150, remaining: 86)

EPOCH 300/300
--------------------------------------------------
‚ö†Ô∏è  Scheduler reached max steps, stopping LR updates.
Results:
  ‚Ä¢ Train Loss: 0.6314
  ‚Ä¢ Validation Loss: 0.7220
  ‚Ä¢ Learning Rate: 0.000001
   üíæ Periodic checkpoint saved: epoch_300.pth
    No improvement (current: 0.7220, best: 0.7208)
    ‚ö† No improvement for 65 epochs (patience: 150, remaining: 85)

================================================================================
TRAINING COMPLETED
================================================================================
Best Val Loss:  0.7208
Total Epochs:   300
Models Saved:   ./Result/a3/Latin14396
TensorBoard:    ./Result/a3/Latin14396/tensorboard_logs
================================================================================

[01:30:06] Training completed. Best val loss: 0.7208

=== TRAINING COMPLETED SUCCESSFULLY ===
Training Finished!

========================================================================
Testing Hybrid2 Baseline Model with Smart Skip Connections and Multi-Scale Aggregation and Deep Supervision: Latin14396
========================================================================
=== Historical Document Segmentation Testing ===

Using 6 classes for manuscript: Latin14396
Model: Hybrid2
Dataset: UDIADS_BIB
Manuscript: Latin14396
Test-Time Augmentation: Enabled
CRF post-processing: Enabled
  - DenseCRF with spatial and color pairwise potentials

================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder for Testing
================================================================================
================================================================================
üöÄ SIMPLE DECODER (Flag-Controlled Enhancements)
================================================================================
  ‚Ä¢ EfficientNet Variant: b4
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Enhancement Flags:
  ‚Ä¢ Deep Supervision: True
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: True
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: True
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Loaded checkpoint from epoch 234
Best validation loss: 0.7208
  ‚úÖ Model checkpoint loaded successfully (exact match)
Loaded checkpoint: best_model_latest.pth
Namespace(cfg=None, output_dir='./Result/a3/Latin14396', use_baseline=True, decoder='EfficientNet-B4', efficientnet_variant='b4', use_deep_supervision=True, use_cbam=False, use_smart_skip=True, use_cross_attn=False, use_multiscale_agg=True, use_groupnorm=True, use_batchnorm=False, use_pos_embed=True, dataset='UDIADS_BIB', manuscript='Latin14396', udiadsbib_root='../../U-DIADS-Bib-MS_patched', divahisdb_root='../../DivaHisDB', use_patched_data=True, num_classes=6, img_size=224, batch_size=24, is_savenii=True, test_save_dir='../predictions', use_crf=True, deterministic=1, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, use_tta=True)
Testing with checkpoint: best_model_latest.pth
Saving predictions to: ./Result/a3/Latin14396/predictions

=== Starting Testing ===
Dataset: UDIADS_BIB
Model: Hybrid2
Manuscript: Latin14396
Save predictions: True

Starting inference on UDIADS_BIB dataset
Found 1620 patches for Latin14396
Using Test-Time Augmentation (TTA) for improved accuracy
CRF post-processing: Enabled
  - DenseCRF with spatial and color pairwise potentials
Processing: 014 (54 patches)
Applying CRF post-processing to 014
CRF post-processing completed for 014
Completed: 014
Processing: 032 (54 patches)
Applying CRF post-processing to 032
CRF post-processing completed for 032
Completed: 032
Processing: 034 (54 patches)
Applying CRF post-processing to 034
CRF post-processing completed for 034
Completed: 034
Processing: 036 (54 patches)
Applying CRF post-processing to 036
CRF post-processing completed for 036
Completed: 036
Processing: 038 (54 patches)
Applying CRF post-processing to 038
CRF post-processing completed for 038
Completed: 038
Processing: 047 (54 patches)
Applying CRF post-processing to 047
CRF post-processing completed for 047
Completed: 047
Processing: 060 (54 patches)
Applying CRF post-processing to 060
CRF post-processing completed for 060
Completed: 060
Processing: 085 (54 patches)
Applying CRF post-processing to 085
CRF post-processing completed for 085
Completed: 085
Processing: 087 (54 patches)
Applying CRF post-processing to 087
CRF post-processing completed for 087
Completed: 087
Processing: 104 (54 patches)
Applying CRF post-processing to 104
CRF post-processing completed for 104
Completed: 104
Processing: 105 (54 patches)
Applying CRF post-processing to 105
CRF post-processing completed for 105
Completed: 105
Processing: 108 (54 patches)
Applying CRF post-processing to 108
CRF post-processing completed for 108
Completed: 108
Processing: 110 (54 patches)
Applying CRF post-processing to 110
CRF post-processing completed for 110
Completed: 110
Processing: 136 (54 patches)
Applying CRF post-processing to 136
CRF post-processing completed for 136
Completed: 136
Processing: 169 (54 patches)
Applying CRF post-processing to 169
CRF post-processing completed for 169
Completed: 169
Processing: 195 (54 patches)
Applying CRF post-processing to 195
CRF post-processing completed for 195
Completed: 195
Processing: 196 (54 patches)
Applying CRF post-processing to 196
CRF post-processing completed for 196
Completed: 196
Processing: 198 (54 patches)
Applying CRF post-processing to 198
CRF post-processing completed for 198
Completed: 198
Processing: 204 (54 patches)
Applying CRF post-processing to 204
CRF post-processing completed for 204
Completed: 204
Processing: 223 (54 patches)
Applying CRF post-processing to 223
CRF post-processing completed for 223
Completed: 223
Processing: 225 (54 patches)
Applying CRF post-processing to 225
CRF post-processing completed for 225
Completed: 225
Processing: 227 (54 patches)
Applying CRF post-processing to 227
CRF post-processing completed for 227
Completed: 227
Processing: 229 (54 patches)
Applying CRF post-processing to 229
CRF post-processing completed for 229
Completed: 229
Processing: 251 (54 patches)
Applying CRF post-processing to 251
CRF post-processing completed for 251
Completed: 251
Processing: 253 (54 patches)
Applying CRF post-processing to 253
CRF post-processing completed for 253
Completed: 253
Processing: 255 (54 patches)
Applying CRF post-processing to 255
CRF post-processing completed for 255
Completed: 255
Processing: 264 (54 patches)
Applying CRF post-processing to 264
CRF post-processing completed for 264
Completed: 264
Processing: 270 (54 patches)
Applying CRF post-processing to 270
CRF post-processing completed for 270
Completed: 270
Processing: 276 (54 patches)
Applying CRF post-processing to 276
CRF post-processing completed for 276
Completed: 276
Processing: 325 (54 patches)
Applying CRF post-processing to 325
CRF post-processing completed for 325
Completed: 325

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9832, Recall=0.9992, F1=0.9911, IoU=0.9824
Paratext       : Precision=0.9013, Recall=0.4738, F1=0.6211, IoU=0.4505
Decoration     : Precision=0.9602, Recall=0.9662, F1=0.9632, IoU=0.9290
Main Text      : Precision=0.9803, Recall=0.8272, F1=0.8972, IoU=0.8136
Title          : Precision=0.9297, Recall=0.7987, F1=0.8592, IoU=0.7532
Chapter Headings: Precision=0.9829, Recall=0.6767, F1=0.8015, IoU=0.6688

Mean metrics:
----------------------------------------
Mean Precision: 0.9562
Mean Recall: 0.7903
Mean F1-Score: 0.8556
Mean IoU: 0.7662

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9832, Recall=0.9992, F1=0.9911, IoU=0.9824
Paratext       : Precision=0.9013, Recall=0.4738, F1=0.6211, IoU=0.4505
Decoration     : Precision=0.9602, Recall=0.9662, F1=0.9632, IoU=0.9290
Main Text      : Precision=0.9803, Recall=0.8272, F1=0.8972, IoU=0.8136
Title          : Precision=0.9297, Recall=0.7987, F1=0.8592, IoU=0.7532
Chapter Headings: Precision=0.9829, Recall=0.6767, F1=0.8015, IoU=0.6688

Mean metrics:
----------------------------------------
Mean Precision: 0.9562
Mean Recall: 0.7903
Mean F1-Score: 0.8556
Mean IoU: 0.7662
Inference completed on 30 images

=== TESTING COMPLETED SUCCESSFULLY ===
Results saved to: ./Result/a3/Latin14396/predictions
==================================================

Calculating average metrics...
Looking for metrics files in: ./Result/a3
  ‚úó Metrics file not found: ./Result/a3/metrics_Latin2.json
  ‚úì Found metrics for Latin14396
  ‚úó Metrics file not found: ./Result/a3/metrics_Latin16746.json
  ‚úó Metrics file not found: ./Result/a3/metrics_Syr341.json

================================================================================
AVERAGE METRICS ACROSS 1 MANUSCRIPT(S)
================================================================================
Manuscripts: Latin14396
Missing: Latin2, Latin16746, Syr341
--------------------------------------------------------------------------------
Mean Precision: 0.9562
Mean Recall:    0.7903
Mean F1-Score:  0.8556
Mean IoU:       0.7662
================================================================================

========================================================================
Training Hybrid2 Baseline Model with Smart Skip Connections and Multi-Scale Aggregation and Deep Supervision: Latin16746
========================================================================
Dataset: U-DIADS-Bib-MS_patched
Architecture: Swin Transformer Encoder ‚Üí 2 Swin Blocks Bottleneck ‚Üí Simple CNN Decoder
Decoder: Simple Decoder (EfficientNet-b4 channel configuration)

Components Enabled:
  ‚úì Swin Encoder (4 stages: 96‚Üí192‚Üí384‚Üí768 dim)
  ‚úì Bottleneck: 2 Swin Transformer blocks (768 dim, 24 heads)
  ‚úì Simple CNN Decoder (channels: [256, 128, 64, 32])
  ‚úì Smart Skip Connections
  ‚úì Multi-Scale Aggregation
  ‚úì Deep Supervision
  ‚úì Positional Embeddings (default: enabled)
  ‚úì GroupNorm (default normalization)

Components Disabled (baseline):
  ‚úó CBAM Attention
  ‚úó Cross-Attention Bottleneck
  ‚úó BatchNorm
========================================================================
All arguments validated successfully!
Setting random seed to 1234 for reproducible training...
Setting up U-DIADS-Bib dataset...
Using 6 classes for manuscript: Latin16746
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin16746/Image/training
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin16746/mask/training_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin16746/Image/validation
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin16746/mask/validation_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder
================================================================================
================================================================================
üöÄ SIMPLE DECODER (Flag-Controlled Enhancements)
================================================================================
  ‚Ä¢ EfficientNet Variant: b4
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Enhancement Flags:
  ‚Ä¢ Deep Supervision: True
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: True
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: True
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Model moved to CUDA
Model created successfully with 6 classes
DEBUG: args.output_dir = ./Result/a3/Latin16746

=== Starting Training ===
Dataset: UDIADS_BIB
Model: Hybrid2
Batch size: 4
Max epochs: 300
Learning rate: 0.0001


================================================================================
TRAINING CONFIGURATION
================================================================================
Dataset: UDIADS_BIB
Model: Hybrid2
Batch Size: 4
Max Epochs: 300
Learning Rate: 0.0001
Number of Classes: 6
Output Directory: ./Result/a3/Latin16746
Early Stopping Patience: 150 epochs
================================================================================

üìä Dataset Statistics:
   - Training samples: 540
   - Validation samples: 540
   - Batch size: 4
   - Steps per epoch: 135


================================================================================
COMPUTING CLASS WEIGHTS
================================================================================
Raw ENS weights: [9.99999990e-05 1.00009434e-04 9.99999990e-05 9.99999990e-05
 1.00760331e-04 9.99999990e-05]

Class Distribution:
Class                Pixels          Frequency       Weight         
-----------------------------------------------------------------
0                        23,958,162        88.4227%         0.9987
1                            92,681         0.3421%         0.9988
2                           683,272         2.5218%         0.9987
3                         2,030,719         7.4948%         0.9987
4                            48,865         0.1803%         1.0063
5                           281,341         1.0383%         0.9987

Total pixels: 27,095,040.0
Beta: 0.9999
Smoothing: 0.0
Weight range: [0.9987, 1.0063]
================================================================================
üìà Class weights computed with ENS method (smoothing=0.1)
   Final weights: [0.9987187 0.9988129 0.9987187 0.9987187 1.0063123 0.9987187]

‚úì Loss functions created: CE (weighted, label_smoothing=0.1), Focal (Œ≥=2.0), Dice
  üìä OneCycleLR: 135 steps/epoch √ó 300 epochs = 40500 total steps
üöÄ Hybrid2 Best Practice: Differential Learning Rates
  üìä Encoder LR:     0.000010 (10x smaller, 119 params)
  üìä Bottleneck LR:  0.000050 (5x smaller, 26 params)
  üìä Decoder LR:     0.000100 (base LR, 90 params)
  ‚öôÔ∏è  Scheduler: OneCycleLR (Peak: 10x, Warmup: 30%, Cosine)
  ‚öôÔ∏è  Weight decay: Encoder=1e-3, Bottleneck=5e-3, Decoder=1e-2

üîç Checking for checkpoint at: ./Result/a3/Latin16746/best_model_latest.pth
   Absolute path: /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid/Result/a3/Latin16746/best_model_latest.pth
   File exists: False

================================================================================
STARTING TRAINING
================================================================================
Early stopping patience: 150 epochs
Learning rate scheduler: OneCycleLR (better convergence for transformers)
================================================================================

EPOCH 1/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.1556
  ‚Ä¢ Validation Loss: 0.9856
  ‚Ä¢ Learning Rate: 0.000100
    ‚úì New best checkpoint saved! Val loss: 0.9856
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 2/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.9149
  ‚Ä¢ Validation Loss: 0.9065
  ‚Ä¢ Learning Rate: 0.000101
    ‚úì New best checkpoint saved! Val loss: 0.9065
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 3/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8407
  ‚Ä¢ Validation Loss: 0.8450
  ‚Ä¢ Learning Rate: 0.000102
    ‚úì New best checkpoint saved! Val loss: 0.8450
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 4/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7916
  ‚Ä¢ Validation Loss: 0.8450
  ‚Ä¢ Learning Rate: 0.000104
    ‚úì New best checkpoint saved! Val loss: 0.8450
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 5/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7763
  ‚Ä¢ Validation Loss: 0.8081
  ‚Ä¢ Learning Rate: 0.000107
    ‚úì New best checkpoint saved! Val loss: 0.8081
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 6/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7527
  ‚Ä¢ Validation Loss: 0.8264
  ‚Ä¢ Learning Rate: 0.000110
    No improvement (current: 0.8264, best: 0.8081)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 7/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7471
  ‚Ä¢ Validation Loss: 0.7957
  ‚Ä¢ Learning Rate: 0.000113
    ‚úì New best checkpoint saved! Val loss: 0.7957
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 8/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7422
  ‚Ä¢ Validation Loss: 0.7930
  ‚Ä¢ Learning Rate: 0.000117
    ‚úì New best checkpoint saved! Val loss: 0.7930
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 9/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7277
  ‚Ä¢ Validation Loss: 0.7739
  ‚Ä¢ Learning Rate: 0.000122
    ‚úì New best checkpoint saved! Val loss: 0.7739
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 10/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7188
  ‚Ä¢ Validation Loss: 0.7771
  ‚Ä¢ Learning Rate: 0.000127
    No improvement (current: 0.7771, best: 0.7739)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 11/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7174
  ‚Ä¢ Validation Loss: 0.8039
  ‚Ä¢ Learning Rate: 0.000133
    No improvement (current: 0.8039, best: 0.7739)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 12/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7109
  ‚Ä¢ Validation Loss: 0.7855
  ‚Ä¢ Learning Rate: 0.000139
    No improvement (current: 0.7855, best: 0.7739)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 13/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7034
  ‚Ä¢ Validation Loss: 0.7644
  ‚Ä¢ Learning Rate: 0.000146
    ‚úì New best checkpoint saved! Val loss: 0.7644
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 14/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6963
  ‚Ä¢ Validation Loss: 0.7564
  ‚Ä¢ Learning Rate: 0.000153
    ‚úì New best checkpoint saved! Val loss: 0.7564
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 15/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7012
  ‚Ä¢ Validation Loss: 0.7915
  ‚Ä¢ Learning Rate: 0.000160
    No improvement (current: 0.7915, best: 0.7564)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 16/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6924
  ‚Ä¢ Validation Loss: 0.7691
  ‚Ä¢ Learning Rate: 0.000168
    No improvement (current: 0.7691, best: 0.7564)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 17/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6806
  ‚Ä¢ Validation Loss: 0.7591
  ‚Ä¢ Learning Rate: 0.000177
    No improvement (current: 0.7591, best: 0.7564)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 18/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6861
  ‚Ä¢ Validation Loss: 0.7641
  ‚Ä¢ Learning Rate: 0.000186
    No improvement (current: 0.7641, best: 0.7564)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 19/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6790
  ‚Ä¢ Validation Loss: 0.7639
  ‚Ä¢ Learning Rate: 0.000195
    No improvement (current: 0.7639, best: 0.7564)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 20/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6820
  ‚Ä¢ Validation Loss: 0.7551
  ‚Ä¢ Learning Rate: 0.000205
    ‚úì New best checkpoint saved! Val loss: 0.7551
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 21/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6645
  ‚Ä¢ Validation Loss: 0.7573
  ‚Ä¢ Learning Rate: 0.000216
    No improvement (current: 0.7573, best: 0.7551)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 22/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6646
  ‚Ä¢ Validation Loss: 0.7832
  ‚Ä¢ Learning Rate: 0.000226
    No improvement (current: 0.7832, best: 0.7551)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 23/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6763
  ‚Ä¢ Validation Loss: 0.7528
  ‚Ä¢ Learning Rate: 0.000237
    ‚úì New best checkpoint saved! Val loss: 0.7528
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 24/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6778
  ‚Ä¢ Validation Loss: 0.7600
  ‚Ä¢ Learning Rate: 0.000249
    No improvement (current: 0.7600, best: 0.7528)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 25/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6641
  ‚Ä¢ Validation Loss: 0.7626
  ‚Ä¢ Learning Rate: 0.000261
    No improvement (current: 0.7626, best: 0.7528)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 26/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6743
  ‚Ä¢ Validation Loss: 0.7575
  ‚Ä¢ Learning Rate: 0.000273
    No improvement (current: 0.7575, best: 0.7528)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 27/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6692
  ‚Ä¢ Validation Loss: 0.7398
  ‚Ä¢ Learning Rate: 0.000286
    ‚úì New best checkpoint saved! Val loss: 0.7398
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 28/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6688
  ‚Ä¢ Validation Loss: 0.7490
  ‚Ä¢ Learning Rate: 0.000298
    No improvement (current: 0.7490, best: 0.7398)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 29/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6630
  ‚Ä¢ Validation Loss: 0.7440
  ‚Ä¢ Learning Rate: 0.000312
    No improvement (current: 0.7440, best: 0.7398)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 30/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6630
  ‚Ä¢ Validation Loss: 0.7818
  ‚Ä¢ Learning Rate: 0.000325
    No improvement (current: 0.7818, best: 0.7398)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 31/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6702
  ‚Ä¢ Validation Loss: 0.7597
  ‚Ä¢ Learning Rate: 0.000339
    No improvement (current: 0.7597, best: 0.7398)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 32/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6711
  ‚Ä¢ Validation Loss: 0.7745
  ‚Ä¢ Learning Rate: 0.000353
    No improvement (current: 0.7745, best: 0.7398)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 33/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6686
  ‚Ä¢ Validation Loss: 0.7667
  ‚Ä¢ Learning Rate: 0.000367
    No improvement (current: 0.7667, best: 0.7398)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 34/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6668
  ‚Ä¢ Validation Loss: 0.7585
  ‚Ä¢ Learning Rate: 0.000381
    No improvement (current: 0.7585, best: 0.7398)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 35/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6761
  ‚Ä¢ Validation Loss: 0.7493
  ‚Ä¢ Learning Rate: 0.000396
    No improvement (current: 0.7493, best: 0.7398)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 36/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6653
  ‚Ä¢ Validation Loss: 0.7688
  ‚Ä¢ Learning Rate: 0.000411
    No improvement (current: 0.7688, best: 0.7398)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 37/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6567
  ‚Ä¢ Validation Loss: 0.7634
  ‚Ä¢ Learning Rate: 0.000426
    No improvement (current: 0.7634, best: 0.7398)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 38/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6781
  ‚Ä¢ Validation Loss: 0.7449
  ‚Ä¢ Learning Rate: 0.000441
    No improvement (current: 0.7449, best: 0.7398)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 39/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6566
  ‚Ä¢ Validation Loss: 0.7583
  ‚Ä¢ Learning Rate: 0.000456
    No improvement (current: 0.7583, best: 0.7398)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 40/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6858
  ‚Ä¢ Validation Loss: 0.7559
  ‚Ä¢ Learning Rate: 0.000472
    No improvement (current: 0.7559, best: 0.7398)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 41/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6732
  ‚Ä¢ Validation Loss: 0.7614
  ‚Ä¢ Learning Rate: 0.000487
    No improvement (current: 0.7614, best: 0.7398)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 42/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6641
  ‚Ä¢ Validation Loss: 0.7684
  ‚Ä¢ Learning Rate: 0.000503
    No improvement (current: 0.7684, best: 0.7398)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 43/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6703
  ‚Ä¢ Validation Loss: 0.7546
  ‚Ä¢ Learning Rate: 0.000519
    No improvement (current: 0.7546, best: 0.7398)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 44/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6657
  ‚Ä¢ Validation Loss: 0.7413
  ‚Ä¢ Learning Rate: 0.000534
    No improvement (current: 0.7413, best: 0.7398)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 45/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6706
  ‚Ä¢ Validation Loss: 0.7489
  ‚Ä¢ Learning Rate: 0.000550
    No improvement (current: 0.7489, best: 0.7398)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 46/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6538
  ‚Ä¢ Validation Loss: 0.7562
  ‚Ä¢ Learning Rate: 0.000566
    No improvement (current: 0.7562, best: 0.7398)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 47/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6621
  ‚Ä¢ Validation Loss: 0.7368
  ‚Ä¢ Learning Rate: 0.000581
    ‚úì New best checkpoint saved! Val loss: 0.7368
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 48/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6780
  ‚Ä¢ Validation Loss: 0.7727
  ‚Ä¢ Learning Rate: 0.000597
    No improvement (current: 0.7727, best: 0.7368)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 49/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6795
  ‚Ä¢ Validation Loss: 0.7463
  ‚Ä¢ Learning Rate: 0.000613
    No improvement (current: 0.7463, best: 0.7368)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 50/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6709
  ‚Ä¢ Validation Loss: 0.7395
  ‚Ä¢ Learning Rate: 0.000628
    No improvement (current: 0.7395, best: 0.7368)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 51/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6626
  ‚Ä¢ Validation Loss: 0.7562
  ‚Ä¢ Learning Rate: 0.000644
    No improvement (current: 0.7562, best: 0.7368)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 52/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6676
  ‚Ä¢ Validation Loss: 0.7474
  ‚Ä¢ Learning Rate: 0.000659
    No improvement (current: 0.7474, best: 0.7368)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 53/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6674
  ‚Ä¢ Validation Loss: 0.7627
  ‚Ä¢ Learning Rate: 0.000674
    No improvement (current: 0.7627, best: 0.7368)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 54/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6659
  ‚Ä¢ Validation Loss: 0.7554
  ‚Ä¢ Learning Rate: 0.000689
    No improvement (current: 0.7554, best: 0.7368)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 55/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6703
  ‚Ä¢ Validation Loss: 0.7396
  ‚Ä¢ Learning Rate: 0.000704
    No improvement (current: 0.7396, best: 0.7368)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 56/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6661
  ‚Ä¢ Validation Loss: 0.7418
  ‚Ä¢ Learning Rate: 0.000719
    No improvement (current: 0.7418, best: 0.7368)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 57/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6467
  ‚Ä¢ Validation Loss: 0.7458
  ‚Ä¢ Learning Rate: 0.000733
    No improvement (current: 0.7458, best: 0.7368)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 58/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6650
  ‚Ä¢ Validation Loss: 0.7528
  ‚Ä¢ Learning Rate: 0.000747
    No improvement (current: 0.7528, best: 0.7368)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 59/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6626
  ‚Ä¢ Validation Loss: 0.7738
  ‚Ä¢ Learning Rate: 0.000761
    No improvement (current: 0.7738, best: 0.7368)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 60/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6831
  ‚Ä¢ Validation Loss: 0.7642
  ‚Ä¢ Learning Rate: 0.000775
    No improvement (current: 0.7642, best: 0.7368)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 61/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6659
  ‚Ä¢ Validation Loss: 0.7436
  ‚Ä¢ Learning Rate: 0.000789
    No improvement (current: 0.7436, best: 0.7368)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 62/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6604
  ‚Ä¢ Validation Loss: 0.7632
  ‚Ä¢ Learning Rate: 0.000802
    No improvement (current: 0.7632, best: 0.7368)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 63/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6738
  ‚Ä¢ Validation Loss: 0.7511
  ‚Ä¢ Learning Rate: 0.000815
    No improvement (current: 0.7511, best: 0.7368)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 64/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6684
  ‚Ä¢ Validation Loss: 0.7559
  ‚Ä¢ Learning Rate: 0.000827
    No improvement (current: 0.7559, best: 0.7368)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 65/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6824
  ‚Ä¢ Validation Loss: 0.7560
  ‚Ä¢ Learning Rate: 0.000839
    No improvement (current: 0.7560, best: 0.7368)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 66/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6625
  ‚Ä¢ Validation Loss: 0.7545
  ‚Ä¢ Learning Rate: 0.000851
    No improvement (current: 0.7545, best: 0.7368)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 67/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7004
  ‚Ä¢ Validation Loss: 0.7664
  ‚Ä¢ Learning Rate: 0.000863
    No improvement (current: 0.7664, best: 0.7368)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 68/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6872
  ‚Ä¢ Validation Loss: 0.7560
  ‚Ä¢ Learning Rate: 0.000874
    No improvement (current: 0.7560, best: 0.7368)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 69/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6690
  ‚Ä¢ Validation Loss: 0.7511
  ‚Ä¢ Learning Rate: 0.000884
    No improvement (current: 0.7511, best: 0.7368)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 70/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6897
  ‚Ä¢ Validation Loss: 0.7590
  ‚Ä¢ Learning Rate: 0.000895
    No improvement (current: 0.7590, best: 0.7368)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 71/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6958
  ‚Ä¢ Validation Loss: 0.7628
  ‚Ä¢ Learning Rate: 0.000905
    No improvement (current: 0.7628, best: 0.7368)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 72/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6783
  ‚Ä¢ Validation Loss: 0.7578
  ‚Ä¢ Learning Rate: 0.000914
    No improvement (current: 0.7578, best: 0.7368)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 73/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6674
  ‚Ä¢ Validation Loss: 0.7377
  ‚Ä¢ Learning Rate: 0.000923
    No improvement (current: 0.7377, best: 0.7368)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 74/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6580
  ‚Ä¢ Validation Loss: 0.7426
  ‚Ä¢ Learning Rate: 0.000932
    No improvement (current: 0.7426, best: 0.7368)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 75/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6622
  ‚Ä¢ Validation Loss: 0.7597
  ‚Ä¢ Learning Rate: 0.000940
    No improvement (current: 0.7597, best: 0.7368)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 76/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6763
  ‚Ä¢ Validation Loss: 0.7450
  ‚Ä¢ Learning Rate: 0.000947
    No improvement (current: 0.7450, best: 0.7368)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 77/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6586
  ‚Ä¢ Validation Loss: 0.7427
  ‚Ä¢ Learning Rate: 0.000955
    No improvement (current: 0.7427, best: 0.7368)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 78/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6577
  ‚Ä¢ Validation Loss: 0.7363
  ‚Ä¢ Learning Rate: 0.000961
    ‚úì New best checkpoint saved! Val loss: 0.7363
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 79/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6431
  ‚Ä¢ Validation Loss: 0.7346
  ‚Ä¢ Learning Rate: 0.000967
    ‚úì New best checkpoint saved! Val loss: 0.7346
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 80/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6530
  ‚Ä¢ Validation Loss: 0.7460
  ‚Ä¢ Learning Rate: 0.000973
    No improvement (current: 0.7460, best: 0.7346)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 81/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6483
  ‚Ä¢ Validation Loss: 1.9303
  ‚Ä¢ Learning Rate: 0.000978
    No improvement (current: 1.9303, best: 0.7346)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 82/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7028
  ‚Ä¢ Validation Loss: 0.7581
  ‚Ä¢ Learning Rate: 0.000983
    No improvement (current: 0.7581, best: 0.7346)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 83/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6598
  ‚Ä¢ Validation Loss: 0.7675
  ‚Ä¢ Learning Rate: 0.000987
    No improvement (current: 0.7675, best: 0.7346)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 84/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6626
  ‚Ä¢ Validation Loss: 0.7382
  ‚Ä¢ Learning Rate: 0.000990
    No improvement (current: 0.7382, best: 0.7346)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 85/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6464
  ‚Ä¢ Validation Loss: 0.7458
  ‚Ä¢ Learning Rate: 0.000993
    No improvement (current: 0.7458, best: 0.7346)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 86/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6542
  ‚Ä¢ Validation Loss: 0.7467
  ‚Ä¢ Learning Rate: 0.000996
    No improvement (current: 0.7467, best: 0.7346)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 87/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6361
  ‚Ä¢ Validation Loss: 0.7310
  ‚Ä¢ Learning Rate: 0.000998
    ‚úì New best checkpoint saved! Val loss: 0.7310
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 88/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6422
  ‚Ä¢ Validation Loss: 0.7444
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.7444, best: 0.7310)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 89/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6427
  ‚Ä¢ Validation Loss: 0.7423
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.7423, best: 0.7310)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 90/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6416
  ‚Ä¢ Validation Loss: 0.7461
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.7461, best: 0.7310)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 91/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6492
  ‚Ä¢ Validation Loss: 0.7587
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.7587, best: 0.7310)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 92/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6820
  ‚Ä¢ Validation Loss: 0.7619
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.7619, best: 0.7310)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 93/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6717
  ‚Ä¢ Validation Loss: 0.7569
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.7569, best: 0.7310)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 94/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6514
  ‚Ä¢ Validation Loss: 0.7535
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.7535, best: 0.7310)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 95/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6600
  ‚Ä¢ Validation Loss: 0.7586
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.7586, best: 0.7310)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 96/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6437
  ‚Ä¢ Validation Loss: 0.7391
  ‚Ä¢ Learning Rate: 0.000998
    No improvement (current: 0.7391, best: 0.7310)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 97/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6439
  ‚Ä¢ Validation Loss: 0.7358
  ‚Ä¢ Learning Rate: 0.000997
    No improvement (current: 0.7358, best: 0.7310)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 98/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6358
  ‚Ä¢ Validation Loss: 0.7291
  ‚Ä¢ Learning Rate: 0.000996
    ‚úì New best checkpoint saved! Val loss: 0.7291
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 99/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6452
  ‚Ä¢ Validation Loss: 0.7550
  ‚Ä¢ Learning Rate: 0.000995
    No improvement (current: 0.7550, best: 0.7291)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 100/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6441
  ‚Ä¢ Validation Loss: 0.7503
  ‚Ä¢ Learning Rate: 0.000994
   üíæ Periodic checkpoint saved: epoch_100.pth
    No improvement (current: 0.7503, best: 0.7291)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 101/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6371
  ‚Ä¢ Validation Loss: 0.7375
  ‚Ä¢ Learning Rate: 0.000993
    No improvement (current: 0.7375, best: 0.7291)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 102/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6471
  ‚Ä¢ Validation Loss: 0.7452
  ‚Ä¢ Learning Rate: 0.000992
    No improvement (current: 0.7452, best: 0.7291)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 103/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6336
  ‚Ä¢ Validation Loss: 0.7328
  ‚Ä¢ Learning Rate: 0.000991
    No improvement (current: 0.7328, best: 0.7291)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 104/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6415
  ‚Ä¢ Validation Loss: 0.7377
  ‚Ä¢ Learning Rate: 0.000989
    No improvement (current: 0.7377, best: 0.7291)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 105/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6384
  ‚Ä¢ Validation Loss: 0.7412
  ‚Ä¢ Learning Rate: 0.000987
    No improvement (current: 0.7412, best: 0.7291)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 106/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6526
  ‚Ä¢ Validation Loss: 0.7408
  ‚Ä¢ Learning Rate: 0.000986
    No improvement (current: 0.7408, best: 0.7291)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 107/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6388
  ‚Ä¢ Validation Loss: 0.7426
  ‚Ä¢ Learning Rate: 0.000984
    No improvement (current: 0.7426, best: 0.7291)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 108/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6582
  ‚Ä¢ Validation Loss: 0.7619
  ‚Ä¢ Learning Rate: 0.000982
    No improvement (current: 0.7619, best: 0.7291)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 109/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6386
  ‚Ä¢ Validation Loss: 0.7466
  ‚Ä¢ Learning Rate: 0.000980
    No improvement (current: 0.7466, best: 0.7291)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 110/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6528
  ‚Ä¢ Validation Loss: 0.7517
  ‚Ä¢ Learning Rate: 0.000978
    No improvement (current: 0.7517, best: 0.7291)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 111/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6485
  ‚Ä¢ Validation Loss: 0.7592
  ‚Ä¢ Learning Rate: 0.000976
    No improvement (current: 0.7592, best: 0.7291)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 112/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6510
  ‚Ä¢ Validation Loss: 0.7589
  ‚Ä¢ Learning Rate: 0.000973
    No improvement (current: 0.7589, best: 0.7291)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 113/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6430
  ‚Ä¢ Validation Loss: 0.7473
  ‚Ä¢ Learning Rate: 0.000971
    No improvement (current: 0.7473, best: 0.7291)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 114/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6410
  ‚Ä¢ Validation Loss: 0.7441
  ‚Ä¢ Learning Rate: 0.000968
    No improvement (current: 0.7441, best: 0.7291)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 115/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6272
  ‚Ä¢ Validation Loss: 0.7475
  ‚Ä¢ Learning Rate: 0.000965
    No improvement (current: 0.7475, best: 0.7291)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 116/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6366
  ‚Ä¢ Validation Loss: 0.7370
  ‚Ä¢ Learning Rate: 0.000963
    No improvement (current: 0.7370, best: 0.7291)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 117/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6364
  ‚Ä¢ Validation Loss: 0.7559
  ‚Ä¢ Learning Rate: 0.000960
    No improvement (current: 0.7559, best: 0.7291)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 118/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6417
  ‚Ä¢ Validation Loss: 0.7435
  ‚Ä¢ Learning Rate: 0.000957
    No improvement (current: 0.7435, best: 0.7291)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 119/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6393
  ‚Ä¢ Validation Loss: 0.7465
  ‚Ä¢ Learning Rate: 0.000954
    No improvement (current: 0.7465, best: 0.7291)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 120/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6455
  ‚Ä¢ Validation Loss: 0.7338
  ‚Ä¢ Learning Rate: 0.000951
    No improvement (current: 0.7338, best: 0.7291)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 121/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6447
  ‚Ä¢ Validation Loss: 0.7607
  ‚Ä¢ Learning Rate: 0.000947
    No improvement (current: 0.7607, best: 0.7291)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 122/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6465
  ‚Ä¢ Validation Loss: 0.7548
  ‚Ä¢ Learning Rate: 0.000944
    No improvement (current: 0.7548, best: 0.7291)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 123/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6298
  ‚Ä¢ Validation Loss: 0.7326
  ‚Ä¢ Learning Rate: 0.000940
    No improvement (current: 0.7326, best: 0.7291)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 124/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6326
  ‚Ä¢ Validation Loss: 0.7376
  ‚Ä¢ Learning Rate: 0.000937
    No improvement (current: 0.7376, best: 0.7291)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 125/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6324
  ‚Ä¢ Validation Loss: 0.7434
  ‚Ä¢ Learning Rate: 0.000933
    No improvement (current: 0.7434, best: 0.7291)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 126/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6252
  ‚Ä¢ Validation Loss: 0.7352
  ‚Ä¢ Learning Rate: 0.000929
    No improvement (current: 0.7352, best: 0.7291)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 127/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6353
  ‚Ä¢ Validation Loss: 0.7398
  ‚Ä¢ Learning Rate: 0.000925
    No improvement (current: 0.7398, best: 0.7291)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 128/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6343
  ‚Ä¢ Validation Loss: 0.7291
  ‚Ä¢ Learning Rate: 0.000921
    ‚úì New best checkpoint saved! Val loss: 0.7291
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 129/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6286
  ‚Ä¢ Validation Loss: 0.7317
  ‚Ä¢ Learning Rate: 0.000917
    No improvement (current: 0.7317, best: 0.7291)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 130/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6315
  ‚Ä¢ Validation Loss: 0.7418
  ‚Ä¢ Learning Rate: 0.000913
    No improvement (current: 0.7418, best: 0.7291)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 131/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6283
  ‚Ä¢ Validation Loss: 0.7368
  ‚Ä¢ Learning Rate: 0.000909
    No improvement (current: 0.7368, best: 0.7291)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 132/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6284
  ‚Ä¢ Validation Loss: 0.7643
  ‚Ä¢ Learning Rate: 0.000905
    No improvement (current: 0.7643, best: 0.7291)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 133/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6378
  ‚Ä¢ Validation Loss: 0.7338
  ‚Ä¢ Learning Rate: 0.000900
    No improvement (current: 0.7338, best: 0.7291)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 134/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6302
  ‚Ä¢ Validation Loss: 0.7398
  ‚Ä¢ Learning Rate: 0.000896
    No improvement (current: 0.7398, best: 0.7291)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 135/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6349
  ‚Ä¢ Validation Loss: 0.7544
  ‚Ä¢ Learning Rate: 0.000891
    No improvement (current: 0.7544, best: 0.7291)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 136/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6303
  ‚Ä¢ Validation Loss: 0.7558
  ‚Ä¢ Learning Rate: 0.000886
    No improvement (current: 0.7558, best: 0.7291)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 137/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6353
  ‚Ä¢ Validation Loss: 0.7445
  ‚Ä¢ Learning Rate: 0.000881
    No improvement (current: 0.7445, best: 0.7291)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 138/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6296
  ‚Ä¢ Validation Loss: 0.7382
  ‚Ä¢ Learning Rate: 0.000877
    No improvement (current: 0.7382, best: 0.7291)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 139/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6372
  ‚Ä¢ Validation Loss: 0.7353
  ‚Ä¢ Learning Rate: 0.000872
    No improvement (current: 0.7353, best: 0.7291)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 140/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6366
  ‚Ä¢ Validation Loss: 0.7289
  ‚Ä¢ Learning Rate: 0.000867
    ‚úì New best checkpoint saved! Val loss: 0.7289
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 141/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6245
  ‚Ä¢ Validation Loss: 0.7249
  ‚Ä¢ Learning Rate: 0.000861
    ‚úì New best checkpoint saved! Val loss: 0.7249
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 142/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6252
  ‚Ä¢ Validation Loss: 0.7258
  ‚Ä¢ Learning Rate: 0.000856
    No improvement (current: 0.7258, best: 0.7249)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 143/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6166
  ‚Ä¢ Validation Loss: 0.7285
  ‚Ä¢ Learning Rate: 0.000851
    No improvement (current: 0.7285, best: 0.7249)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 144/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6337
  ‚Ä¢ Validation Loss: 0.7372
  ‚Ä¢ Learning Rate: 0.000846
    No improvement (current: 0.7372, best: 0.7249)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 145/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6216
  ‚Ä¢ Validation Loss: 0.7326
  ‚Ä¢ Learning Rate: 0.000840
    No improvement (current: 0.7326, best: 0.7249)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 146/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6369
  ‚Ä¢ Validation Loss: 0.7282
  ‚Ä¢ Learning Rate: 0.000835
    No improvement (current: 0.7282, best: 0.7249)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 147/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6236
  ‚Ä¢ Validation Loss: 0.7345
  ‚Ä¢ Learning Rate: 0.000829
    No improvement (current: 0.7345, best: 0.7249)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 148/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6231
  ‚Ä¢ Validation Loss: 0.7292
  ‚Ä¢ Learning Rate: 0.000823
    No improvement (current: 0.7292, best: 0.7249)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 149/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6282
  ‚Ä¢ Validation Loss: 0.7448
  ‚Ä¢ Learning Rate: 0.000818
    No improvement (current: 0.7448, best: 0.7249)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 150/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6227
  ‚Ä¢ Validation Loss: 0.7311
  ‚Ä¢ Learning Rate: 0.000812
    No improvement (current: 0.7311, best: 0.7249)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 151/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6190
  ‚Ä¢ Validation Loss: 0.7352
  ‚Ä¢ Learning Rate: 0.000806
    No improvement (current: 0.7352, best: 0.7249)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 152/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6255
  ‚Ä¢ Validation Loss: 0.7333
  ‚Ä¢ Learning Rate: 0.000800
    No improvement (current: 0.7333, best: 0.7249)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 153/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6209
  ‚Ä¢ Validation Loss: 0.7373
  ‚Ä¢ Learning Rate: 0.000794
    No improvement (current: 0.7373, best: 0.7249)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 154/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6318
  ‚Ä¢ Validation Loss: 0.7618
  ‚Ä¢ Learning Rate: 0.000788
    No improvement (current: 0.7618, best: 0.7249)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 155/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6393
  ‚Ä¢ Validation Loss: 0.7310
  ‚Ä¢ Learning Rate: 0.000782
    No improvement (current: 0.7310, best: 0.7249)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 156/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6312
  ‚Ä¢ Validation Loss: 0.7420
  ‚Ä¢ Learning Rate: 0.000776
    No improvement (current: 0.7420, best: 0.7249)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 157/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6269
  ‚Ä¢ Validation Loss: 0.7343
  ‚Ä¢ Learning Rate: 0.000769
    No improvement (current: 0.7343, best: 0.7249)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 158/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6297
  ‚Ä¢ Validation Loss: 0.7366
  ‚Ä¢ Learning Rate: 0.000763
    No improvement (current: 0.7366, best: 0.7249)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 159/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6297
  ‚Ä¢ Validation Loss: 0.7250
  ‚Ä¢ Learning Rate: 0.000757
    No improvement (current: 0.7250, best: 0.7249)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 160/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6160
  ‚Ä¢ Validation Loss: 0.7430
  ‚Ä¢ Learning Rate: 0.000750
    No improvement (current: 0.7430, best: 0.7249)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 161/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6623
  ‚Ä¢ Validation Loss: 0.7268
  ‚Ä¢ Learning Rate: 0.000744
    No improvement (current: 0.7268, best: 0.7249)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 162/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6321
  ‚Ä¢ Validation Loss: 0.7303
  ‚Ä¢ Learning Rate: 0.000737
    No improvement (current: 0.7303, best: 0.7249)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 163/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6396
  ‚Ä¢ Validation Loss: 0.7347
  ‚Ä¢ Learning Rate: 0.000731
    No improvement (current: 0.7347, best: 0.7249)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 164/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6368
  ‚Ä¢ Validation Loss: 0.7323
  ‚Ä¢ Learning Rate: 0.000724
    No improvement (current: 0.7323, best: 0.7249)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 165/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6347
  ‚Ä¢ Validation Loss: 0.7279
  ‚Ä¢ Learning Rate: 0.000717
    No improvement (current: 0.7279, best: 0.7249)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 166/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6233
  ‚Ä¢ Validation Loss: 0.7363
  ‚Ä¢ Learning Rate: 0.000710
    No improvement (current: 0.7363, best: 0.7249)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 167/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6308
  ‚Ä¢ Validation Loss: 0.7361
  ‚Ä¢ Learning Rate: 0.000704
    No improvement (current: 0.7361, best: 0.7249)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 168/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6263
  ‚Ä¢ Validation Loss: 0.7482
  ‚Ä¢ Learning Rate: 0.000697
    No improvement (current: 0.7482, best: 0.7249)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 169/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6231
  ‚Ä¢ Validation Loss: 0.7582
  ‚Ä¢ Learning Rate: 0.000690
    No improvement (current: 0.7582, best: 0.7249)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 170/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6355
  ‚Ä¢ Validation Loss: 0.7388
  ‚Ä¢ Learning Rate: 0.000683
    No improvement (current: 0.7388, best: 0.7249)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 171/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6190
  ‚Ä¢ Validation Loss: 0.7359
  ‚Ä¢ Learning Rate: 0.000676
    No improvement (current: 0.7359, best: 0.7249)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 172/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6293
  ‚Ä¢ Validation Loss: 0.7358
  ‚Ä¢ Learning Rate: 0.000669
    No improvement (current: 0.7358, best: 0.7249)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 173/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6307
  ‚Ä¢ Validation Loss: 0.7363
  ‚Ä¢ Learning Rate: 0.000662
    No improvement (current: 0.7363, best: 0.7249)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 174/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6300
  ‚Ä¢ Validation Loss: 0.7237
  ‚Ä¢ Learning Rate: 0.000655
    ‚úì New best checkpoint saved! Val loss: 0.7237
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 175/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6178
  ‚Ä¢ Validation Loss: 0.7491
  ‚Ä¢ Learning Rate: 0.000648
    No improvement (current: 0.7491, best: 0.7237)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 176/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6228
  ‚Ä¢ Validation Loss: 0.7318
  ‚Ä¢ Learning Rate: 0.000641
    No improvement (current: 0.7318, best: 0.7237)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 177/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6290
  ‚Ä¢ Validation Loss: 0.7268
  ‚Ä¢ Learning Rate: 0.000633
    No improvement (current: 0.7268, best: 0.7237)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 178/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6176
  ‚Ä¢ Validation Loss: 0.7320
  ‚Ä¢ Learning Rate: 0.000626
    No improvement (current: 0.7320, best: 0.7237)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 179/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6204
  ‚Ä¢ Validation Loss: 0.7376
  ‚Ä¢ Learning Rate: 0.000619
    No improvement (current: 0.7376, best: 0.7237)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 180/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6229
  ‚Ä¢ Validation Loss: 0.7325
  ‚Ä¢ Learning Rate: 0.000612
    No improvement (current: 0.7325, best: 0.7237)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 181/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6149
  ‚Ä¢ Validation Loss: 0.7390
  ‚Ä¢ Learning Rate: 0.000604
    No improvement (current: 0.7390, best: 0.7237)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 182/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6070
  ‚Ä¢ Validation Loss: 0.7286
  ‚Ä¢ Learning Rate: 0.000597
    No improvement (current: 0.7286, best: 0.7237)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 183/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6187
  ‚Ä¢ Validation Loss: 0.7261
  ‚Ä¢ Learning Rate: 0.000590
    No improvement (current: 0.7261, best: 0.7237)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 184/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6187
  ‚Ä¢ Validation Loss: 0.7343
  ‚Ä¢ Learning Rate: 0.000582
    No improvement (current: 0.7343, best: 0.7237)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 185/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6215
  ‚Ä¢ Validation Loss: 0.7294
  ‚Ä¢ Learning Rate: 0.000575
    No improvement (current: 0.7294, best: 0.7237)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 186/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6095
  ‚Ä¢ Validation Loss: 0.7384
  ‚Ä¢ Learning Rate: 0.000567
    No improvement (current: 0.7384, best: 0.7237)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 187/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6207
  ‚Ä¢ Validation Loss: 0.7418
  ‚Ä¢ Learning Rate: 0.000560
    No improvement (current: 0.7418, best: 0.7237)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 188/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6239
  ‚Ä¢ Validation Loss: 0.7501
  ‚Ä¢ Learning Rate: 0.000553
    No improvement (current: 0.7501, best: 0.7237)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 189/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6169
  ‚Ä¢ Validation Loss: 0.7277
  ‚Ä¢ Learning Rate: 0.000545
    No improvement (current: 0.7277, best: 0.7237)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 190/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6232
  ‚Ä¢ Validation Loss: 0.7268
  ‚Ä¢ Learning Rate: 0.000538
    No improvement (current: 0.7268, best: 0.7237)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 191/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6127
  ‚Ä¢ Validation Loss: 0.7284
  ‚Ä¢ Learning Rate: 0.000530
    No improvement (current: 0.7284, best: 0.7237)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 192/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6117
  ‚Ä¢ Validation Loss: 0.7249
  ‚Ä¢ Learning Rate: 0.000523
    No improvement (current: 0.7249, best: 0.7237)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 193/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6093
  ‚Ä¢ Validation Loss: 0.7192
  ‚Ä¢ Learning Rate: 0.000515
    ‚úì New best checkpoint saved! Val loss: 0.7192
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 194/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6136
  ‚Ä¢ Validation Loss: 0.7352
  ‚Ä¢ Learning Rate: 0.000508
    No improvement (current: 0.7352, best: 0.7192)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 195/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6067
  ‚Ä¢ Validation Loss: 0.7241
  ‚Ä¢ Learning Rate: 0.000500
    No improvement (current: 0.7241, best: 0.7192)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 196/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6175
  ‚Ä¢ Validation Loss: 0.7239
  ‚Ä¢ Learning Rate: 0.000493
    No improvement (current: 0.7239, best: 0.7192)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 197/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6096
  ‚Ä¢ Validation Loss: 0.7265
  ‚Ä¢ Learning Rate: 0.000486
    No improvement (current: 0.7265, best: 0.7192)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 198/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6174
  ‚Ä¢ Validation Loss: 0.7516
  ‚Ä¢ Learning Rate: 0.000478
    No improvement (current: 0.7516, best: 0.7192)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 199/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6147
  ‚Ä¢ Validation Loss: 0.7450
  ‚Ä¢ Learning Rate: 0.000471
    No improvement (current: 0.7450, best: 0.7192)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 200/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6192
  ‚Ä¢ Validation Loss: 0.7280
  ‚Ä¢ Learning Rate: 0.000463
   üíæ Periodic checkpoint saved: epoch_200.pth
    No improvement (current: 0.7280, best: 0.7192)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 201/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6174
  ‚Ä¢ Validation Loss: 0.7380
  ‚Ä¢ Learning Rate: 0.000456
    No improvement (current: 0.7380, best: 0.7192)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 202/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6064
  ‚Ä¢ Validation Loss: 0.7315
  ‚Ä¢ Learning Rate: 0.000448
    No improvement (current: 0.7315, best: 0.7192)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 203/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6087
  ‚Ä¢ Validation Loss: 0.7363
  ‚Ä¢ Learning Rate: 0.000441
    No improvement (current: 0.7363, best: 0.7192)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 204/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6139
  ‚Ä¢ Validation Loss: 0.7293
  ‚Ä¢ Learning Rate: 0.000433
    No improvement (current: 0.7293, best: 0.7192)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 205/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6097
  ‚Ä¢ Validation Loss: 0.7377
  ‚Ä¢ Learning Rate: 0.000426
    No improvement (current: 0.7377, best: 0.7192)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 206/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6030
  ‚Ä¢ Validation Loss: 0.7348
  ‚Ä¢ Learning Rate: 0.000419
    No improvement (current: 0.7348, best: 0.7192)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 207/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6179
  ‚Ä¢ Validation Loss: 0.7289
  ‚Ä¢ Learning Rate: 0.000411
    No improvement (current: 0.7289, best: 0.7192)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 208/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6121
  ‚Ä¢ Validation Loss: 0.7276
  ‚Ä¢ Learning Rate: 0.000404
    No improvement (current: 0.7276, best: 0.7192)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 209/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6171
  ‚Ä¢ Validation Loss: 0.7363
  ‚Ä¢ Learning Rate: 0.000397
    No improvement (current: 0.7363, best: 0.7192)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 210/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6112
  ‚Ä¢ Validation Loss: 0.7343
  ‚Ä¢ Learning Rate: 0.000389
    No improvement (current: 0.7343, best: 0.7192)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 211/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6062
  ‚Ä¢ Validation Loss: 0.7293
  ‚Ä¢ Learning Rate: 0.000382
    No improvement (current: 0.7293, best: 0.7192)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 212/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6060
  ‚Ä¢ Validation Loss: 0.7264
  ‚Ä¢ Learning Rate: 0.000375
    No improvement (current: 0.7264, best: 0.7192)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 213/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6143
  ‚Ä¢ Validation Loss: 0.7257
  ‚Ä¢ Learning Rate: 0.000368
    No improvement (current: 0.7257, best: 0.7192)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 214/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6104
  ‚Ä¢ Validation Loss: 0.7241
  ‚Ä¢ Learning Rate: 0.000360
    No improvement (current: 0.7241, best: 0.7192)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 215/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6023
  ‚Ä¢ Validation Loss: 0.7220
  ‚Ä¢ Learning Rate: 0.000353
    No improvement (current: 0.7220, best: 0.7192)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 216/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6130
  ‚Ä¢ Validation Loss: 0.7293
  ‚Ä¢ Learning Rate: 0.000346
    No improvement (current: 0.7293, best: 0.7192)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 217/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6081
  ‚Ä¢ Validation Loss: 0.7215
  ‚Ä¢ Learning Rate: 0.000339
    No improvement (current: 0.7215, best: 0.7192)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 218/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6115
  ‚Ä¢ Validation Loss: 0.7217
  ‚Ä¢ Learning Rate: 0.000332
    No improvement (current: 0.7217, best: 0.7192)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 219/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6045
  ‚Ä¢ Validation Loss: 0.7396
  ‚Ä¢ Learning Rate: 0.000325
    No improvement (current: 0.7396, best: 0.7192)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 220/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6126
  ‚Ä¢ Validation Loss: 0.7198
  ‚Ä¢ Learning Rate: 0.000318
    No improvement (current: 0.7198, best: 0.7192)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 221/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6140
  ‚Ä¢ Validation Loss: 0.7358
  ‚Ä¢ Learning Rate: 0.000311
    No improvement (current: 0.7358, best: 0.7192)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 222/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6030
  ‚Ä¢ Validation Loss: 0.7368
  ‚Ä¢ Learning Rate: 0.000304
    No improvement (current: 0.7368, best: 0.7192)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 223/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6054
  ‚Ä¢ Validation Loss: 0.7288
  ‚Ä¢ Learning Rate: 0.000297
    No improvement (current: 0.7288, best: 0.7192)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 224/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6064
  ‚Ä¢ Validation Loss: 0.7278
  ‚Ä¢ Learning Rate: 0.000290
    No improvement (current: 0.7278, best: 0.7192)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 225/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6155
  ‚Ä¢ Validation Loss: 0.7251
  ‚Ä¢ Learning Rate: 0.000284
    No improvement (current: 0.7251, best: 0.7192)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 226/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6031
  ‚Ä¢ Validation Loss: 0.7366
  ‚Ä¢ Learning Rate: 0.000277
    No improvement (current: 0.7366, best: 0.7192)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 227/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6126
  ‚Ä¢ Validation Loss: 0.7295
  ‚Ä¢ Learning Rate: 0.000270
    No improvement (current: 0.7295, best: 0.7192)
    ‚ö† No improvement for 34 epochs (patience: 150, remaining: 116)

EPOCH 228/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6092
  ‚Ä¢ Validation Loss: 0.7306
  ‚Ä¢ Learning Rate: 0.000264
    No improvement (current: 0.7306, best: 0.7192)
    ‚ö† No improvement for 35 epochs (patience: 150, remaining: 115)

EPOCH 229/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6027
  ‚Ä¢ Validation Loss: 0.7247
  ‚Ä¢ Learning Rate: 0.000257
    No improvement (current: 0.7247, best: 0.7192)
    ‚ö† No improvement for 36 epochs (patience: 150, remaining: 114)

EPOCH 230/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6095
  ‚Ä¢ Validation Loss: 0.7274
  ‚Ä¢ Learning Rate: 0.000251
    No improvement (current: 0.7274, best: 0.7192)
    ‚ö† No improvement for 37 epochs (patience: 150, remaining: 113)

EPOCH 231/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6033
  ‚Ä¢ Validation Loss: 0.7282
  ‚Ä¢ Learning Rate: 0.000244
    No improvement (current: 0.7282, best: 0.7192)
    ‚ö† No improvement for 38 epochs (patience: 150, remaining: 112)

EPOCH 232/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6084
  ‚Ä¢ Validation Loss: 0.7292
  ‚Ä¢ Learning Rate: 0.000238
    No improvement (current: 0.7292, best: 0.7192)
    ‚ö† No improvement for 39 epochs (patience: 150, remaining: 111)

EPOCH 233/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6072
  ‚Ä¢ Validation Loss: 0.7304
  ‚Ä¢ Learning Rate: 0.000232
    No improvement (current: 0.7304, best: 0.7192)
    ‚ö† No improvement for 40 epochs (patience: 150, remaining: 110)

EPOCH 234/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6047
  ‚Ä¢ Validation Loss: 0.7345
  ‚Ä¢ Learning Rate: 0.000225
    No improvement (current: 0.7345, best: 0.7192)
    ‚ö† No improvement for 41 epochs (patience: 150, remaining: 109)

EPOCH 235/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6109
  ‚Ä¢ Validation Loss: 0.7325
  ‚Ä¢ Learning Rate: 0.000219
    No improvement (current: 0.7325, best: 0.7192)
    ‚ö† No improvement for 42 epochs (patience: 150, remaining: 108)

EPOCH 236/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6066
  ‚Ä¢ Validation Loss: 0.7250
  ‚Ä¢ Learning Rate: 0.000213
    No improvement (current: 0.7250, best: 0.7192)
    ‚ö† No improvement for 43 epochs (patience: 150, remaining: 107)

EPOCH 237/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6063
  ‚Ä¢ Validation Loss: 0.7444
  ‚Ä¢ Learning Rate: 0.000207
    No improvement (current: 0.7444, best: 0.7192)
    ‚ö† No improvement for 44 epochs (patience: 150, remaining: 106)

EPOCH 238/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5997
  ‚Ä¢ Validation Loss: 0.7271
  ‚Ä¢ Learning Rate: 0.000201
    No improvement (current: 0.7271, best: 0.7192)
    ‚ö† No improvement for 45 epochs (patience: 150, remaining: 105)

EPOCH 239/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6077
  ‚Ä¢ Validation Loss: 0.7339
  ‚Ä¢ Learning Rate: 0.000195
    No improvement (current: 0.7339, best: 0.7192)
    ‚ö† No improvement for 46 epochs (patience: 150, remaining: 104)

EPOCH 240/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6014
  ‚Ä¢ Validation Loss: 0.7326
  ‚Ä¢ Learning Rate: 0.000189
    No improvement (current: 0.7326, best: 0.7192)
    ‚ö† No improvement for 47 epochs (patience: 150, remaining: 103)

EPOCH 241/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5992
  ‚Ä¢ Validation Loss: 0.7277
  ‚Ä¢ Learning Rate: 0.000183
    No improvement (current: 0.7277, best: 0.7192)
    ‚ö† No improvement for 48 epochs (patience: 150, remaining: 102)

EPOCH 242/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6138
  ‚Ä¢ Validation Loss: 0.7288
  ‚Ä¢ Learning Rate: 0.000177
    No improvement (current: 0.7288, best: 0.7192)
    ‚ö† No improvement for 49 epochs (patience: 150, remaining: 101)

EPOCH 243/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6038
  ‚Ä¢ Validation Loss: 0.7235
  ‚Ä¢ Learning Rate: 0.000172
    No improvement (current: 0.7235, best: 0.7192)
    ‚ö† No improvement for 50 epochs (patience: 150, remaining: 100)

EPOCH 244/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6054
  ‚Ä¢ Validation Loss: 0.7278
  ‚Ä¢ Learning Rate: 0.000166
    No improvement (current: 0.7278, best: 0.7192)
    ‚ö† No improvement for 51 epochs (patience: 150, remaining: 99)

EPOCH 245/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5988
  ‚Ä¢ Validation Loss: 0.7305
  ‚Ä¢ Learning Rate: 0.000161
    No improvement (current: 0.7305, best: 0.7192)
    ‚ö† No improvement for 52 epochs (patience: 150, remaining: 98)

EPOCH 246/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5990
  ‚Ä¢ Validation Loss: 0.7251
  ‚Ä¢ Learning Rate: 0.000155
    No improvement (current: 0.7251, best: 0.7192)
    ‚ö† No improvement for 53 epochs (patience: 150, remaining: 97)

EPOCH 247/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6025
  ‚Ä¢ Validation Loss: 0.7262
  ‚Ä¢ Learning Rate: 0.000150
    No improvement (current: 0.7262, best: 0.7192)
    ‚ö† No improvement for 54 epochs (patience: 150, remaining: 96)

EPOCH 248/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6050
  ‚Ä¢ Validation Loss: 0.7358
  ‚Ä¢ Learning Rate: 0.000145
    No improvement (current: 0.7358, best: 0.7192)
    ‚ö† No improvement for 55 epochs (patience: 150, remaining: 95)

EPOCH 249/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6086
  ‚Ä¢ Validation Loss: 0.7280
  ‚Ä¢ Learning Rate: 0.000139
    No improvement (current: 0.7280, best: 0.7192)
    ‚ö† No improvement for 56 epochs (patience: 150, remaining: 94)

EPOCH 250/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6039
  ‚Ä¢ Validation Loss: 0.7399
  ‚Ä¢ Learning Rate: 0.000134
    No improvement (current: 0.7399, best: 0.7192)
    ‚ö† No improvement for 57 epochs (patience: 150, remaining: 93)

EPOCH 251/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6048
  ‚Ä¢ Validation Loss: 0.7360
  ‚Ä¢ Learning Rate: 0.000129
    No improvement (current: 0.7360, best: 0.7192)
    ‚ö† No improvement for 58 epochs (patience: 150, remaining: 92)

EPOCH 252/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6111
  ‚Ä¢ Validation Loss: 0.7432
  ‚Ä¢ Learning Rate: 0.000124
    No improvement (current: 0.7432, best: 0.7192)
    ‚ö† No improvement for 59 epochs (patience: 150, remaining: 91)

EPOCH 253/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6018
  ‚Ä¢ Validation Loss: 0.7262
  ‚Ä¢ Learning Rate: 0.000119
    No improvement (current: 0.7262, best: 0.7192)
    ‚ö† No improvement for 60 epochs (patience: 150, remaining: 90)

EPOCH 254/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6022
  ‚Ä¢ Validation Loss: 0.7332
  ‚Ä¢ Learning Rate: 0.000115
    No improvement (current: 0.7332, best: 0.7192)
    ‚ö† No improvement for 61 epochs (patience: 150, remaining: 89)

EPOCH 255/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6005
  ‚Ä¢ Validation Loss: 0.7330
  ‚Ä¢ Learning Rate: 0.000110
    No improvement (current: 0.7330, best: 0.7192)
    ‚ö† No improvement for 62 epochs (patience: 150, remaining: 88)

EPOCH 256/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6036
  ‚Ä¢ Validation Loss: 0.7328
  ‚Ä¢ Learning Rate: 0.000105
    No improvement (current: 0.7328, best: 0.7192)
    ‚ö† No improvement for 63 epochs (patience: 150, remaining: 87)

EPOCH 257/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5923
  ‚Ä¢ Validation Loss: 0.7289
  ‚Ä¢ Learning Rate: 0.000101
    No improvement (current: 0.7289, best: 0.7192)
    ‚ö† No improvement for 64 epochs (patience: 150, remaining: 86)

EPOCH 258/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6051
  ‚Ä¢ Validation Loss: 0.7346
  ‚Ä¢ Learning Rate: 0.000096
    No improvement (current: 0.7346, best: 0.7192)
    ‚ö† No improvement for 65 epochs (patience: 150, remaining: 85)

EPOCH 259/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6115
  ‚Ä¢ Validation Loss: 0.7268
  ‚Ä¢ Learning Rate: 0.000092
    No improvement (current: 0.7268, best: 0.7192)
    ‚ö† No improvement for 66 epochs (patience: 150, remaining: 84)

EPOCH 260/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5969
  ‚Ä¢ Validation Loss: 0.7256
  ‚Ä¢ Learning Rate: 0.000088
    No improvement (current: 0.7256, best: 0.7192)
    ‚ö† No improvement for 67 epochs (patience: 150, remaining: 83)

EPOCH 261/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6067
  ‚Ä¢ Validation Loss: 0.7333
  ‚Ä¢ Learning Rate: 0.000084
    No improvement (current: 0.7333, best: 0.7192)
    ‚ö† No improvement for 68 epochs (patience: 150, remaining: 82)

EPOCH 262/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5968
  ‚Ä¢ Validation Loss: 0.7286
  ‚Ä¢ Learning Rate: 0.000080
    No improvement (current: 0.7286, best: 0.7192)
    ‚ö† No improvement for 69 epochs (patience: 150, remaining: 81)

EPOCH 263/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5990
  ‚Ä¢ Validation Loss: 0.7319
  ‚Ä¢ Learning Rate: 0.000076
    No improvement (current: 0.7319, best: 0.7192)
    ‚ö† No improvement for 70 epochs (patience: 150, remaining: 80)

EPOCH 264/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6104
  ‚Ä¢ Validation Loss: 0.7355
  ‚Ä¢ Learning Rate: 0.000072
    No improvement (current: 0.7355, best: 0.7192)
    ‚ö† No improvement for 71 epochs (patience: 150, remaining: 79)

EPOCH 265/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6044
  ‚Ä¢ Validation Loss: 0.7308
  ‚Ä¢ Learning Rate: 0.000068
    No improvement (current: 0.7308, best: 0.7192)
    ‚ö† No improvement for 72 epochs (patience: 150, remaining: 78)

EPOCH 266/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6066
  ‚Ä¢ Validation Loss: 0.7335
  ‚Ä¢ Learning Rate: 0.000064
    No improvement (current: 0.7335, best: 0.7192)
    ‚ö† No improvement for 73 epochs (patience: 150, remaining: 77)

EPOCH 267/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6059
  ‚Ä¢ Validation Loss: 0.7254
  ‚Ä¢ Learning Rate: 0.000061
    No improvement (current: 0.7254, best: 0.7192)
    ‚ö† No improvement for 74 epochs (patience: 150, remaining: 76)

EPOCH 268/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6085
  ‚Ä¢ Validation Loss: 0.7343
  ‚Ä¢ Learning Rate: 0.000057
    No improvement (current: 0.7343, best: 0.7192)
    ‚ö† No improvement for 75 epochs (patience: 150, remaining: 75)

EPOCH 269/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6091
  ‚Ä¢ Validation Loss: 0.7305
  ‚Ä¢ Learning Rate: 0.000054
    No improvement (current: 0.7305, best: 0.7192)
    ‚ö† No improvement for 76 epochs (patience: 150, remaining: 74)

EPOCH 270/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6049
  ‚Ä¢ Validation Loss: 0.7240
  ‚Ä¢ Learning Rate: 0.000050
    No improvement (current: 0.7240, best: 0.7192)
    ‚ö† No improvement for 77 epochs (patience: 150, remaining: 73)

EPOCH 271/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6036
  ‚Ä¢ Validation Loss: 0.7361
  ‚Ä¢ Learning Rate: 0.000047
    No improvement (current: 0.7361, best: 0.7192)
    ‚ö† No improvement for 78 epochs (patience: 150, remaining: 72)

EPOCH 272/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6011
  ‚Ä¢ Validation Loss: 0.7324
  ‚Ä¢ Learning Rate: 0.000044
    No improvement (current: 0.7324, best: 0.7192)
    ‚ö† No improvement for 79 epochs (patience: 150, remaining: 71)

EPOCH 273/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6074
  ‚Ä¢ Validation Loss: 0.7339
  ‚Ä¢ Learning Rate: 0.000041
    No improvement (current: 0.7339, best: 0.7192)
    ‚ö† No improvement for 80 epochs (patience: 150, remaining: 70)

EPOCH 274/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6101
  ‚Ä¢ Validation Loss: 0.7349
  ‚Ä¢ Learning Rate: 0.000038
    No improvement (current: 0.7349, best: 0.7192)
    ‚ö† No improvement for 81 epochs (patience: 150, remaining: 69)

EPOCH 275/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6072
  ‚Ä¢ Validation Loss: 0.7342
  ‚Ä¢ Learning Rate: 0.000036
    No improvement (current: 0.7342, best: 0.7192)
    ‚ö† No improvement for 82 epochs (patience: 150, remaining: 68)

EPOCH 276/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6066
  ‚Ä¢ Validation Loss: 0.7346
  ‚Ä¢ Learning Rate: 0.000033
    No improvement (current: 0.7346, best: 0.7192)
    ‚ö† No improvement for 83 epochs (patience: 150, remaining: 67)

EPOCH 277/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6036
  ‚Ä¢ Validation Loss: 0.7348
  ‚Ä¢ Learning Rate: 0.000030
    No improvement (current: 0.7348, best: 0.7192)
    ‚ö† No improvement for 84 epochs (patience: 150, remaining: 66)

EPOCH 278/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6042
  ‚Ä¢ Validation Loss: 0.7348
  ‚Ä¢ Learning Rate: 0.000028
    No improvement (current: 0.7348, best: 0.7192)
    ‚ö† No improvement for 85 epochs (patience: 150, remaining: 65)

EPOCH 279/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5990
  ‚Ä¢ Validation Loss: 0.7349
  ‚Ä¢ Learning Rate: 0.000025
    No improvement (current: 0.7349, best: 0.7192)
    ‚ö† No improvement for 86 epochs (patience: 150, remaining: 64)

EPOCH 280/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6085
  ‚Ä¢ Validation Loss: 0.7345
  ‚Ä¢ Learning Rate: 0.000023
    No improvement (current: 0.7345, best: 0.7192)
    ‚ö† No improvement for 87 epochs (patience: 150, remaining: 63)

EPOCH 281/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6005
  ‚Ä¢ Validation Loss: 0.7298
  ‚Ä¢ Learning Rate: 0.000021
    No improvement (current: 0.7298, best: 0.7192)
    ‚ö† No improvement for 88 epochs (patience: 150, remaining: 62)

EPOCH 282/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6060
  ‚Ä¢ Validation Loss: 0.7292
  ‚Ä¢ Learning Rate: 0.000019
    No improvement (current: 0.7292, best: 0.7192)
    ‚ö† No improvement for 89 epochs (patience: 150, remaining: 61)

EPOCH 283/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6057
  ‚Ä¢ Validation Loss: 0.7311
  ‚Ä¢ Learning Rate: 0.000017
    No improvement (current: 0.7311, best: 0.7192)
    ‚ö† No improvement for 90 epochs (patience: 150, remaining: 60)

EPOCH 284/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6031
  ‚Ä¢ Validation Loss: 0.7348
  ‚Ä¢ Learning Rate: 0.000015
    No improvement (current: 0.7348, best: 0.7192)
    ‚ö† No improvement for 91 epochs (patience: 150, remaining: 59)

EPOCH 285/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6081
  ‚Ä¢ Validation Loss: 0.7356
  ‚Ä¢ Learning Rate: 0.000014
    No improvement (current: 0.7356, best: 0.7192)
    ‚ö† No improvement for 92 epochs (patience: 150, remaining: 58)

EPOCH 286/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6051
  ‚Ä¢ Validation Loss: 0.7352
  ‚Ä¢ Learning Rate: 0.000012
    No improvement (current: 0.7352, best: 0.7192)
    ‚ö† No improvement for 93 epochs (patience: 150, remaining: 57)

EPOCH 287/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6000
  ‚Ä¢ Validation Loss: 0.7343
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.7343, best: 0.7192)
    ‚ö† No improvement for 94 epochs (patience: 150, remaining: 56)

EPOCH 288/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5995
  ‚Ä¢ Validation Loss: 0.7341
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.7341, best: 0.7192)
    ‚ö† No improvement for 95 epochs (patience: 150, remaining: 55)

EPOCH 289/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6027
  ‚Ä¢ Validation Loss: 0.7339
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.7339, best: 0.7192)
    ‚ö† No improvement for 96 epochs (patience: 150, remaining: 54)

EPOCH 290/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6017
  ‚Ä¢ Validation Loss: 0.7342
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.7342, best: 0.7192)
    ‚ö† No improvement for 97 epochs (patience: 150, remaining: 53)

EPOCH 291/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6027
  ‚Ä¢ Validation Loss: 0.7342
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.7342, best: 0.7192)
    ‚ö† No improvement for 98 epochs (patience: 150, remaining: 52)

EPOCH 292/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5967
  ‚Ä¢ Validation Loss: 0.7342
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.7342, best: 0.7192)
    ‚ö† No improvement for 99 epochs (patience: 150, remaining: 51)

EPOCH 293/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6095
  ‚Ä¢ Validation Loss: 0.7338
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.7338, best: 0.7192)
    ‚ö† No improvement for 100 epochs (patience: 150, remaining: 50)

EPOCH 294/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6038
  ‚Ä¢ Validation Loss: 0.7339
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.7339, best: 0.7192)
    ‚ö† No improvement for 101 epochs (patience: 150, remaining: 49)

EPOCH 295/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5967
  ‚Ä¢ Validation Loss: 0.7341
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.7341, best: 0.7192)
    ‚ö† No improvement for 102 epochs (patience: 150, remaining: 48)

EPOCH 296/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6012
  ‚Ä¢ Validation Loss: 0.7339
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.7339, best: 0.7192)
    ‚ö† No improvement for 103 epochs (patience: 150, remaining: 47)

EPOCH 297/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6014
  ‚Ä¢ Validation Loss: 0.7337
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.7337, best: 0.7192)
    ‚ö† No improvement for 104 epochs (patience: 150, remaining: 46)

EPOCH 298/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6003
  ‚Ä¢ Validation Loss: 0.7337
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.7337, best: 0.7192)
    ‚ö† No improvement for 105 epochs (patience: 150, remaining: 45)

EPOCH 299/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6052
  ‚Ä¢ Validation Loss: 0.7333
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.7333, best: 0.7192)
    ‚ö† No improvement for 106 epochs (patience: 150, remaining: 44)

EPOCH 300/300
--------------------------------------------------
‚ö†Ô∏è  Scheduler reached max steps, stopping LR updates.
Results:
  ‚Ä¢ Train Loss: 0.6044
  ‚Ä¢ Validation Loss: 0.7336
  ‚Ä¢ Learning Rate: 0.000001
   üíæ Periodic checkpoint saved: epoch_300.pth
    No improvement (current: 0.7336, best: 0.7192)
    ‚ö† No improvement for 107 epochs (patience: 150, remaining: 43)

================================================================================
TRAINING COMPLETED
================================================================================
Best Val Loss:  0.7192
Total Epochs:   300
Models Saved:   ./Result/a3/Latin16746
TensorBoard:    ./Result/a3/Latin16746/tensorboard_logs
================================================================================

[03:10:54] Training completed. Best val loss: 0.7192

=== TRAINING COMPLETED SUCCESSFULLY ===
Training Finished!

========================================================================
Testing Hybrid2 Baseline Model with Smart Skip Connections and Multi-Scale Aggregation and Deep Supervision: Latin16746
========================================================================
=== Historical Document Segmentation Testing ===

Using 6 classes for manuscript: Latin16746
Model: Hybrid2
Dataset: UDIADS_BIB
Manuscript: Latin16746
Test-Time Augmentation: Enabled
CRF post-processing: Enabled
  - DenseCRF with spatial and color pairwise potentials

================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder for Testing
================================================================================
================================================================================
üöÄ SIMPLE DECODER (Flag-Controlled Enhancements)
================================================================================
  ‚Ä¢ EfficientNet Variant: b4
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Enhancement Flags:
  ‚Ä¢ Deep Supervision: True
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: True
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: True
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Loaded checkpoint from epoch 192
Best validation loss: 0.7192
  ‚úÖ Model checkpoint loaded successfully (exact match)
Loaded checkpoint: best_model_latest.pth
Namespace(cfg=None, output_dir='./Result/a3/Latin16746', use_baseline=True, decoder='EfficientNet-B4', efficientnet_variant='b4', use_deep_supervision=True, use_cbam=False, use_smart_skip=True, use_cross_attn=False, use_multiscale_agg=True, use_groupnorm=True, use_batchnorm=False, use_pos_embed=True, dataset='UDIADS_BIB', manuscript='Latin16746', udiadsbib_root='../../U-DIADS-Bib-MS_patched', divahisdb_root='../../DivaHisDB', use_patched_data=True, num_classes=6, img_size=224, batch_size=24, is_savenii=True, test_save_dir='../predictions', use_crf=True, deterministic=1, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, use_tta=True)
Testing with checkpoint: best_model_latest.pth
Saving predictions to: ./Result/a3/Latin16746/predictions

=== Starting Testing ===
Dataset: UDIADS_BIB
Model: Hybrid2
Manuscript: Latin16746
Save predictions: True

Starting inference on UDIADS_BIB dataset
Found 1620 patches for Latin16746
Using Test-Time Augmentation (TTA) for improved accuracy
CRF post-processing: Enabled
  - DenseCRF with spatial and color pairwise potentials
Processing: 009 (54 patches)
Applying CRF post-processing to 009
CRF post-processing completed for 009
Completed: 009
Processing: 020 (54 patches)
Applying CRF post-processing to 020
CRF post-processing completed for 020
Completed: 020
Processing: 022 (54 patches)
Applying CRF post-processing to 022
CRF post-processing completed for 022
Completed: 022
Processing: 029 (54 patches)
Applying CRF post-processing to 029
CRF post-processing completed for 029
Completed: 029
Processing: 035 (54 patches)
Applying CRF post-processing to 035
CRF post-processing completed for 035
Completed: 035
Processing: 048 (54 patches)
Applying CRF post-processing to 048
CRF post-processing completed for 048
Completed: 048
Processing: 069 (54 patches)
Applying CRF post-processing to 069
CRF post-processing completed for 069
Completed: 069
Processing: 082 (54 patches)
Applying CRF post-processing to 082
CRF post-processing completed for 082
Completed: 082
Processing: 088 (54 patches)
Applying CRF post-processing to 088
CRF post-processing completed for 088
Completed: 088
Processing: 089 (54 patches)
Applying CRF post-processing to 089
CRF post-processing completed for 089
Completed: 089
Processing: 091 (54 patches)
Applying CRF post-processing to 091
CRF post-processing completed for 091
Completed: 091
Processing: 100 (54 patches)
Applying CRF post-processing to 100
CRF post-processing completed for 100
Completed: 100
Processing: 106 (54 patches)
Applying CRF post-processing to 106
CRF post-processing completed for 106
Completed: 106
Processing: 117 (54 patches)
Applying CRF post-processing to 117
CRF post-processing completed for 117
Completed: 117
Processing: 123 (54 patches)
Applying CRF post-processing to 123
CRF post-processing completed for 123
Completed: 123
Processing: 125 (54 patches)
Applying CRF post-processing to 125
CRF post-processing completed for 125
Completed: 125
Processing: 130 (54 patches)
Applying CRF post-processing to 130
CRF post-processing completed for 130
Completed: 130
Processing: 133 (54 patches)
Applying CRF post-processing to 133
CRF post-processing completed for 133
Completed: 133
Processing: 137 (54 patches)
Applying CRF post-processing to 137
CRF post-processing completed for 137
Completed: 137
Processing: 146 (54 patches)
Applying CRF post-processing to 146
CRF post-processing completed for 146
Completed: 146
Processing: 166 (54 patches)
Applying CRF post-processing to 166
CRF post-processing completed for 166
Completed: 166
Processing: 184 (54 patches)
Applying CRF post-processing to 184
CRF post-processing completed for 184
Completed: 184
Processing: 215 (54 patches)
Applying CRF post-processing to 215
CRF post-processing completed for 215
Completed: 215
Processing: 237 (54 patches)
Applying CRF post-processing to 237
CRF post-processing completed for 237
Completed: 237
Processing: 243 (54 patches)
Applying CRF post-processing to 243
CRF post-processing completed for 243
Completed: 243
Processing: 255 (54 patches)
Applying CRF post-processing to 255
CRF post-processing completed for 255
Completed: 255
Processing: 258 (54 patches)
Applying CRF post-processing to 258
CRF post-processing completed for 258
Completed: 258
Processing: 284 (54 patches)
Applying CRF post-processing to 284
CRF post-processing completed for 284
Completed: 284
Processing: 325 (54 patches)
Applying CRF post-processing to 325
CRF post-processing completed for 325
Completed: 325
Processing: 357 (54 patches)
Applying CRF post-processing to 357
CRF post-processing completed for 357
Completed: 357

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9855, Recall=0.9981, F1=0.9918, IoU=0.9836
Paratext       : Precision=0.9143, Recall=0.6691, F1=0.7727, IoU=0.6296
Decoration     : Precision=0.9923, Recall=0.9100, F1=0.9493, IoU=0.9036
Main Text      : Precision=0.9718, Recall=0.8971, F1=0.9329, IoU=0.8743
Title          : Precision=0.8719, Recall=0.7099, F1=0.7826, IoU=0.6428
Chapter Headings: Precision=0.9662, Recall=0.7812, F1=0.8639, IoU=0.7604

Mean metrics:
----------------------------------------
Mean Precision: 0.9503
Mean Recall: 0.8275
Mean F1-Score: 0.8822
Mean IoU: 0.7991

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9855, Recall=0.9981, F1=0.9918, IoU=0.9836
Paratext       : Precision=0.9143, Recall=0.6691, F1=0.7727, IoU=0.6296
Decoration     : Precision=0.9923, Recall=0.9100, F1=0.9493, IoU=0.9036
Main Text      : Precision=0.9718, Recall=0.8971, F1=0.9329, IoU=0.8743
Title          : Precision=0.8719, Recall=0.7099, F1=0.7826, IoU=0.6428
Chapter Headings: Precision=0.9662, Recall=0.7812, F1=0.8639, IoU=0.7604

Mean metrics:
----------------------------------------
Mean Precision: 0.9503
Mean Recall: 0.8275
Mean F1-Score: 0.8822
Mean IoU: 0.7991
Inference completed on 30 images

=== TESTING COMPLETED SUCCESSFULLY ===
Results saved to: ./Result/a3/Latin16746/predictions
==================================================

Calculating average metrics...
Looking for metrics files in: ./Result/a3
  ‚úó Metrics file not found: ./Result/a3/metrics_Latin2.json
  ‚úó Metrics file not found: ./Result/a3/metrics_Latin14396.json
  ‚úì Found metrics for Latin16746
  ‚úó Metrics file not found: ./Result/a3/metrics_Syr341.json

================================================================================
AVERAGE METRICS ACROSS 1 MANUSCRIPT(S)
================================================================================
Manuscripts: Latin16746
Missing: Latin2, Latin14396, Syr341
--------------------------------------------------------------------------------
Mean Precision: 0.9503
Mean Recall:    0.8275
Mean F1-Score:  0.8822
Mean IoU:       0.7991
================================================================================

========================================================================
Training Hybrid2 Baseline Model with Smart Skip Connections and Multi-Scale Aggregation and Deep Supervision: Syr341
========================================================================
Dataset: U-DIADS-Bib-MS_patched
Architecture: Swin Transformer Encoder ‚Üí 2 Swin Blocks Bottleneck ‚Üí Simple CNN Decoder
Decoder: Simple Decoder (EfficientNet-b4 channel configuration)

Components Enabled:
  ‚úì Swin Encoder (4 stages: 96‚Üí192‚Üí384‚Üí768 dim)
  ‚úì Bottleneck: 2 Swin Transformer blocks (768 dim, 24 heads)
  ‚úì Simple CNN Decoder (channels: [256, 128, 64, 32])
  ‚úì Smart Skip Connections
  ‚úì Multi-Scale Aggregation
  ‚úì Deep Supervision
  ‚úì Positional Embeddings (default: enabled)
  ‚úì GroupNorm (default normalization)

Components Disabled (baseline):
  ‚úó CBAM Attention
  ‚úó Cross-Attention Bottleneck
  ‚úó BatchNorm
========================================================================
All arguments validated successfully!
Setting random seed to 1234 for reproducible training...
Setting up U-DIADS-Bib dataset...
Detected Syriaque341 manuscript: using 5 classes (no Chapter Headings)
Looking for images in: ../../U-DIADS-Bib-MS_patched/Syr341/Image/training
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Syr341/mask/training_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
Looking for images in: ../../U-DIADS-Bib-MS_patched/Syr341/Image/validation
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Syr341/mask/validation_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder
================================================================================
================================================================================
üöÄ SIMPLE DECODER (Flag-Controlled Enhancements)
================================================================================
  ‚Ä¢ EfficientNet Variant: b4
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Enhancement Flags:
  ‚Ä¢ Deep Supervision: True
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: True
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: True
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Model moved to CUDA
Model created successfully with 5 classes
DEBUG: args.output_dir = ./Result/a3/Syr341

=== Starting Training ===
Dataset: UDIADS_BIB
Model: Hybrid2
Batch size: 4
Max epochs: 300
Learning rate: 0.0001


================================================================================
TRAINING CONFIGURATION
================================================================================
Dataset: UDIADS_BIB
Model: Hybrid2
Batch Size: 4
Max Epochs: 300
Learning Rate: 0.0001
Number of Classes: 5
Output Directory: ./Result/a3/Syr341
Early Stopping Patience: 150 epochs
================================================================================

üìä Dataset Statistics:
   - Training samples: 540
   - Validation samples: 540
   - Batch size: 4
   - Steps per epoch: 135


================================================================================
COMPUTING CLASS WEIGHTS
================================================================================
Raw ENS weights: [9.99999990e-05 1.00964968e-04 9.99999990e-05 9.99999990e-05
 1.03734323e-04]

Class Distribution:
Class                Pixels          Frequency       Weight         
-----------------------------------------------------------------
0                        22,747,305        83.9538%         0.9907
1                            46,502         0.1716%         1.0002
2                         1,252,058         4.6210%         0.9907
3                         3,015,934        11.1309%         0.9907
4                            33,241         0.1227%         1.0277

Total pixels: 27,095,040.0
Beta: 0.9999
Smoothing: 0.0
Weight range: [0.9907, 1.0277]
================================================================================
üìà Class weights computed with ENS method (smoothing=0.1)
   Final weights: [0.9906889 1.0002488 0.9906889 0.9906889 1.0276845]

‚úì Loss functions created: CE (weighted, label_smoothing=0.1), Focal (Œ≥=2.0), Dice
  üìä OneCycleLR: 135 steps/epoch √ó 300 epochs = 40500 total steps
üöÄ Hybrid2 Best Practice: Differential Learning Rates
  üìä Encoder LR:     0.000010 (10x smaller, 119 params)
  üìä Bottleneck LR:  0.000050 (5x smaller, 26 params)
  üìä Decoder LR:     0.000100 (base LR, 90 params)
  ‚öôÔ∏è  Scheduler: OneCycleLR (Peak: 10x, Warmup: 30%, Cosine)
  ‚öôÔ∏è  Weight decay: Encoder=1e-3, Bottleneck=5e-3, Decoder=1e-2

üîç Checking for checkpoint at: ./Result/a3/Syr341/best_model_latest.pth
   Absolute path: /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid/Result/a3/Syr341/best_model_latest.pth
   File exists: False

================================================================================
STARTING TRAINING
================================================================================
Early stopping patience: 150 epochs
Learning rate scheduler: OneCycleLR (better convergence for transformers)
================================================================================

EPOCH 1/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 1.1833
  ‚Ä¢ Validation Loss: 1.0173
  ‚Ä¢ Learning Rate: 0.000100
    ‚úì New best checkpoint saved! Val loss: 1.0173
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 2/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.9464
  ‚Ä¢ Validation Loss: 0.8976
  ‚Ä¢ Learning Rate: 0.000101
    ‚úì New best checkpoint saved! Val loss: 0.8976
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 3/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8866
  ‚Ä¢ Validation Loss: 0.8569
  ‚Ä¢ Learning Rate: 0.000102
    ‚úì New best checkpoint saved! Val loss: 0.8569
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 4/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8309
  ‚Ä¢ Validation Loss: 0.8347
  ‚Ä¢ Learning Rate: 0.000104
    ‚úì New best checkpoint saved! Val loss: 0.8347
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 5/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8171
  ‚Ä¢ Validation Loss: 0.8160
  ‚Ä¢ Learning Rate: 0.000107
    ‚úì New best checkpoint saved! Val loss: 0.8160
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 6/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7898
  ‚Ä¢ Validation Loss: 0.8044
  ‚Ä¢ Learning Rate: 0.000110
    ‚úì New best checkpoint saved! Val loss: 0.8044
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 7/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7796
  ‚Ä¢ Validation Loss: 0.8176
  ‚Ä¢ Learning Rate: 0.000113
    No improvement (current: 0.8176, best: 0.8044)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 8/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7637
  ‚Ä¢ Validation Loss: 0.8035
  ‚Ä¢ Learning Rate: 0.000117
    ‚úì New best checkpoint saved! Val loss: 0.8035
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 9/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7600
  ‚Ä¢ Validation Loss: 0.7913
  ‚Ä¢ Learning Rate: 0.000122
    ‚úì New best checkpoint saved! Val loss: 0.7913
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 10/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7479
  ‚Ä¢ Validation Loss: 0.8200
  ‚Ä¢ Learning Rate: 0.000127
    No improvement (current: 0.8200, best: 0.7913)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 11/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7561
  ‚Ä¢ Validation Loss: 0.7882
  ‚Ä¢ Learning Rate: 0.000133
    ‚úì New best checkpoint saved! Val loss: 0.7882
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 12/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7502
  ‚Ä¢ Validation Loss: 0.7874
  ‚Ä¢ Learning Rate: 0.000139
    ‚úì New best checkpoint saved! Val loss: 0.7874
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 13/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7440
  ‚Ä¢ Validation Loss: 0.7767
  ‚Ä¢ Learning Rate: 0.000146
    ‚úì New best checkpoint saved! Val loss: 0.7767
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 14/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7391
  ‚Ä¢ Validation Loss: 0.7784
  ‚Ä¢ Learning Rate: 0.000153
    No improvement (current: 0.7784, best: 0.7767)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 15/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7515
  ‚Ä¢ Validation Loss: 0.7850
  ‚Ä¢ Learning Rate: 0.000160
    No improvement (current: 0.7850, best: 0.7767)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 16/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7367
  ‚Ä¢ Validation Loss: 0.7820
  ‚Ä¢ Learning Rate: 0.000168
    No improvement (current: 0.7820, best: 0.7767)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 17/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7304
  ‚Ä¢ Validation Loss: 0.7834
  ‚Ä¢ Learning Rate: 0.000177
    No improvement (current: 0.7834, best: 0.7767)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 18/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7237
  ‚Ä¢ Validation Loss: 0.7711
  ‚Ä¢ Learning Rate: 0.000186
    ‚úì New best checkpoint saved! Val loss: 0.7711
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 19/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7280
  ‚Ä¢ Validation Loss: 0.7808
  ‚Ä¢ Learning Rate: 0.000195
    No improvement (current: 0.7808, best: 0.7711)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 20/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7277
  ‚Ä¢ Validation Loss: 0.7808
  ‚Ä¢ Learning Rate: 0.000205
    No improvement (current: 0.7808, best: 0.7711)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 21/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7399
  ‚Ä¢ Validation Loss: 0.7829
  ‚Ä¢ Learning Rate: 0.000216
    No improvement (current: 0.7829, best: 0.7711)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 22/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7394
  ‚Ä¢ Validation Loss: 0.7744
  ‚Ä¢ Learning Rate: 0.000226
    No improvement (current: 0.7744, best: 0.7711)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 23/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7237
  ‚Ä¢ Validation Loss: 0.8326
  ‚Ä¢ Learning Rate: 0.000237
    No improvement (current: 0.8326, best: 0.7711)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 24/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7460
  ‚Ä¢ Validation Loss: 0.7666
  ‚Ä¢ Learning Rate: 0.000249
    ‚úì New best checkpoint saved! Val loss: 0.7666
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 25/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7190
  ‚Ä¢ Validation Loss: 0.7678
  ‚Ä¢ Learning Rate: 0.000261
    No improvement (current: 0.7678, best: 0.7666)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 26/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7168
  ‚Ä¢ Validation Loss: 0.7670
  ‚Ä¢ Learning Rate: 0.000273
    No improvement (current: 0.7670, best: 0.7666)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 27/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7159
  ‚Ä¢ Validation Loss: 0.7758
  ‚Ä¢ Learning Rate: 0.000286
    No improvement (current: 0.7758, best: 0.7666)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 28/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7190
  ‚Ä¢ Validation Loss: 0.7766
  ‚Ä¢ Learning Rate: 0.000298
    No improvement (current: 0.7766, best: 0.7666)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 29/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7224
  ‚Ä¢ Validation Loss: 0.7698
  ‚Ä¢ Learning Rate: 0.000312
    No improvement (current: 0.7698, best: 0.7666)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 30/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7185
  ‚Ä¢ Validation Loss: 0.7715
  ‚Ä¢ Learning Rate: 0.000325
    No improvement (current: 0.7715, best: 0.7666)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 31/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7237
  ‚Ä¢ Validation Loss: 0.7728
  ‚Ä¢ Learning Rate: 0.000339
    No improvement (current: 0.7728, best: 0.7666)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 32/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7234
  ‚Ä¢ Validation Loss: 0.8126
  ‚Ä¢ Learning Rate: 0.000353
    No improvement (current: 0.8126, best: 0.7666)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 33/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7216
  ‚Ä¢ Validation Loss: 0.7713
  ‚Ä¢ Learning Rate: 0.000367
    No improvement (current: 0.7713, best: 0.7666)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 34/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7509
  ‚Ä¢ Validation Loss: 0.7716
  ‚Ä¢ Learning Rate: 0.000381
    No improvement (current: 0.7716, best: 0.7666)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 35/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7342
  ‚Ä¢ Validation Loss: 0.7795
  ‚Ä¢ Learning Rate: 0.000396
    No improvement (current: 0.7795, best: 0.7666)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 36/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7362
  ‚Ä¢ Validation Loss: 0.8049
  ‚Ä¢ Learning Rate: 0.000411
    No improvement (current: 0.8049, best: 0.7666)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 37/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7332
  ‚Ä¢ Validation Loss: 0.7638
  ‚Ä¢ Learning Rate: 0.000426
    ‚úì New best checkpoint saved! Val loss: 0.7638
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 38/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7305
  ‚Ä¢ Validation Loss: 0.7803
  ‚Ä¢ Learning Rate: 0.000441
    No improvement (current: 0.7803, best: 0.7638)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 39/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7182
  ‚Ä¢ Validation Loss: 0.7625
  ‚Ä¢ Learning Rate: 0.000456
    ‚úì New best checkpoint saved! Val loss: 0.7625
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 40/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7214
  ‚Ä¢ Validation Loss: 0.7838
  ‚Ä¢ Learning Rate: 0.000472
    No improvement (current: 0.7838, best: 0.7625)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 41/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7305
  ‚Ä¢ Validation Loss: 0.7752
  ‚Ä¢ Learning Rate: 0.000487
    No improvement (current: 0.7752, best: 0.7625)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 42/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7271
  ‚Ä¢ Validation Loss: 0.7724
  ‚Ä¢ Learning Rate: 0.000503
    No improvement (current: 0.7724, best: 0.7625)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 43/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7190
  ‚Ä¢ Validation Loss: 0.7670
  ‚Ä¢ Learning Rate: 0.000519
    No improvement (current: 0.7670, best: 0.7625)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 44/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7273
  ‚Ä¢ Validation Loss: 0.7824
  ‚Ä¢ Learning Rate: 0.000534
    No improvement (current: 0.7824, best: 0.7625)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 45/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7180
  ‚Ä¢ Validation Loss: 0.7792
  ‚Ä¢ Learning Rate: 0.000550
    No improvement (current: 0.7792, best: 0.7625)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 46/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7287
  ‚Ä¢ Validation Loss: 0.7633
  ‚Ä¢ Learning Rate: 0.000566
    No improvement (current: 0.7633, best: 0.7625)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 47/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7297
  ‚Ä¢ Validation Loss: 0.7794
  ‚Ä¢ Learning Rate: 0.000581
    No improvement (current: 0.7794, best: 0.7625)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 48/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7345
  ‚Ä¢ Validation Loss: 0.7740
  ‚Ä¢ Learning Rate: 0.000597
    No improvement (current: 0.7740, best: 0.7625)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 49/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7865
  ‚Ä¢ Validation Loss: 0.7738
  ‚Ä¢ Learning Rate: 0.000613
    No improvement (current: 0.7738, best: 0.7625)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 50/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7203
  ‚Ä¢ Validation Loss: 0.7711
  ‚Ä¢ Learning Rate: 0.000628
    No improvement (current: 0.7711, best: 0.7625)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 51/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7983
  ‚Ä¢ Validation Loss: 0.7697
  ‚Ä¢ Learning Rate: 0.000644
    No improvement (current: 0.7697, best: 0.7625)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 52/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7349
  ‚Ä¢ Validation Loss: 0.7846
  ‚Ä¢ Learning Rate: 0.000659
    No improvement (current: 0.7846, best: 0.7625)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 53/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7333
  ‚Ä¢ Validation Loss: 0.7984
  ‚Ä¢ Learning Rate: 0.000674
    No improvement (current: 0.7984, best: 0.7625)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 54/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7357
  ‚Ä¢ Validation Loss: 0.7632
  ‚Ä¢ Learning Rate: 0.000689
    No improvement (current: 0.7632, best: 0.7625)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 55/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7176
  ‚Ä¢ Validation Loss: 0.7702
  ‚Ä¢ Learning Rate: 0.000704
    No improvement (current: 0.7702, best: 0.7625)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 56/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7318
  ‚Ä¢ Validation Loss: 0.7832
  ‚Ä¢ Learning Rate: 0.000719
    No improvement (current: 0.7832, best: 0.7625)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 57/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7348
  ‚Ä¢ Validation Loss: 0.7741
  ‚Ä¢ Learning Rate: 0.000733
    No improvement (current: 0.7741, best: 0.7625)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 58/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7251
  ‚Ä¢ Validation Loss: 0.7729
  ‚Ä¢ Learning Rate: 0.000747
    No improvement (current: 0.7729, best: 0.7625)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 59/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7099
  ‚Ä¢ Validation Loss: 0.7665
  ‚Ä¢ Learning Rate: 0.000761
    No improvement (current: 0.7665, best: 0.7625)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 60/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7146
  ‚Ä¢ Validation Loss: 0.7609
  ‚Ä¢ Learning Rate: 0.000775
    ‚úì New best checkpoint saved! Val loss: 0.7609
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 61/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7414
  ‚Ä¢ Validation Loss: 0.7685
  ‚Ä¢ Learning Rate: 0.000789
    No improvement (current: 0.7685, best: 0.7609)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 62/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7178
  ‚Ä¢ Validation Loss: 0.8607
  ‚Ä¢ Learning Rate: 0.000802
    No improvement (current: 0.8607, best: 0.7609)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 63/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7369
  ‚Ä¢ Validation Loss: 0.7692
  ‚Ä¢ Learning Rate: 0.000815
    No improvement (current: 0.7692, best: 0.7609)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 64/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7190
  ‚Ä¢ Validation Loss: 0.7643
  ‚Ä¢ Learning Rate: 0.000827
    No improvement (current: 0.7643, best: 0.7609)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 65/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7014
  ‚Ä¢ Validation Loss: 0.7618
  ‚Ä¢ Learning Rate: 0.000839
    No improvement (current: 0.7618, best: 0.7609)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 66/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7184
  ‚Ä¢ Validation Loss: 0.7726
  ‚Ä¢ Learning Rate: 0.000851
    No improvement (current: 0.7726, best: 0.7609)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 67/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7305
  ‚Ä¢ Validation Loss: 0.7731
  ‚Ä¢ Learning Rate: 0.000863
    No improvement (current: 0.7731, best: 0.7609)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 68/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7087
  ‚Ä¢ Validation Loss: 0.7610
  ‚Ä¢ Learning Rate: 0.000874
    No improvement (current: 0.7610, best: 0.7609)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 69/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7423
  ‚Ä¢ Validation Loss: 0.7678
  ‚Ä¢ Learning Rate: 0.000884
    No improvement (current: 0.7678, best: 0.7609)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 70/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7433
  ‚Ä¢ Validation Loss: 0.7774
  ‚Ä¢ Learning Rate: 0.000895
    No improvement (current: 0.7774, best: 0.7609)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 71/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7180
  ‚Ä¢ Validation Loss: 0.7788
  ‚Ä¢ Learning Rate: 0.000905
    No improvement (current: 0.7788, best: 0.7609)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 72/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.8619
  ‚Ä¢ Validation Loss: 0.8014
  ‚Ä¢ Learning Rate: 0.000914
    No improvement (current: 0.8014, best: 0.7609)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 73/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7586
  ‚Ä¢ Validation Loss: 0.7810
  ‚Ä¢ Learning Rate: 0.000923
    No improvement (current: 0.7810, best: 0.7609)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 74/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7289
  ‚Ä¢ Validation Loss: 0.7685
  ‚Ä¢ Learning Rate: 0.000932
    No improvement (current: 0.7685, best: 0.7609)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 75/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7135
  ‚Ä¢ Validation Loss: 0.7645
  ‚Ä¢ Learning Rate: 0.000940
    No improvement (current: 0.7645, best: 0.7609)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 76/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7286
  ‚Ä¢ Validation Loss: 0.7687
  ‚Ä¢ Learning Rate: 0.000947
    No improvement (current: 0.7687, best: 0.7609)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 77/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7100
  ‚Ä¢ Validation Loss: 0.7796
  ‚Ä¢ Learning Rate: 0.000955
    No improvement (current: 0.7796, best: 0.7609)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 78/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7231
  ‚Ä¢ Validation Loss: 0.7621
  ‚Ä¢ Learning Rate: 0.000961
    No improvement (current: 0.7621, best: 0.7609)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 79/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7165
  ‚Ä¢ Validation Loss: 0.7624
  ‚Ä¢ Learning Rate: 0.000967
    No improvement (current: 0.7624, best: 0.7609)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 80/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7283
  ‚Ä¢ Validation Loss: 0.7657
  ‚Ä¢ Learning Rate: 0.000973
    No improvement (current: 0.7657, best: 0.7609)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 81/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7079
  ‚Ä¢ Validation Loss: 0.7652
  ‚Ä¢ Learning Rate: 0.000978
    No improvement (current: 0.7652, best: 0.7609)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 82/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7145
  ‚Ä¢ Validation Loss: 0.7702
  ‚Ä¢ Learning Rate: 0.000983
    No improvement (current: 0.7702, best: 0.7609)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 83/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7153
  ‚Ä¢ Validation Loss: 0.7662
  ‚Ä¢ Learning Rate: 0.000987
    No improvement (current: 0.7662, best: 0.7609)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 84/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7251
  ‚Ä¢ Validation Loss: 0.7623
  ‚Ä¢ Learning Rate: 0.000990
    No improvement (current: 0.7623, best: 0.7609)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 85/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7273
  ‚Ä¢ Validation Loss: 0.7696
  ‚Ä¢ Learning Rate: 0.000993
    No improvement (current: 0.7696, best: 0.7609)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 86/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7044
  ‚Ä¢ Validation Loss: 0.7955
  ‚Ä¢ Learning Rate: 0.000996
    No improvement (current: 0.7955, best: 0.7609)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 87/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7072
  ‚Ä¢ Validation Loss: 0.7754
  ‚Ä¢ Learning Rate: 0.000998
    No improvement (current: 0.7754, best: 0.7609)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 88/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7083
  ‚Ä¢ Validation Loss: 0.7594
  ‚Ä¢ Learning Rate: 0.000999
    ‚úì New best checkpoint saved! Val loss: 0.7594
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 89/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6894
  ‚Ä¢ Validation Loss: 0.7580
  ‚Ä¢ Learning Rate: 0.001000
    ‚úì New best checkpoint saved! Val loss: 0.7580
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 90/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6951
  ‚Ä¢ Validation Loss: 0.8450
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.8450, best: 0.7580)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 91/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7053
  ‚Ä¢ Validation Loss: 0.7582
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.7582, best: 0.7580)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 92/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6979
  ‚Ä¢ Validation Loss: 0.7613
  ‚Ä¢ Learning Rate: 0.001000
    No improvement (current: 0.7613, best: 0.7580)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 93/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6922
  ‚Ä¢ Validation Loss: 0.7583
  ‚Ä¢ Learning Rate: 0.000999
    No improvement (current: 0.7583, best: 0.7580)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 94/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6892
  ‚Ä¢ Validation Loss: 0.7577
  ‚Ä¢ Learning Rate: 0.000999
    ‚úì New best checkpoint saved! Val loss: 0.7577
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 95/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6925
  ‚Ä¢ Validation Loss: 0.7541
  ‚Ä¢ Learning Rate: 0.000999
    ‚úì New best checkpoint saved! Val loss: 0.7541
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 96/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6944
  ‚Ä¢ Validation Loss: 0.7607
  ‚Ä¢ Learning Rate: 0.000998
    No improvement (current: 0.7607, best: 0.7541)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 97/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6836
  ‚Ä¢ Validation Loss: 0.7513
  ‚Ä¢ Learning Rate: 0.000997
    ‚úì New best checkpoint saved! Val loss: 0.7513
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 98/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7026
  ‚Ä¢ Validation Loss: 0.7558
  ‚Ä¢ Learning Rate: 0.000996
    No improvement (current: 0.7558, best: 0.7513)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 99/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6911
  ‚Ä¢ Validation Loss: 0.7554
  ‚Ä¢ Learning Rate: 0.000995
    No improvement (current: 0.7554, best: 0.7513)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 100/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6866
  ‚Ä¢ Validation Loss: 0.7575
  ‚Ä¢ Learning Rate: 0.000994
   üíæ Periodic checkpoint saved: epoch_100.pth
    No improvement (current: 0.7575, best: 0.7513)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 101/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6979
  ‚Ä¢ Validation Loss: 0.7713
  ‚Ä¢ Learning Rate: 0.000993
    No improvement (current: 0.7713, best: 0.7513)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 102/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6883
  ‚Ä¢ Validation Loss: 0.7546
  ‚Ä¢ Learning Rate: 0.000992
    No improvement (current: 0.7546, best: 0.7513)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 103/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6899
  ‚Ä¢ Validation Loss: 0.7544
  ‚Ä¢ Learning Rate: 0.000991
    No improvement (current: 0.7544, best: 0.7513)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 104/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6895
  ‚Ä¢ Validation Loss: 0.7690
  ‚Ä¢ Learning Rate: 0.000989
    No improvement (current: 0.7690, best: 0.7513)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 105/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6852
  ‚Ä¢ Validation Loss: 0.7560
  ‚Ä¢ Learning Rate: 0.000987
    No improvement (current: 0.7560, best: 0.7513)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 106/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6902
  ‚Ä¢ Validation Loss: 0.7586
  ‚Ä¢ Learning Rate: 0.000986
    No improvement (current: 0.7586, best: 0.7513)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 107/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6827
  ‚Ä¢ Validation Loss: 0.7545
  ‚Ä¢ Learning Rate: 0.000984
    No improvement (current: 0.7545, best: 0.7513)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 108/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6968
  ‚Ä¢ Validation Loss: 0.7723
  ‚Ä¢ Learning Rate: 0.000982
    No improvement (current: 0.7723, best: 0.7513)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 109/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6927
  ‚Ä¢ Validation Loss: 0.7607
  ‚Ä¢ Learning Rate: 0.000980
    No improvement (current: 0.7607, best: 0.7513)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 110/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6800
  ‚Ä¢ Validation Loss: 0.7586
  ‚Ä¢ Learning Rate: 0.000978
    No improvement (current: 0.7586, best: 0.7513)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 111/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6820
  ‚Ä¢ Validation Loss: 0.7554
  ‚Ä¢ Learning Rate: 0.000976
    No improvement (current: 0.7554, best: 0.7513)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 112/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6803
  ‚Ä¢ Validation Loss: 0.7615
  ‚Ä¢ Learning Rate: 0.000973
    No improvement (current: 0.7615, best: 0.7513)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 113/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7118
  ‚Ä¢ Validation Loss: 0.7530
  ‚Ä¢ Learning Rate: 0.000971
    No improvement (current: 0.7530, best: 0.7513)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 114/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.7019
  ‚Ä¢ Validation Loss: 0.7664
  ‚Ä¢ Learning Rate: 0.000968
    No improvement (current: 0.7664, best: 0.7513)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 115/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6851
  ‚Ä¢ Validation Loss: 0.7589
  ‚Ä¢ Learning Rate: 0.000965
    No improvement (current: 0.7589, best: 0.7513)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 116/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6817
  ‚Ä¢ Validation Loss: 0.7592
  ‚Ä¢ Learning Rate: 0.000963
    No improvement (current: 0.7592, best: 0.7513)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 117/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6765
  ‚Ä¢ Validation Loss: 0.7659
  ‚Ä¢ Learning Rate: 0.000960
    No improvement (current: 0.7659, best: 0.7513)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 118/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6818
  ‚Ä¢ Validation Loss: 0.7536
  ‚Ä¢ Learning Rate: 0.000957
    No improvement (current: 0.7536, best: 0.7513)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 119/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6773
  ‚Ä¢ Validation Loss: 0.7679
  ‚Ä¢ Learning Rate: 0.000954
    No improvement (current: 0.7679, best: 0.7513)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 120/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6728
  ‚Ä¢ Validation Loss: 0.7574
  ‚Ä¢ Learning Rate: 0.000951
    No improvement (current: 0.7574, best: 0.7513)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 121/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6793
  ‚Ä¢ Validation Loss: 0.7543
  ‚Ä¢ Learning Rate: 0.000947
    No improvement (current: 0.7543, best: 0.7513)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 122/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6737
  ‚Ä¢ Validation Loss: 0.7562
  ‚Ä¢ Learning Rate: 0.000944
    No improvement (current: 0.7562, best: 0.7513)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 123/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6745
  ‚Ä¢ Validation Loss: 0.7545
  ‚Ä¢ Learning Rate: 0.000940
    No improvement (current: 0.7545, best: 0.7513)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 124/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6907
  ‚Ä¢ Validation Loss: 0.7634
  ‚Ä¢ Learning Rate: 0.000937
    No improvement (current: 0.7634, best: 0.7513)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 125/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6823
  ‚Ä¢ Validation Loss: 0.7515
  ‚Ä¢ Learning Rate: 0.000933
    No improvement (current: 0.7515, best: 0.7513)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 126/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6761
  ‚Ä¢ Validation Loss: 0.7524
  ‚Ä¢ Learning Rate: 0.000929
    No improvement (current: 0.7524, best: 0.7513)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 127/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6660
  ‚Ä¢ Validation Loss: 0.7535
  ‚Ä¢ Learning Rate: 0.000925
    No improvement (current: 0.7535, best: 0.7513)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 128/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6702
  ‚Ä¢ Validation Loss: 0.7574
  ‚Ä¢ Learning Rate: 0.000921
    No improvement (current: 0.7574, best: 0.7513)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 129/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6684
  ‚Ä¢ Validation Loss: 0.7533
  ‚Ä¢ Learning Rate: 0.000917
    No improvement (current: 0.7533, best: 0.7513)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 130/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6743
  ‚Ä¢ Validation Loss: 0.7533
  ‚Ä¢ Learning Rate: 0.000913
    No improvement (current: 0.7533, best: 0.7513)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 131/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6732
  ‚Ä¢ Validation Loss: 0.7512
  ‚Ä¢ Learning Rate: 0.000909
    ‚úì New best checkpoint saved! Val loss: 0.7512
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 132/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6683
  ‚Ä¢ Validation Loss: 0.7609
  ‚Ä¢ Learning Rate: 0.000905
    No improvement (current: 0.7609, best: 0.7512)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 133/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6715
  ‚Ä¢ Validation Loss: 0.7505
  ‚Ä¢ Learning Rate: 0.000900
    ‚úì New best checkpoint saved! Val loss: 0.7505
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 134/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6683
  ‚Ä¢ Validation Loss: 0.7506
  ‚Ä¢ Learning Rate: 0.000896
    No improvement (current: 0.7506, best: 0.7505)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 135/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6718
  ‚Ä¢ Validation Loss: 0.7648
  ‚Ä¢ Learning Rate: 0.000891
    No improvement (current: 0.7648, best: 0.7505)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 136/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6794
  ‚Ä¢ Validation Loss: 0.7589
  ‚Ä¢ Learning Rate: 0.000886
    No improvement (current: 0.7589, best: 0.7505)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 137/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6679
  ‚Ä¢ Validation Loss: 0.7518
  ‚Ä¢ Learning Rate: 0.000881
    No improvement (current: 0.7518, best: 0.7505)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 138/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6587
  ‚Ä¢ Validation Loss: 0.7548
  ‚Ä¢ Learning Rate: 0.000877
    No improvement (current: 0.7548, best: 0.7505)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 139/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6697
  ‚Ä¢ Validation Loss: 0.7636
  ‚Ä¢ Learning Rate: 0.000872
    No improvement (current: 0.7636, best: 0.7505)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 140/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6780
  ‚Ä¢ Validation Loss: 0.7608
  ‚Ä¢ Learning Rate: 0.000867
    No improvement (current: 0.7608, best: 0.7505)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 141/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6807
  ‚Ä¢ Validation Loss: 0.7724
  ‚Ä¢ Learning Rate: 0.000861
    No improvement (current: 0.7724, best: 0.7505)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 142/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6774
  ‚Ä¢ Validation Loss: 0.7567
  ‚Ä¢ Learning Rate: 0.000856
    No improvement (current: 0.7567, best: 0.7505)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 143/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6643
  ‚Ä¢ Validation Loss: 0.7485
  ‚Ä¢ Learning Rate: 0.000851
    ‚úì New best checkpoint saved! Val loss: 0.7485
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 144/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6639
  ‚Ä¢ Validation Loss: 0.7532
  ‚Ä¢ Learning Rate: 0.000846
    No improvement (current: 0.7532, best: 0.7485)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 145/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6598
  ‚Ä¢ Validation Loss: 0.7485
  ‚Ä¢ Learning Rate: 0.000840
    No improvement (current: 0.7485, best: 0.7485)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 146/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6672
  ‚Ä¢ Validation Loss: 0.7540
  ‚Ä¢ Learning Rate: 0.000835
    No improvement (current: 0.7540, best: 0.7485)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 147/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6622
  ‚Ä¢ Validation Loss: 0.7538
  ‚Ä¢ Learning Rate: 0.000829
    No improvement (current: 0.7538, best: 0.7485)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 148/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6632
  ‚Ä¢ Validation Loss: 0.7575
  ‚Ä¢ Learning Rate: 0.000823
    No improvement (current: 0.7575, best: 0.7485)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 149/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6625
  ‚Ä¢ Validation Loss: 0.7495
  ‚Ä¢ Learning Rate: 0.000818
    No improvement (current: 0.7495, best: 0.7485)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 150/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6669
  ‚Ä¢ Validation Loss: 0.7491
  ‚Ä¢ Learning Rate: 0.000812
    No improvement (current: 0.7491, best: 0.7485)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 151/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6707
  ‚Ä¢ Validation Loss: 0.7545
  ‚Ä¢ Learning Rate: 0.000806
    No improvement (current: 0.7545, best: 0.7485)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 152/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6627
  ‚Ä¢ Validation Loss: 0.7557
  ‚Ä¢ Learning Rate: 0.000800
    No improvement (current: 0.7557, best: 0.7485)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 153/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6720
  ‚Ä¢ Validation Loss: 0.7906
  ‚Ä¢ Learning Rate: 0.000794
    No improvement (current: 0.7906, best: 0.7485)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 154/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6734
  ‚Ä¢ Validation Loss: 0.7574
  ‚Ä¢ Learning Rate: 0.000788
    No improvement (current: 0.7574, best: 0.7485)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 155/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6707
  ‚Ä¢ Validation Loss: 0.7554
  ‚Ä¢ Learning Rate: 0.000782
    No improvement (current: 0.7554, best: 0.7485)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 156/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6661
  ‚Ä¢ Validation Loss: 0.7559
  ‚Ä¢ Learning Rate: 0.000776
    No improvement (current: 0.7559, best: 0.7485)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 157/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6640
  ‚Ä¢ Validation Loss: 0.7570
  ‚Ä¢ Learning Rate: 0.000769
    No improvement (current: 0.7570, best: 0.7485)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 158/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6640
  ‚Ä¢ Validation Loss: 0.7543
  ‚Ä¢ Learning Rate: 0.000763
    No improvement (current: 0.7543, best: 0.7485)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 159/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6636
  ‚Ä¢ Validation Loss: 0.7514
  ‚Ä¢ Learning Rate: 0.000757
    No improvement (current: 0.7514, best: 0.7485)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 160/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6644
  ‚Ä¢ Validation Loss: 0.7581
  ‚Ä¢ Learning Rate: 0.000750
    No improvement (current: 0.7581, best: 0.7485)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 161/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6564
  ‚Ä¢ Validation Loss: 0.7503
  ‚Ä¢ Learning Rate: 0.000744
    No improvement (current: 0.7503, best: 0.7485)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 162/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6577
  ‚Ä¢ Validation Loss: 0.7470
  ‚Ä¢ Learning Rate: 0.000737
    ‚úì New best checkpoint saved! Val loss: 0.7470
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 163/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6571
  ‚Ä¢ Validation Loss: 0.7499
  ‚Ä¢ Learning Rate: 0.000731
    No improvement (current: 0.7499, best: 0.7470)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 164/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6581
  ‚Ä¢ Validation Loss: 0.7529
  ‚Ä¢ Learning Rate: 0.000724
    No improvement (current: 0.7529, best: 0.7470)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 165/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6529
  ‚Ä¢ Validation Loss: 0.7526
  ‚Ä¢ Learning Rate: 0.000717
    No improvement (current: 0.7526, best: 0.7470)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 166/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6507
  ‚Ä¢ Validation Loss: 0.7513
  ‚Ä¢ Learning Rate: 0.000710
    No improvement (current: 0.7513, best: 0.7470)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 167/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6559
  ‚Ä¢ Validation Loss: 0.7555
  ‚Ä¢ Learning Rate: 0.000704
    No improvement (current: 0.7555, best: 0.7470)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 168/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6603
  ‚Ä¢ Validation Loss: 0.7479
  ‚Ä¢ Learning Rate: 0.000697
    No improvement (current: 0.7479, best: 0.7470)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 169/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6574
  ‚Ä¢ Validation Loss: 0.7560
  ‚Ä¢ Learning Rate: 0.000690
    No improvement (current: 0.7560, best: 0.7470)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 170/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6674
  ‚Ä¢ Validation Loss: 0.7508
  ‚Ä¢ Learning Rate: 0.000683
    No improvement (current: 0.7508, best: 0.7470)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 171/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6594
  ‚Ä¢ Validation Loss: 0.7549
  ‚Ä¢ Learning Rate: 0.000676
    No improvement (current: 0.7549, best: 0.7470)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 172/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6609
  ‚Ä¢ Validation Loss: 0.7481
  ‚Ä¢ Learning Rate: 0.000669
    No improvement (current: 0.7481, best: 0.7470)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 173/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6576
  ‚Ä¢ Validation Loss: 0.7532
  ‚Ä¢ Learning Rate: 0.000662
    No improvement (current: 0.7532, best: 0.7470)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 174/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6558
  ‚Ä¢ Validation Loss: 0.7487
  ‚Ä¢ Learning Rate: 0.000655
    No improvement (current: 0.7487, best: 0.7470)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 175/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6612
  ‚Ä¢ Validation Loss: 0.7484
  ‚Ä¢ Learning Rate: 0.000648
    No improvement (current: 0.7484, best: 0.7470)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 176/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6503
  ‚Ä¢ Validation Loss: 0.7485
  ‚Ä¢ Learning Rate: 0.000641
    No improvement (current: 0.7485, best: 0.7470)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 177/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6567
  ‚Ä¢ Validation Loss: 0.7475
  ‚Ä¢ Learning Rate: 0.000633
    No improvement (current: 0.7475, best: 0.7470)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 178/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6595
  ‚Ä¢ Validation Loss: 0.7483
  ‚Ä¢ Learning Rate: 0.000626
    No improvement (current: 0.7483, best: 0.7470)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 179/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6507
  ‚Ä¢ Validation Loss: 0.7500
  ‚Ä¢ Learning Rate: 0.000619
    No improvement (current: 0.7500, best: 0.7470)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 180/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6536
  ‚Ä¢ Validation Loss: 0.7481
  ‚Ä¢ Learning Rate: 0.000612
    No improvement (current: 0.7481, best: 0.7470)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 181/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6505
  ‚Ä¢ Validation Loss: 0.7495
  ‚Ä¢ Learning Rate: 0.000604
    No improvement (current: 0.7495, best: 0.7470)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 182/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6634
  ‚Ä¢ Validation Loss: 0.7515
  ‚Ä¢ Learning Rate: 0.000597
    No improvement (current: 0.7515, best: 0.7470)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 183/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6504
  ‚Ä¢ Validation Loss: 0.7504
  ‚Ä¢ Learning Rate: 0.000590
    No improvement (current: 0.7504, best: 0.7470)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 184/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6625
  ‚Ä¢ Validation Loss: 0.7529
  ‚Ä¢ Learning Rate: 0.000582
    No improvement (current: 0.7529, best: 0.7470)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 185/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6600
  ‚Ä¢ Validation Loss: 0.7489
  ‚Ä¢ Learning Rate: 0.000575
    No improvement (current: 0.7489, best: 0.7470)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 186/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6536
  ‚Ä¢ Validation Loss: 0.7556
  ‚Ä¢ Learning Rate: 0.000567
    No improvement (current: 0.7556, best: 0.7470)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 187/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6589
  ‚Ä¢ Validation Loss: 0.7466
  ‚Ä¢ Learning Rate: 0.000560
    ‚úì New best checkpoint saved! Val loss: 0.7466
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 188/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6514
  ‚Ä¢ Validation Loss: 0.7528
  ‚Ä¢ Learning Rate: 0.000553
    No improvement (current: 0.7528, best: 0.7466)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 189/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6576
  ‚Ä¢ Validation Loss: 0.7473
  ‚Ä¢ Learning Rate: 0.000545
    No improvement (current: 0.7473, best: 0.7466)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 190/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6547
  ‚Ä¢ Validation Loss: 0.7502
  ‚Ä¢ Learning Rate: 0.000538
    No improvement (current: 0.7502, best: 0.7466)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 191/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6607
  ‚Ä¢ Validation Loss: 0.7505
  ‚Ä¢ Learning Rate: 0.000530
    No improvement (current: 0.7505, best: 0.7466)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 192/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6559
  ‚Ä¢ Validation Loss: 0.7553
  ‚Ä¢ Learning Rate: 0.000523
    No improvement (current: 0.7553, best: 0.7466)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 193/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6527
  ‚Ä¢ Validation Loss: 0.7513
  ‚Ä¢ Learning Rate: 0.000515
    No improvement (current: 0.7513, best: 0.7466)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 194/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6482
  ‚Ä¢ Validation Loss: 0.7499
  ‚Ä¢ Learning Rate: 0.000508
    No improvement (current: 0.7499, best: 0.7466)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 195/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6542
  ‚Ä¢ Validation Loss: 0.7535
  ‚Ä¢ Learning Rate: 0.000500
    No improvement (current: 0.7535, best: 0.7466)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 196/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6557
  ‚Ä¢ Validation Loss: 0.7507
  ‚Ä¢ Learning Rate: 0.000493
    No improvement (current: 0.7507, best: 0.7466)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 197/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6486
  ‚Ä¢ Validation Loss: 0.7512
  ‚Ä¢ Learning Rate: 0.000486
    No improvement (current: 0.7512, best: 0.7466)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 198/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6614
  ‚Ä¢ Validation Loss: 0.7645
  ‚Ä¢ Learning Rate: 0.000478
    No improvement (current: 0.7645, best: 0.7466)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 199/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6609
  ‚Ä¢ Validation Loss: 0.7528
  ‚Ä¢ Learning Rate: 0.000471
    No improvement (current: 0.7528, best: 0.7466)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 200/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6533
  ‚Ä¢ Validation Loss: 0.7528
  ‚Ä¢ Learning Rate: 0.000463
   üíæ Periodic checkpoint saved: epoch_200.pth
    No improvement (current: 0.7528, best: 0.7466)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 201/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6552
  ‚Ä¢ Validation Loss: 0.7523
  ‚Ä¢ Learning Rate: 0.000456
    No improvement (current: 0.7523, best: 0.7466)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 202/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6502
  ‚Ä¢ Validation Loss: 0.7510
  ‚Ä¢ Learning Rate: 0.000448
    No improvement (current: 0.7510, best: 0.7466)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 203/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6499
  ‚Ä¢ Validation Loss: 0.7529
  ‚Ä¢ Learning Rate: 0.000441
    No improvement (current: 0.7529, best: 0.7466)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 204/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6464
  ‚Ä¢ Validation Loss: 0.7513
  ‚Ä¢ Learning Rate: 0.000433
    No improvement (current: 0.7513, best: 0.7466)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 205/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6500
  ‚Ä¢ Validation Loss: 0.7518
  ‚Ä¢ Learning Rate: 0.000426
    No improvement (current: 0.7518, best: 0.7466)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 206/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6553
  ‚Ä¢ Validation Loss: 0.7523
  ‚Ä¢ Learning Rate: 0.000419
    No improvement (current: 0.7523, best: 0.7466)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 207/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6550
  ‚Ä¢ Validation Loss: 0.7537
  ‚Ä¢ Learning Rate: 0.000411
    No improvement (current: 0.7537, best: 0.7466)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 208/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6513
  ‚Ä¢ Validation Loss: 0.7521
  ‚Ä¢ Learning Rate: 0.000404
    No improvement (current: 0.7521, best: 0.7466)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 209/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6551
  ‚Ä¢ Validation Loss: 0.7539
  ‚Ä¢ Learning Rate: 0.000397
    No improvement (current: 0.7539, best: 0.7466)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 210/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6486
  ‚Ä¢ Validation Loss: 0.7506
  ‚Ä¢ Learning Rate: 0.000389
    No improvement (current: 0.7506, best: 0.7466)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 211/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6549
  ‚Ä¢ Validation Loss: 0.7532
  ‚Ä¢ Learning Rate: 0.000382
    No improvement (current: 0.7532, best: 0.7466)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 212/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6523
  ‚Ä¢ Validation Loss: 0.7523
  ‚Ä¢ Learning Rate: 0.000375
    No improvement (current: 0.7523, best: 0.7466)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 213/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6575
  ‚Ä¢ Validation Loss: 0.7529
  ‚Ä¢ Learning Rate: 0.000368
    No improvement (current: 0.7529, best: 0.7466)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 214/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6460
  ‚Ä¢ Validation Loss: 0.7518
  ‚Ä¢ Learning Rate: 0.000360
    No improvement (current: 0.7518, best: 0.7466)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 215/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6525
  ‚Ä¢ Validation Loss: 0.7508
  ‚Ä¢ Learning Rate: 0.000353
    No improvement (current: 0.7508, best: 0.7466)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 216/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6521
  ‚Ä¢ Validation Loss: 0.7517
  ‚Ä¢ Learning Rate: 0.000346
    No improvement (current: 0.7517, best: 0.7466)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 217/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6524
  ‚Ä¢ Validation Loss: 0.7518
  ‚Ä¢ Learning Rate: 0.000339
    No improvement (current: 0.7518, best: 0.7466)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 218/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6509
  ‚Ä¢ Validation Loss: 0.7521
  ‚Ä¢ Learning Rate: 0.000332
    No improvement (current: 0.7521, best: 0.7466)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 219/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6560
  ‚Ä¢ Validation Loss: 0.7514
  ‚Ä¢ Learning Rate: 0.000325
    No improvement (current: 0.7514, best: 0.7466)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 220/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6515
  ‚Ä¢ Validation Loss: 0.7538
  ‚Ä¢ Learning Rate: 0.000318
    No improvement (current: 0.7538, best: 0.7466)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 221/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6457
  ‚Ä¢ Validation Loss: 0.7509
  ‚Ä¢ Learning Rate: 0.000311
    No improvement (current: 0.7509, best: 0.7466)
    ‚ö† No improvement for 34 epochs (patience: 150, remaining: 116)

EPOCH 222/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6503
  ‚Ä¢ Validation Loss: 0.7518
  ‚Ä¢ Learning Rate: 0.000304
    No improvement (current: 0.7518, best: 0.7466)
    ‚ö† No improvement for 35 epochs (patience: 150, remaining: 115)

EPOCH 223/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6513
  ‚Ä¢ Validation Loss: 0.7523
  ‚Ä¢ Learning Rate: 0.000297
    No improvement (current: 0.7523, best: 0.7466)
    ‚ö† No improvement for 36 epochs (patience: 150, remaining: 114)

EPOCH 224/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6423
  ‚Ä¢ Validation Loss: 0.7507
  ‚Ä¢ Learning Rate: 0.000290
    No improvement (current: 0.7507, best: 0.7466)
    ‚ö† No improvement for 37 epochs (patience: 150, remaining: 113)

EPOCH 225/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6484
  ‚Ä¢ Validation Loss: 0.7512
  ‚Ä¢ Learning Rate: 0.000284
    No improvement (current: 0.7512, best: 0.7466)
    ‚ö† No improvement for 38 epochs (patience: 150, remaining: 112)

EPOCH 226/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6492
  ‚Ä¢ Validation Loss: 0.7543
  ‚Ä¢ Learning Rate: 0.000277
    No improvement (current: 0.7543, best: 0.7466)
    ‚ö† No improvement for 39 epochs (patience: 150, remaining: 111)

EPOCH 227/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6571
  ‚Ä¢ Validation Loss: 0.7533
  ‚Ä¢ Learning Rate: 0.000270
    No improvement (current: 0.7533, best: 0.7466)
    ‚ö† No improvement for 40 epochs (patience: 150, remaining: 110)

EPOCH 228/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6454
  ‚Ä¢ Validation Loss: 0.7540
  ‚Ä¢ Learning Rate: 0.000264
    No improvement (current: 0.7540, best: 0.7466)
    ‚ö† No improvement for 41 epochs (patience: 150, remaining: 109)

EPOCH 229/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6475
  ‚Ä¢ Validation Loss: 0.7512
  ‚Ä¢ Learning Rate: 0.000257
    No improvement (current: 0.7512, best: 0.7466)
    ‚ö† No improvement for 42 epochs (patience: 150, remaining: 108)

EPOCH 230/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6493
  ‚Ä¢ Validation Loss: 0.7514
  ‚Ä¢ Learning Rate: 0.000251
    No improvement (current: 0.7514, best: 0.7466)
    ‚ö† No improvement for 43 epochs (patience: 150, remaining: 107)

EPOCH 231/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6519
  ‚Ä¢ Validation Loss: 0.7513
  ‚Ä¢ Learning Rate: 0.000244
    No improvement (current: 0.7513, best: 0.7466)
    ‚ö† No improvement for 44 epochs (patience: 150, remaining: 106)

EPOCH 232/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6510
  ‚Ä¢ Validation Loss: 0.7512
  ‚Ä¢ Learning Rate: 0.000238
    No improvement (current: 0.7512, best: 0.7466)
    ‚ö† No improvement for 45 epochs (patience: 150, remaining: 105)

EPOCH 233/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6467
  ‚Ä¢ Validation Loss: 0.7510
  ‚Ä¢ Learning Rate: 0.000232
    No improvement (current: 0.7510, best: 0.7466)
    ‚ö† No improvement for 46 epochs (patience: 150, remaining: 104)

EPOCH 234/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6430
  ‚Ä¢ Validation Loss: 0.7502
  ‚Ä¢ Learning Rate: 0.000225
    No improvement (current: 0.7502, best: 0.7466)
    ‚ö† No improvement for 47 epochs (patience: 150, remaining: 103)

EPOCH 235/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6434
  ‚Ä¢ Validation Loss: 0.7534
  ‚Ä¢ Learning Rate: 0.000219
    No improvement (current: 0.7534, best: 0.7466)
    ‚ö† No improvement for 48 epochs (patience: 150, remaining: 102)

EPOCH 236/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6477
  ‚Ä¢ Validation Loss: 0.7529
  ‚Ä¢ Learning Rate: 0.000213
    No improvement (current: 0.7529, best: 0.7466)
    ‚ö† No improvement for 49 epochs (patience: 150, remaining: 101)

EPOCH 237/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6430
  ‚Ä¢ Validation Loss: 0.7509
  ‚Ä¢ Learning Rate: 0.000207
    No improvement (current: 0.7509, best: 0.7466)
    ‚ö† No improvement for 50 epochs (patience: 150, remaining: 100)

EPOCH 238/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6515
  ‚Ä¢ Validation Loss: 0.7526
  ‚Ä¢ Learning Rate: 0.000201
    No improvement (current: 0.7526, best: 0.7466)
    ‚ö† No improvement for 51 epochs (patience: 150, remaining: 99)

EPOCH 239/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6397
  ‚Ä¢ Validation Loss: 0.7538
  ‚Ä¢ Learning Rate: 0.000195
    No improvement (current: 0.7538, best: 0.7466)
    ‚ö† No improvement for 52 epochs (patience: 150, remaining: 98)

EPOCH 240/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6452
  ‚Ä¢ Validation Loss: 0.7533
  ‚Ä¢ Learning Rate: 0.000189
    No improvement (current: 0.7533, best: 0.7466)
    ‚ö† No improvement for 53 epochs (patience: 150, remaining: 97)

EPOCH 241/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6514
  ‚Ä¢ Validation Loss: 0.7521
  ‚Ä¢ Learning Rate: 0.000183
    No improvement (current: 0.7521, best: 0.7466)
    ‚ö† No improvement for 54 epochs (patience: 150, remaining: 96)

EPOCH 242/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6489
  ‚Ä¢ Validation Loss: 0.7536
  ‚Ä¢ Learning Rate: 0.000177
    No improvement (current: 0.7536, best: 0.7466)
    ‚ö† No improvement for 55 epochs (patience: 150, remaining: 95)

EPOCH 243/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6490
  ‚Ä¢ Validation Loss: 0.7534
  ‚Ä¢ Learning Rate: 0.000172
    No improvement (current: 0.7534, best: 0.7466)
    ‚ö† No improvement for 56 epochs (patience: 150, remaining: 94)

EPOCH 244/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6418
  ‚Ä¢ Validation Loss: 0.7542
  ‚Ä¢ Learning Rate: 0.000166
    No improvement (current: 0.7542, best: 0.7466)
    ‚ö† No improvement for 57 epochs (patience: 150, remaining: 93)

EPOCH 245/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6496
  ‚Ä¢ Validation Loss: 0.7516
  ‚Ä¢ Learning Rate: 0.000161
    No improvement (current: 0.7516, best: 0.7466)
    ‚ö† No improvement for 58 epochs (patience: 150, remaining: 92)

EPOCH 246/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6541
  ‚Ä¢ Validation Loss: 0.7528
  ‚Ä¢ Learning Rate: 0.000155
    No improvement (current: 0.7528, best: 0.7466)
    ‚ö† No improvement for 59 epochs (patience: 150, remaining: 91)

EPOCH 247/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6515
  ‚Ä¢ Validation Loss: 0.7523
  ‚Ä¢ Learning Rate: 0.000150
    No improvement (current: 0.7523, best: 0.7466)
    ‚ö† No improvement for 60 epochs (patience: 150, remaining: 90)

EPOCH 248/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6543
  ‚Ä¢ Validation Loss: 0.7536
  ‚Ä¢ Learning Rate: 0.000145
    No improvement (current: 0.7536, best: 0.7466)
    ‚ö† No improvement for 61 epochs (patience: 150, remaining: 89)

EPOCH 249/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6546
  ‚Ä¢ Validation Loss: 0.7519
  ‚Ä¢ Learning Rate: 0.000139
    No improvement (current: 0.7519, best: 0.7466)
    ‚ö† No improvement for 62 epochs (patience: 150, remaining: 88)

EPOCH 250/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6398
  ‚Ä¢ Validation Loss: 0.7528
  ‚Ä¢ Learning Rate: 0.000134
    No improvement (current: 0.7528, best: 0.7466)
    ‚ö† No improvement for 63 epochs (patience: 150, remaining: 87)

EPOCH 251/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6493
  ‚Ä¢ Validation Loss: 0.7532
  ‚Ä¢ Learning Rate: 0.000129
    No improvement (current: 0.7532, best: 0.7466)
    ‚ö† No improvement for 64 epochs (patience: 150, remaining: 86)

EPOCH 252/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6551
  ‚Ä¢ Validation Loss: 0.7528
  ‚Ä¢ Learning Rate: 0.000124
    No improvement (current: 0.7528, best: 0.7466)
    ‚ö† No improvement for 65 epochs (patience: 150, remaining: 85)

EPOCH 253/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6538
  ‚Ä¢ Validation Loss: 0.7536
  ‚Ä¢ Learning Rate: 0.000119
    No improvement (current: 0.7536, best: 0.7466)
    ‚ö† No improvement for 66 epochs (patience: 150, remaining: 84)

EPOCH 254/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6401
  ‚Ä¢ Validation Loss: 0.7539
  ‚Ä¢ Learning Rate: 0.000115
    No improvement (current: 0.7539, best: 0.7466)
    ‚ö† No improvement for 67 epochs (patience: 150, remaining: 83)

EPOCH 255/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6431
  ‚Ä¢ Validation Loss: 0.7524
  ‚Ä¢ Learning Rate: 0.000110
    No improvement (current: 0.7524, best: 0.7466)
    ‚ö† No improvement for 68 epochs (patience: 150, remaining: 82)

EPOCH 256/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6464
  ‚Ä¢ Validation Loss: 0.7533
  ‚Ä¢ Learning Rate: 0.000105
    No improvement (current: 0.7533, best: 0.7466)
    ‚ö† No improvement for 69 epochs (patience: 150, remaining: 81)

EPOCH 257/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6452
  ‚Ä¢ Validation Loss: 0.7533
  ‚Ä¢ Learning Rate: 0.000101
    No improvement (current: 0.7533, best: 0.7466)
    ‚ö† No improvement for 70 epochs (patience: 150, remaining: 80)

EPOCH 258/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6425
  ‚Ä¢ Validation Loss: 0.7533
  ‚Ä¢ Learning Rate: 0.000096
    No improvement (current: 0.7533, best: 0.7466)
    ‚ö† No improvement for 71 epochs (patience: 150, remaining: 79)

EPOCH 259/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6403
  ‚Ä¢ Validation Loss: 0.7526
  ‚Ä¢ Learning Rate: 0.000092
    No improvement (current: 0.7526, best: 0.7466)
    ‚ö† No improvement for 72 epochs (patience: 150, remaining: 78)

EPOCH 260/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6456
  ‚Ä¢ Validation Loss: 0.7534
  ‚Ä¢ Learning Rate: 0.000088
    No improvement (current: 0.7534, best: 0.7466)
    ‚ö† No improvement for 73 epochs (patience: 150, remaining: 77)

EPOCH 261/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6495
  ‚Ä¢ Validation Loss: 0.7512
  ‚Ä¢ Learning Rate: 0.000084
    No improvement (current: 0.7512, best: 0.7466)
    ‚ö† No improvement for 74 epochs (patience: 150, remaining: 76)

EPOCH 262/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6421
  ‚Ä¢ Validation Loss: 0.7533
  ‚Ä¢ Learning Rate: 0.000080
    No improvement (current: 0.7533, best: 0.7466)
    ‚ö† No improvement for 75 epochs (patience: 150, remaining: 75)

EPOCH 263/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6458
  ‚Ä¢ Validation Loss: 0.7523
  ‚Ä¢ Learning Rate: 0.000076
    No improvement (current: 0.7523, best: 0.7466)
    ‚ö† No improvement for 76 epochs (patience: 150, remaining: 74)

EPOCH 264/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6445
  ‚Ä¢ Validation Loss: 0.7529
  ‚Ä¢ Learning Rate: 0.000072
    No improvement (current: 0.7529, best: 0.7466)
    ‚ö† No improvement for 77 epochs (patience: 150, remaining: 73)

EPOCH 265/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6418
  ‚Ä¢ Validation Loss: 0.7534
  ‚Ä¢ Learning Rate: 0.000068
    No improvement (current: 0.7534, best: 0.7466)
    ‚ö† No improvement for 78 epochs (patience: 150, remaining: 72)

EPOCH 266/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6527
  ‚Ä¢ Validation Loss: 0.7527
  ‚Ä¢ Learning Rate: 0.000064
    No improvement (current: 0.7527, best: 0.7466)
    ‚ö† No improvement for 79 epochs (patience: 150, remaining: 71)

EPOCH 267/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6367
  ‚Ä¢ Validation Loss: 0.7533
  ‚Ä¢ Learning Rate: 0.000061
    No improvement (current: 0.7533, best: 0.7466)
    ‚ö† No improvement for 80 epochs (patience: 150, remaining: 70)

EPOCH 268/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6399
  ‚Ä¢ Validation Loss: 0.7530
  ‚Ä¢ Learning Rate: 0.000057
    No improvement (current: 0.7530, best: 0.7466)
    ‚ö† No improvement for 81 epochs (patience: 150, remaining: 69)

EPOCH 269/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6455
  ‚Ä¢ Validation Loss: 0.7540
  ‚Ä¢ Learning Rate: 0.000054
    No improvement (current: 0.7540, best: 0.7466)
    ‚ö† No improvement for 82 epochs (patience: 150, remaining: 68)

EPOCH 270/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6406
  ‚Ä¢ Validation Loss: 0.7538
  ‚Ä¢ Learning Rate: 0.000050
    No improvement (current: 0.7538, best: 0.7466)
    ‚ö† No improvement for 83 epochs (patience: 150, remaining: 67)

EPOCH 271/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6387
  ‚Ä¢ Validation Loss: 0.7530
  ‚Ä¢ Learning Rate: 0.000047
    No improvement (current: 0.7530, best: 0.7466)
    ‚ö† No improvement for 84 epochs (patience: 150, remaining: 66)

EPOCH 272/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6477
  ‚Ä¢ Validation Loss: 0.7530
  ‚Ä¢ Learning Rate: 0.000044
    No improvement (current: 0.7530, best: 0.7466)
    ‚ö† No improvement for 85 epochs (patience: 150, remaining: 65)

EPOCH 273/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6476
  ‚Ä¢ Validation Loss: 0.7533
  ‚Ä¢ Learning Rate: 0.000041
    No improvement (current: 0.7533, best: 0.7466)
    ‚ö† No improvement for 86 epochs (patience: 150, remaining: 64)

EPOCH 274/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6458
  ‚Ä¢ Validation Loss: 0.7536
  ‚Ä¢ Learning Rate: 0.000038
    No improvement (current: 0.7536, best: 0.7466)
    ‚ö† No improvement for 87 epochs (patience: 150, remaining: 63)

EPOCH 275/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6481
  ‚Ä¢ Validation Loss: 0.7542
  ‚Ä¢ Learning Rate: 0.000036
    No improvement (current: 0.7542, best: 0.7466)
    ‚ö† No improvement for 88 epochs (patience: 150, remaining: 62)

EPOCH 276/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6438
  ‚Ä¢ Validation Loss: 0.7534
  ‚Ä¢ Learning Rate: 0.000033
    No improvement (current: 0.7534, best: 0.7466)
    ‚ö† No improvement for 89 epochs (patience: 150, remaining: 61)

EPOCH 277/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6478
  ‚Ä¢ Validation Loss: 0.7541
  ‚Ä¢ Learning Rate: 0.000030
    No improvement (current: 0.7541, best: 0.7466)
    ‚ö† No improvement for 90 epochs (patience: 150, remaining: 60)

EPOCH 278/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6529
  ‚Ä¢ Validation Loss: 0.7526
  ‚Ä¢ Learning Rate: 0.000028
    No improvement (current: 0.7526, best: 0.7466)
    ‚ö† No improvement for 91 epochs (patience: 150, remaining: 59)

EPOCH 279/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6403
  ‚Ä¢ Validation Loss: 0.7530
  ‚Ä¢ Learning Rate: 0.000025
    No improvement (current: 0.7530, best: 0.7466)
    ‚ö† No improvement for 92 epochs (patience: 150, remaining: 58)

EPOCH 280/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6462
  ‚Ä¢ Validation Loss: 0.7531
  ‚Ä¢ Learning Rate: 0.000023
    No improvement (current: 0.7531, best: 0.7466)
    ‚ö† No improvement for 93 epochs (patience: 150, remaining: 57)

EPOCH 281/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6425
  ‚Ä¢ Validation Loss: 0.7536
  ‚Ä¢ Learning Rate: 0.000021
    No improvement (current: 0.7536, best: 0.7466)
    ‚ö† No improvement for 94 epochs (patience: 150, remaining: 56)

EPOCH 282/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6478
  ‚Ä¢ Validation Loss: 0.7531
  ‚Ä¢ Learning Rate: 0.000019
    No improvement (current: 0.7531, best: 0.7466)
    ‚ö† No improvement for 95 epochs (patience: 150, remaining: 55)

EPOCH 283/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6480
  ‚Ä¢ Validation Loss: 0.7535
  ‚Ä¢ Learning Rate: 0.000017
    No improvement (current: 0.7535, best: 0.7466)
    ‚ö† No improvement for 96 epochs (patience: 150, remaining: 54)

EPOCH 284/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6494
  ‚Ä¢ Validation Loss: 0.7536
  ‚Ä¢ Learning Rate: 0.000015
    No improvement (current: 0.7536, best: 0.7466)
    ‚ö† No improvement for 97 epochs (patience: 150, remaining: 53)

EPOCH 285/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6462
  ‚Ä¢ Validation Loss: 0.7534
  ‚Ä¢ Learning Rate: 0.000014
    No improvement (current: 0.7534, best: 0.7466)
    ‚ö† No improvement for 98 epochs (patience: 150, remaining: 52)

EPOCH 286/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6390
  ‚Ä¢ Validation Loss: 0.7535
  ‚Ä¢ Learning Rate: 0.000012
    No improvement (current: 0.7535, best: 0.7466)
    ‚ö† No improvement for 99 epochs (patience: 150, remaining: 51)

EPOCH 287/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6468
  ‚Ä¢ Validation Loss: 0.7533
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.7533, best: 0.7466)
    ‚ö† No improvement for 100 epochs (patience: 150, remaining: 50)

EPOCH 288/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6489
  ‚Ä¢ Validation Loss: 0.7535
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.7535, best: 0.7466)
    ‚ö† No improvement for 101 epochs (patience: 150, remaining: 49)

EPOCH 289/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6358
  ‚Ä¢ Validation Loss: 0.7535
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.7535, best: 0.7466)
    ‚ö† No improvement for 102 epochs (patience: 150, remaining: 48)

EPOCH 290/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6463
  ‚Ä¢ Validation Loss: 0.7532
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.7532, best: 0.7466)
    ‚ö† No improvement for 103 epochs (patience: 150, remaining: 47)

EPOCH 291/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6422
  ‚Ä¢ Validation Loss: 0.7533
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.7533, best: 0.7466)
    ‚ö† No improvement for 104 epochs (patience: 150, remaining: 46)

EPOCH 292/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6374
  ‚Ä¢ Validation Loss: 0.7534
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.7534, best: 0.7466)
    ‚ö† No improvement for 105 epochs (patience: 150, remaining: 45)

EPOCH 293/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6414
  ‚Ä¢ Validation Loss: 0.7535
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.7535, best: 0.7466)
    ‚ö† No improvement for 106 epochs (patience: 150, remaining: 44)

EPOCH 294/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6511
  ‚Ä¢ Validation Loss: 0.7534
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.7534, best: 0.7466)
    ‚ö† No improvement for 107 epochs (patience: 150, remaining: 43)

EPOCH 295/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6473
  ‚Ä¢ Validation Loss: 0.7534
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.7534, best: 0.7466)
    ‚ö† No improvement for 108 epochs (patience: 150, remaining: 42)

EPOCH 296/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6447
  ‚Ä¢ Validation Loss: 0.7534
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.7534, best: 0.7466)
    ‚ö† No improvement for 109 epochs (patience: 150, remaining: 41)

EPOCH 297/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6449
  ‚Ä¢ Validation Loss: 0.7534
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.7534, best: 0.7466)
    ‚ö† No improvement for 110 epochs (patience: 150, remaining: 40)

EPOCH 298/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6455
  ‚Ä¢ Validation Loss: 0.7534
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.7534, best: 0.7466)
    ‚ö† No improvement for 111 epochs (patience: 150, remaining: 39)

EPOCH 299/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6494
  ‚Ä¢ Validation Loss: 0.7534
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.7534, best: 0.7466)
    ‚ö† No improvement for 112 epochs (patience: 150, remaining: 38)

EPOCH 300/300
--------------------------------------------------
‚ö†Ô∏è  Scheduler reached max steps, stopping LR updates.
Results:
  ‚Ä¢ Train Loss: 0.6405
  ‚Ä¢ Validation Loss: 0.7534
  ‚Ä¢ Learning Rate: 0.000001
   üíæ Periodic checkpoint saved: epoch_300.pth
    No improvement (current: 0.7534, best: 0.7466)
    ‚ö† No improvement for 113 epochs (patience: 150, remaining: 37)

================================================================================
TRAINING COMPLETED
================================================================================
Best Val Loss:  0.7466
Total Epochs:   300
Models Saved:   ./Result/a3/Syr341
TensorBoard:    ./Result/a3/Syr341/tensorboard_logs
================================================================================

[04:47:34] Training completed. Best val loss: 0.7466

=== TRAINING COMPLETED SUCCESSFULLY ===
Training Finished!

========================================================================
Testing Hybrid2 Baseline Model with Smart Skip Connections and Multi-Scale Aggregation and Deep Supervision: Syr341
========================================================================
=== Historical Document Segmentation Testing ===

Detected Syriaque341 manuscript: using 5 classes (no Chapter Headings)
Model: Hybrid2
Dataset: UDIADS_BIB
Manuscript: Syr341
Test-Time Augmentation: Enabled
CRF post-processing: Enabled
  - DenseCRF with spatial and color pairwise potentials

================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder for Testing
================================================================================
================================================================================
üöÄ SIMPLE DECODER (Flag-Controlled Enhancements)
================================================================================
  ‚Ä¢ EfficientNet Variant: b4
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Enhancement Flags:
  ‚Ä¢ Deep Supervision: True
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: True
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: True
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Loaded checkpoint from epoch 186
Best validation loss: 0.7466
  ‚úÖ Model checkpoint loaded successfully (exact match)
Loaded checkpoint: best_model_latest.pth
Namespace(cfg=None, output_dir='./Result/a3/Syr341', use_baseline=True, decoder='EfficientNet-B4', efficientnet_variant='b4', use_deep_supervision=True, use_cbam=False, use_smart_skip=True, use_cross_attn=False, use_multiscale_agg=True, use_groupnorm=True, use_batchnorm=False, use_pos_embed=True, dataset='UDIADS_BIB', manuscript='Syr341', udiadsbib_root='../../U-DIADS-Bib-MS_patched', divahisdb_root='../../DivaHisDB', use_patched_data=True, num_classes=5, img_size=224, batch_size=24, is_savenii=True, test_save_dir='../predictions', use_crf=True, deterministic=1, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, use_tta=True)
Testing with checkpoint: best_model_latest.pth
Saving predictions to: ./Result/a3/Syr341/predictions

=== Starting Testing ===
Dataset: UDIADS_BIB
Model: Hybrid2
Manuscript: Syr341
Save predictions: True

Starting inference on UDIADS_BIB dataset
Found 1620 patches for Syr341
Using Test-Time Augmentation (TTA) for improved accuracy
CRF post-processing: Enabled
  - DenseCRF with spatial and color pairwise potentials
Processing: 031 (54 patches)
Applying CRF post-processing to 031
CRF post-processing completed for 031
Completed: 031
Processing: 053 (54 patches)
Applying CRF post-processing to 053
CRF post-processing completed for 053
Completed: 053
Processing: 054 (54 patches)
Applying CRF post-processing to 054
CRF post-processing completed for 054
Completed: 054
Processing: 071 (54 patches)
Applying CRF post-processing to 071
CRF post-processing completed for 071
Completed: 071
Processing: 073 (54 patches)
Applying CRF post-processing to 073
CRF post-processing completed for 073
Completed: 073
Processing: 075 (54 patches)
Applying CRF post-processing to 075
CRF post-processing completed for 075
Completed: 075
Processing: 100 (54 patches)
Applying CRF post-processing to 100
CRF post-processing completed for 100
Completed: 100
Processing: 137 (54 patches)
Applying CRF post-processing to 137
CRF post-processing completed for 137
Completed: 137
Processing: 150 (54 patches)
Applying CRF post-processing to 150
CRF post-processing completed for 150
Completed: 150
Processing: 160 (54 patches)
Applying CRF post-processing to 160
CRF post-processing completed for 160
Completed: 160
Processing: 167 (54 patches)
Applying CRF post-processing to 167
CRF post-processing completed for 167
Completed: 167
Processing: 184 (54 patches)
Applying CRF post-processing to 184
CRF post-processing completed for 184
Completed: 184
Processing: 190 (54 patches)
Applying CRF post-processing to 190
CRF post-processing completed for 190
Completed: 190
Processing: 201 (54 patches)
Applying CRF post-processing to 201
CRF post-processing completed for 201
Completed: 201
Processing: 210 (54 patches)
Applying CRF post-processing to 210
CRF post-processing completed for 210
Completed: 210
Processing: 222 (54 patches)
Applying CRF post-processing to 222
CRF post-processing completed for 222
Completed: 222
Processing: 224 (54 patches)
Applying CRF post-processing to 224
CRF post-processing completed for 224
Completed: 224
Processing: 231 (54 patches)
Applying CRF post-processing to 231
CRF post-processing completed for 231
Completed: 231
Processing: 241 (54 patches)
Applying CRF post-processing to 241
CRF post-processing completed for 241
Completed: 241
Processing: 249 (54 patches)
Applying CRF post-processing to 249
CRF post-processing completed for 249
Completed: 249
Processing: 252 (54 patches)
Applying CRF post-processing to 252
CRF post-processing completed for 252
Completed: 252
Processing: 267 (54 patches)
Applying CRF post-processing to 267
CRF post-processing completed for 267
Completed: 267
Processing: 281 (54 patches)
Applying CRF post-processing to 281
CRF post-processing completed for 281
Completed: 281
Processing: 286 (54 patches)
Applying CRF post-processing to 286
CRF post-processing completed for 286
Completed: 286
Processing: 290 (54 patches)
Applying CRF post-processing to 290
CRF post-processing completed for 290
Completed: 290
Processing: 313 (54 patches)
Applying CRF post-processing to 313
CRF post-processing completed for 313
Completed: 313
Processing: 362 (54 patches)
Applying CRF post-processing to 362
CRF post-processing completed for 362
Completed: 362
Processing: 368 (54 patches)
Applying CRF post-processing to 368
CRF post-processing completed for 368
Completed: 368
Processing: 376 (54 patches)
Applying CRF post-processing to 376
CRF post-processing completed for 376
Completed: 376
Processing: 446 (54 patches)
Applying CRF post-processing to 446
CRF post-processing completed for 446
Completed: 446

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9396, Recall=0.9933, F1=0.9657, IoU=0.9337
Paratext       : Precision=0.7637, Recall=0.3509, F1=0.4809, IoU=0.3165
Decoration     : Precision=0.9725, Recall=0.8972, F1=0.9334, IoU=0.8750
Main Text      : Precision=0.9293, Recall=0.5786, F1=0.7132, IoU=0.5542
Title          : Precision=0.5931, Recall=0.5287, F1=0.5591, IoU=0.3880

Mean metrics:
----------------------------------------
Mean Precision: 0.8396
Mean Recall: 0.6698
Mean F1-Score: 0.7304
Mean IoU: 0.6135

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9396, Recall=0.9933, F1=0.9657, IoU=0.9337
Paratext       : Precision=0.7637, Recall=0.3509, F1=0.4809, IoU=0.3165
Decoration     : Precision=0.9725, Recall=0.8972, F1=0.9334, IoU=0.8750
Main Text      : Precision=0.9293, Recall=0.5786, F1=0.7132, IoU=0.5542
Title          : Precision=0.5931, Recall=0.5287, F1=0.5591, IoU=0.3880

Mean metrics:
----------------------------------------
Mean Precision: 0.8396
Mean Recall: 0.6698
Mean F1-Score: 0.7304
Mean IoU: 0.6135
Inference completed on 30 images

=== TESTING COMPLETED SUCCESSFULLY ===
Results saved to: ./Result/a3/Syr341/predictions
==================================================

Calculating average metrics...
Looking for metrics files in: ./Result/a3
  ‚úó Metrics file not found: ./Result/a3/metrics_Latin2.json
  ‚úó Metrics file not found: ./Result/a3/metrics_Latin14396.json
  ‚úó Metrics file not found: ./Result/a3/metrics_Latin16746.json
  ‚úì Found metrics for Syr341

================================================================================
AVERAGE METRICS ACROSS 1 MANUSCRIPT(S)
================================================================================
Manuscripts: Syr341
Missing: Latin2, Latin14396, Latin16746
--------------------------------------------------------------------------------
Mean Precision: 0.8396
Mean Recall:    0.6698
Mean F1-Score:  0.7304
Mean IoU:       0.6135
================================================================================

========================================================================
ALL MANUSCRIPTS COMPLETED - HYBRID2 BASELINE MODEL WITH SMART SKIP CONNECTIONS AND MULTI-SCALE AGGREGATION AND DEEP SUPERVISION
========================================================================
Model: Hybrid2 Baseline (Swin Encoder + Simple Decoder with Smart Skip Connections and Multi-Scale Aggregation and Deep Supervision)
Results saved in: ./Result/a3/


========================================================================
AGGREGATING RESULTS ACROSS ALL MANUSCRIPTS
========================================================================

================================================================================
PARSING MANUSCRIPT RESULTS
================================================================================

Processing: Latin2
  Directory: ./Result/a3/Latin2
  ‚úó Could not find metrics for Latin2
    Please ensure testing has completed and output files exist

Processing: Latin14396
  Directory: ./Result/a3/Latin14396
  ‚úó Could not find metrics for Latin14396
    Please ensure testing has completed and output files exist

Processing: Latin16746
  Directory: ./Result/a3/Latin16746
  ‚úó Could not find metrics for Latin16746
    Please ensure testing has completed and output files exist

Processing: Syr341
  Directory: ./Result/a3/Syr341
  ‚úó Could not find metrics for Syr341
    Please ensure testing has completed and output files exist

================================================================================
ERROR: No metrics found!
================================================================================
Please ensure that:
  1. Testing has completed for all manuscripts
  2. Output files (.out or .txt) exist in the results directory
  3. The results_dir path is correct
================================================================================

========================================================================
AGGREGATION COMPLETE
========================================================================
Aggregated metrics saved to: ./Result/a3/aggregated_metrics.txt

=== JOB_STATISTICS ===
=== current date     : Fri Nov 14 04:55:12 AM CET 2025
= Job-ID             : 1321765 on tinygpu
= Job-Name           : r3
= Job-Command        : /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid/run3.sh
= Initial workdir    : /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid
= Queue/Partition    : work
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 22:00:00
= Elapsed runtime    : 06:12:42
= Total RAM usage    : 8.4 GiB of requested  GiB (%)   
= Node list          : tg068
= Subm/Elig/Start/End: 2025-11-13T22:42:42 / 2025-11-13T22:42:42 / 2025-11-13T22:42:43 / 2025-11-14T04:55:25
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/woody             0.0K  1000.0G  1500.0G        N/A       1    5,000K   7,500K        N/A    
    /home/hpc              73.3G   104.9G   209.7G        N/A     236K     500K   1,000K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA GeForce RTX 2080 Ti, 00000000:3B:00.0, 2494404, 51 %, 26 %, 1810 MiB, 3957711 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:3B:00.0, 2502912, 7 %, 2 %, 434 MiB, 445227 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:3B:00.0, 2503010, 51 %, 25 %, 1810 MiB, 5616742 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:3B:00.0, 2514705, 8 %, 2 %, 434 MiB, 474761 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:3B:00.0, 2514794, 52 %, 26 %, 1810 MiB, 5552875 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:3B:00.0, 2526552, 7 %, 2 %, 434 MiB, 461044 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:3B:00.0, 2526636, 52 %, 26 %, 1782 MiB, 5321248 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:3B:00.0, 2538384, 7 %, 2 %, 438 MiB, 449542 ms
