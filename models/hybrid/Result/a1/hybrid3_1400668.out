### Starting TaskPrologue of job 1400668 on tg065 at Thu Nov 20 04:59:18 PM CET 2025
Running on cores 2-3,10-11,18-19,26-27 with governor ondemand
Thu Nov 20 16:59:18 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 2080 Ti     On  |   00000000:3B:00.0 Off |                  N/A |
| 27%   29C    P8             12W /  250W |       1MiB /  11264MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue


========================================================================
Training Hybrid2 Baseline Model with EfficientNet-B4 Decoder + Simple Skip Connections: Latin2
========================================================================
Dataset: U-DIADS-Bib-MS_patched
Architecture: Swin Transformer Encoder ‚Üí 2 Swin Blocks Bottleneck ‚Üí EfficientNet-B4 Decoder
Decoder: EfficientNet-B4 Decoder (Real MBConv blocks)

Components Enabled:
  ‚úì Swin Encoder (4 stages: 96‚Üí192‚Üí384‚Üí768 dim)
  ‚úì Bottleneck: 2 Swin Transformer blocks (768 dim, 24 heads)
  ‚úì EfficientNet-B4 Decoder (MBConv blocks, channels: [256, 128, 64, 32])
  ‚úì Simple Skip Connections
  ‚úì Positional Embeddings (default: enabled)
  ‚úì GroupNorm (default normalization)
  ‚úì Balanced Sampler (oversampling rare classes)
  ‚úì Class-Aware Augmentation

Components Disabled (baseline):
  ‚úó Smart Skip Connections
  ‚úó CBAM Attention
  ‚úó Cross-Attention Bottleneck
  ‚úó BatchNorm
  ‚úó Deep Supervision
  ‚úó Multi-Scale Aggregation
========================================================================
All arguments validated successfully!
Setting random seed to 1234 for reproducible training...
Setting up U-DIADS-Bib dataset...
Using 6 classes for manuscript: Latin2
‚úì Class-aware augmentation enabled (stronger augmentation for rare classes)
  Rare classes: Paratext, Decoration, Title, Chapter Headings
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin2/Image/training
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin2/mask/training_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin2/Image/validation
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin2/mask/validation_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
Balanced sampler created (continuous rarity-based oversampling).
‚úì Balanced sampler enabled (oversampling rare classes)
================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder
================================================================================
================================================================================
üöÄ EFFICIENTNET-B4 DECODER (Real MBConv Blocks)
================================================================================
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Using MBConv blocks (NOT simple Conv)
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Optional Features:
  ‚Ä¢ Deep Supervision: False
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: False
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: False
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Model moved to CUDA
Model created successfully with 6 classes
DEBUG: args.output_dir = ./Result/a4/Latin2

=== Starting Training ===
Dataset: UDIADS_BIB
Model: Hybrid2
Batch size: 16
Max epochs: 300
Learning rate: 0.0001


================================================================================
TRAINING CONFIGURATION
================================================================================
Dataset: UDIADS_BIB
Model: Hybrid2
Batch Size: 16
Max Epochs: 300
Learning Rate: 0.0001
Number of Classes: 6
Output Directory: ./Result/a4/Latin2
Early Stopping Patience: 150 epochs
================================================================================

üìä Dataset Statistics:
   - Training samples: 540
   - Validation samples: 540
   - Batch size: 16
   - Steps per epoch: 34


================================================================================
COMPUTING CLASS WEIGHTS
================================================================================
Raw ENS weights: [9.99999990e-05 1.03287895e-04 9.99999990e-05 9.99999990e-05
 1.00003115e-04 1.00000103e-04]

Class Distribution:
Class                Pixels          Frequency       Weight         
-----------------------------------------------------------------
0                        25,105,103        92.6557%         0.9945
1                            34,471         0.1272%         1.0272
2                           638,823         2.3577%         0.9945
3                         1,075,139         3.9680%         0.9945
4                           103,758         0.3829%         0.9946
5                           137,746         0.5084%         0.9945

Total pixels: 27,095,040.0
Beta: 0.9999
Smoothing: 0.0
Weight range: [0.9945, 1.0272]
================================================================================
üìà Class weights computed with ENS method (smoothing=0.1)
   Final weights: [0.99454474 1.0272443  0.99454474 0.99454474 0.99457574 0.99454576]

‚úì Loss functions created: CE (weighted, label_smoothing=0.1), Focal (Œ≥=2.0), Dice
üöÄ Hybrid2 Best Practice: Differential Learning Rates
  üìä Encoder LR:     0.000010 (10x smaller, 119 params)
  üìä Bottleneck LR:  0.000050 (5x smaller, 26 params)
  üìä Decoder LR:     0.000100 (base LR, 139 params)
  ‚öôÔ∏è  Scheduler: CosineAnnealingWarmRestarts (T_0=50, T_mult=2)
  ‚öôÔ∏è  Weight decay: Encoder=1e-3, Bottleneck=5e-3, Decoder=1e-2

üîç Checking for checkpoint at: ./Result/a4/Latin2/best_model_latest.pth
   Absolute path: /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid/Result/a4/Latin2/best_model_latest.pth
   File exists: False

================================================================================
STARTING TRAINING
================================================================================
Early stopping patience: 150 epochs
Learning rate scheduler: CosineAnnealingWarmRestarts (better convergence for transformers)
================================================================================

EPOCH 1/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6439
  ‚Ä¢ Validation Loss: 0.5578
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.5578
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 2/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5199
  ‚Ä¢ Validation Loss: 0.5146
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.5146
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 3/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4762
  ‚Ä¢ Validation Loss: 0.4860
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4860
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 4/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4547
  ‚Ä¢ Validation Loss: 0.4697
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4697
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 5/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4387
  ‚Ä¢ Validation Loss: 0.4548
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4548
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 6/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4185
  ‚Ä¢ Validation Loss: 0.4439
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4439
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 7/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4036
  ‚Ä¢ Validation Loss: 0.4378
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4378
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 8/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4012
  ‚Ä¢ Validation Loss: 0.4335
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4335
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 9/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3918
  ‚Ä¢ Validation Loss: 0.4217
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.4217
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 10/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3783
  ‚Ä¢ Validation Loss: 0.4121
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.4121
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 11/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3733
  ‚Ä¢ Validation Loss: 0.4061
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.4061
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 12/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3556
  ‚Ä¢ Validation Loss: 0.4024
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.4024
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 13/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3450
  ‚Ä¢ Validation Loss: 0.3941
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3941
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 14/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3489
  ‚Ä¢ Validation Loss: 0.3959
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3959, best: 0.3941)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 15/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3372
  ‚Ä¢ Validation Loss: 0.3893
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3893
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 16/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3330
  ‚Ä¢ Validation Loss: 0.3891
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3891
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 17/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3266
  ‚Ä¢ Validation Loss: 0.3814
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3814
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 18/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3284
  ‚Ä¢ Validation Loss: 0.3867
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3867, best: 0.3814)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 19/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3243
  ‚Ä¢ Validation Loss: 0.3729
  ‚Ä¢ Learning Rate: 0.000007
    ‚úì New best checkpoint saved! Val loss: 0.3729
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 20/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3155
  ‚Ä¢ Validation Loss: 0.3659
  ‚Ä¢ Learning Rate: 0.000007
    ‚úì New best checkpoint saved! Val loss: 0.3659
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 21/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3104
  ‚Ä¢ Validation Loss: 0.3777
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3777, best: 0.3659)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 22/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3105
  ‚Ä¢ Validation Loss: 0.3727
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3727, best: 0.3659)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 23/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3012
  ‚Ä¢ Validation Loss: 0.3593
  ‚Ä¢ Learning Rate: 0.000006
    ‚úì New best checkpoint saved! Val loss: 0.3593
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 24/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3012
  ‚Ä¢ Validation Loss: 0.3653
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3653, best: 0.3593)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 25/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3013
  ‚Ä¢ Validation Loss: 0.3607
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3607, best: 0.3593)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 26/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2971
  ‚Ä¢ Validation Loss: 0.3630
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3630, best: 0.3593)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 27/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3002
  ‚Ä¢ Validation Loss: 0.3579
  ‚Ä¢ Learning Rate: 0.000005
    ‚úì New best checkpoint saved! Val loss: 0.3579
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 28/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2871
  ‚Ä¢ Validation Loss: 0.3586
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3586, best: 0.3579)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 29/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2907
  ‚Ä¢ Validation Loss: 0.3617
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3617, best: 0.3579)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 30/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2871
  ‚Ä¢ Validation Loss: 0.3548
  ‚Ä¢ Learning Rate: 0.000004
    ‚úì New best checkpoint saved! Val loss: 0.3548
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 31/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2842
  ‚Ä¢ Validation Loss: 0.3539
  ‚Ä¢ Learning Rate: 0.000004
    ‚úì New best checkpoint saved! Val loss: 0.3539
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 32/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2843
  ‚Ä¢ Validation Loss: 0.3516
  ‚Ä¢ Learning Rate: 0.000003
    ‚úì New best checkpoint saved! Val loss: 0.3516
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 33/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2799
  ‚Ä¢ Validation Loss: 0.3482
  ‚Ä¢ Learning Rate: 0.000003
    ‚úì New best checkpoint saved! Val loss: 0.3482
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 34/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2804
  ‚Ä¢ Validation Loss: 0.3526
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3526, best: 0.3482)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 35/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2838
  ‚Ä¢ Validation Loss: 0.3500
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3500, best: 0.3482)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 36/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2830
  ‚Ä¢ Validation Loss: 0.3557
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3557, best: 0.3482)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 37/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2798
  ‚Ä¢ Validation Loss: 0.3525
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3525, best: 0.3482)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 38/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2747
  ‚Ä¢ Validation Loss: 0.3504
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3504, best: 0.3482)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 39/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2614
  ‚Ä¢ Validation Loss: 0.3486
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3486, best: 0.3482)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 40/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2730
  ‚Ä¢ Validation Loss: 0.3481
  ‚Ä¢ Learning Rate: 0.000001
    ‚úì New best checkpoint saved! Val loss: 0.3481
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 41/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2709
  ‚Ä¢ Validation Loss: 0.3446
  ‚Ä¢ Learning Rate: 0.000001
    ‚úì New best checkpoint saved! Val loss: 0.3446
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 42/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2712
  ‚Ä¢ Validation Loss: 0.3462
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3462, best: 0.3446)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 43/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2693
  ‚Ä¢ Validation Loss: 0.3465
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3465, best: 0.3446)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 44/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2681
  ‚Ä¢ Validation Loss: 0.3436
  ‚Ä¢ Learning Rate: 0.000001
    ‚úì New best checkpoint saved! Val loss: 0.3436
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 45/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2694
  ‚Ä¢ Validation Loss: 0.3444
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3444, best: 0.3436)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 46/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2650
  ‚Ä¢ Validation Loss: 0.3425
  ‚Ä¢ Learning Rate: 0.000000
    ‚úì New best checkpoint saved! Val loss: 0.3425
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 47/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2692
  ‚Ä¢ Validation Loss: 0.3447
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3447, best: 0.3425)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 48/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2703
  ‚Ä¢ Validation Loss: 0.3441
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3441, best: 0.3425)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 49/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2621
  ‚Ä¢ Validation Loss: 0.3439
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3439, best: 0.3425)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 50/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2643
  ‚Ä¢ Validation Loss: 0.3440
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3440, best: 0.3425)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 51/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2778
  ‚Ä¢ Validation Loss: 0.3570
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3570, best: 0.3425)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 52/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2904
  ‚Ä¢ Validation Loss: 0.3542
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3542, best: 0.3425)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 53/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2787
  ‚Ä¢ Validation Loss: 0.3484
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3484, best: 0.3425)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 54/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2881
  ‚Ä¢ Validation Loss: 0.3677
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3677, best: 0.3425)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 55/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2849
  ‚Ä¢ Validation Loss: 0.3608
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3608, best: 0.3425)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 56/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2801
  ‚Ä¢ Validation Loss: 0.3559
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3559, best: 0.3425)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 57/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2817
  ‚Ä¢ Validation Loss: 0.3843
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3843, best: 0.3425)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 58/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2743
  ‚Ä¢ Validation Loss: 0.3457
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3457, best: 0.3425)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 59/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2783
  ‚Ä¢ Validation Loss: 0.3418
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.3418
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 60/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2786
  ‚Ä¢ Validation Loss: 0.3589
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3589, best: 0.3418)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 61/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2724
  ‚Ä¢ Validation Loss: 0.3498
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3498, best: 0.3418)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 62/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2717
  ‚Ä¢ Validation Loss: 0.3548
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3548, best: 0.3418)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 63/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2723
  ‚Ä¢ Validation Loss: 0.3497
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3497, best: 0.3418)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 64/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2612
  ‚Ä¢ Validation Loss: 0.3434
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3434, best: 0.3418)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 65/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2663
  ‚Ä¢ Validation Loss: 0.3451
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3451, best: 0.3418)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 66/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2651
  ‚Ä¢ Validation Loss: 0.3391
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3391
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 67/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2616
  ‚Ä¢ Validation Loss: 0.3339
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3339
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 68/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2669
  ‚Ä¢ Validation Loss: 0.3381
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3381, best: 0.3339)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 69/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2639
  ‚Ä¢ Validation Loss: 0.3383
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3383, best: 0.3339)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 70/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2645
  ‚Ä¢ Validation Loss: 0.3390
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3390, best: 0.3339)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 71/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2512
  ‚Ä¢ Validation Loss: 0.3371
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3371, best: 0.3339)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 72/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2701
  ‚Ä¢ Validation Loss: 0.3296
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3296
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 73/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2622
  ‚Ä¢ Validation Loss: 0.3483
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3483, best: 0.3296)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 74/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2621
  ‚Ä¢ Validation Loss: 0.3563
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3563, best: 0.3296)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 75/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2533
  ‚Ä¢ Validation Loss: 0.3320
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3320, best: 0.3296)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 76/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2556
  ‚Ä¢ Validation Loss: 0.3394
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3394, best: 0.3296)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 77/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2517
  ‚Ä¢ Validation Loss: 0.3412
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3412, best: 0.3296)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 78/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2560
  ‚Ä¢ Validation Loss: 0.3394
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3394, best: 0.3296)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 79/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2566
  ‚Ä¢ Validation Loss: 0.3432
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3432, best: 0.3296)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 80/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2619
  ‚Ä¢ Validation Loss: 0.3354
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3354, best: 0.3296)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 81/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2509
  ‚Ä¢ Validation Loss: 0.3333
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3333, best: 0.3296)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 82/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2498
  ‚Ä¢ Validation Loss: 0.3306
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3306, best: 0.3296)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 83/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2426
  ‚Ä¢ Validation Loss: 0.3370
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3370, best: 0.3296)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 84/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2561
  ‚Ä¢ Validation Loss: 0.3237
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3237
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 85/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2452
  ‚Ä¢ Validation Loss: 0.3228
  ‚Ä¢ Learning Rate: 0.000007
    ‚úì New best checkpoint saved! Val loss: 0.3228
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 86/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2426
  ‚Ä¢ Validation Loss: 0.3367
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3367, best: 0.3228)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 87/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2456
  ‚Ä¢ Validation Loss: 0.3380
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3380, best: 0.3228)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 88/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2451
  ‚Ä¢ Validation Loss: 0.3304
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3304, best: 0.3228)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 89/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2412
  ‚Ä¢ Validation Loss: 0.3393
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3393, best: 0.3228)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 90/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2547
  ‚Ä¢ Validation Loss: 0.3309
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3309, best: 0.3228)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 91/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2462
  ‚Ä¢ Validation Loss: 0.3263
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3263, best: 0.3228)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 92/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2483
  ‚Ä¢ Validation Loss: 0.3329
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3329, best: 0.3228)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 93/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2414
  ‚Ä¢ Validation Loss: 0.3323
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3323, best: 0.3228)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 94/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2462
  ‚Ä¢ Validation Loss: 0.3318
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3318, best: 0.3228)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 95/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2376
  ‚Ä¢ Validation Loss: 0.3305
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3305, best: 0.3228)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 96/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2349
  ‚Ä¢ Validation Loss: 0.3274
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3274, best: 0.3228)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 97/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2451
  ‚Ä¢ Validation Loss: 0.3291
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3291, best: 0.3228)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 98/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2335
  ‚Ä¢ Validation Loss: 0.3259
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3259, best: 0.3228)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 99/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2399
  ‚Ä¢ Validation Loss: 0.3307
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3307, best: 0.3228)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 100/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2327
  ‚Ä¢ Validation Loss: 0.3384
  ‚Ä¢ Learning Rate: 0.000005
   üíæ Periodic checkpoint saved: epoch_100.pth
    No improvement (current: 0.3384, best: 0.3228)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 101/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2353
  ‚Ä¢ Validation Loss: 0.3312
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3312, best: 0.3228)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 102/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2376
  ‚Ä¢ Validation Loss: 0.3255
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3255, best: 0.3228)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 103/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2315
  ‚Ä¢ Validation Loss: 0.3355
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3355, best: 0.3228)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 104/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2354
  ‚Ä¢ Validation Loss: 0.3279
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3279, best: 0.3228)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 105/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2364
  ‚Ä¢ Validation Loss: 0.3271
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3271, best: 0.3228)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 106/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2352
  ‚Ä¢ Validation Loss: 0.3347
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3347, best: 0.3228)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 107/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2310
  ‚Ä¢ Validation Loss: 0.3257
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3257, best: 0.3228)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 108/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2311
  ‚Ä¢ Validation Loss: 0.3234
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3234, best: 0.3228)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 109/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2392
  ‚Ä¢ Validation Loss: 0.3277
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3277, best: 0.3228)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 110/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2356
  ‚Ä¢ Validation Loss: 0.3218
  ‚Ä¢ Learning Rate: 0.000004
    ‚úì New best checkpoint saved! Val loss: 0.3218
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 111/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2222
  ‚Ä¢ Validation Loss: 0.3265
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3265, best: 0.3218)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 112/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2262
  ‚Ä¢ Validation Loss: 0.3223
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3223, best: 0.3218)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 113/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2290
  ‚Ä¢ Validation Loss: 0.3246
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3246, best: 0.3218)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 114/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2294
  ‚Ä¢ Validation Loss: 0.3295
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3295, best: 0.3218)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 115/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2335
  ‚Ä¢ Validation Loss: 0.3231
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3231, best: 0.3218)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 116/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2235
  ‚Ä¢ Validation Loss: 0.3261
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3261, best: 0.3218)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 117/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2255
  ‚Ä¢ Validation Loss: 0.3264
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3264, best: 0.3218)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 118/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2270
  ‚Ä¢ Validation Loss: 0.3260
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3260, best: 0.3218)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 119/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2189
  ‚Ä¢ Validation Loss: 0.3252
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3252, best: 0.3218)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 120/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2327
  ‚Ä¢ Validation Loss: 0.3201
  ‚Ä¢ Learning Rate: 0.000002
    ‚úì New best checkpoint saved! Val loss: 0.3201
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 121/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2305
  ‚Ä¢ Validation Loss: 0.3251
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3251, best: 0.3201)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 122/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2180
  ‚Ä¢ Validation Loss: 0.3256
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3256, best: 0.3201)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 123/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2335
  ‚Ä¢ Validation Loss: 0.3242
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3242, best: 0.3201)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 124/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2216
  ‚Ä¢ Validation Loss: 0.3206
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3206, best: 0.3201)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 125/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2181
  ‚Ä¢ Validation Loss: 0.3221
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3221, best: 0.3201)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 126/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2170
  ‚Ä¢ Validation Loss: 0.3209
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3209, best: 0.3201)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 127/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2159
  ‚Ä¢ Validation Loss: 0.3201
  ‚Ä¢ Learning Rate: 0.000001
    ‚úì New best checkpoint saved! Val loss: 0.3201
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 128/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2247
  ‚Ä¢ Validation Loss: 0.3218
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3218, best: 0.3201)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 129/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2209
  ‚Ä¢ Validation Loss: 0.3258
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3258, best: 0.3201)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 130/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2172
  ‚Ä¢ Validation Loss: 0.3228
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3228, best: 0.3201)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 131/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2238
  ‚Ä¢ Validation Loss: 0.3209
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3209, best: 0.3201)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 132/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2144
  ‚Ä¢ Validation Loss: 0.3207
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3207, best: 0.3201)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 133/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2253
  ‚Ä¢ Validation Loss: 0.3208
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3208, best: 0.3201)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 134/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2230
  ‚Ä¢ Validation Loss: 0.3214
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3214, best: 0.3201)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 135/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2214
  ‚Ä¢ Validation Loss: 0.3224
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3224, best: 0.3201)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 136/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2295
  ‚Ä¢ Validation Loss: 0.3205
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3205, best: 0.3201)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 137/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2218
  ‚Ä¢ Validation Loss: 0.3200
  ‚Ä¢ Learning Rate: 0.000001
    ‚úì New best checkpoint saved! Val loss: 0.3200
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 138/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2151
  ‚Ä¢ Validation Loss: 0.3207
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3207, best: 0.3200)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 139/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2114
  ‚Ä¢ Validation Loss: 0.3221
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3221, best: 0.3200)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 140/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2110
  ‚Ä¢ Validation Loss: 0.3218
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3218, best: 0.3200)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 141/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2135
  ‚Ä¢ Validation Loss: 0.3218
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3218, best: 0.3200)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 142/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2247
  ‚Ä¢ Validation Loss: 0.3216
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3216, best: 0.3200)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 143/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2258
  ‚Ä¢ Validation Loss: 0.3219
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3219, best: 0.3200)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 144/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2242
  ‚Ä¢ Validation Loss: 0.3219
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3219, best: 0.3200)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 145/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2109
  ‚Ä¢ Validation Loss: 0.3220
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3220, best: 0.3200)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 146/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2233
  ‚Ä¢ Validation Loss: 0.3225
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3225, best: 0.3200)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 147/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2291
  ‚Ä¢ Validation Loss: 0.3225
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3225, best: 0.3200)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 148/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2243
  ‚Ä¢ Validation Loss: 0.3223
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3223, best: 0.3200)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 149/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2269
  ‚Ä¢ Validation Loss: 0.3223
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3223, best: 0.3200)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 150/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2124
  ‚Ä¢ Validation Loss: 0.3222
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3222, best: 0.3200)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 151/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2260
  ‚Ä¢ Validation Loss: 0.3346
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3346, best: 0.3200)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 152/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2446
  ‚Ä¢ Validation Loss: 0.3381
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3381, best: 0.3200)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 153/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2355
  ‚Ä¢ Validation Loss: 0.3258
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3258, best: 0.3200)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 154/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2208
  ‚Ä¢ Validation Loss: 0.3208
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3208, best: 0.3200)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 155/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2338
  ‚Ä¢ Validation Loss: 0.3251
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3251, best: 0.3200)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 156/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2495
  ‚Ä¢ Validation Loss: 0.3336
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3336, best: 0.3200)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 157/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2322
  ‚Ä¢ Validation Loss: 0.3265
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3265, best: 0.3200)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 158/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2309
  ‚Ä¢ Validation Loss: 0.3239
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3239, best: 0.3200)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 159/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2351
  ‚Ä¢ Validation Loss: 0.3364
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3364, best: 0.3200)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 160/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2435
  ‚Ä¢ Validation Loss: 0.3200
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3200, best: 0.3200)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 161/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2323
  ‚Ä¢ Validation Loss: 0.3187
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.3187
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 162/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2391
  ‚Ä¢ Validation Loss: 0.3300
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3300, best: 0.3187)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 163/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2307
  ‚Ä¢ Validation Loss: 0.3199
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3199, best: 0.3187)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 164/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2320
  ‚Ä¢ Validation Loss: 0.3194
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3194, best: 0.3187)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 165/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2324
  ‚Ä¢ Validation Loss: 0.3333
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3333, best: 0.3187)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 166/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2339
  ‚Ä¢ Validation Loss: 0.3188
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3188, best: 0.3187)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 167/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2390
  ‚Ä¢ Validation Loss: 0.3238
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3238, best: 0.3187)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 168/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2305
  ‚Ä¢ Validation Loss: 0.3257
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3257, best: 0.3187)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 169/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2306
  ‚Ä¢ Validation Loss: 0.3283
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3283, best: 0.3187)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 170/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2240
  ‚Ä¢ Validation Loss: 0.3193
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3193, best: 0.3187)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 171/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2245
  ‚Ä¢ Validation Loss: 0.3289
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3289, best: 0.3187)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 172/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2327
  ‚Ä¢ Validation Loss: 0.3284
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3284, best: 0.3187)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 173/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2379
  ‚Ä¢ Validation Loss: 0.3169
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.3169
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 174/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2306
  ‚Ä¢ Validation Loss: 0.3223
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3223, best: 0.3169)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 175/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2340
  ‚Ä¢ Validation Loss: 0.3341
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3341, best: 0.3169)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 176/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2302
  ‚Ä¢ Validation Loss: 0.3201
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3201, best: 0.3169)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 177/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2305
  ‚Ä¢ Validation Loss: 0.3288
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3288, best: 0.3169)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 178/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2193
  ‚Ä¢ Validation Loss: 0.3349
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3349, best: 0.3169)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 179/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2217
  ‚Ä¢ Validation Loss: 0.3159
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.3159
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 180/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2358
  ‚Ä¢ Validation Loss: 0.3315
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3315, best: 0.3159)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 181/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2371
  ‚Ä¢ Validation Loss: 0.3197
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3197, best: 0.3159)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 182/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2248
  ‚Ä¢ Validation Loss: 0.3312
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3312, best: 0.3159)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 183/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2188
  ‚Ä¢ Validation Loss: 0.3262
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3262, best: 0.3159)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 184/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2206
  ‚Ä¢ Validation Loss: 0.3220
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3220, best: 0.3159)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 185/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2310
  ‚Ä¢ Validation Loss: 0.3227
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3227, best: 0.3159)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 186/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2277
  ‚Ä¢ Validation Loss: 0.3143
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3143
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 187/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2258
  ‚Ä¢ Validation Loss: 0.3231
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3231, best: 0.3143)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 188/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2294
  ‚Ä¢ Validation Loss: 0.3227
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3227, best: 0.3143)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 189/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2252
  ‚Ä¢ Validation Loss: 0.3144
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3144, best: 0.3143)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 190/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2289
  ‚Ä¢ Validation Loss: 0.3302
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3302, best: 0.3143)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 191/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2224
  ‚Ä¢ Validation Loss: 0.3184
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3184, best: 0.3143)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 192/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2175
  ‚Ä¢ Validation Loss: 0.3194
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3194, best: 0.3143)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 193/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2275
  ‚Ä¢ Validation Loss: 0.3243
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3243, best: 0.3143)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 194/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2188
  ‚Ä¢ Validation Loss: 0.3132
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3132
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 195/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2168
  ‚Ä¢ Validation Loss: 0.3251
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3251, best: 0.3132)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 196/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2222
  ‚Ä¢ Validation Loss: 0.3140
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3140, best: 0.3132)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 197/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2243
  ‚Ä¢ Validation Loss: 0.3169
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3169, best: 0.3132)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 198/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2277
  ‚Ä¢ Validation Loss: 0.3190
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3190, best: 0.3132)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 199/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2163
  ‚Ä¢ Validation Loss: 0.3177
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3177, best: 0.3132)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 200/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2192
  ‚Ä¢ Validation Loss: 0.3143
  ‚Ä¢ Learning Rate: 0.000009
   üíæ Periodic checkpoint saved: epoch_200.pth
    No improvement (current: 0.3143, best: 0.3132)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 201/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2143
  ‚Ä¢ Validation Loss: 0.3142
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3142, best: 0.3132)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 202/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2239
  ‚Ä¢ Validation Loss: 0.3261
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3261, best: 0.3132)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 203/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2185
  ‚Ä¢ Validation Loss: 0.3172
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3172, best: 0.3132)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 204/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2280
  ‚Ä¢ Validation Loss: 0.3176
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3176, best: 0.3132)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 205/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2250
  ‚Ä¢ Validation Loss: 0.3111
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3111
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 206/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2204
  ‚Ä¢ Validation Loss: 0.3154
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3154, best: 0.3111)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 207/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2184
  ‚Ä¢ Validation Loss: 0.3186
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3186, best: 0.3111)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 208/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2082
  ‚Ä¢ Validation Loss: 0.3175
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3175, best: 0.3111)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 209/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2131
  ‚Ä¢ Validation Loss: 0.3207
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3207, best: 0.3111)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 210/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2150
  ‚Ä¢ Validation Loss: 0.3213
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3213, best: 0.3111)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 211/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2189
  ‚Ä¢ Validation Loss: 0.3210
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3210, best: 0.3111)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 212/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2193
  ‚Ä¢ Validation Loss: 0.3165
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3165, best: 0.3111)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 213/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2125
  ‚Ä¢ Validation Loss: 0.3109
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3109
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 214/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2174
  ‚Ä¢ Validation Loss: 0.3127
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3127, best: 0.3109)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 215/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2180
  ‚Ä¢ Validation Loss: 0.3173
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3173, best: 0.3109)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 216/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2193
  ‚Ä¢ Validation Loss: 0.3162
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3162, best: 0.3109)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 217/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2231
  ‚Ä¢ Validation Loss: 0.3110
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3110, best: 0.3109)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 218/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2185
  ‚Ä¢ Validation Loss: 0.3301
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3301, best: 0.3109)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 219/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2220
  ‚Ä¢ Validation Loss: 0.3197
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3197, best: 0.3109)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 220/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2227
  ‚Ä¢ Validation Loss: 0.3155
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3155, best: 0.3109)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 221/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2213
  ‚Ä¢ Validation Loss: 0.3259
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3259, best: 0.3109)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 222/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2220
  ‚Ä¢ Validation Loss: 0.3199
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3199, best: 0.3109)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 223/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2243
  ‚Ä¢ Validation Loss: 0.3179
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3179, best: 0.3109)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 224/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2137
  ‚Ä¢ Validation Loss: 0.3246
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3246, best: 0.3109)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 225/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2161
  ‚Ä¢ Validation Loss: 0.3298
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3298, best: 0.3109)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 226/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2184
  ‚Ä¢ Validation Loss: 0.3209
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3209, best: 0.3109)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 227/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2136
  ‚Ä¢ Validation Loss: 0.3158
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3158, best: 0.3109)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 228/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2121
  ‚Ä¢ Validation Loss: 0.3202
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3202, best: 0.3109)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 229/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2111
  ‚Ä¢ Validation Loss: 0.3199
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3199, best: 0.3109)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 230/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2154
  ‚Ä¢ Validation Loss: 0.3145
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3145, best: 0.3109)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 231/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2121
  ‚Ä¢ Validation Loss: 0.3253
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3253, best: 0.3109)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 232/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2140
  ‚Ä¢ Validation Loss: 0.3182
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3182, best: 0.3109)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 233/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2200
  ‚Ä¢ Validation Loss: 0.3297
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3297, best: 0.3109)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 234/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2101
  ‚Ä¢ Validation Loss: 0.3266
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3266, best: 0.3109)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 235/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2107
  ‚Ä¢ Validation Loss: 0.3241
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3241, best: 0.3109)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 236/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2152
  ‚Ä¢ Validation Loss: 0.3158
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3158, best: 0.3109)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 237/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2005
  ‚Ä¢ Validation Loss: 0.3200
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3200, best: 0.3109)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 238/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2250
  ‚Ä¢ Validation Loss: 0.3189
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3189, best: 0.3109)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 239/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2079
  ‚Ä¢ Validation Loss: 0.3214
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3214, best: 0.3109)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 240/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2086
  ‚Ä¢ Validation Loss: 0.3182
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3182, best: 0.3109)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 241/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2167
  ‚Ä¢ Validation Loss: 0.3174
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3174, best: 0.3109)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 242/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2061
  ‚Ä¢ Validation Loss: 0.3206
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3206, best: 0.3109)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 243/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2020
  ‚Ä¢ Validation Loss: 0.3222
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3222, best: 0.3109)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 244/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2109
  ‚Ä¢ Validation Loss: 0.3168
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3168, best: 0.3109)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 245/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2075
  ‚Ä¢ Validation Loss: 0.3163
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3163, best: 0.3109)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 246/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2127
  ‚Ä¢ Validation Loss: 0.3229
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3229, best: 0.3109)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 247/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2121
  ‚Ä¢ Validation Loss: 0.3150
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3150, best: 0.3109)
    ‚ö† No improvement for 34 epochs (patience: 150, remaining: 116)

EPOCH 248/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2021
  ‚Ä¢ Validation Loss: 0.3189
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3189, best: 0.3109)
    ‚ö† No improvement for 35 epochs (patience: 150, remaining: 115)

EPOCH 249/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2126
  ‚Ä¢ Validation Loss: 0.3166
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3166, best: 0.3109)
    ‚ö† No improvement for 36 epochs (patience: 150, remaining: 114)

EPOCH 250/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2147
  ‚Ä¢ Validation Loss: 0.3221
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3221, best: 0.3109)
    ‚ö† No improvement for 37 epochs (patience: 150, remaining: 113)

EPOCH 251/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2115
  ‚Ä¢ Validation Loss: 0.3172
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3172, best: 0.3109)
    ‚ö† No improvement for 38 epochs (patience: 150, remaining: 112)

EPOCH 252/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2091
  ‚Ä¢ Validation Loss: 0.3165
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3165, best: 0.3109)
    ‚ö† No improvement for 39 epochs (patience: 150, remaining: 111)

EPOCH 253/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2093
  ‚Ä¢ Validation Loss: 0.3158
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3158, best: 0.3109)
    ‚ö† No improvement for 40 epochs (patience: 150, remaining: 110)

EPOCH 254/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2007
  ‚Ä¢ Validation Loss: 0.3148
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3148, best: 0.3109)
    ‚ö† No improvement for 41 epochs (patience: 150, remaining: 109)

EPOCH 255/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2114
  ‚Ä¢ Validation Loss: 0.3162
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3162, best: 0.3109)
    ‚ö† No improvement for 42 epochs (patience: 150, remaining: 108)

EPOCH 256/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2111
  ‚Ä¢ Validation Loss: 0.3130
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3130, best: 0.3109)
    ‚ö† No improvement for 43 epochs (patience: 150, remaining: 107)

EPOCH 257/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2056
  ‚Ä¢ Validation Loss: 0.3132
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3132, best: 0.3109)
    ‚ö† No improvement for 44 epochs (patience: 150, remaining: 106)

EPOCH 258/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2041
  ‚Ä¢ Validation Loss: 0.3255
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3255, best: 0.3109)
    ‚ö† No improvement for 45 epochs (patience: 150, remaining: 105)

EPOCH 259/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2044
  ‚Ä¢ Validation Loss: 0.3208
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3208, best: 0.3109)
    ‚ö† No improvement for 46 epochs (patience: 150, remaining: 104)

EPOCH 260/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2070
  ‚Ä¢ Validation Loss: 0.3102
  ‚Ä¢ Learning Rate: 0.000004
    ‚úì New best checkpoint saved! Val loss: 0.3102
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 261/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2016
  ‚Ä¢ Validation Loss: 0.3145
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3145, best: 0.3102)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 262/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2042
  ‚Ä¢ Validation Loss: 0.3170
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3170, best: 0.3102)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 263/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2143
  ‚Ä¢ Validation Loss: 0.3127
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3127, best: 0.3102)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 264/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2028
  ‚Ä¢ Validation Loss: 0.3126
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3126, best: 0.3102)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 265/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2052
  ‚Ä¢ Validation Loss: 0.3126
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3126, best: 0.3102)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 266/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2162
  ‚Ä¢ Validation Loss: 0.3164
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3164, best: 0.3102)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 267/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2083
  ‚Ä¢ Validation Loss: 0.3158
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3158, best: 0.3102)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 268/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2039
  ‚Ä¢ Validation Loss: 0.3085
  ‚Ä¢ Learning Rate: 0.000004
    ‚úì New best checkpoint saved! Val loss: 0.3085
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 269/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2173
  ‚Ä¢ Validation Loss: 0.3104
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3104, best: 0.3085)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 270/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2080
  ‚Ä¢ Validation Loss: 0.3162
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3162, best: 0.3085)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 271/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2059
  ‚Ä¢ Validation Loss: 0.3180
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3180, best: 0.3085)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 272/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2043
  ‚Ä¢ Validation Loss: 0.3176
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3176, best: 0.3085)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 273/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2050
  ‚Ä¢ Validation Loss: 0.3175
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3175, best: 0.3085)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 274/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2135
  ‚Ä¢ Validation Loss: 0.3169
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3169, best: 0.3085)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 275/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2069
  ‚Ä¢ Validation Loss: 0.3147
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3147, best: 0.3085)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 276/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2012
  ‚Ä¢ Validation Loss: 0.3161
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3161, best: 0.3085)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 277/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2021
  ‚Ä¢ Validation Loss: 0.3134
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3134, best: 0.3085)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 278/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2141
  ‚Ä¢ Validation Loss: 0.3159
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3159, best: 0.3085)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 279/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2033
  ‚Ä¢ Validation Loss: 0.3122
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3122, best: 0.3085)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 280/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2079
  ‚Ä¢ Validation Loss: 0.3113
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3113, best: 0.3085)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 281/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1961
  ‚Ä¢ Validation Loss: 0.3132
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3132, best: 0.3085)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 282/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2058
  ‚Ä¢ Validation Loss: 0.3147
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3147, best: 0.3085)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 283/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2001
  ‚Ä¢ Validation Loss: 0.3089
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3089, best: 0.3085)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 284/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2006
  ‚Ä¢ Validation Loss: 0.3128
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3128, best: 0.3085)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 285/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2002
  ‚Ä¢ Validation Loss: 0.3156
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3156, best: 0.3085)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 286/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2043
  ‚Ä¢ Validation Loss: 0.3116
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3116, best: 0.3085)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 287/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1999
  ‚Ä¢ Validation Loss: 0.3144
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3144, best: 0.3085)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 288/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2058
  ‚Ä¢ Validation Loss: 0.3119
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3119, best: 0.3085)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 289/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2082
  ‚Ä¢ Validation Loss: 0.3112
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3112, best: 0.3085)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 290/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1922
  ‚Ä¢ Validation Loss: 0.3134
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3134, best: 0.3085)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 291/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2043
  ‚Ä¢ Validation Loss: 0.3146
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3146, best: 0.3085)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 292/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2090
  ‚Ä¢ Validation Loss: 0.3165
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3165, best: 0.3085)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 293/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1979
  ‚Ä¢ Validation Loss: 0.3143
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3143, best: 0.3085)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 294/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1971
  ‚Ä¢ Validation Loss: 0.3153
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3153, best: 0.3085)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 295/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1928
  ‚Ä¢ Validation Loss: 0.3117
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3117, best: 0.3085)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 296/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2105
  ‚Ä¢ Validation Loss: 0.3121
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3121, best: 0.3085)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 297/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1934
  ‚Ä¢ Validation Loss: 0.3097
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3097, best: 0.3085)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 298/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2067
  ‚Ä¢ Validation Loss: 0.3091
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3091, best: 0.3085)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 299/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2050
  ‚Ä¢ Validation Loss: 0.3111
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3111, best: 0.3085)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 300/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2061
  ‚Ä¢ Validation Loss: 0.3113
  ‚Ä¢ Learning Rate: 0.000002
   üíæ Periodic checkpoint saved: epoch_300.pth
    No improvement (current: 0.3113, best: 0.3085)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

================================================================================
TRAINING COMPLETED
================================================================================
Best Val Loss:  0.3085
Total Epochs:   300
Models Saved:   ./Result/a4/Latin2
TensorBoard:    ./Result/a4/Latin2/tensorboard_logs
================================================================================

[18:10:48] Training completed. Best val loss: 0.3085

=== TRAINING COMPLETED SUCCESSFULLY ===
Training Finished!

========================================================================
Testing Hybrid2 Baseline Model with EfficientNet-B4 Decoder + Simple Skip Connections: Latin2
========================================================================
=== Historical Document Segmentation Testing ===

Using 6 classes for manuscript: Latin2
Model: Hybrid2
Dataset: UDIADS_BIB
Manuscript: Latin2
Test-Time Augmentation: Enabled
CRF post-processing: Disabled

================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder for Testing
================================================================================
================================================================================
üöÄ EFFICIENTNET-B4 DECODER (Real MBConv Blocks)
================================================================================
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Using MBConv blocks (NOT simple Conv)
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Optional Features:
  ‚Ä¢ Deep Supervision: False
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: False
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: False
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Loaded checkpoint from epoch 267
Best validation loss: 0.3085
  ‚úÖ Model checkpoint loaded successfully (exact match)
Loaded checkpoint: best_model_latest.pth
Namespace(cfg=None, output_dir='./Result/a4/Latin2', use_baseline=True, decoder='EfficientNet-B4', efficientnet_variant='b4', use_deep_supervision=False, use_cbam=False, use_smart_skip=False, use_cross_attn=False, use_multiscale_agg=False, use_groupnorm=True, use_batchnorm=False, use_pos_embed=True, dataset='UDIADS_BIB', manuscript='Latin2', udiadsbib_root='../../U-DIADS-Bib-MS_patched', divahisdb_root='../../DivaHisDB', use_patched_data=True, num_classes=6, img_size=224, batch_size=24, is_savenii=True, test_save_dir='../predictions', use_crf=False, deterministic=1, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, use_tta=True)
Testing with checkpoint: best_model_latest.pth
Saving predictions to: ./Result/a4/Latin2/predictions

=== Starting Testing ===
Dataset: UDIADS_BIB
Model: Hybrid2
Manuscript: Latin2
Save predictions: True

Starting inference on UDIADS_BIB dataset
Found 1620 patches for Latin2
Using Test-Time Augmentation (TTA) for improved accuracy
CRF post-processing: Disabled
Processing: 076 (54 patches)
Completed: 076
Processing: 079 (54 patches)
Completed: 079
Processing: 082 (54 patches)
Completed: 082
Processing: 095 (54 patches)
Completed: 095
Processing: 106 (54 patches)
Completed: 106
Processing: 111 (54 patches)
Completed: 111
Processing: 115 (54 patches)
Completed: 115
Processing: 117 (54 patches)
Completed: 117
Processing: 128 (54 patches)
Completed: 128
Processing: 134 (54 patches)
Completed: 134
Processing: 138 (54 patches)
Completed: 138
Processing: 142 (54 patches)
Completed: 142
Processing: 159 (54 patches)
Completed: 159
Processing: 166 (54 patches)
Completed: 166
Processing: 185 (54 patches)
Completed: 185
Processing: 200 (54 patches)
Completed: 200
Processing: 203 (54 patches)
Completed: 203
Processing: 208 (54 patches)
Completed: 208
Processing: 229 (54 patches)
Completed: 229
Processing: 230 (54 patches)
Completed: 230
Processing: 235 (54 patches)
Completed: 235
Processing: 236 (54 patches)
Completed: 236
Processing: 248 (54 patches)
Completed: 248
Processing: 249 (54 patches)
Completed: 249
Processing: 250 (54 patches)
Completed: 250
Processing: 251 (54 patches)
Completed: 251
Processing: 252 (54 patches)
Completed: 252
Processing: 275 (54 patches)
Completed: 275
Processing: 277 (54 patches)
Completed: 277
Processing: 297 (54 patches)
Completed: 297

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9916, Recall=0.9915, F1=0.9916, IoU=0.9833
Paratext       : Precision=0.6248, Recall=0.7278, F1=0.6724, IoU=0.5065
Decoration     : Precision=0.8835, Recall=0.8606, F1=0.8719, IoU=0.7729
Main Text      : Precision=0.8191, Recall=0.8782, F1=0.8477, IoU=0.7356
Title          : Precision=0.8581, Recall=0.8364, F1=0.8472, IoU=0.7348
Chapter Headings: Precision=0.7503, Recall=0.2915, F1=0.4199, IoU=0.2657

Mean metrics:
----------------------------------------
Mean Precision: 0.8212
Mean Recall: 0.7644
Mean F1-Score: 0.7751
Mean IoU: 0.6665

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9916, Recall=0.9915, F1=0.9916, IoU=0.9833
Paratext       : Precision=0.6248, Recall=0.7278, F1=0.6724, IoU=0.5065
Decoration     : Precision=0.8835, Recall=0.8606, F1=0.8719, IoU=0.7729
Main Text      : Precision=0.8191, Recall=0.8782, F1=0.8477, IoU=0.7356
Title          : Precision=0.8581, Recall=0.8364, F1=0.8472, IoU=0.7348
Chapter Headings: Precision=0.7503, Recall=0.2915, F1=0.4199, IoU=0.2657

Mean metrics:
----------------------------------------
Mean Precision: 0.8212
Mean Recall: 0.7644
Mean F1-Score: 0.7751
Mean IoU: 0.6665
Inference completed on 30 images

=== TESTING COMPLETED SUCCESSFULLY ===
Results saved to: ./Result/a4/Latin2/predictions
==================================================

Calculating average metrics...
Looking for metrics files in: ./Result/a4
  ‚úì Found metrics for Latin2
  ‚úó Metrics file not found: ./Result/a4/metrics_Latin14396.json
  ‚úó Metrics file not found: ./Result/a4/metrics_Latin16746.json
  ‚úó Metrics file not found: ./Result/a4/metrics_Syr341.json

================================================================================
AVERAGE METRICS ACROSS 1 MANUSCRIPT(S)
================================================================================
Manuscripts: Latin2
Missing: Latin14396, Latin16746, Syr341
--------------------------------------------------------------------------------
Mean Precision: 0.8212
Mean Recall:    0.7644
Mean F1-Score:  0.7751
Mean IoU:       0.6665
================================================================================

========================================================================
Training Hybrid2 Baseline Model with EfficientNet-B4 Decoder + Simple Skip Connections: Latin14396
========================================================================
Dataset: U-DIADS-Bib-MS_patched
Architecture: Swin Transformer Encoder ‚Üí 2 Swin Blocks Bottleneck ‚Üí EfficientNet-B4 Decoder
Decoder: EfficientNet-B4 Decoder (Real MBConv blocks)

Components Enabled:
  ‚úì Swin Encoder (4 stages: 96‚Üí192‚Üí384‚Üí768 dim)
  ‚úì Bottleneck: 2 Swin Transformer blocks (768 dim, 24 heads)
  ‚úì EfficientNet-B4 Decoder (MBConv blocks, channels: [256, 128, 64, 32])
  ‚úì Simple Skip Connections
  ‚úì Positional Embeddings (default: enabled)
  ‚úì GroupNorm (default normalization)
  ‚úì Balanced Sampler (oversampling rare classes)
  ‚úì Class-Aware Augmentation

Components Disabled (baseline):
  ‚úó Smart Skip Connections
  ‚úó CBAM Attention
  ‚úó Cross-Attention Bottleneck
  ‚úó BatchNorm
  ‚úó Deep Supervision
  ‚úó Multi-Scale Aggregation
========================================================================
All arguments validated successfully!
Setting random seed to 1234 for reproducible training...
Setting up U-DIADS-Bib dataset...
Using 6 classes for manuscript: Latin14396
‚úì Class-aware augmentation enabled (stronger augmentation for rare classes)
  Rare classes: Paratext, Decoration, Title, Chapter Headings
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin14396/Image/training
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin14396/mask/training_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin14396/Image/validation
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin14396/mask/validation_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
Balanced sampler created (continuous rarity-based oversampling).
‚úì Balanced sampler enabled (oversampling rare classes)
================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder
================================================================================
================================================================================
üöÄ EFFICIENTNET-B4 DECODER (Real MBConv Blocks)
================================================================================
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Using MBConv blocks (NOT simple Conv)
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Optional Features:
  ‚Ä¢ Deep Supervision: False
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: False
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: False
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Model moved to CUDA
Model created successfully with 6 classes
DEBUG: args.output_dir = ./Result/a4/Latin14396

=== Starting Training ===
Dataset: UDIADS_BIB
Model: Hybrid2
Batch size: 16
Max epochs: 300
Learning rate: 0.0001


================================================================================
TRAINING CONFIGURATION
================================================================================
Dataset: UDIADS_BIB
Model: Hybrid2
Batch Size: 16
Max Epochs: 300
Learning Rate: 0.0001
Number of Classes: 6
Output Directory: ./Result/a4/Latin14396
Early Stopping Patience: 150 epochs
================================================================================

üìä Dataset Statistics:
   - Training samples: 540
   - Validation samples: 540
   - Batch size: 16
   - Steps per epoch: 34


================================================================================
COMPUTING CLASS WEIGHTS
================================================================================
Raw ENS weights: [9.99999990e-05 1.09839441e-04 9.99999990e-05 9.99999990e-05
 1.00000006e-04 1.00000021e-04]

Class Distribution:
Class                Pixels          Frequency       Weight         
-----------------------------------------------------------------
0                        24,235,884        89.4477%         0.9839
1                            24,125         0.0890%         1.0807
2                           460,965         1.7013%         0.9839
3                         2,056,396         7.5896%         0.9839
4                           164,544         0.6073%         0.9839
5                           153,126         0.5651%         0.9839

Total pixels: 27,095,040.0
Beta: 0.9999
Smoothing: 0.0
Weight range: [0.9839, 1.0807]
================================================================================
üìà Class weights computed with ENS method (smoothing=0.1)
   Final weights: [0.9838655  1.0806724  0.9838655  0.9838655  0.98386556 0.9838657 ]

‚úì Loss functions created: CE (weighted, label_smoothing=0.1), Focal (Œ≥=2.0), Dice
üöÄ Hybrid2 Best Practice: Differential Learning Rates
  üìä Encoder LR:     0.000010 (10x smaller, 119 params)
  üìä Bottleneck LR:  0.000050 (5x smaller, 26 params)
  üìä Decoder LR:     0.000100 (base LR, 139 params)
  ‚öôÔ∏è  Scheduler: CosineAnnealingWarmRestarts (T_0=50, T_mult=2)
  ‚öôÔ∏è  Weight decay: Encoder=1e-3, Bottleneck=5e-3, Decoder=1e-2

üîç Checking for checkpoint at: ./Result/a4/Latin14396/best_model_latest.pth
   Absolute path: /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid/Result/a4/Latin14396/best_model_latest.pth
   File exists: False

================================================================================
STARTING TRAINING
================================================================================
Early stopping patience: 150 epochs
Learning rate scheduler: CosineAnnealingWarmRestarts (better convergence for transformers)
================================================================================

EPOCH 1/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6535
  ‚Ä¢ Validation Loss: 0.5513
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.5513
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 2/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5157
  ‚Ä¢ Validation Loss: 0.5145
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.5145
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 3/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4844
  ‚Ä¢ Validation Loss: 0.4847
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4847
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 4/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4633
  ‚Ä¢ Validation Loss: 0.4638
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4638
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 5/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4420
  ‚Ä¢ Validation Loss: 0.4453
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4453
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 6/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4214
  ‚Ä¢ Validation Loss: 0.4347
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4347
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 7/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4106
  ‚Ä¢ Validation Loss: 0.4229
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4229
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 8/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4058
  ‚Ä¢ Validation Loss: 0.4159
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4159
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 9/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3987
  ‚Ä¢ Validation Loss: 0.4102
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.4102
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 10/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3877
  ‚Ä¢ Validation Loss: 0.4087
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.4087
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 11/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3832
  ‚Ä¢ Validation Loss: 0.3978
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3978
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 12/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3784
  ‚Ä¢ Validation Loss: 0.3964
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3964
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 13/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3730
  ‚Ä¢ Validation Loss: 0.3954
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3954
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 14/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3701
  ‚Ä¢ Validation Loss: 0.3973
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3973, best: 0.3954)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 15/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3657
  ‚Ä¢ Validation Loss: 0.3865
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3865
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 16/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3612
  ‚Ä¢ Validation Loss: 0.3941
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3941, best: 0.3865)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 17/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3607
  ‚Ä¢ Validation Loss: 0.3820
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3820
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 18/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3611
  ‚Ä¢ Validation Loss: 0.3759
  ‚Ä¢ Learning Rate: 0.000007
    ‚úì New best checkpoint saved! Val loss: 0.3759
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 19/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3509
  ‚Ä¢ Validation Loss: 0.3822
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3822, best: 0.3759)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 20/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3428
  ‚Ä¢ Validation Loss: 0.3785
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3785, best: 0.3759)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 21/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3438
  ‚Ä¢ Validation Loss: 0.3743
  ‚Ä¢ Learning Rate: 0.000007
    ‚úì New best checkpoint saved! Val loss: 0.3743
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 22/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3396
  ‚Ä¢ Validation Loss: 0.3688
  ‚Ä¢ Learning Rate: 0.000006
    ‚úì New best checkpoint saved! Val loss: 0.3688
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 23/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3380
  ‚Ä¢ Validation Loss: 0.3651
  ‚Ä¢ Learning Rate: 0.000006
    ‚úì New best checkpoint saved! Val loss: 0.3651
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 24/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3344
  ‚Ä¢ Validation Loss: 0.3631
  ‚Ä¢ Learning Rate: 0.000006
    ‚úì New best checkpoint saved! Val loss: 0.3631
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 25/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3326
  ‚Ä¢ Validation Loss: 0.3658
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3658, best: 0.3631)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 26/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3306
  ‚Ä¢ Validation Loss: 0.3626
  ‚Ä¢ Learning Rate: 0.000005
    ‚úì New best checkpoint saved! Val loss: 0.3626
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 27/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3222
  ‚Ä¢ Validation Loss: 0.3617
  ‚Ä¢ Learning Rate: 0.000005
    ‚úì New best checkpoint saved! Val loss: 0.3617
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 28/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3276
  ‚Ä¢ Validation Loss: 0.3604
  ‚Ä¢ Learning Rate: 0.000004
    ‚úì New best checkpoint saved! Val loss: 0.3604
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 29/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3271
  ‚Ä¢ Validation Loss: 0.3551
  ‚Ä¢ Learning Rate: 0.000004
    ‚úì New best checkpoint saved! Val loss: 0.3551
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 30/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3224
  ‚Ä¢ Validation Loss: 0.3612
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3612, best: 0.3551)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 31/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3211
  ‚Ä¢ Validation Loss: 0.3505
  ‚Ä¢ Learning Rate: 0.000004
    ‚úì New best checkpoint saved! Val loss: 0.3505
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 32/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3165
  ‚Ä¢ Validation Loss: 0.3529
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3529, best: 0.3505)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 33/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3120
  ‚Ä¢ Validation Loss: 0.3519
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3519, best: 0.3505)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 34/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3136
  ‚Ä¢ Validation Loss: 0.3527
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3527, best: 0.3505)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 35/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3093
  ‚Ä¢ Validation Loss: 0.3481
  ‚Ä¢ Learning Rate: 0.000002
    ‚úì New best checkpoint saved! Val loss: 0.3481
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 36/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3037
  ‚Ä¢ Validation Loss: 0.3498
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3498, best: 0.3481)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 37/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2980
  ‚Ä¢ Validation Loss: 0.3496
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3496, best: 0.3481)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 38/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3034
  ‚Ä¢ Validation Loss: 0.3490
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3490, best: 0.3481)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 39/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3031
  ‚Ä¢ Validation Loss: 0.3499
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3499, best: 0.3481)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 40/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2978
  ‚Ä¢ Validation Loss: 0.3475
  ‚Ä¢ Learning Rate: 0.000001
    ‚úì New best checkpoint saved! Val loss: 0.3475
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 41/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3033
  ‚Ä¢ Validation Loss: 0.3454
  ‚Ä¢ Learning Rate: 0.000001
    ‚úì New best checkpoint saved! Val loss: 0.3454
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 42/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3003
  ‚Ä¢ Validation Loss: 0.3477
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3477, best: 0.3454)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 43/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2929
  ‚Ä¢ Validation Loss: 0.3457
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3457, best: 0.3454)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 44/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2945
  ‚Ä¢ Validation Loss: 0.3455
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3455, best: 0.3454)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 45/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2870
  ‚Ä¢ Validation Loss: 0.3445
  ‚Ä¢ Learning Rate: 0.000000
    ‚úì New best checkpoint saved! Val loss: 0.3445
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 46/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2911
  ‚Ä¢ Validation Loss: 0.3447
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3447, best: 0.3445)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 47/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2975
  ‚Ä¢ Validation Loss: 0.3459
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3459, best: 0.3445)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 48/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2977
  ‚Ä¢ Validation Loss: 0.3456
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3456, best: 0.3445)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 49/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2933
  ‚Ä¢ Validation Loss: 0.3453
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3453, best: 0.3445)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 50/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2945
  ‚Ä¢ Validation Loss: 0.3454
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3454, best: 0.3445)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 51/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3155
  ‚Ä¢ Validation Loss: 0.3626
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3626, best: 0.3445)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 52/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3150
  ‚Ä¢ Validation Loss: 0.3504
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3504, best: 0.3445)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 53/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3167
  ‚Ä¢ Validation Loss: 0.3531
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3531, best: 0.3445)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 54/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3195
  ‚Ä¢ Validation Loss: 0.3522
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3522, best: 0.3445)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 55/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3116
  ‚Ä¢ Validation Loss: 0.3627
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3627, best: 0.3445)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 56/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3163
  ‚Ä¢ Validation Loss: 0.3542
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3542, best: 0.3445)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 57/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3008
  ‚Ä¢ Validation Loss: 0.3579
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3579, best: 0.3445)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 58/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3081
  ‚Ä¢ Validation Loss: 0.3510
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3510, best: 0.3445)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 59/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3036
  ‚Ä¢ Validation Loss: 0.3497
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3497, best: 0.3445)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 60/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2932
  ‚Ä¢ Validation Loss: 0.3473
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3473, best: 0.3445)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 61/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2977
  ‚Ä¢ Validation Loss: 0.3559
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3559, best: 0.3445)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 62/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3002
  ‚Ä¢ Validation Loss: 0.3454
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3454, best: 0.3445)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 63/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2975
  ‚Ä¢ Validation Loss: 0.3423
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.3423
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 64/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2950
  ‚Ä¢ Validation Loss: 0.3391
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.3391
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 65/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2948
  ‚Ä¢ Validation Loss: 0.3367
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.3367
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 66/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2887
  ‚Ä¢ Validation Loss: 0.3405
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3405, best: 0.3367)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 67/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2895
  ‚Ä¢ Validation Loss: 0.3403
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3403, best: 0.3367)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 68/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2817
  ‚Ä¢ Validation Loss: 0.3469
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3469, best: 0.3367)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 69/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2941
  ‚Ä¢ Validation Loss: 0.3450
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3450, best: 0.3367)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 70/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2883
  ‚Ä¢ Validation Loss: 0.3443
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3443, best: 0.3367)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 71/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2764
  ‚Ä¢ Validation Loss: 0.3492
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3492, best: 0.3367)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 72/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2892
  ‚Ä¢ Validation Loss: 0.3371
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3371, best: 0.3367)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 73/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2806
  ‚Ä¢ Validation Loss: 0.3337
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3337
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 74/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2791
  ‚Ä¢ Validation Loss: 0.3335
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3335
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 75/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2750
  ‚Ä¢ Validation Loss: 0.3396
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3396, best: 0.3335)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 76/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2818
  ‚Ä¢ Validation Loss: 0.3344
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3344, best: 0.3335)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 77/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2688
  ‚Ä¢ Validation Loss: 0.3322
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3322
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 78/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2677
  ‚Ä¢ Validation Loss: 0.3312
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3312
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 79/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2698
  ‚Ä¢ Validation Loss: 0.3413
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3413, best: 0.3312)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 80/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2614
  ‚Ä¢ Validation Loss: 0.3287
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3287
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 81/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2699
  ‚Ä¢ Validation Loss: 0.3279
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3279
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 82/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2694
  ‚Ä¢ Validation Loss: 0.3322
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3322, best: 0.3279)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 83/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2590
  ‚Ä¢ Validation Loss: 0.3250
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3250
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 84/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2688
  ‚Ä¢ Validation Loss: 0.3296
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3296, best: 0.3250)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 85/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2687
  ‚Ä¢ Validation Loss: 0.3273
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3273, best: 0.3250)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 86/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2662
  ‚Ä¢ Validation Loss: 0.3314
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3314, best: 0.3250)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 87/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2686
  ‚Ä¢ Validation Loss: 0.3269
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3269, best: 0.3250)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 88/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2624
  ‚Ä¢ Validation Loss: 0.3263
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3263, best: 0.3250)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 89/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2718
  ‚Ä¢ Validation Loss: 0.3298
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3298, best: 0.3250)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 90/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2615
  ‚Ä¢ Validation Loss: 0.3223
  ‚Ä¢ Learning Rate: 0.000007
    ‚úì New best checkpoint saved! Val loss: 0.3223
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 91/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2692
  ‚Ä¢ Validation Loss: 0.3227
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3227, best: 0.3223)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 92/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2570
  ‚Ä¢ Validation Loss: 0.3266
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3266, best: 0.3223)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 93/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2612
  ‚Ä¢ Validation Loss: 0.3195
  ‚Ä¢ Learning Rate: 0.000006
    ‚úì New best checkpoint saved! Val loss: 0.3195
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 94/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2587
  ‚Ä¢ Validation Loss: 0.3211
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3211, best: 0.3195)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 95/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2661
  ‚Ä¢ Validation Loss: 0.3239
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3239, best: 0.3195)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 96/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2523
  ‚Ä¢ Validation Loss: 0.3224
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3224, best: 0.3195)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 97/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2501
  ‚Ä¢ Validation Loss: 0.3225
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3225, best: 0.3195)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 98/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2585
  ‚Ä¢ Validation Loss: 0.3192
  ‚Ä¢ Learning Rate: 0.000006
    ‚úì New best checkpoint saved! Val loss: 0.3192
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 99/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2525
  ‚Ä¢ Validation Loss: 0.3220
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3220, best: 0.3192)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 100/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2573
  ‚Ä¢ Validation Loss: 0.3241
  ‚Ä¢ Learning Rate: 0.000005
   üíæ Periodic checkpoint saved: epoch_100.pth
    No improvement (current: 0.3241, best: 0.3192)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 101/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2536
  ‚Ä¢ Validation Loss: 0.3217
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3217, best: 0.3192)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 102/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2526
  ‚Ä¢ Validation Loss: 0.3252
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3252, best: 0.3192)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 103/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2584
  ‚Ä¢ Validation Loss: 0.3195
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3195, best: 0.3192)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 104/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2547
  ‚Ä¢ Validation Loss: 0.3242
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3242, best: 0.3192)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 105/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2510
  ‚Ä¢ Validation Loss: 0.3198
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3198, best: 0.3192)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 106/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2423
  ‚Ä¢ Validation Loss: 0.3235
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3235, best: 0.3192)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 107/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2417
  ‚Ä¢ Validation Loss: 0.3199
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3199, best: 0.3192)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 108/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2438
  ‚Ä¢ Validation Loss: 0.3188
  ‚Ä¢ Learning Rate: 0.000004
    ‚úì New best checkpoint saved! Val loss: 0.3188
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 109/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2574
  ‚Ä¢ Validation Loss: 0.3183
  ‚Ä¢ Learning Rate: 0.000004
    ‚úì New best checkpoint saved! Val loss: 0.3183
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 110/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2439
  ‚Ä¢ Validation Loss: 0.3207
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3207, best: 0.3183)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 111/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2512
  ‚Ä¢ Validation Loss: 0.3216
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3216, best: 0.3183)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 112/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2449
  ‚Ä¢ Validation Loss: 0.3188
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3188, best: 0.3183)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 113/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2505
  ‚Ä¢ Validation Loss: 0.3187
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3187, best: 0.3183)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 114/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2419
  ‚Ä¢ Validation Loss: 0.3193
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3193, best: 0.3183)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 115/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2381
  ‚Ä¢ Validation Loss: 0.3169
  ‚Ä¢ Learning Rate: 0.000003
    ‚úì New best checkpoint saved! Val loss: 0.3169
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 116/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2386
  ‚Ä¢ Validation Loss: 0.3177
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3177, best: 0.3169)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 117/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2457
  ‚Ä¢ Validation Loss: 0.3193
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3193, best: 0.3169)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 118/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2369
  ‚Ä¢ Validation Loss: 0.3192
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3192, best: 0.3169)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 119/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2443
  ‚Ä¢ Validation Loss: 0.3182
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3182, best: 0.3169)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 120/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2375
  ‚Ä¢ Validation Loss: 0.3182
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3182, best: 0.3169)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 121/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2378
  ‚Ä¢ Validation Loss: 0.3201
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3201, best: 0.3169)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 122/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2422
  ‚Ä¢ Validation Loss: 0.3181
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3181, best: 0.3169)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 123/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2461
  ‚Ä¢ Validation Loss: 0.3180
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3180, best: 0.3169)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 124/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2380
  ‚Ä¢ Validation Loss: 0.3155
  ‚Ä¢ Learning Rate: 0.000002
    ‚úì New best checkpoint saved! Val loss: 0.3155
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 125/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2310
  ‚Ä¢ Validation Loss: 0.3162
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3162, best: 0.3155)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 126/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2289
  ‚Ä¢ Validation Loss: 0.3174
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3174, best: 0.3155)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 127/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2363
  ‚Ä¢ Validation Loss: 0.3158
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3158, best: 0.3155)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 128/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2322
  ‚Ä¢ Validation Loss: 0.3176
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3176, best: 0.3155)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 129/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2404
  ‚Ä¢ Validation Loss: 0.3156
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3156, best: 0.3155)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 130/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2389
  ‚Ä¢ Validation Loss: 0.3161
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3161, best: 0.3155)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 131/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2293
  ‚Ä¢ Validation Loss: 0.3168
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3168, best: 0.3155)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 132/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2491
  ‚Ä¢ Validation Loss: 0.3170
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3170, best: 0.3155)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 133/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2297
  ‚Ä¢ Validation Loss: 0.3168
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3168, best: 0.3155)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 134/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2396
  ‚Ä¢ Validation Loss: 0.3157
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3157, best: 0.3155)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 135/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2273
  ‚Ä¢ Validation Loss: 0.3169
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3169, best: 0.3155)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 136/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2405
  ‚Ä¢ Validation Loss: 0.3177
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3177, best: 0.3155)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 137/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2354
  ‚Ä¢ Validation Loss: 0.3166
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3166, best: 0.3155)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 138/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2369
  ‚Ä¢ Validation Loss: 0.3164
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3164, best: 0.3155)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 139/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2314
  ‚Ä¢ Validation Loss: 0.3177
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3177, best: 0.3155)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 140/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2358
  ‚Ä¢ Validation Loss: 0.3169
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3169, best: 0.3155)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 141/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2369
  ‚Ä¢ Validation Loss: 0.3160
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3160, best: 0.3155)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 142/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2303
  ‚Ä¢ Validation Loss: 0.3160
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3160, best: 0.3155)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 143/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2396
  ‚Ä¢ Validation Loss: 0.3160
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3160, best: 0.3155)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 144/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2391
  ‚Ä¢ Validation Loss: 0.3162
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3162, best: 0.3155)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 145/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2321
  ‚Ä¢ Validation Loss: 0.3164
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3164, best: 0.3155)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 146/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2366
  ‚Ä¢ Validation Loss: 0.3163
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3163, best: 0.3155)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 147/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2359
  ‚Ä¢ Validation Loss: 0.3163
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3163, best: 0.3155)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 148/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2271
  ‚Ä¢ Validation Loss: 0.3163
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3163, best: 0.3155)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 149/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2468
  ‚Ä¢ Validation Loss: 0.3163
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3163, best: 0.3155)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 150/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2323
  ‚Ä¢ Validation Loss: 0.3163
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3163, best: 0.3155)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 151/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2450
  ‚Ä¢ Validation Loss: 0.3325
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3325, best: 0.3155)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 152/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2537
  ‚Ä¢ Validation Loss: 0.3305
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3305, best: 0.3155)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 153/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2557
  ‚Ä¢ Validation Loss: 0.3237
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3237, best: 0.3155)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 154/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2496
  ‚Ä¢ Validation Loss: 0.3209
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3209, best: 0.3155)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 155/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2505
  ‚Ä¢ Validation Loss: 0.3258
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3258, best: 0.3155)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 156/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2538
  ‚Ä¢ Validation Loss: 0.3212
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3212, best: 0.3155)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 157/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2637
  ‚Ä¢ Validation Loss: 0.3278
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3278, best: 0.3155)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 158/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2590
  ‚Ä¢ Validation Loss: 0.3200
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3200, best: 0.3155)
    ‚ö† No improvement for 34 epochs (patience: 150, remaining: 116)

EPOCH 159/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2528
  ‚Ä¢ Validation Loss: 0.3192
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3192, best: 0.3155)
    ‚ö† No improvement for 35 epochs (patience: 150, remaining: 115)

EPOCH 160/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2463
  ‚Ä¢ Validation Loss: 0.3238
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3238, best: 0.3155)
    ‚ö† No improvement for 36 epochs (patience: 150, remaining: 114)

EPOCH 161/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2541
  ‚Ä¢ Validation Loss: 0.3330
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3330, best: 0.3155)
    ‚ö† No improvement for 37 epochs (patience: 150, remaining: 113)

EPOCH 162/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2543
  ‚Ä¢ Validation Loss: 0.3231
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3231, best: 0.3155)
    ‚ö† No improvement for 38 epochs (patience: 150, remaining: 112)

EPOCH 163/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2492
  ‚Ä¢ Validation Loss: 0.3169
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3169, best: 0.3155)
    ‚ö† No improvement for 39 epochs (patience: 150, remaining: 111)

EPOCH 164/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2574
  ‚Ä¢ Validation Loss: 0.3229
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3229, best: 0.3155)
    ‚ö† No improvement for 40 epochs (patience: 150, remaining: 110)

EPOCH 165/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2515
  ‚Ä¢ Validation Loss: 0.3215
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3215, best: 0.3155)
    ‚ö† No improvement for 41 epochs (patience: 150, remaining: 109)

EPOCH 166/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2584
  ‚Ä¢ Validation Loss: 0.3281
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3281, best: 0.3155)
    ‚ö† No improvement for 42 epochs (patience: 150, remaining: 108)

EPOCH 167/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2491
  ‚Ä¢ Validation Loss: 0.3205
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3205, best: 0.3155)
    ‚ö† No improvement for 43 epochs (patience: 150, remaining: 107)

EPOCH 168/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2541
  ‚Ä¢ Validation Loss: 0.3201
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3201, best: 0.3155)
    ‚ö† No improvement for 44 epochs (patience: 150, remaining: 106)

EPOCH 169/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2498
  ‚Ä¢ Validation Loss: 0.3231
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3231, best: 0.3155)
    ‚ö† No improvement for 45 epochs (patience: 150, remaining: 105)

EPOCH 170/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2436
  ‚Ä¢ Validation Loss: 0.3144
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.3144
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 171/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2507
  ‚Ä¢ Validation Loss: 0.3212
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3212, best: 0.3144)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 172/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2512
  ‚Ä¢ Validation Loss: 0.3267
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3267, best: 0.3144)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 173/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2418
  ‚Ä¢ Validation Loss: 0.3240
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3240, best: 0.3144)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 174/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2504
  ‚Ä¢ Validation Loss: 0.3227
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3227, best: 0.3144)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 175/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2494
  ‚Ä¢ Validation Loss: 0.3195
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3195, best: 0.3144)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 176/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2435
  ‚Ä¢ Validation Loss: 0.3222
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3222, best: 0.3144)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 177/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2422
  ‚Ä¢ Validation Loss: 0.3177
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3177, best: 0.3144)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 178/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2447
  ‚Ä¢ Validation Loss: 0.3167
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3167, best: 0.3144)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 179/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2411
  ‚Ä¢ Validation Loss: 0.3208
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3208, best: 0.3144)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 180/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2388
  ‚Ä¢ Validation Loss: 0.3211
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3211, best: 0.3144)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 181/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2380
  ‚Ä¢ Validation Loss: 0.3227
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3227, best: 0.3144)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 182/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2461
  ‚Ä¢ Validation Loss: 0.3163
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3163, best: 0.3144)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 183/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2401
  ‚Ä¢ Validation Loss: 0.3195
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3195, best: 0.3144)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 184/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2449
  ‚Ä¢ Validation Loss: 0.3185
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3185, best: 0.3144)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 185/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2441
  ‚Ä¢ Validation Loss: 0.3173
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3173, best: 0.3144)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 186/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2489
  ‚Ä¢ Validation Loss: 0.3244
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3244, best: 0.3144)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 187/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2373
  ‚Ä¢ Validation Loss: 0.3179
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3179, best: 0.3144)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 188/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2409
  ‚Ä¢ Validation Loss: 0.3254
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3254, best: 0.3144)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 189/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2451
  ‚Ä¢ Validation Loss: 0.3156
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3156, best: 0.3144)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 190/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2344
  ‚Ä¢ Validation Loss: 0.3251
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3251, best: 0.3144)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 191/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2394
  ‚Ä¢ Validation Loss: 0.3157
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3157, best: 0.3144)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 192/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2362
  ‚Ä¢ Validation Loss: 0.3173
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3173, best: 0.3144)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 193/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2359
  ‚Ä¢ Validation Loss: 0.3163
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3163, best: 0.3144)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 194/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2342
  ‚Ä¢ Validation Loss: 0.3209
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3209, best: 0.3144)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 195/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2341
  ‚Ä¢ Validation Loss: 0.3150
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3150, best: 0.3144)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 196/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2272
  ‚Ä¢ Validation Loss: 0.3187
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3187, best: 0.3144)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 197/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2385
  ‚Ä¢ Validation Loss: 0.3163
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3163, best: 0.3144)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 198/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2406
  ‚Ä¢ Validation Loss: 0.3185
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3185, best: 0.3144)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 199/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2377
  ‚Ä¢ Validation Loss: 0.3188
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3188, best: 0.3144)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 200/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2365
  ‚Ä¢ Validation Loss: 0.3156
  ‚Ä¢ Learning Rate: 0.000009
   üíæ Periodic checkpoint saved: epoch_200.pth
    No improvement (current: 0.3156, best: 0.3144)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 201/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2326
  ‚Ä¢ Validation Loss: 0.3153
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3153, best: 0.3144)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 202/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2448
  ‚Ä¢ Validation Loss: 0.3156
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3156, best: 0.3144)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 203/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2278
  ‚Ä¢ Validation Loss: 0.3198
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3198, best: 0.3144)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 204/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2258
  ‚Ä¢ Validation Loss: 0.3146
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3146, best: 0.3144)
    ‚ö† No improvement for 34 epochs (patience: 150, remaining: 116)

EPOCH 205/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2419
  ‚Ä¢ Validation Loss: 0.3178
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3178, best: 0.3144)
    ‚ö† No improvement for 35 epochs (patience: 150, remaining: 115)

EPOCH 206/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2400
  ‚Ä¢ Validation Loss: 0.3143
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3143
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 207/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2320
  ‚Ä¢ Validation Loss: 0.3157
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3157, best: 0.3143)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 208/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2393
  ‚Ä¢ Validation Loss: 0.3165
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3165, best: 0.3143)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 209/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2308
  ‚Ä¢ Validation Loss: 0.3127
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3127
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 210/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2329
  ‚Ä¢ Validation Loss: 0.3122
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3122
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 211/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2255
  ‚Ä¢ Validation Loss: 0.3156
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3156, best: 0.3122)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 212/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2232
  ‚Ä¢ Validation Loss: 0.3203
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3203, best: 0.3122)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 213/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2394
  ‚Ä¢ Validation Loss: 0.3152
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3152, best: 0.3122)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 214/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2361
  ‚Ä¢ Validation Loss: 0.3186
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3186, best: 0.3122)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 215/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2247
  ‚Ä¢ Validation Loss: 0.3142
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3142, best: 0.3122)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 216/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2311
  ‚Ä¢ Validation Loss: 0.3134
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3134, best: 0.3122)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 217/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2241
  ‚Ä¢ Validation Loss: 0.3259
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3259, best: 0.3122)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 218/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2317
  ‚Ä¢ Validation Loss: 0.3129
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3129, best: 0.3122)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 219/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2232
  ‚Ä¢ Validation Loss: 0.3197
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3197, best: 0.3122)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 220/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2268
  ‚Ä¢ Validation Loss: 0.3162
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3162, best: 0.3122)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 221/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2242
  ‚Ä¢ Validation Loss: 0.3157
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3157, best: 0.3122)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 222/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2414
  ‚Ä¢ Validation Loss: 0.3133
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3133, best: 0.3122)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 223/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2237
  ‚Ä¢ Validation Loss: 0.3201
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3201, best: 0.3122)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 224/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2342
  ‚Ä¢ Validation Loss: 0.3152
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3152, best: 0.3122)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 225/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2337
  ‚Ä¢ Validation Loss: 0.3125
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3125, best: 0.3122)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 226/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2299
  ‚Ä¢ Validation Loss: 0.3174
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3174, best: 0.3122)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 227/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2293
  ‚Ä¢ Validation Loss: 0.3175
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3175, best: 0.3122)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 228/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2264
  ‚Ä¢ Validation Loss: 0.3151
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3151, best: 0.3122)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 229/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2288
  ‚Ä¢ Validation Loss: 0.3118
  ‚Ä¢ Learning Rate: 0.000007
    ‚úì New best checkpoint saved! Val loss: 0.3118
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 230/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2249
  ‚Ä¢ Validation Loss: 0.3149
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3149, best: 0.3118)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 231/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2346
  ‚Ä¢ Validation Loss: 0.3147
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3147, best: 0.3118)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 232/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2222
  ‚Ä¢ Validation Loss: 0.3152
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3152, best: 0.3118)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 233/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2271
  ‚Ä¢ Validation Loss: 0.3130
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3130, best: 0.3118)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 234/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2215
  ‚Ä¢ Validation Loss: 0.3167
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3167, best: 0.3118)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 235/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2313
  ‚Ä¢ Validation Loss: 0.3123
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3123, best: 0.3118)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 236/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2248
  ‚Ä¢ Validation Loss: 0.3146
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3146, best: 0.3118)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 237/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2298
  ‚Ä¢ Validation Loss: 0.3133
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3133, best: 0.3118)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 238/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2217
  ‚Ä¢ Validation Loss: 0.3109
  ‚Ä¢ Learning Rate: 0.000006
    ‚úì New best checkpoint saved! Val loss: 0.3109
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 239/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2264
  ‚Ä¢ Validation Loss: 0.3122
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3122, best: 0.3109)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 240/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2191
  ‚Ä¢ Validation Loss: 0.3175
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3175, best: 0.3109)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 241/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2272
  ‚Ä¢ Validation Loss: 0.3139
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3139, best: 0.3109)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 242/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2319
  ‚Ä¢ Validation Loss: 0.3140
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3140, best: 0.3109)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 243/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2257
  ‚Ä¢ Validation Loss: 0.3141
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3141, best: 0.3109)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 244/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2216
  ‚Ä¢ Validation Loss: 0.3124
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3124, best: 0.3109)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 245/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2315
  ‚Ä¢ Validation Loss: 0.3142
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3142, best: 0.3109)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 246/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2287
  ‚Ä¢ Validation Loss: 0.3140
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3140, best: 0.3109)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 247/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2230
  ‚Ä¢ Validation Loss: 0.3134
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3134, best: 0.3109)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 248/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2291
  ‚Ä¢ Validation Loss: 0.3135
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3135, best: 0.3109)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 249/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2226
  ‚Ä¢ Validation Loss: 0.3147
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3147, best: 0.3109)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 250/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2243
  ‚Ä¢ Validation Loss: 0.3165
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3165, best: 0.3109)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 251/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2298
  ‚Ä¢ Validation Loss: 0.3145
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3145, best: 0.3109)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 252/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2290
  ‚Ä¢ Validation Loss: 0.3122
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3122, best: 0.3109)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 253/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2278
  ‚Ä¢ Validation Loss: 0.3112
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3112, best: 0.3109)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 254/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2230
  ‚Ä¢ Validation Loss: 0.3147
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3147, best: 0.3109)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 255/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2210
  ‚Ä¢ Validation Loss: 0.3136
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3136, best: 0.3109)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 256/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2272
  ‚Ä¢ Validation Loss: 0.3149
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3149, best: 0.3109)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 257/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2226
  ‚Ä¢ Validation Loss: 0.3151
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3151, best: 0.3109)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 258/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2186
  ‚Ä¢ Validation Loss: 0.3128
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3128, best: 0.3109)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 259/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2242
  ‚Ä¢ Validation Loss: 0.3150
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3150, best: 0.3109)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 260/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2374
  ‚Ä¢ Validation Loss: 0.3105
  ‚Ä¢ Learning Rate: 0.000004
    ‚úì New best checkpoint saved! Val loss: 0.3105
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 261/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2222
  ‚Ä¢ Validation Loss: 0.3123
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3123, best: 0.3105)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 262/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2223
  ‚Ä¢ Validation Loss: 0.3147
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3147, best: 0.3105)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 263/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2153
  ‚Ä¢ Validation Loss: 0.3119
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3119, best: 0.3105)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 264/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2210
  ‚Ä¢ Validation Loss: 0.3114
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3114, best: 0.3105)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 265/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2211
  ‚Ä¢ Validation Loss: 0.3127
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3127, best: 0.3105)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 266/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2147
  ‚Ä¢ Validation Loss: 0.3112
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3112, best: 0.3105)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 267/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2235
  ‚Ä¢ Validation Loss: 0.3131
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3131, best: 0.3105)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 268/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2160
  ‚Ä¢ Validation Loss: 0.3127
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3127, best: 0.3105)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 269/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2200
  ‚Ä¢ Validation Loss: 0.3147
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3147, best: 0.3105)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 270/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2276
  ‚Ä¢ Validation Loss: 0.3131
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3131, best: 0.3105)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 271/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2172
  ‚Ä¢ Validation Loss: 0.3110
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3110, best: 0.3105)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 272/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2213
  ‚Ä¢ Validation Loss: 0.3118
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3118, best: 0.3105)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 273/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2183
  ‚Ä¢ Validation Loss: 0.3137
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3137, best: 0.3105)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 274/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2197
  ‚Ä¢ Validation Loss: 0.3127
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3127, best: 0.3105)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 275/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2291
  ‚Ä¢ Validation Loss: 0.3116
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3116, best: 0.3105)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 276/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2294
  ‚Ä¢ Validation Loss: 0.3106
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3106, best: 0.3105)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 277/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2219
  ‚Ä¢ Validation Loss: 0.3127
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3127, best: 0.3105)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 278/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2176
  ‚Ä¢ Validation Loss: 0.3123
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3123, best: 0.3105)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 279/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2212
  ‚Ä¢ Validation Loss: 0.3138
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3138, best: 0.3105)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 280/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2226
  ‚Ä¢ Validation Loss: 0.3096
  ‚Ä¢ Learning Rate: 0.000003
    ‚úì New best checkpoint saved! Val loss: 0.3096
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 281/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2193
  ‚Ä¢ Validation Loss: 0.3125
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3125, best: 0.3096)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 282/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2139
  ‚Ä¢ Validation Loss: 0.3123
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3123, best: 0.3096)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 283/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2171
  ‚Ä¢ Validation Loss: 0.3127
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3127, best: 0.3096)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 284/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2194
  ‚Ä¢ Validation Loss: 0.3141
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3141, best: 0.3096)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 285/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2302
  ‚Ä¢ Validation Loss: 0.3096
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3096, best: 0.3096)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 286/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2196
  ‚Ä¢ Validation Loss: 0.3142
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3142, best: 0.3096)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 287/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2103
  ‚Ä¢ Validation Loss: 0.3126
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3126, best: 0.3096)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 288/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2221
  ‚Ä¢ Validation Loss: 0.3125
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3125, best: 0.3096)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 289/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2169
  ‚Ä¢ Validation Loss: 0.3125
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3125, best: 0.3096)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 290/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2196
  ‚Ä¢ Validation Loss: 0.3126
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3126, best: 0.3096)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 291/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2214
  ‚Ä¢ Validation Loss: 0.3135
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3135, best: 0.3096)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 292/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2325
  ‚Ä¢ Validation Loss: 0.3139
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3139, best: 0.3096)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 293/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2212
  ‚Ä¢ Validation Loss: 0.3135
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3135, best: 0.3096)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 294/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2223
  ‚Ä¢ Validation Loss: 0.3113
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3113, best: 0.3096)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 295/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2251
  ‚Ä¢ Validation Loss: 0.3146
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3146, best: 0.3096)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 296/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2250
  ‚Ä¢ Validation Loss: 0.3128
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3128, best: 0.3096)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 297/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2202
  ‚Ä¢ Validation Loss: 0.3148
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3148, best: 0.3096)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 298/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2193
  ‚Ä¢ Validation Loss: 0.3123
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3123, best: 0.3096)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 299/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2167
  ‚Ä¢ Validation Loss: 0.3115
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3115, best: 0.3096)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 300/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2256
  ‚Ä¢ Validation Loss: 0.3134
  ‚Ä¢ Learning Rate: 0.000002
   üíæ Periodic checkpoint saved: epoch_300.pth
    No improvement (current: 0.3134, best: 0.3096)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

================================================================================
TRAINING COMPLETED
================================================================================
Best Val Loss:  0.3096
Total Epochs:   300
Models Saved:   ./Result/a4/Latin14396
TensorBoard:    ./Result/a4/Latin14396/tensorboard_logs
================================================================================

[19:24:24] Training completed. Best val loss: 0.3096

=== TRAINING COMPLETED SUCCESSFULLY ===
Training Finished!

========================================================================
Testing Hybrid2 Baseline Model with EfficientNet-B4 Decoder + Simple Skip Connections: Latin14396
========================================================================
=== Historical Document Segmentation Testing ===

Using 6 classes for manuscript: Latin14396
Model: Hybrid2
Dataset: UDIADS_BIB
Manuscript: Latin14396
Test-Time Augmentation: Enabled
CRF post-processing: Disabled

================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder for Testing
================================================================================
================================================================================
üöÄ EFFICIENTNET-B4 DECODER (Real MBConv Blocks)
================================================================================
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Using MBConv blocks (NOT simple Conv)
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Optional Features:
  ‚Ä¢ Deep Supervision: False
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: False
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: False
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Loaded checkpoint from epoch 279
Best validation loss: 0.3096
  ‚úÖ Model checkpoint loaded successfully (exact match)
Loaded checkpoint: best_model_latest.pth
Namespace(cfg=None, output_dir='./Result/a4/Latin14396', use_baseline=True, decoder='EfficientNet-B4', efficientnet_variant='b4', use_deep_supervision=False, use_cbam=False, use_smart_skip=False, use_cross_attn=False, use_multiscale_agg=False, use_groupnorm=True, use_batchnorm=False, use_pos_embed=True, dataset='UDIADS_BIB', manuscript='Latin14396', udiadsbib_root='../../U-DIADS-Bib-MS_patched', divahisdb_root='../../DivaHisDB', use_patched_data=True, num_classes=6, img_size=224, batch_size=24, is_savenii=True, test_save_dir='../predictions', use_crf=False, deterministic=1, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, use_tta=True)
Testing with checkpoint: best_model_latest.pth
Saving predictions to: ./Result/a4/Latin14396/predictions

=== Starting Testing ===
Dataset: UDIADS_BIB
Model: Hybrid2
Manuscript: Latin14396
Save predictions: True

Starting inference on UDIADS_BIB dataset
Found 1620 patches for Latin14396
Using Test-Time Augmentation (TTA) for improved accuracy
CRF post-processing: Disabled
Processing: 014 (54 patches)
Completed: 014
Processing: 032 (54 patches)
Completed: 032
Processing: 034 (54 patches)
Completed: 034
Processing: 036 (54 patches)
Completed: 036
Processing: 038 (54 patches)
Completed: 038
Processing: 047 (54 patches)
Completed: 047
Processing: 060 (54 patches)
Completed: 060
Processing: 085 (54 patches)
Completed: 085
Processing: 087 (54 patches)
Completed: 087
Processing: 104 (54 patches)
Completed: 104
Processing: 105 (54 patches)
Completed: 105
Processing: 108 (54 patches)
Completed: 108
Processing: 110 (54 patches)
Completed: 110
Processing: 136 (54 patches)
Completed: 136
Processing: 169 (54 patches)
Completed: 169
Processing: 195 (54 patches)
Completed: 195
Processing: 196 (54 patches)
Completed: 196
Processing: 198 (54 patches)
Completed: 198
Processing: 204 (54 patches)
Completed: 204
Processing: 223 (54 patches)
Completed: 223
Processing: 225 (54 patches)
Completed: 225
Processing: 227 (54 patches)
Completed: 227
Processing: 229 (54 patches)
Completed: 229
Processing: 251 (54 patches)
Completed: 251
Processing: 253 (54 patches)
Completed: 253
Processing: 255 (54 patches)
Completed: 255
Processing: 264 (54 patches)
Completed: 264
Processing: 270 (54 patches)
Completed: 270
Processing: 276 (54 patches)
Completed: 276
Processing: 325 (54 patches)
Completed: 325

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9906, Recall=0.9924, F1=0.9915, IoU=0.9832
Paratext       : Precision=0.7319, Recall=0.5260, F1=0.6121, IoU=0.4410
Decoration     : Precision=0.9506, Recall=0.9596, F1=0.9551, IoU=0.9140
Main Text      : Precision=0.8972, Recall=0.9048, F1=0.9010, IoU=0.8198
Title          : Precision=0.9017, Recall=0.8223, F1=0.8602, IoU=0.7547
Chapter Headings: Precision=0.8272, Recall=0.5613, F1=0.6688, IoU=0.5024

Mean metrics:
----------------------------------------
Mean Precision: 0.8832
Mean Recall: 0.7944
Mean F1-Score: 0.8314
Mean IoU: 0.7358

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9906, Recall=0.9924, F1=0.9915, IoU=0.9832
Paratext       : Precision=0.7319, Recall=0.5260, F1=0.6121, IoU=0.4410
Decoration     : Precision=0.9506, Recall=0.9596, F1=0.9551, IoU=0.9140
Main Text      : Precision=0.8972, Recall=0.9048, F1=0.9010, IoU=0.8198
Title          : Precision=0.9017, Recall=0.8223, F1=0.8602, IoU=0.7547
Chapter Headings: Precision=0.8272, Recall=0.5613, F1=0.6688, IoU=0.5024

Mean metrics:
----------------------------------------
Mean Precision: 0.8832
Mean Recall: 0.7944
Mean F1-Score: 0.8314
Mean IoU: 0.7358
Inference completed on 30 images

=== TESTING COMPLETED SUCCESSFULLY ===
Results saved to: ./Result/a4/Latin14396/predictions
==================================================

Calculating average metrics...
Looking for metrics files in: ./Result/a4
  ‚úó Metrics file not found: ./Result/a4/metrics_Latin2.json
  ‚úì Found metrics for Latin14396
  ‚úó Metrics file not found: ./Result/a4/metrics_Latin16746.json
  ‚úó Metrics file not found: ./Result/a4/metrics_Syr341.json

================================================================================
AVERAGE METRICS ACROSS 1 MANUSCRIPT(S)
================================================================================
Manuscripts: Latin14396
Missing: Latin2, Latin16746, Syr341
--------------------------------------------------------------------------------
Mean Precision: 0.8832
Mean Recall:    0.7944
Mean F1-Score:  0.8314
Mean IoU:       0.7358
================================================================================

========================================================================
Training Hybrid2 Baseline Model with EfficientNet-B4 Decoder + Simple Skip Connections: Latin16746
========================================================================
Dataset: U-DIADS-Bib-MS_patched
Architecture: Swin Transformer Encoder ‚Üí 2 Swin Blocks Bottleneck ‚Üí EfficientNet-B4 Decoder
Decoder: EfficientNet-B4 Decoder (Real MBConv blocks)

Components Enabled:
  ‚úì Swin Encoder (4 stages: 96‚Üí192‚Üí384‚Üí768 dim)
  ‚úì Bottleneck: 2 Swin Transformer blocks (768 dim, 24 heads)
  ‚úì EfficientNet-B4 Decoder (MBConv blocks, channels: [256, 128, 64, 32])
  ‚úì Simple Skip Connections
  ‚úì Positional Embeddings (default: enabled)
  ‚úì GroupNorm (default normalization)
  ‚úì Balanced Sampler (oversampling rare classes)
  ‚úì Class-Aware Augmentation

Components Disabled (baseline):
  ‚úó Smart Skip Connections
  ‚úó CBAM Attention
  ‚úó Cross-Attention Bottleneck
  ‚úó BatchNorm
  ‚úó Deep Supervision
  ‚úó Multi-Scale Aggregation
========================================================================
All arguments validated successfully!
Setting random seed to 1234 for reproducible training...
Setting up U-DIADS-Bib dataset...
Using 6 classes for manuscript: Latin16746
‚úì Class-aware augmentation enabled (stronger augmentation for rare classes)
  Rare classes: Paratext, Decoration, Title, Chapter Headings
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin16746/Image/training
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin16746/mask/training_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
Looking for images in: ../../U-DIADS-Bib-MS_patched/Latin16746/Image/validation
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Latin16746/mask/validation_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
Balanced sampler created (continuous rarity-based oversampling).
‚úì Balanced sampler enabled (oversampling rare classes)
================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder
================================================================================
================================================================================
üöÄ EFFICIENTNET-B4 DECODER (Real MBConv Blocks)
================================================================================
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Using MBConv blocks (NOT simple Conv)
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Optional Features:
  ‚Ä¢ Deep Supervision: False
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: False
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: False
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Model moved to CUDA
Model created successfully with 6 classes
DEBUG: args.output_dir = ./Result/a4/Latin16746

=== Starting Training ===
Dataset: UDIADS_BIB
Model: Hybrid2
Batch size: 16
Max epochs: 300
Learning rate: 0.0001


================================================================================
TRAINING CONFIGURATION
================================================================================
Dataset: UDIADS_BIB
Model: Hybrid2
Batch Size: 16
Max Epochs: 300
Learning Rate: 0.0001
Number of Classes: 6
Output Directory: ./Result/a4/Latin16746
Early Stopping Patience: 150 epochs
================================================================================

üìä Dataset Statistics:
   - Training samples: 540
   - Validation samples: 540
   - Batch size: 16
   - Steps per epoch: 34


================================================================================
COMPUTING CLASS WEIGHTS
================================================================================
Raw ENS weights: [9.99999990e-05 1.00009434e-04 9.99999990e-05 9.99999990e-05
 1.00760331e-04 9.99999990e-05]

Class Distribution:
Class                Pixels          Frequency       Weight         
-----------------------------------------------------------------
0                        23,958,162        88.4227%         0.9987
1                            92,681         0.3421%         0.9988
2                           683,272         2.5218%         0.9987
3                         2,030,719         7.4948%         0.9987
4                            48,865         0.1803%         1.0063
5                           281,341         1.0383%         0.9987

Total pixels: 27,095,040.0
Beta: 0.9999
Smoothing: 0.0
Weight range: [0.9987, 1.0063]
================================================================================
üìà Class weights computed with ENS method (smoothing=0.1)
   Final weights: [0.9987187 0.9988129 0.9987187 0.9987187 1.0063123 0.9987187]

‚úì Loss functions created: CE (weighted, label_smoothing=0.1), Focal (Œ≥=2.0), Dice
üöÄ Hybrid2 Best Practice: Differential Learning Rates
  üìä Encoder LR:     0.000010 (10x smaller, 119 params)
  üìä Bottleneck LR:  0.000050 (5x smaller, 26 params)
  üìä Decoder LR:     0.000100 (base LR, 139 params)
  ‚öôÔ∏è  Scheduler: CosineAnnealingWarmRestarts (T_0=50, T_mult=2)
  ‚öôÔ∏è  Weight decay: Encoder=1e-3, Bottleneck=5e-3, Decoder=1e-2

üîç Checking for checkpoint at: ./Result/a4/Latin16746/best_model_latest.pth
   Absolute path: /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid/Result/a4/Latin16746/best_model_latest.pth
   File exists: False

================================================================================
STARTING TRAINING
================================================================================
Early stopping patience: 150 epochs
Learning rate scheduler: CosineAnnealingWarmRestarts (better convergence for transformers)
================================================================================

EPOCH 1/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6583
  ‚Ä¢ Validation Loss: 0.5450
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.5450
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 2/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5168
  ‚Ä¢ Validation Loss: 0.4888
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4888
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 3/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4652
  ‚Ä¢ Validation Loss: 0.4539
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4539
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 4/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4337
  ‚Ä¢ Validation Loss: 0.4331
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4331
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 5/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4160
  ‚Ä¢ Validation Loss: 0.4157
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4157
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 6/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3967
  ‚Ä¢ Validation Loss: 0.4043
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4043
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 7/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3812
  ‚Ä¢ Validation Loss: 0.3991
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.3991
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 8/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3702
  ‚Ä¢ Validation Loss: 0.3870
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.3870
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 9/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3621
  ‚Ä¢ Validation Loss: 0.3826
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3826
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 10/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3568
  ‚Ä¢ Validation Loss: 0.3751
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3751
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 11/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3440
  ‚Ä¢ Validation Loss: 0.3735
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3735
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 12/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3428
  ‚Ä¢ Validation Loss: 0.3662
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3662
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 13/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3343
  ‚Ä¢ Validation Loss: 0.3617
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3617
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 14/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3276
  ‚Ä¢ Validation Loss: 0.3605
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3605
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 15/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3220
  ‚Ä¢ Validation Loss: 0.3557
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3557
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 16/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3232
  ‚Ä¢ Validation Loss: 0.3560
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3560, best: 0.3557)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 17/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3175
  ‚Ä¢ Validation Loss: 0.3536
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3536
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 18/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3142
  ‚Ä¢ Validation Loss: 0.3477
  ‚Ä¢ Learning Rate: 0.000007
    ‚úì New best checkpoint saved! Val loss: 0.3477
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 19/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3113
  ‚Ä¢ Validation Loss: 0.3492
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3492, best: 0.3477)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 20/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3044
  ‚Ä¢ Validation Loss: 0.3400
  ‚Ä¢ Learning Rate: 0.000007
    ‚úì New best checkpoint saved! Val loss: 0.3400
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 21/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2999
  ‚Ä¢ Validation Loss: 0.3473
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3473, best: 0.3400)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 22/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3015
  ‚Ä¢ Validation Loss: 0.3443
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3443, best: 0.3400)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 23/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3011
  ‚Ä¢ Validation Loss: 0.3364
  ‚Ä¢ Learning Rate: 0.000006
    ‚úì New best checkpoint saved! Val loss: 0.3364
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 24/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2987
  ‚Ä¢ Validation Loss: 0.3360
  ‚Ä¢ Learning Rate: 0.000006
    ‚úì New best checkpoint saved! Val loss: 0.3360
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 25/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2886
  ‚Ä¢ Validation Loss: 0.3391
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3391, best: 0.3360)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 26/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2943
  ‚Ä¢ Validation Loss: 0.3303
  ‚Ä¢ Learning Rate: 0.000005
    ‚úì New best checkpoint saved! Val loss: 0.3303
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 27/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2822
  ‚Ä¢ Validation Loss: 0.3301
  ‚Ä¢ Learning Rate: 0.000005
    ‚úì New best checkpoint saved! Val loss: 0.3301
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 28/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2769
  ‚Ä¢ Validation Loss: 0.3315
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3315, best: 0.3301)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 29/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2800
  ‚Ä¢ Validation Loss: 0.3285
  ‚Ä¢ Learning Rate: 0.000004
    ‚úì New best checkpoint saved! Val loss: 0.3285
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 30/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2827
  ‚Ä¢ Validation Loss: 0.3294
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3294, best: 0.3285)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 31/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2732
  ‚Ä¢ Validation Loss: 0.3293
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3293, best: 0.3285)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 32/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2706
  ‚Ä¢ Validation Loss: 0.3262
  ‚Ä¢ Learning Rate: 0.000003
    ‚úì New best checkpoint saved! Val loss: 0.3262
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 33/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2728
  ‚Ä¢ Validation Loss: 0.3247
  ‚Ä¢ Learning Rate: 0.000003
    ‚úì New best checkpoint saved! Val loss: 0.3247
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 34/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2677
  ‚Ä¢ Validation Loss: 0.3227
  ‚Ä¢ Learning Rate: 0.000003
    ‚úì New best checkpoint saved! Val loss: 0.3227
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 35/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2710
  ‚Ä¢ Validation Loss: 0.3270
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3270, best: 0.3227)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 36/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2724
  ‚Ä¢ Validation Loss: 0.3250
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3250, best: 0.3227)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 37/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2614
  ‚Ä¢ Validation Loss: 0.3208
  ‚Ä¢ Learning Rate: 0.000002
    ‚úì New best checkpoint saved! Val loss: 0.3208
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 38/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2665
  ‚Ä¢ Validation Loss: 0.3232
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3232, best: 0.3208)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 39/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2545
  ‚Ä¢ Validation Loss: 0.3216
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3216, best: 0.3208)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 40/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2665
  ‚Ä¢ Validation Loss: 0.3199
  ‚Ä¢ Learning Rate: 0.000001
    ‚úì New best checkpoint saved! Val loss: 0.3199
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 41/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2650
  ‚Ä¢ Validation Loss: 0.3205
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3205, best: 0.3199)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 42/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2589
  ‚Ä¢ Validation Loss: 0.3198
  ‚Ä¢ Learning Rate: 0.000001
    ‚úì New best checkpoint saved! Val loss: 0.3198
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 43/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2627
  ‚Ä¢ Validation Loss: 0.3186
  ‚Ä¢ Learning Rate: 0.000001
    ‚úì New best checkpoint saved! Val loss: 0.3186
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 44/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2602
  ‚Ä¢ Validation Loss: 0.3187
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3187, best: 0.3186)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 45/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2627
  ‚Ä¢ Validation Loss: 0.3189
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3189, best: 0.3186)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 46/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2538
  ‚Ä¢ Validation Loss: 0.3194
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3194, best: 0.3186)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 47/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2606
  ‚Ä¢ Validation Loss: 0.3189
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3189, best: 0.3186)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 48/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2502
  ‚Ä¢ Validation Loss: 0.3185
  ‚Ä¢ Learning Rate: 0.000000
    ‚úì New best checkpoint saved! Val loss: 0.3185
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 49/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2626
  ‚Ä¢ Validation Loss: 0.3185
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3185, best: 0.3185)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 50/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2567
  ‚Ä¢ Validation Loss: 0.3187
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3187, best: 0.3185)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 51/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2795
  ‚Ä¢ Validation Loss: 0.3276
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3276, best: 0.3185)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 52/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2710
  ‚Ä¢ Validation Loss: 0.3216
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3216, best: 0.3185)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 53/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2748
  ‚Ä¢ Validation Loss: 0.3313
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3313, best: 0.3185)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 54/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2786
  ‚Ä¢ Validation Loss: 0.3270
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3270, best: 0.3185)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 55/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2738
  ‚Ä¢ Validation Loss: 0.3233
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3233, best: 0.3185)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 56/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2633
  ‚Ä¢ Validation Loss: 0.3211
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3211, best: 0.3185)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 57/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2664
  ‚Ä¢ Validation Loss: 0.3244
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3244, best: 0.3185)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 58/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2624
  ‚Ä¢ Validation Loss: 0.3268
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3268, best: 0.3185)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 59/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2615
  ‚Ä¢ Validation Loss: 0.3194
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3194, best: 0.3185)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 60/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2644
  ‚Ä¢ Validation Loss: 0.3193
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3193, best: 0.3185)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 61/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2560
  ‚Ä¢ Validation Loss: 0.3221
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3221, best: 0.3185)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 62/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2581
  ‚Ä¢ Validation Loss: 0.3197
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3197, best: 0.3185)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 63/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2544
  ‚Ä¢ Validation Loss: 0.3250
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3250, best: 0.3185)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 64/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2585
  ‚Ä¢ Validation Loss: 0.3144
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.3144
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 65/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2469
  ‚Ä¢ Validation Loss: 0.3181
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3181, best: 0.3144)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 66/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2410
  ‚Ä¢ Validation Loss: 0.3142
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3142
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 67/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2486
  ‚Ä¢ Validation Loss: 0.3140
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3140
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 68/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2539
  ‚Ä¢ Validation Loss: 0.3229
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3229, best: 0.3140)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 69/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2537
  ‚Ä¢ Validation Loss: 0.3178
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3178, best: 0.3140)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 70/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2432
  ‚Ä¢ Validation Loss: 0.3163
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3163, best: 0.3140)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 71/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2480
  ‚Ä¢ Validation Loss: 0.3082
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3082
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 72/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2418
  ‚Ä¢ Validation Loss: 0.3084
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3084, best: 0.3082)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 73/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2478
  ‚Ä¢ Validation Loss: 0.3072
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3072
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 74/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2495
  ‚Ä¢ Validation Loss: 0.3157
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3157, best: 0.3072)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 75/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2302
  ‚Ä¢ Validation Loss: 0.3076
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3076, best: 0.3072)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 76/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2479
  ‚Ä¢ Validation Loss: 0.3118
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3118, best: 0.3072)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 77/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2290
  ‚Ä¢ Validation Loss: 0.3062
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3062
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 78/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2429
  ‚Ä¢ Validation Loss: 0.3052
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3052
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 79/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2377
  ‚Ä¢ Validation Loss: 0.3136
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3136, best: 0.3052)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 80/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2378
  ‚Ä¢ Validation Loss: 0.3066
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3066, best: 0.3052)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 81/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2290
  ‚Ä¢ Validation Loss: 0.3073
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3073, best: 0.3052)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 82/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2451
  ‚Ä¢ Validation Loss: 0.3109
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3109, best: 0.3052)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 83/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2227
  ‚Ä¢ Validation Loss: 0.3050
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3050
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 84/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2396
  ‚Ä¢ Validation Loss: 0.3120
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3120, best: 0.3050)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 85/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2288
  ‚Ä¢ Validation Loss: 0.3079
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3079, best: 0.3050)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 86/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2299
  ‚Ä¢ Validation Loss: 0.3057
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3057, best: 0.3050)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 87/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2264
  ‚Ä¢ Validation Loss: 0.3080
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3080, best: 0.3050)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 88/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2245
  ‚Ä¢ Validation Loss: 0.3046
  ‚Ä¢ Learning Rate: 0.000007
    ‚úì New best checkpoint saved! Val loss: 0.3046
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 89/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2269
  ‚Ä¢ Validation Loss: 0.3007
  ‚Ä¢ Learning Rate: 0.000007
    ‚úì New best checkpoint saved! Val loss: 0.3007
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 90/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2199
  ‚Ä¢ Validation Loss: 0.3012
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3012, best: 0.3007)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 91/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2228
  ‚Ä¢ Validation Loss: 0.3003
  ‚Ä¢ Learning Rate: 0.000007
    ‚úì New best checkpoint saved! Val loss: 0.3003
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 92/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2235
  ‚Ä¢ Validation Loss: 0.3005
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3005, best: 0.3003)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 93/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2267
  ‚Ä¢ Validation Loss: 0.3049
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3049, best: 0.3003)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 94/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2201
  ‚Ä¢ Validation Loss: 0.3038
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3038, best: 0.3003)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 95/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2237
  ‚Ä¢ Validation Loss: 0.3034
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3034, best: 0.3003)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 96/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2271
  ‚Ä¢ Validation Loss: 0.3031
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3031, best: 0.3003)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 97/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2208
  ‚Ä¢ Validation Loss: 0.3010
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3010, best: 0.3003)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 98/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2187
  ‚Ä¢ Validation Loss: 0.3055
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3055, best: 0.3003)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 99/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2142
  ‚Ä¢ Validation Loss: 0.3009
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3009, best: 0.3003)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 100/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2232
  ‚Ä¢ Validation Loss: 0.3051
  ‚Ä¢ Learning Rate: 0.000005
   üíæ Periodic checkpoint saved: epoch_100.pth
    No improvement (current: 0.3051, best: 0.3003)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 101/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2174
  ‚Ä¢ Validation Loss: 0.2985
  ‚Ä¢ Learning Rate: 0.000005
    ‚úì New best checkpoint saved! Val loss: 0.2985
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 102/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2195
  ‚Ä¢ Validation Loss: 0.3021
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3021, best: 0.2985)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 103/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2111
  ‚Ä¢ Validation Loss: 0.2996
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.2996, best: 0.2985)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 104/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2153
  ‚Ä¢ Validation Loss: 0.2994
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.2994, best: 0.2985)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 105/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2178
  ‚Ä¢ Validation Loss: 0.3062
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3062, best: 0.2985)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 106/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2128
  ‚Ä¢ Validation Loss: 0.3027
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3027, best: 0.2985)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 107/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2070
  ‚Ä¢ Validation Loss: 0.2997
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.2997, best: 0.2985)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 108/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2151
  ‚Ä¢ Validation Loss: 0.3010
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3010, best: 0.2985)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 109/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2177
  ‚Ä¢ Validation Loss: 0.3021
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3021, best: 0.2985)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 110/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2199
  ‚Ä¢ Validation Loss: 0.2977
  ‚Ä¢ Learning Rate: 0.000004
    ‚úì New best checkpoint saved! Val loss: 0.2977
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 111/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2164
  ‚Ä¢ Validation Loss: 0.3001
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3001, best: 0.2977)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 112/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2068
  ‚Ä¢ Validation Loss: 0.2996
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.2996, best: 0.2977)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 113/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2109
  ‚Ä¢ Validation Loss: 0.2998
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.2998, best: 0.2977)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 114/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2113
  ‚Ä¢ Validation Loss: 0.3008
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3008, best: 0.2977)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 115/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2126
  ‚Ä¢ Validation Loss: 0.2997
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.2997, best: 0.2977)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 116/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2116
  ‚Ä¢ Validation Loss: 0.3012
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3012, best: 0.2977)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 117/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2156
  ‚Ä¢ Validation Loss: 0.2960
  ‚Ä¢ Learning Rate: 0.000003
    ‚úì New best checkpoint saved! Val loss: 0.2960
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 118/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2096
  ‚Ä¢ Validation Loss: 0.2993
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.2993, best: 0.2960)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 119/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2039
  ‚Ä¢ Validation Loss: 0.2949
  ‚Ä¢ Learning Rate: 0.000002
    ‚úì New best checkpoint saved! Val loss: 0.2949
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 120/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2051
  ‚Ä¢ Validation Loss: 0.2994
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2994, best: 0.2949)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 121/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2054
  ‚Ä¢ Validation Loss: 0.2987
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2987, best: 0.2949)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 122/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2182
  ‚Ä¢ Validation Loss: 0.2979
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2979, best: 0.2949)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 123/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2040
  ‚Ä¢ Validation Loss: 0.2965
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2965, best: 0.2949)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 124/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2031
  ‚Ä¢ Validation Loss: 0.2976
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2976, best: 0.2949)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 125/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2068
  ‚Ä¢ Validation Loss: 0.2970
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2970, best: 0.2949)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 126/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2079
  ‚Ä¢ Validation Loss: 0.2942
  ‚Ä¢ Learning Rate: 0.000002
    ‚úì New best checkpoint saved! Val loss: 0.2942
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 127/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2046
  ‚Ä¢ Validation Loss: 0.2949
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.2949, best: 0.2942)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 128/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2069
  ‚Ä¢ Validation Loss: 0.2953
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.2953, best: 0.2942)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 129/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2052
  ‚Ä¢ Validation Loss: 0.2986
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.2986, best: 0.2942)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 130/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2115
  ‚Ä¢ Validation Loss: 0.2957
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.2957, best: 0.2942)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 131/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2040
  ‚Ä¢ Validation Loss: 0.2968
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.2968, best: 0.2942)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 132/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2054
  ‚Ä¢ Validation Loss: 0.2966
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.2966, best: 0.2942)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 133/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1995
  ‚Ä¢ Validation Loss: 0.2953
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.2953, best: 0.2942)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 134/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1995
  ‚Ä¢ Validation Loss: 0.2973
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.2973, best: 0.2942)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 135/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2042
  ‚Ä¢ Validation Loss: 0.2952
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.2952, best: 0.2942)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 136/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2072
  ‚Ä¢ Validation Loss: 0.2978
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.2978, best: 0.2942)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 137/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2059
  ‚Ä¢ Validation Loss: 0.2974
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.2974, best: 0.2942)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 138/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2066
  ‚Ä¢ Validation Loss: 0.2978
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.2978, best: 0.2942)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 139/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2113
  ‚Ä¢ Validation Loss: 0.2977
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.2977, best: 0.2942)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 140/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2085
  ‚Ä¢ Validation Loss: 0.2963
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.2963, best: 0.2942)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 141/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2068
  ‚Ä¢ Validation Loss: 0.2966
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.2966, best: 0.2942)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 142/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2006
  ‚Ä¢ Validation Loss: 0.2967
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.2967, best: 0.2942)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 143/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2067
  ‚Ä¢ Validation Loss: 0.2965
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.2965, best: 0.2942)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 144/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2049
  ‚Ä¢ Validation Loss: 0.2966
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.2966, best: 0.2942)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 145/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2061
  ‚Ä¢ Validation Loss: 0.2965
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.2965, best: 0.2942)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 146/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2109
  ‚Ä¢ Validation Loss: 0.2968
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.2968, best: 0.2942)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 147/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2077
  ‚Ä¢ Validation Loss: 0.2969
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.2969, best: 0.2942)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 148/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2060
  ‚Ä¢ Validation Loss: 0.2971
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.2971, best: 0.2942)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 149/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2090
  ‚Ä¢ Validation Loss: 0.2971
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.2971, best: 0.2942)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 150/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2135
  ‚Ä¢ Validation Loss: 0.2969
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.2969, best: 0.2942)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 151/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2250
  ‚Ä¢ Validation Loss: 0.3027
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3027, best: 0.2942)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 152/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2252
  ‚Ä¢ Validation Loss: 0.3002
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3002, best: 0.2942)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 153/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2280
  ‚Ä¢ Validation Loss: 0.3009
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3009, best: 0.2942)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 154/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2272
  ‚Ä¢ Validation Loss: 0.2996
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.2996, best: 0.2942)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 155/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2279
  ‚Ä¢ Validation Loss: 0.3194
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3194, best: 0.2942)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 156/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2243
  ‚Ä¢ Validation Loss: 0.3032
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3032, best: 0.2942)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 157/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2217
  ‚Ä¢ Validation Loss: 0.2988
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.2988, best: 0.2942)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 158/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2188
  ‚Ä¢ Validation Loss: 0.3000
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3000, best: 0.2942)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 159/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2209
  ‚Ä¢ Validation Loss: 0.3155
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3155, best: 0.2942)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 160/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2150
  ‚Ä¢ Validation Loss: 0.3076
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3076, best: 0.2942)
    ‚ö† No improvement for 34 epochs (patience: 150, remaining: 116)

EPOCH 161/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2138
  ‚Ä¢ Validation Loss: 0.2987
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.2987, best: 0.2942)
    ‚ö† No improvement for 35 epochs (patience: 150, remaining: 115)

EPOCH 162/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2134
  ‚Ä¢ Validation Loss: 0.3031
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3031, best: 0.2942)
    ‚ö† No improvement for 36 epochs (patience: 150, remaining: 114)

EPOCH 163/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2118
  ‚Ä¢ Validation Loss: 0.2997
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.2997, best: 0.2942)
    ‚ö† No improvement for 37 epochs (patience: 150, remaining: 113)

EPOCH 164/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2180
  ‚Ä¢ Validation Loss: 0.3050
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3050, best: 0.2942)
    ‚ö† No improvement for 38 epochs (patience: 150, remaining: 112)

EPOCH 165/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2241
  ‚Ä¢ Validation Loss: 0.3133
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3133, best: 0.2942)
    ‚ö† No improvement for 39 epochs (patience: 150, remaining: 111)

EPOCH 166/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2169
  ‚Ä¢ Validation Loss: 0.2974
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.2974, best: 0.2942)
    ‚ö† No improvement for 40 epochs (patience: 150, remaining: 110)

EPOCH 167/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2080
  ‚Ä¢ Validation Loss: 0.3003
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3003, best: 0.2942)
    ‚ö† No improvement for 41 epochs (patience: 150, remaining: 109)

EPOCH 168/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2137
  ‚Ä¢ Validation Loss: 0.3048
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3048, best: 0.2942)
    ‚ö† No improvement for 42 epochs (patience: 150, remaining: 108)

EPOCH 169/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2198
  ‚Ä¢ Validation Loss: 0.2981
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.2981, best: 0.2942)
    ‚ö† No improvement for 43 epochs (patience: 150, remaining: 107)

EPOCH 170/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2121
  ‚Ä¢ Validation Loss: 0.3005
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3005, best: 0.2942)
    ‚ö† No improvement for 44 epochs (patience: 150, remaining: 106)

EPOCH 171/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2165
  ‚Ä¢ Validation Loss: 0.2954
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.2954, best: 0.2942)
    ‚ö† No improvement for 45 epochs (patience: 150, remaining: 105)

EPOCH 172/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2220
  ‚Ä¢ Validation Loss: 0.2945
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.2945, best: 0.2942)
    ‚ö† No improvement for 46 epochs (patience: 150, remaining: 104)

EPOCH 173/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2144
  ‚Ä¢ Validation Loss: 0.3124
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3124, best: 0.2942)
    ‚ö† No improvement for 47 epochs (patience: 150, remaining: 103)

EPOCH 174/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2178
  ‚Ä¢ Validation Loss: 0.2965
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.2965, best: 0.2942)
    ‚ö† No improvement for 48 epochs (patience: 150, remaining: 102)

EPOCH 175/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2199
  ‚Ä¢ Validation Loss: 0.2986
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.2986, best: 0.2942)
    ‚ö† No improvement for 49 epochs (patience: 150, remaining: 101)

EPOCH 176/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2161
  ‚Ä¢ Validation Loss: 0.3054
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3054, best: 0.2942)
    ‚ö† No improvement for 50 epochs (patience: 150, remaining: 100)

EPOCH 177/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2148
  ‚Ä¢ Validation Loss: 0.3134
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3134, best: 0.2942)
    ‚ö† No improvement for 51 epochs (patience: 150, remaining: 99)

EPOCH 178/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2230
  ‚Ä¢ Validation Loss: 0.3006
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3006, best: 0.2942)
    ‚ö† No improvement for 52 epochs (patience: 150, remaining: 98)

EPOCH 179/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2070
  ‚Ä¢ Validation Loss: 0.3040
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3040, best: 0.2942)
    ‚ö† No improvement for 53 epochs (patience: 150, remaining: 97)

EPOCH 180/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2203
  ‚Ä¢ Validation Loss: 0.3031
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3031, best: 0.2942)
    ‚ö† No improvement for 54 epochs (patience: 150, remaining: 96)

EPOCH 181/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2169
  ‚Ä¢ Validation Loss: 0.3015
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3015, best: 0.2942)
    ‚ö† No improvement for 55 epochs (patience: 150, remaining: 95)

EPOCH 182/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2091
  ‚Ä¢ Validation Loss: 0.2945
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.2945, best: 0.2942)
    ‚ö† No improvement for 56 epochs (patience: 150, remaining: 94)

EPOCH 183/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2041
  ‚Ä¢ Validation Loss: 0.2955
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.2955, best: 0.2942)
    ‚ö† No improvement for 57 epochs (patience: 150, remaining: 93)

EPOCH 184/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2159
  ‚Ä¢ Validation Loss: 0.2970
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.2970, best: 0.2942)
    ‚ö† No improvement for 58 epochs (patience: 150, remaining: 92)

EPOCH 185/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2148
  ‚Ä¢ Validation Loss: 0.2968
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.2968, best: 0.2942)
    ‚ö† No improvement for 59 epochs (patience: 150, remaining: 91)

EPOCH 186/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2183
  ‚Ä¢ Validation Loss: 0.3034
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3034, best: 0.2942)
    ‚ö† No improvement for 60 epochs (patience: 150, remaining: 90)

EPOCH 187/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2118
  ‚Ä¢ Validation Loss: 0.2980
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.2980, best: 0.2942)
    ‚ö† No improvement for 61 epochs (patience: 150, remaining: 89)

EPOCH 188/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2106
  ‚Ä¢ Validation Loss: 0.3058
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3058, best: 0.2942)
    ‚ö† No improvement for 62 epochs (patience: 150, remaining: 88)

EPOCH 189/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2120
  ‚Ä¢ Validation Loss: 0.2940
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.2940
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 190/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2039
  ‚Ä¢ Validation Loss: 0.3073
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3073, best: 0.2940)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 191/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2186
  ‚Ä¢ Validation Loss: 0.3006
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3006, best: 0.2940)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 192/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2104
  ‚Ä¢ Validation Loss: 0.2960
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.2960, best: 0.2940)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 193/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2129
  ‚Ä¢ Validation Loss: 0.3007
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3007, best: 0.2940)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 194/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2114
  ‚Ä¢ Validation Loss: 0.2968
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.2968, best: 0.2940)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 195/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2166
  ‚Ä¢ Validation Loss: 0.2981
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.2981, best: 0.2940)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 196/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2059
  ‚Ä¢ Validation Loss: 0.2960
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.2960, best: 0.2940)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 197/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2085
  ‚Ä¢ Validation Loss: 0.2984
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.2984, best: 0.2940)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 198/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2125
  ‚Ä¢ Validation Loss: 0.2988
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.2988, best: 0.2940)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 199/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2080
  ‚Ä¢ Validation Loss: 0.3005
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3005, best: 0.2940)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 200/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2131
  ‚Ä¢ Validation Loss: 0.3037
  ‚Ä¢ Learning Rate: 0.000009
   üíæ Periodic checkpoint saved: epoch_200.pth
    No improvement (current: 0.3037, best: 0.2940)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 201/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2022
  ‚Ä¢ Validation Loss: 0.3077
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3077, best: 0.2940)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 202/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2070
  ‚Ä¢ Validation Loss: 0.2969
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.2969, best: 0.2940)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 203/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2038
  ‚Ä¢ Validation Loss: 0.3013
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3013, best: 0.2940)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 204/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2068
  ‚Ä¢ Validation Loss: 0.2991
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.2991, best: 0.2940)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 205/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2043
  ‚Ä¢ Validation Loss: 0.2982
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.2982, best: 0.2940)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 206/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2073
  ‚Ä¢ Validation Loss: 0.3059
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3059, best: 0.2940)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 207/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2086
  ‚Ä¢ Validation Loss: 0.2938
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.2938
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 208/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2063
  ‚Ä¢ Validation Loss: 0.2976
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.2976, best: 0.2938)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 209/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2104
  ‚Ä¢ Validation Loss: 0.2943
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.2943, best: 0.2938)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 210/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2053
  ‚Ä¢ Validation Loss: 0.3123
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3123, best: 0.2938)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 211/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2123
  ‚Ä¢ Validation Loss: 0.2971
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.2971, best: 0.2938)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 212/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2033
  ‚Ä¢ Validation Loss: 0.3012
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3012, best: 0.2938)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 213/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2051
  ‚Ä¢ Validation Loss: 0.2933
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.2933
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 214/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2065
  ‚Ä¢ Validation Loss: 0.2962
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.2962, best: 0.2933)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 215/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2116
  ‚Ä¢ Validation Loss: 0.2943
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.2943, best: 0.2933)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 216/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2083
  ‚Ä¢ Validation Loss: 0.2930
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.2930
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 217/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2144
  ‚Ä¢ Validation Loss: 0.2952
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.2952, best: 0.2930)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 218/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2066
  ‚Ä¢ Validation Loss: 0.3015
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3015, best: 0.2930)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 219/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1999
  ‚Ä¢ Validation Loss: 0.2963
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.2963, best: 0.2930)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 220/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2077
  ‚Ä¢ Validation Loss: 0.2999
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.2999, best: 0.2930)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 221/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2135
  ‚Ä¢ Validation Loss: 0.2964
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.2964, best: 0.2930)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 222/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1925
  ‚Ä¢ Validation Loss: 0.3011
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3011, best: 0.2930)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 223/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2031
  ‚Ä¢ Validation Loss: 0.3014
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3014, best: 0.2930)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 224/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2062
  ‚Ä¢ Validation Loss: 0.2946
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.2946, best: 0.2930)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 225/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2078
  ‚Ä¢ Validation Loss: 0.3015
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3015, best: 0.2930)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 226/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1996
  ‚Ä¢ Validation Loss: 0.2938
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.2938, best: 0.2930)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 227/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2042
  ‚Ä¢ Validation Loss: 0.3017
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3017, best: 0.2930)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 228/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2058
  ‚Ä¢ Validation Loss: 0.2975
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.2975, best: 0.2930)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 229/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2018
  ‚Ä¢ Validation Loss: 0.2941
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.2941, best: 0.2930)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 230/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2113
  ‚Ä¢ Validation Loss: 0.2921
  ‚Ä¢ Learning Rate: 0.000007
    ‚úì New best checkpoint saved! Val loss: 0.2921
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 231/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1997
  ‚Ä¢ Validation Loss: 0.2976
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.2976, best: 0.2921)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 232/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2083
  ‚Ä¢ Validation Loss: 0.2958
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.2958, best: 0.2921)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 233/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1996
  ‚Ä¢ Validation Loss: 0.2930
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.2930, best: 0.2921)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 234/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2088
  ‚Ä¢ Validation Loss: 0.2962
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.2962, best: 0.2921)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 235/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2103
  ‚Ä¢ Validation Loss: 0.2978
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.2978, best: 0.2921)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 236/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1998
  ‚Ä¢ Validation Loss: 0.3005
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3005, best: 0.2921)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 237/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1997
  ‚Ä¢ Validation Loss: 0.3011
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3011, best: 0.2921)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 238/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2071
  ‚Ä¢ Validation Loss: 0.2924
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.2924, best: 0.2921)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 239/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2024
  ‚Ä¢ Validation Loss: 0.2941
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.2941, best: 0.2921)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 240/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2051
  ‚Ä¢ Validation Loss: 0.2958
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.2958, best: 0.2921)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 241/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2021
  ‚Ä¢ Validation Loss: 0.2943
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.2943, best: 0.2921)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 242/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2011
  ‚Ä¢ Validation Loss: 0.2887
  ‚Ä¢ Learning Rate: 0.000006
    ‚úì New best checkpoint saved! Val loss: 0.2887
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 243/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1960
  ‚Ä¢ Validation Loss: 0.3015
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3015, best: 0.2887)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 244/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1922
  ‚Ä¢ Validation Loss: 0.2897
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.2897, best: 0.2887)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 245/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2032
  ‚Ä¢ Validation Loss: 0.2944
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.2944, best: 0.2887)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 246/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1982
  ‚Ä¢ Validation Loss: 0.2947
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.2947, best: 0.2887)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 247/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2015
  ‚Ä¢ Validation Loss: 0.2942
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.2942, best: 0.2887)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 248/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1938
  ‚Ä¢ Validation Loss: 0.2953
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.2953, best: 0.2887)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 249/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1961
  ‚Ä¢ Validation Loss: 0.2948
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.2948, best: 0.2887)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 250/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1979
  ‚Ä¢ Validation Loss: 0.2962
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.2962, best: 0.2887)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 251/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1989
  ‚Ä¢ Validation Loss: 0.2995
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.2995, best: 0.2887)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 252/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1981
  ‚Ä¢ Validation Loss: 0.2943
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.2943, best: 0.2887)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 253/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2034
  ‚Ä¢ Validation Loss: 0.2963
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.2963, best: 0.2887)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 254/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1939
  ‚Ä¢ Validation Loss: 0.2933
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.2933, best: 0.2887)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 255/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2058
  ‚Ä¢ Validation Loss: 0.2967
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.2967, best: 0.2887)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 256/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1961
  ‚Ä¢ Validation Loss: 0.2907
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.2907, best: 0.2887)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 257/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1996
  ‚Ä¢ Validation Loss: 0.2947
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.2947, best: 0.2887)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 258/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1996
  ‚Ä¢ Validation Loss: 0.2919
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.2919, best: 0.2887)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 259/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1988
  ‚Ä¢ Validation Loss: 0.2939
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.2939, best: 0.2887)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 260/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2016
  ‚Ä¢ Validation Loss: 0.2901
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.2901, best: 0.2887)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 261/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1960
  ‚Ä¢ Validation Loss: 0.2940
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.2940, best: 0.2887)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 262/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2005
  ‚Ä¢ Validation Loss: 0.2925
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.2925, best: 0.2887)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 263/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1941
  ‚Ä¢ Validation Loss: 0.2903
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.2903, best: 0.2887)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 264/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1971
  ‚Ä¢ Validation Loss: 0.2888
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.2888, best: 0.2887)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 265/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2065
  ‚Ä¢ Validation Loss: 0.2966
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.2966, best: 0.2887)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 266/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1965
  ‚Ä¢ Validation Loss: 0.2933
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.2933, best: 0.2887)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 267/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1959
  ‚Ä¢ Validation Loss: 0.2936
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.2936, best: 0.2887)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 268/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1907
  ‚Ä¢ Validation Loss: 0.2935
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.2935, best: 0.2887)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 269/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1962
  ‚Ä¢ Validation Loss: 0.2910
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.2910, best: 0.2887)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 270/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1967
  ‚Ä¢ Validation Loss: 0.2890
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.2890, best: 0.2887)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 271/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1966
  ‚Ä¢ Validation Loss: 0.2925
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.2925, best: 0.2887)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 272/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1917
  ‚Ä¢ Validation Loss: 0.2924
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.2924, best: 0.2887)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 273/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1918
  ‚Ä¢ Validation Loss: 0.2920
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.2920, best: 0.2887)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 274/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1947
  ‚Ä¢ Validation Loss: 0.2949
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.2949, best: 0.2887)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 275/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1943
  ‚Ä¢ Validation Loss: 0.2929
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.2929, best: 0.2887)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 276/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1895
  ‚Ä¢ Validation Loss: 0.2952
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.2952, best: 0.2887)
    ‚ö† No improvement for 34 epochs (patience: 150, remaining: 116)

EPOCH 277/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2016
  ‚Ä¢ Validation Loss: 0.2937
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.2937, best: 0.2887)
    ‚ö† No improvement for 35 epochs (patience: 150, remaining: 115)

EPOCH 278/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2014
  ‚Ä¢ Validation Loss: 0.2907
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.2907, best: 0.2887)
    ‚ö† No improvement for 36 epochs (patience: 150, remaining: 114)

EPOCH 279/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1959
  ‚Ä¢ Validation Loss: 0.2941
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.2941, best: 0.2887)
    ‚ö† No improvement for 37 epochs (patience: 150, remaining: 113)

EPOCH 280/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1975
  ‚Ä¢ Validation Loss: 0.2904
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.2904, best: 0.2887)
    ‚ö† No improvement for 38 epochs (patience: 150, remaining: 112)

EPOCH 281/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1988
  ‚Ä¢ Validation Loss: 0.2931
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.2931, best: 0.2887)
    ‚ö† No improvement for 39 epochs (patience: 150, remaining: 111)

EPOCH 282/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1930
  ‚Ä¢ Validation Loss: 0.2934
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.2934, best: 0.2887)
    ‚ö† No improvement for 40 epochs (patience: 150, remaining: 110)

EPOCH 283/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1905
  ‚Ä¢ Validation Loss: 0.2919
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.2919, best: 0.2887)
    ‚ö† No improvement for 41 epochs (patience: 150, remaining: 109)

EPOCH 284/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1922
  ‚Ä¢ Validation Loss: 0.2882
  ‚Ä¢ Learning Rate: 0.000003
    ‚úì New best checkpoint saved! Val loss: 0.2882
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 285/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1963
  ‚Ä¢ Validation Loss: 0.2909
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.2909, best: 0.2882)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 286/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1965
  ‚Ä¢ Validation Loss: 0.2908
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2908, best: 0.2882)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 287/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1947
  ‚Ä¢ Validation Loss: 0.2919
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2919, best: 0.2882)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 288/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1983
  ‚Ä¢ Validation Loss: 0.2931
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2931, best: 0.2882)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 289/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1947
  ‚Ä¢ Validation Loss: 0.2919
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2919, best: 0.2882)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 290/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1982
  ‚Ä¢ Validation Loss: 0.2921
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2921, best: 0.2882)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 291/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2003
  ‚Ä¢ Validation Loss: 0.2937
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2937, best: 0.2882)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 292/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2002
  ‚Ä¢ Validation Loss: 0.2951
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2951, best: 0.2882)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 293/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1994
  ‚Ä¢ Validation Loss: 0.2915
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2915, best: 0.2882)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 294/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2008
  ‚Ä¢ Validation Loss: 0.2923
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2923, best: 0.2882)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 295/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1941
  ‚Ä¢ Validation Loss: 0.2911
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2911, best: 0.2882)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 296/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1981
  ‚Ä¢ Validation Loss: 0.2924
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2924, best: 0.2882)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 297/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1903
  ‚Ä¢ Validation Loss: 0.2896
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2896, best: 0.2882)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 298/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1952
  ‚Ä¢ Validation Loss: 0.2897
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2897, best: 0.2882)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 299/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1891
  ‚Ä¢ Validation Loss: 0.2908
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.2908, best: 0.2882)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 300/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.1968
  ‚Ä¢ Validation Loss: 0.2902
  ‚Ä¢ Learning Rate: 0.000002
   üíæ Periodic checkpoint saved: epoch_300.pth
    No improvement (current: 0.2902, best: 0.2882)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

================================================================================
TRAINING COMPLETED
================================================================================
Best Val Loss:  0.2882
Total Epochs:   300
Models Saved:   ./Result/a4/Latin16746
TensorBoard:    ./Result/a4/Latin16746/tensorboard_logs
================================================================================

[20:37:49] Training completed. Best val loss: 0.2882

=== TRAINING COMPLETED SUCCESSFULLY ===
Training Finished!

========================================================================
Testing Hybrid2 Baseline Model with EfficientNet-B4 Decoder + Simple Skip Connections: Latin16746
========================================================================
=== Historical Document Segmentation Testing ===

Using 6 classes for manuscript: Latin16746
Model: Hybrid2
Dataset: UDIADS_BIB
Manuscript: Latin16746
Test-Time Augmentation: Enabled
CRF post-processing: Disabled

================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder for Testing
================================================================================
================================================================================
üöÄ EFFICIENTNET-B4 DECODER (Real MBConv Blocks)
================================================================================
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Using MBConv blocks (NOT simple Conv)
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Optional Features:
  ‚Ä¢ Deep Supervision: False
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: False
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: False
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Loaded checkpoint from epoch 283
Best validation loss: 0.2882
  ‚úÖ Model checkpoint loaded successfully (exact match)
Loaded checkpoint: best_model_latest.pth
Namespace(cfg=None, output_dir='./Result/a4/Latin16746', use_baseline=True, decoder='EfficientNet-B4', efficientnet_variant='b4', use_deep_supervision=False, use_cbam=False, use_smart_skip=False, use_cross_attn=False, use_multiscale_agg=False, use_groupnorm=True, use_batchnorm=False, use_pos_embed=True, dataset='UDIADS_BIB', manuscript='Latin16746', udiadsbib_root='../../U-DIADS-Bib-MS_patched', divahisdb_root='../../DivaHisDB', use_patched_data=True, num_classes=6, img_size=224, batch_size=24, is_savenii=True, test_save_dir='../predictions', use_crf=False, deterministic=1, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, use_tta=True)
Testing with checkpoint: best_model_latest.pth
Saving predictions to: ./Result/a4/Latin16746/predictions

=== Starting Testing ===
Dataset: UDIADS_BIB
Model: Hybrid2
Manuscript: Latin16746
Save predictions: True

Starting inference on UDIADS_BIB dataset
Found 1620 patches for Latin16746
Using Test-Time Augmentation (TTA) for improved accuracy
CRF post-processing: Disabled
Processing: 009 (54 patches)
Completed: 009
Processing: 020 (54 patches)
Completed: 020
Processing: 022 (54 patches)
Completed: 022
Processing: 029 (54 patches)
Completed: 029
Processing: 035 (54 patches)
Completed: 035
Processing: 048 (54 patches)
Completed: 048
Processing: 069 (54 patches)
Completed: 069
Processing: 082 (54 patches)
Completed: 082
Processing: 088 (54 patches)
Completed: 088
Processing: 089 (54 patches)
Completed: 089
Processing: 091 (54 patches)
Completed: 091
Processing: 100 (54 patches)
Completed: 100
Processing: 106 (54 patches)
Completed: 106
Processing: 117 (54 patches)
Completed: 117
Processing: 123 (54 patches)
Completed: 123
Processing: 125 (54 patches)
Completed: 125
Processing: 130 (54 patches)
Completed: 130
Processing: 133 (54 patches)
Completed: 133
Processing: 137 (54 patches)
Completed: 137
Processing: 146 (54 patches)
Completed: 146
Processing: 166 (54 patches)
Completed: 166
Processing: 184 (54 patches)
Completed: 184
Processing: 215 (54 patches)
Completed: 215
Processing: 237 (54 patches)
Completed: 237
Processing: 243 (54 patches)
Completed: 243
Processing: 255 (54 patches)
Completed: 255
Processing: 258 (54 patches)
Completed: 258
Processing: 284 (54 patches)
Completed: 284
Processing: 325 (54 patches)
Completed: 325
Processing: 357 (54 patches)
Completed: 357

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9854, Recall=0.9924, F1=0.9889, IoU=0.9781
Paratext       : Precision=0.7752, Recall=0.7858, F1=0.7804, IoU=0.6399
Decoration     : Precision=0.9756, Recall=0.7958, F1=0.8766, IoU=0.7803
Main Text      : Precision=0.9128, Recall=0.9301, F1=0.9214, IoU=0.8542
Title          : Precision=0.6955, Recall=0.7926, F1=0.7409, IoU=0.5884
Chapter Headings: Precision=0.9144, Recall=0.7414, F1=0.8189, IoU=0.6933

Mean metrics:
----------------------------------------
Mean Precision: 0.8765
Mean Recall: 0.8397
Mean F1-Score: 0.8545
Mean IoU: 0.7557

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9854, Recall=0.9924, F1=0.9889, IoU=0.9781
Paratext       : Precision=0.7752, Recall=0.7858, F1=0.7804, IoU=0.6399
Decoration     : Precision=0.9756, Recall=0.7958, F1=0.8766, IoU=0.7803
Main Text      : Precision=0.9128, Recall=0.9301, F1=0.9214, IoU=0.8542
Title          : Precision=0.6955, Recall=0.7926, F1=0.7409, IoU=0.5884
Chapter Headings: Precision=0.9144, Recall=0.7414, F1=0.8189, IoU=0.6933

Mean metrics:
----------------------------------------
Mean Precision: 0.8765
Mean Recall: 0.8397
Mean F1-Score: 0.8545
Mean IoU: 0.7557
Inference completed on 30 images

=== TESTING COMPLETED SUCCESSFULLY ===
Results saved to: ./Result/a4/Latin16746/predictions
==================================================

Calculating average metrics...
Looking for metrics files in: ./Result/a4
  ‚úó Metrics file not found: ./Result/a4/metrics_Latin2.json
  ‚úó Metrics file not found: ./Result/a4/metrics_Latin14396.json
  ‚úì Found metrics for Latin16746
  ‚úó Metrics file not found: ./Result/a4/metrics_Syr341.json

================================================================================
AVERAGE METRICS ACROSS 1 MANUSCRIPT(S)
================================================================================
Manuscripts: Latin16746
Missing: Latin2, Latin14396, Syr341
--------------------------------------------------------------------------------
Mean Precision: 0.8765
Mean Recall:    0.8397
Mean F1-Score:  0.8545
Mean IoU:       0.7557
================================================================================

========================================================================
Training Hybrid2 Baseline Model with EfficientNet-B4 Decoder + Simple Skip Connections: Syr341
========================================================================
Dataset: U-DIADS-Bib-MS_patched
Architecture: Swin Transformer Encoder ‚Üí 2 Swin Blocks Bottleneck ‚Üí EfficientNet-B4 Decoder
Decoder: EfficientNet-B4 Decoder (Real MBConv blocks)

Components Enabled:
  ‚úì Swin Encoder (4 stages: 96‚Üí192‚Üí384‚Üí768 dim)
  ‚úì Bottleneck: 2 Swin Transformer blocks (768 dim, 24 heads)
  ‚úì EfficientNet-B4 Decoder (MBConv blocks, channels: [256, 128, 64, 32])
  ‚úì Simple Skip Connections
  ‚úì Positional Embeddings (default: enabled)
  ‚úì GroupNorm (default normalization)
  ‚úì Balanced Sampler (oversampling rare classes)
  ‚úì Class-Aware Augmentation

Components Disabled (baseline):
  ‚úó Smart Skip Connections
  ‚úó CBAM Attention
  ‚úó Cross-Attention Bottleneck
  ‚úó BatchNorm
  ‚úó Deep Supervision
  ‚úó Multi-Scale Aggregation
========================================================================
All arguments validated successfully!
Setting random seed to 1234 for reproducible training...
Setting up U-DIADS-Bib dataset...
Detected Syriaque341 manuscript: using 5 classes (no Chapter Headings)
‚úì Class-aware augmentation enabled (stronger augmentation for rare classes)
  Rare classes: Paratext, Decoration, Title
Looking for images in: ../../U-DIADS-Bib-MS_patched/Syr341/Image/training
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Syr341/mask/training_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
Looking for images in: ../../U-DIADS-Bib-MS_patched/Syr341/Image/validation
Looking for masks in: ../../U-DIADS-Bib-MS_patched/Syr341/mask/validation_labels
Found 540 patch images
Successfully matched 540 image-mask pairs
Balanced sampler created (continuous rarity-based oversampling).
‚úì Balanced sampler enabled (oversampling rare classes)
================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder
================================================================================
================================================================================
üöÄ EFFICIENTNET-B4 DECODER (Real MBConv Blocks)
================================================================================
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Using MBConv blocks (NOT simple Conv)
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Optional Features:
  ‚Ä¢ Deep Supervision: False
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: False
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: False
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Model moved to CUDA
Model created successfully with 5 classes
DEBUG: args.output_dir = ./Result/a4/Syr341

=== Starting Training ===
Dataset: UDIADS_BIB
Model: Hybrid2
Batch size: 16
Max epochs: 300
Learning rate: 0.0001


================================================================================
TRAINING CONFIGURATION
================================================================================
Dataset: UDIADS_BIB
Model: Hybrid2
Batch Size: 16
Max Epochs: 300
Learning Rate: 0.0001
Number of Classes: 5
Output Directory: ./Result/a4/Syr341
Early Stopping Patience: 150 epochs
================================================================================

üìä Dataset Statistics:
   - Training samples: 540
   - Validation samples: 540
   - Batch size: 16
   - Steps per epoch: 34


================================================================================
COMPUTING CLASS WEIGHTS
================================================================================
Raw ENS weights: [9.99999990e-05 1.00964968e-04 9.99999990e-05 9.99999990e-05
 1.03734323e-04]

Class Distribution:
Class                Pixels          Frequency       Weight         
-----------------------------------------------------------------
0                        22,747,305        83.9538%         0.9907
1                            46,502         0.1716%         1.0002
2                         1,252,058         4.6210%         0.9907
3                         3,015,934        11.1309%         0.9907
4                            33,241         0.1227%         1.0277

Total pixels: 27,095,040.0
Beta: 0.9999
Smoothing: 0.0
Weight range: [0.9907, 1.0277]
================================================================================
üìà Class weights computed with ENS method (smoothing=0.1)
   Final weights: [0.9906889 1.0002488 0.9906889 0.9906889 1.0276845]

‚úì Loss functions created: CE (weighted, label_smoothing=0.1), Focal (Œ≥=2.0), Dice
üöÄ Hybrid2 Best Practice: Differential Learning Rates
  üìä Encoder LR:     0.000010 (10x smaller, 119 params)
  üìä Bottleneck LR:  0.000050 (5x smaller, 26 params)
  üìä Decoder LR:     0.000100 (base LR, 139 params)
  ‚öôÔ∏è  Scheduler: CosineAnnealingWarmRestarts (T_0=50, T_mult=2)
  ‚öôÔ∏è  Weight decay: Encoder=1e-3, Bottleneck=5e-3, Decoder=1e-2

üîç Checking for checkpoint at: ./Result/a4/Syr341/best_model_latest.pth
   Absolute path: /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid/Result/a4/Syr341/best_model_latest.pth
   File exists: False

================================================================================
STARTING TRAINING
================================================================================
Early stopping patience: 150 epochs
Learning rate scheduler: CosineAnnealingWarmRestarts (better convergence for transformers)
================================================================================

EPOCH 1/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.6404
  ‚Ä¢ Validation Loss: 0.5137
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.5137
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 2/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.5101
  ‚Ä¢ Validation Loss: 0.4706
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4706
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 3/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4678
  ‚Ä¢ Validation Loss: 0.4506
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4506
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 4/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4379
  ‚Ä¢ Validation Loss: 0.4336
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4336
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 5/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4234
  ‚Ä¢ Validation Loss: 0.4252
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4252
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 6/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.4105
  ‚Ä¢ Validation Loss: 0.4122
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4122
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 7/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3968
  ‚Ä¢ Validation Loss: 0.4054
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4054
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 8/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3776
  ‚Ä¢ Validation Loss: 0.4003
  ‚Ä¢ Learning Rate: 0.000010
    ‚úì New best checkpoint saved! Val loss: 0.4003
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 9/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3752
  ‚Ä¢ Validation Loss: 0.3940
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3940
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 10/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3721
  ‚Ä¢ Validation Loss: 0.3892
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3892
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 11/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3591
  ‚Ä¢ Validation Loss: 0.3886
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3886
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 12/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3614
  ‚Ä¢ Validation Loss: 0.3850
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3850
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 13/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3520
  ‚Ä¢ Validation Loss: 0.3794
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3794
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 14/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3498
  ‚Ä¢ Validation Loss: 0.3780
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3780
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 15/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3465
  ‚Ä¢ Validation Loss: 0.3820
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3820, best: 0.3780)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 16/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3451
  ‚Ä¢ Validation Loss: 0.3777
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3777
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 17/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3347
  ‚Ä¢ Validation Loss: 0.3751
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3751
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 18/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3292
  ‚Ä¢ Validation Loss: 0.3688
  ‚Ä¢ Learning Rate: 0.000007
    ‚úì New best checkpoint saved! Val loss: 0.3688
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 19/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3384
  ‚Ä¢ Validation Loss: 0.3619
  ‚Ä¢ Learning Rate: 0.000007
    ‚úì New best checkpoint saved! Val loss: 0.3619
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 20/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3170
  ‚Ä¢ Validation Loss: 0.3647
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3647, best: 0.3619)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 21/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3215
  ‚Ä¢ Validation Loss: 0.3646
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3646, best: 0.3619)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 22/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3188
  ‚Ä¢ Validation Loss: 0.3642
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3642, best: 0.3619)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 23/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3119
  ‚Ä¢ Validation Loss: 0.3604
  ‚Ä¢ Learning Rate: 0.000006
    ‚úì New best checkpoint saved! Val loss: 0.3604
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 24/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3075
  ‚Ä¢ Validation Loss: 0.3539
  ‚Ä¢ Learning Rate: 0.000006
    ‚úì New best checkpoint saved! Val loss: 0.3539
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 25/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3059
  ‚Ä¢ Validation Loss: 0.3524
  ‚Ä¢ Learning Rate: 0.000005
    ‚úì New best checkpoint saved! Val loss: 0.3524
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 26/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3056
  ‚Ä¢ Validation Loss: 0.3625
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3625, best: 0.3524)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 27/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3019
  ‚Ä¢ Validation Loss: 0.3523
  ‚Ä¢ Learning Rate: 0.000005
    ‚úì New best checkpoint saved! Val loss: 0.3523
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 28/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2919
  ‚Ä¢ Validation Loss: 0.3515
  ‚Ä¢ Learning Rate: 0.000004
    ‚úì New best checkpoint saved! Val loss: 0.3515
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 29/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3014
  ‚Ä¢ Validation Loss: 0.3556
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3556, best: 0.3515)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 30/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2882
  ‚Ä¢ Validation Loss: 0.3487
  ‚Ä¢ Learning Rate: 0.000004
    ‚úì New best checkpoint saved! Val loss: 0.3487
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 31/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2978
  ‚Ä¢ Validation Loss: 0.3469
  ‚Ä¢ Learning Rate: 0.000004
    ‚úì New best checkpoint saved! Val loss: 0.3469
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 32/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2956
  ‚Ä¢ Validation Loss: 0.3615
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3615, best: 0.3469)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 33/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2959
  ‚Ä¢ Validation Loss: 0.3469
  ‚Ä¢ Learning Rate: 0.000003
    ‚úì New best checkpoint saved! Val loss: 0.3469
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 34/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2869
  ‚Ä¢ Validation Loss: 0.3486
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3486, best: 0.3469)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 35/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2784
  ‚Ä¢ Validation Loss: 0.3413
  ‚Ä¢ Learning Rate: 0.000002
    ‚úì New best checkpoint saved! Val loss: 0.3413
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 36/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2885
  ‚Ä¢ Validation Loss: 0.3451
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3451, best: 0.3413)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 37/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2851
  ‚Ä¢ Validation Loss: 0.3435
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3435, best: 0.3413)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 38/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2759
  ‚Ä¢ Validation Loss: 0.3445
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3445, best: 0.3413)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 39/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2807
  ‚Ä¢ Validation Loss: 0.3437
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3437, best: 0.3413)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 40/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2682
  ‚Ä¢ Validation Loss: 0.3446
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3446, best: 0.3413)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 41/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2709
  ‚Ä¢ Validation Loss: 0.3428
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3428, best: 0.3413)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 42/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2765
  ‚Ä¢ Validation Loss: 0.3433
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3433, best: 0.3413)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 43/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2760
  ‚Ä¢ Validation Loss: 0.3435
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3435, best: 0.3413)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 44/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2845
  ‚Ä¢ Validation Loss: 0.3423
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3423, best: 0.3413)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 45/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2860
  ‚Ä¢ Validation Loss: 0.3425
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3425, best: 0.3413)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 46/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2799
  ‚Ä¢ Validation Loss: 0.3403
  ‚Ä¢ Learning Rate: 0.000000
    ‚úì New best checkpoint saved! Val loss: 0.3403
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 47/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2806
  ‚Ä¢ Validation Loss: 0.3415
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3415, best: 0.3403)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 48/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2816
  ‚Ä¢ Validation Loss: 0.3418
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3418, best: 0.3403)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 49/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2706
  ‚Ä¢ Validation Loss: 0.3416
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3416, best: 0.3403)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 50/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2786
  ‚Ä¢ Validation Loss: 0.3417
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3417, best: 0.3403)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 51/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2821
  ‚Ä¢ Validation Loss: 0.3526
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3526, best: 0.3403)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 52/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2977
  ‚Ä¢ Validation Loss: 0.3442
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3442, best: 0.3403)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 53/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2929
  ‚Ä¢ Validation Loss: 0.3638
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3638, best: 0.3403)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 54/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3002
  ‚Ä¢ Validation Loss: 0.3477
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3477, best: 0.3403)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 55/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2927
  ‚Ä¢ Validation Loss: 0.3631
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3631, best: 0.3403)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 56/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.3055
  ‚Ä¢ Validation Loss: 0.3427
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3427, best: 0.3403)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 57/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2919
  ‚Ä¢ Validation Loss: 0.3633
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3633, best: 0.3403)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 58/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2773
  ‚Ä¢ Validation Loss: 0.3463
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3463, best: 0.3403)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 59/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2871
  ‚Ä¢ Validation Loss: 0.3571
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3571, best: 0.3403)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 60/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2943
  ‚Ä¢ Validation Loss: 0.3418
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3418, best: 0.3403)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 61/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2871
  ‚Ä¢ Validation Loss: 0.3444
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3444, best: 0.3403)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 62/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2811
  ‚Ä¢ Validation Loss: 0.3457
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3457, best: 0.3403)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 63/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2747
  ‚Ä¢ Validation Loss: 0.3409
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3409, best: 0.3403)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 64/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2776
  ‚Ä¢ Validation Loss: 0.3406
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3406, best: 0.3403)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 65/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2872
  ‚Ä¢ Validation Loss: 0.3419
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3419, best: 0.3403)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 66/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2777
  ‚Ä¢ Validation Loss: 0.3383
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3383
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 67/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2728
  ‚Ä¢ Validation Loss: 0.3455
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3455, best: 0.3383)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 68/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2680
  ‚Ä¢ Validation Loss: 0.3513
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3513, best: 0.3383)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 69/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2768
  ‚Ä¢ Validation Loss: 0.3365
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3365
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 70/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2914
  ‚Ä¢ Validation Loss: 0.3454
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3454, best: 0.3365)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 71/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2791
  ‚Ä¢ Validation Loss: 0.3410
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3410, best: 0.3365)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 72/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2601
  ‚Ä¢ Validation Loss: 0.3360
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3360
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 73/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2629
  ‚Ä¢ Validation Loss: 0.3475
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3475, best: 0.3360)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 74/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2696
  ‚Ä¢ Validation Loss: 0.3456
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3456, best: 0.3360)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 75/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2666
  ‚Ä¢ Validation Loss: 0.3380
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3380, best: 0.3360)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 76/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2614
  ‚Ä¢ Validation Loss: 0.3389
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3389, best: 0.3360)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 77/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2622
  ‚Ä¢ Validation Loss: 0.3369
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3369, best: 0.3360)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 78/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2752
  ‚Ä¢ Validation Loss: 0.3346
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3346
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 79/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2577
  ‚Ä¢ Validation Loss: 0.3346
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3346
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 80/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2652
  ‚Ä¢ Validation Loss: 0.3313
  ‚Ä¢ Learning Rate: 0.000008
    ‚úì New best checkpoint saved! Val loss: 0.3313
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 81/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2668
  ‚Ä¢ Validation Loss: 0.3508
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3508, best: 0.3313)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 82/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2511
  ‚Ä¢ Validation Loss: 0.3403
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3403, best: 0.3313)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 83/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2522
  ‚Ä¢ Validation Loss: 0.3411
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3411, best: 0.3313)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 84/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2692
  ‚Ä¢ Validation Loss: 0.3318
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3318, best: 0.3313)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 85/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2676
  ‚Ä¢ Validation Loss: 0.3400
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3400, best: 0.3313)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 86/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2658
  ‚Ä¢ Validation Loss: 0.3408
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3408, best: 0.3313)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 87/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2512
  ‚Ä¢ Validation Loss: 0.3327
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3327, best: 0.3313)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 88/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2603
  ‚Ä¢ Validation Loss: 0.3310
  ‚Ä¢ Learning Rate: 0.000007
    ‚úì New best checkpoint saved! Val loss: 0.3310
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 89/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2517
  ‚Ä¢ Validation Loss: 0.3311
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3311, best: 0.3310)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 90/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2460
  ‚Ä¢ Validation Loss: 0.3334
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3334, best: 0.3310)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 91/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2541
  ‚Ä¢ Validation Loss: 0.3341
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3341, best: 0.3310)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 92/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2474
  ‚Ä¢ Validation Loss: 0.3409
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3409, best: 0.3310)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 93/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2551
  ‚Ä¢ Validation Loss: 0.3447
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3447, best: 0.3310)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 94/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2501
  ‚Ä¢ Validation Loss: 0.3345
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3345, best: 0.3310)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 95/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2569
  ‚Ä¢ Validation Loss: 0.3365
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3365, best: 0.3310)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 96/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2494
  ‚Ä¢ Validation Loss: 0.3346
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3346, best: 0.3310)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 97/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2570
  ‚Ä¢ Validation Loss: 0.3359
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3359, best: 0.3310)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 98/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2561
  ‚Ä¢ Validation Loss: 0.3357
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3357, best: 0.3310)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 99/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2420
  ‚Ä¢ Validation Loss: 0.3322
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3322, best: 0.3310)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 100/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2540
  ‚Ä¢ Validation Loss: 0.3406
  ‚Ä¢ Learning Rate: 0.000005
   üíæ Periodic checkpoint saved: epoch_100.pth
    No improvement (current: 0.3406, best: 0.3310)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 101/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2555
  ‚Ä¢ Validation Loss: 0.3354
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3354, best: 0.3310)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 102/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2538
  ‚Ä¢ Validation Loss: 0.3322
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3322, best: 0.3310)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 103/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2469
  ‚Ä¢ Validation Loss: 0.3312
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3312, best: 0.3310)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 104/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2574
  ‚Ä¢ Validation Loss: 0.3287
  ‚Ä¢ Learning Rate: 0.000005
    ‚úì New best checkpoint saved! Val loss: 0.3287
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 105/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2552
  ‚Ä¢ Validation Loss: 0.3342
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3342, best: 0.3287)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 106/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2448
  ‚Ä¢ Validation Loss: 0.3353
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3353, best: 0.3287)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 107/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2471
  ‚Ä¢ Validation Loss: 0.3340
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3340, best: 0.3287)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 108/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2420
  ‚Ä¢ Validation Loss: 0.3266
  ‚Ä¢ Learning Rate: 0.000004
    ‚úì New best checkpoint saved! Val loss: 0.3266
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 109/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2458
  ‚Ä¢ Validation Loss: 0.3292
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3292, best: 0.3266)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 110/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2416
  ‚Ä¢ Validation Loss: 0.3282
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3282, best: 0.3266)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 111/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2454
  ‚Ä¢ Validation Loss: 0.3282
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3282, best: 0.3266)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 112/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2441
  ‚Ä¢ Validation Loss: 0.3351
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3351, best: 0.3266)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 113/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2425
  ‚Ä¢ Validation Loss: 0.3375
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3375, best: 0.3266)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 114/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2307
  ‚Ä¢ Validation Loss: 0.3393
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3393, best: 0.3266)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 115/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2462
  ‚Ä¢ Validation Loss: 0.3359
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3359, best: 0.3266)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 116/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2463
  ‚Ä¢ Validation Loss: 0.3276
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3276, best: 0.3266)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 117/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2343
  ‚Ä¢ Validation Loss: 0.3264
  ‚Ä¢ Learning Rate: 0.000003
    ‚úì New best checkpoint saved! Val loss: 0.3264
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 118/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2327
  ‚Ä¢ Validation Loss: 0.3269
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3269, best: 0.3264)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 119/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2395
  ‚Ä¢ Validation Loss: 0.3294
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3294, best: 0.3264)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 120/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2384
  ‚Ä¢ Validation Loss: 0.3324
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3324, best: 0.3264)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 121/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2450
  ‚Ä¢ Validation Loss: 0.3314
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3314, best: 0.3264)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 122/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2360
  ‚Ä¢ Validation Loss: 0.3328
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3328, best: 0.3264)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 123/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2240
  ‚Ä¢ Validation Loss: 0.3318
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3318, best: 0.3264)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 124/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2251
  ‚Ä¢ Validation Loss: 0.3310
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3310, best: 0.3264)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 125/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2401
  ‚Ä¢ Validation Loss: 0.3328
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3328, best: 0.3264)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 126/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2321
  ‚Ä¢ Validation Loss: 0.3335
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3335, best: 0.3264)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 127/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2347
  ‚Ä¢ Validation Loss: 0.3344
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3344, best: 0.3264)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 128/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2444
  ‚Ä¢ Validation Loss: 0.3315
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3315, best: 0.3264)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 129/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2401
  ‚Ä¢ Validation Loss: 0.3316
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3316, best: 0.3264)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 130/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2356
  ‚Ä¢ Validation Loss: 0.3304
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3304, best: 0.3264)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 131/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2362
  ‚Ä¢ Validation Loss: 0.3308
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3308, best: 0.3264)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 132/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2424
  ‚Ä¢ Validation Loss: 0.3287
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3287, best: 0.3264)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 133/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2258
  ‚Ä¢ Validation Loss: 0.3319
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3319, best: 0.3264)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 134/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2431
  ‚Ä¢ Validation Loss: 0.3315
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3315, best: 0.3264)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 135/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2331
  ‚Ä¢ Validation Loss: 0.3311
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3311, best: 0.3264)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 136/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2358
  ‚Ä¢ Validation Loss: 0.3309
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3309, best: 0.3264)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 137/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2346
  ‚Ä¢ Validation Loss: 0.3299
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3299, best: 0.3264)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 138/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2385
  ‚Ä¢ Validation Loss: 0.3291
  ‚Ä¢ Learning Rate: 0.000001
    No improvement (current: 0.3291, best: 0.3264)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 139/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2262
  ‚Ä¢ Validation Loss: 0.3303
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3303, best: 0.3264)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 140/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2424
  ‚Ä¢ Validation Loss: 0.3302
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3302, best: 0.3264)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 141/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2348
  ‚Ä¢ Validation Loss: 0.3305
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3305, best: 0.3264)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 142/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2390
  ‚Ä¢ Validation Loss: 0.3303
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3303, best: 0.3264)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 143/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2362
  ‚Ä¢ Validation Loss: 0.3304
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3304, best: 0.3264)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 144/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2414
  ‚Ä¢ Validation Loss: 0.3304
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3304, best: 0.3264)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 145/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2427
  ‚Ä¢ Validation Loss: 0.3300
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3300, best: 0.3264)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 146/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2411
  ‚Ä¢ Validation Loss: 0.3297
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3297, best: 0.3264)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 147/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2366
  ‚Ä¢ Validation Loss: 0.3298
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3298, best: 0.3264)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 148/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2264
  ‚Ä¢ Validation Loss: 0.3297
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3297, best: 0.3264)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 149/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2359
  ‚Ä¢ Validation Loss: 0.3297
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3297, best: 0.3264)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 150/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2395
  ‚Ä¢ Validation Loss: 0.3298
  ‚Ä¢ Learning Rate: 0.000000
    No improvement (current: 0.3298, best: 0.3264)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 151/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2501
  ‚Ä¢ Validation Loss: 0.3401
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3401, best: 0.3264)
    ‚ö† No improvement for 34 epochs (patience: 150, remaining: 116)

EPOCH 152/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2576
  ‚Ä¢ Validation Loss: 0.3384
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3384, best: 0.3264)
    ‚ö† No improvement for 35 epochs (patience: 150, remaining: 115)

EPOCH 153/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2544
  ‚Ä¢ Validation Loss: 0.3506
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3506, best: 0.3264)
    ‚ö† No improvement for 36 epochs (patience: 150, remaining: 114)

EPOCH 154/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2490
  ‚Ä¢ Validation Loss: 0.3429
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3429, best: 0.3264)
    ‚ö† No improvement for 37 epochs (patience: 150, remaining: 113)

EPOCH 155/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2430
  ‚Ä¢ Validation Loss: 0.3317
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3317, best: 0.3264)
    ‚ö† No improvement for 38 epochs (patience: 150, remaining: 112)

EPOCH 156/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2509
  ‚Ä¢ Validation Loss: 0.3404
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3404, best: 0.3264)
    ‚ö† No improvement for 39 epochs (patience: 150, remaining: 111)

EPOCH 157/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2483
  ‚Ä¢ Validation Loss: 0.3363
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3363, best: 0.3264)
    ‚ö† No improvement for 40 epochs (patience: 150, remaining: 110)

EPOCH 158/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2520
  ‚Ä¢ Validation Loss: 0.3379
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3379, best: 0.3264)
    ‚ö† No improvement for 41 epochs (patience: 150, remaining: 109)

EPOCH 159/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2501
  ‚Ä¢ Validation Loss: 0.3483
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3483, best: 0.3264)
    ‚ö† No improvement for 42 epochs (patience: 150, remaining: 108)

EPOCH 160/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2501
  ‚Ä¢ Validation Loss: 0.3406
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3406, best: 0.3264)
    ‚ö† No improvement for 43 epochs (patience: 150, remaining: 107)

EPOCH 161/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2462
  ‚Ä¢ Validation Loss: 0.3321
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3321, best: 0.3264)
    ‚ö† No improvement for 44 epochs (patience: 150, remaining: 106)

EPOCH 162/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2496
  ‚Ä¢ Validation Loss: 0.3380
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3380, best: 0.3264)
    ‚ö† No improvement for 45 epochs (patience: 150, remaining: 105)

EPOCH 163/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2528
  ‚Ä¢ Validation Loss: 0.3403
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3403, best: 0.3264)
    ‚ö† No improvement for 46 epochs (patience: 150, remaining: 104)

EPOCH 164/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2423
  ‚Ä¢ Validation Loss: 0.3351
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3351, best: 0.3264)
    ‚ö† No improvement for 47 epochs (patience: 150, remaining: 103)

EPOCH 165/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2510
  ‚Ä¢ Validation Loss: 0.3342
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3342, best: 0.3264)
    ‚ö† No improvement for 48 epochs (patience: 150, remaining: 102)

EPOCH 166/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2417
  ‚Ä¢ Validation Loss: 0.3428
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3428, best: 0.3264)
    ‚ö† No improvement for 49 epochs (patience: 150, remaining: 101)

EPOCH 167/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2535
  ‚Ä¢ Validation Loss: 0.3294
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3294, best: 0.3264)
    ‚ö† No improvement for 50 epochs (patience: 150, remaining: 100)

EPOCH 168/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2462
  ‚Ä¢ Validation Loss: 0.3389
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3389, best: 0.3264)
    ‚ö† No improvement for 51 epochs (patience: 150, remaining: 99)

EPOCH 169/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2518
  ‚Ä¢ Validation Loss: 0.3329
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3329, best: 0.3264)
    ‚ö† No improvement for 52 epochs (patience: 150, remaining: 98)

EPOCH 170/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2545
  ‚Ä¢ Validation Loss: 0.3281
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3281, best: 0.3264)
    ‚ö† No improvement for 53 epochs (patience: 150, remaining: 97)

EPOCH 171/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2527
  ‚Ä¢ Validation Loss: 0.3380
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3380, best: 0.3264)
    ‚ö† No improvement for 54 epochs (patience: 150, remaining: 96)

EPOCH 172/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2550
  ‚Ä¢ Validation Loss: 0.3361
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3361, best: 0.3264)
    ‚ö† No improvement for 55 epochs (patience: 150, remaining: 95)

EPOCH 173/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2446
  ‚Ä¢ Validation Loss: 0.3473
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3473, best: 0.3264)
    ‚ö† No improvement for 56 epochs (patience: 150, remaining: 94)

EPOCH 174/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2442
  ‚Ä¢ Validation Loss: 0.3346
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3346, best: 0.3264)
    ‚ö† No improvement for 57 epochs (patience: 150, remaining: 93)

EPOCH 175/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2420
  ‚Ä¢ Validation Loss: 0.3352
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3352, best: 0.3264)
    ‚ö† No improvement for 58 epochs (patience: 150, remaining: 92)

EPOCH 176/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2412
  ‚Ä¢ Validation Loss: 0.3352
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3352, best: 0.3264)
    ‚ö† No improvement for 59 epochs (patience: 150, remaining: 91)

EPOCH 177/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2488
  ‚Ä¢ Validation Loss: 0.3410
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3410, best: 0.3264)
    ‚ö† No improvement for 60 epochs (patience: 150, remaining: 90)

EPOCH 178/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2395
  ‚Ä¢ Validation Loss: 0.3296
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3296, best: 0.3264)
    ‚ö† No improvement for 61 epochs (patience: 150, remaining: 89)

EPOCH 179/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2411
  ‚Ä¢ Validation Loss: 0.3281
  ‚Ä¢ Learning Rate: 0.000010
    No improvement (current: 0.3281, best: 0.3264)
    ‚ö† No improvement for 62 epochs (patience: 150, remaining: 88)

EPOCH 180/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2437
  ‚Ä¢ Validation Loss: 0.3349
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3349, best: 0.3264)
    ‚ö† No improvement for 63 epochs (patience: 150, remaining: 87)

EPOCH 181/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2340
  ‚Ä¢ Validation Loss: 0.3292
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3292, best: 0.3264)
    ‚ö† No improvement for 64 epochs (patience: 150, remaining: 86)

EPOCH 182/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2503
  ‚Ä¢ Validation Loss: 0.3338
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3338, best: 0.3264)
    ‚ö† No improvement for 65 epochs (patience: 150, remaining: 85)

EPOCH 183/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2405
  ‚Ä¢ Validation Loss: 0.3443
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3443, best: 0.3264)
    ‚ö† No improvement for 66 epochs (patience: 150, remaining: 84)

EPOCH 184/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2342
  ‚Ä¢ Validation Loss: 0.3497
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3497, best: 0.3264)
    ‚ö† No improvement for 67 epochs (patience: 150, remaining: 83)

EPOCH 185/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2379
  ‚Ä¢ Validation Loss: 0.3400
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3400, best: 0.3264)
    ‚ö† No improvement for 68 epochs (patience: 150, remaining: 82)

EPOCH 186/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2381
  ‚Ä¢ Validation Loss: 0.3384
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3384, best: 0.3264)
    ‚ö† No improvement for 69 epochs (patience: 150, remaining: 81)

EPOCH 187/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2453
  ‚Ä¢ Validation Loss: 0.3367
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3367, best: 0.3264)
    ‚ö† No improvement for 70 epochs (patience: 150, remaining: 80)

EPOCH 188/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2396
  ‚Ä¢ Validation Loss: 0.3379
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3379, best: 0.3264)
    ‚ö† No improvement for 71 epochs (patience: 150, remaining: 79)

EPOCH 189/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2415
  ‚Ä¢ Validation Loss: 0.3416
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3416, best: 0.3264)
    ‚ö† No improvement for 72 epochs (patience: 150, remaining: 78)

EPOCH 190/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2399
  ‚Ä¢ Validation Loss: 0.3313
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3313, best: 0.3264)
    ‚ö† No improvement for 73 epochs (patience: 150, remaining: 77)

EPOCH 191/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2530
  ‚Ä¢ Validation Loss: 0.3315
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3315, best: 0.3264)
    ‚ö† No improvement for 74 epochs (patience: 150, remaining: 76)

EPOCH 192/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2375
  ‚Ä¢ Validation Loss: 0.3255
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3255
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 193/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2360
  ‚Ä¢ Validation Loss: 0.3414
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3414, best: 0.3255)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 194/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2320
  ‚Ä¢ Validation Loss: 0.3477
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3477, best: 0.3255)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 195/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2374
  ‚Ä¢ Validation Loss: 0.3296
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3296, best: 0.3255)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 196/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2412
  ‚Ä¢ Validation Loss: 0.3251
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3251
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 197/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2257
  ‚Ä¢ Validation Loss: 0.3364
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3364, best: 0.3251)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 198/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2378
  ‚Ä¢ Validation Loss: 0.3344
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3344, best: 0.3251)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 199/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2347
  ‚Ä¢ Validation Loss: 0.3284
  ‚Ä¢ Learning Rate: 0.000009
    No improvement (current: 0.3284, best: 0.3251)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 200/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2365
  ‚Ä¢ Validation Loss: 0.3254
  ‚Ä¢ Learning Rate: 0.000009
   üíæ Periodic checkpoint saved: epoch_200.pth
    No improvement (current: 0.3254, best: 0.3251)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 201/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2367
  ‚Ä¢ Validation Loss: 0.3244
  ‚Ä¢ Learning Rate: 0.000009
    ‚úì New best checkpoint saved! Val loss: 0.3244
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 202/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2328
  ‚Ä¢ Validation Loss: 0.3329
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3329, best: 0.3244)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 203/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2390
  ‚Ä¢ Validation Loss: 0.3318
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3318, best: 0.3244)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 204/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2414
  ‚Ä¢ Validation Loss: 0.3393
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3393, best: 0.3244)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 205/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2462
  ‚Ä¢ Validation Loss: 0.3377
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3377, best: 0.3244)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 206/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2357
  ‚Ä¢ Validation Loss: 0.3394
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3394, best: 0.3244)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 207/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2368
  ‚Ä¢ Validation Loss: 0.3375
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3375, best: 0.3244)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 208/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2369
  ‚Ä¢ Validation Loss: 0.3251
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3251, best: 0.3244)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 209/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2389
  ‚Ä¢ Validation Loss: 0.3369
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3369, best: 0.3244)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 210/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2335
  ‚Ä¢ Validation Loss: 0.3371
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3371, best: 0.3244)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 211/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2198
  ‚Ä¢ Validation Loss: 0.3287
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3287, best: 0.3244)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 212/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2304
  ‚Ä¢ Validation Loss: 0.3294
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3294, best: 0.3244)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 213/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2370
  ‚Ä¢ Validation Loss: 0.3284
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3284, best: 0.3244)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 214/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2303
  ‚Ä¢ Validation Loss: 0.3288
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3288, best: 0.3244)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 215/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2301
  ‚Ä¢ Validation Loss: 0.3290
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3290, best: 0.3244)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 216/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2324
  ‚Ä¢ Validation Loss: 0.3249
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3249, best: 0.3244)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 217/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2314
  ‚Ä¢ Validation Loss: 0.3248
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3248, best: 0.3244)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 218/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2330
  ‚Ä¢ Validation Loss: 0.3373
  ‚Ä¢ Learning Rate: 0.000008
    No improvement (current: 0.3373, best: 0.3244)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 219/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2311
  ‚Ä¢ Validation Loss: 0.3261
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3261, best: 0.3244)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 220/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2314
  ‚Ä¢ Validation Loss: 0.3287
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3287, best: 0.3244)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 221/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2325
  ‚Ä¢ Validation Loss: 0.3282
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3282, best: 0.3244)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 222/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2284
  ‚Ä¢ Validation Loss: 0.3380
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3380, best: 0.3244)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 223/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2349
  ‚Ä¢ Validation Loss: 0.3319
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3319, best: 0.3244)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 224/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2204
  ‚Ä¢ Validation Loss: 0.3344
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3344, best: 0.3244)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 225/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2322
  ‚Ä¢ Validation Loss: 0.3352
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3352, best: 0.3244)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 226/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2275
  ‚Ä¢ Validation Loss: 0.3297
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3297, best: 0.3244)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 227/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2344
  ‚Ä¢ Validation Loss: 0.3325
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3325, best: 0.3244)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 228/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2262
  ‚Ä¢ Validation Loss: 0.3311
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3311, best: 0.3244)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 229/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2377
  ‚Ä¢ Validation Loss: 0.3288
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3288, best: 0.3244)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 230/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2288
  ‚Ä¢ Validation Loss: 0.3283
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3283, best: 0.3244)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 231/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2255
  ‚Ä¢ Validation Loss: 0.3260
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3260, best: 0.3244)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 232/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2335
  ‚Ä¢ Validation Loss: 0.3280
  ‚Ä¢ Learning Rate: 0.000007
    No improvement (current: 0.3280, best: 0.3244)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 233/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2300
  ‚Ä¢ Validation Loss: 0.3309
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3309, best: 0.3244)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 234/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2246
  ‚Ä¢ Validation Loss: 0.3328
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3328, best: 0.3244)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 235/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2221
  ‚Ä¢ Validation Loss: 0.3315
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3315, best: 0.3244)
    ‚ö† No improvement for 34 epochs (patience: 150, remaining: 116)

EPOCH 236/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2308
  ‚Ä¢ Validation Loss: 0.3329
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3329, best: 0.3244)
    ‚ö† No improvement for 35 epochs (patience: 150, remaining: 115)

EPOCH 237/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2253
  ‚Ä¢ Validation Loss: 0.3376
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3376, best: 0.3244)
    ‚ö† No improvement for 36 epochs (patience: 150, remaining: 114)

EPOCH 238/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2311
  ‚Ä¢ Validation Loss: 0.3276
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3276, best: 0.3244)
    ‚ö† No improvement for 37 epochs (patience: 150, remaining: 113)

EPOCH 239/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2231
  ‚Ä¢ Validation Loss: 0.3258
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3258, best: 0.3244)
    ‚ö† No improvement for 38 epochs (patience: 150, remaining: 112)

EPOCH 240/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2352
  ‚Ä¢ Validation Loss: 0.3250
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3250, best: 0.3244)
    ‚ö† No improvement for 39 epochs (patience: 150, remaining: 111)

EPOCH 241/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2328
  ‚Ä¢ Validation Loss: 0.3282
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3282, best: 0.3244)
    ‚ö† No improvement for 40 epochs (patience: 150, remaining: 110)

EPOCH 242/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2314
  ‚Ä¢ Validation Loss: 0.3248
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3248, best: 0.3244)
    ‚ö† No improvement for 41 epochs (patience: 150, remaining: 109)

EPOCH 243/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2267
  ‚Ä¢ Validation Loss: 0.3329
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3329, best: 0.3244)
    ‚ö† No improvement for 42 epochs (patience: 150, remaining: 108)

EPOCH 244/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2248
  ‚Ä¢ Validation Loss: 0.3323
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3323, best: 0.3244)
    ‚ö† No improvement for 43 epochs (patience: 150, remaining: 107)

EPOCH 245/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2357
  ‚Ä¢ Validation Loss: 0.3273
  ‚Ä¢ Learning Rate: 0.000006
    No improvement (current: 0.3273, best: 0.3244)
    ‚ö† No improvement for 44 epochs (patience: 150, remaining: 106)

EPOCH 246/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2360
  ‚Ä¢ Validation Loss: 0.3283
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3283, best: 0.3244)
    ‚ö† No improvement for 45 epochs (patience: 150, remaining: 105)

EPOCH 247/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2224
  ‚Ä¢ Validation Loss: 0.3315
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3315, best: 0.3244)
    ‚ö† No improvement for 46 epochs (patience: 150, remaining: 104)

EPOCH 248/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2306
  ‚Ä¢ Validation Loss: 0.3299
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3299, best: 0.3244)
    ‚ö† No improvement for 47 epochs (patience: 150, remaining: 103)

EPOCH 249/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2155
  ‚Ä¢ Validation Loss: 0.3266
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3266, best: 0.3244)
    ‚ö† No improvement for 48 epochs (patience: 150, remaining: 102)

EPOCH 250/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2260
  ‚Ä¢ Validation Loss: 0.3307
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3307, best: 0.3244)
    ‚ö† No improvement for 49 epochs (patience: 150, remaining: 101)

EPOCH 251/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2175
  ‚Ä¢ Validation Loss: 0.3304
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3304, best: 0.3244)
    ‚ö† No improvement for 50 epochs (patience: 150, remaining: 100)

EPOCH 252/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2286
  ‚Ä¢ Validation Loss: 0.3259
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3259, best: 0.3244)
    ‚ö† No improvement for 51 epochs (patience: 150, remaining: 99)

EPOCH 253/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2272
  ‚Ä¢ Validation Loss: 0.3283
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3283, best: 0.3244)
    ‚ö† No improvement for 52 epochs (patience: 150, remaining: 98)

EPOCH 254/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2280
  ‚Ä¢ Validation Loss: 0.3247
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3247, best: 0.3244)
    ‚ö† No improvement for 53 epochs (patience: 150, remaining: 97)

EPOCH 255/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2314
  ‚Ä¢ Validation Loss: 0.3296
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3296, best: 0.3244)
    ‚ö† No improvement for 54 epochs (patience: 150, remaining: 96)

EPOCH 256/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2230
  ‚Ä¢ Validation Loss: 0.3263
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3263, best: 0.3244)
    ‚ö† No improvement for 55 epochs (patience: 150, remaining: 95)

EPOCH 257/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2231
  ‚Ä¢ Validation Loss: 0.3295
  ‚Ä¢ Learning Rate: 0.000005
    No improvement (current: 0.3295, best: 0.3244)
    ‚ö† No improvement for 56 epochs (patience: 150, remaining: 94)

EPOCH 258/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2316
  ‚Ä¢ Validation Loss: 0.3229
  ‚Ä¢ Learning Rate: 0.000005
    ‚úì New best checkpoint saved! Val loss: 0.3229
    ‚úì Improvement detected! Resetting patience counter.

EPOCH 259/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2348
  ‚Ä¢ Validation Loss: 0.3252
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3252, best: 0.3229)
    ‚ö† No improvement for 1 epochs (patience: 150, remaining: 149)

EPOCH 260/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2239
  ‚Ä¢ Validation Loss: 0.3314
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3314, best: 0.3229)
    ‚ö† No improvement for 2 epochs (patience: 150, remaining: 148)

EPOCH 261/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2270
  ‚Ä¢ Validation Loss: 0.3281
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3281, best: 0.3229)
    ‚ö† No improvement for 3 epochs (patience: 150, remaining: 147)

EPOCH 262/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2266
  ‚Ä¢ Validation Loss: 0.3275
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3275, best: 0.3229)
    ‚ö† No improvement for 4 epochs (patience: 150, remaining: 146)

EPOCH 263/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2291
  ‚Ä¢ Validation Loss: 0.3244
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3244, best: 0.3229)
    ‚ö† No improvement for 5 epochs (patience: 150, remaining: 145)

EPOCH 264/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2107
  ‚Ä¢ Validation Loss: 0.3266
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3266, best: 0.3229)
    ‚ö† No improvement for 6 epochs (patience: 150, remaining: 144)

EPOCH 265/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2349
  ‚Ä¢ Validation Loss: 0.3272
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3272, best: 0.3229)
    ‚ö† No improvement for 7 epochs (patience: 150, remaining: 143)

EPOCH 266/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2255
  ‚Ä¢ Validation Loss: 0.3282
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3282, best: 0.3229)
    ‚ö† No improvement for 8 epochs (patience: 150, remaining: 142)

EPOCH 267/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2217
  ‚Ä¢ Validation Loss: 0.3355
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3355, best: 0.3229)
    ‚ö† No improvement for 9 epochs (patience: 150, remaining: 141)

EPOCH 268/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2220
  ‚Ä¢ Validation Loss: 0.3342
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3342, best: 0.3229)
    ‚ö† No improvement for 10 epochs (patience: 150, remaining: 140)

EPOCH 269/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2117
  ‚Ä¢ Validation Loss: 0.3287
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3287, best: 0.3229)
    ‚ö† No improvement for 11 epochs (patience: 150, remaining: 139)

EPOCH 270/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2190
  ‚Ä¢ Validation Loss: 0.3275
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3275, best: 0.3229)
    ‚ö† No improvement for 12 epochs (patience: 150, remaining: 138)

EPOCH 271/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2248
  ‚Ä¢ Validation Loss: 0.3316
  ‚Ä¢ Learning Rate: 0.000004
    No improvement (current: 0.3316, best: 0.3229)
    ‚ö† No improvement for 13 epochs (patience: 150, remaining: 137)

EPOCH 272/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2286
  ‚Ä¢ Validation Loss: 0.3316
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3316, best: 0.3229)
    ‚ö† No improvement for 14 epochs (patience: 150, remaining: 136)

EPOCH 273/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2213
  ‚Ä¢ Validation Loss: 0.3308
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3308, best: 0.3229)
    ‚ö† No improvement for 15 epochs (patience: 150, remaining: 135)

EPOCH 274/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2264
  ‚Ä¢ Validation Loss: 0.3326
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3326, best: 0.3229)
    ‚ö† No improvement for 16 epochs (patience: 150, remaining: 134)

EPOCH 275/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2214
  ‚Ä¢ Validation Loss: 0.3309
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3309, best: 0.3229)
    ‚ö† No improvement for 17 epochs (patience: 150, remaining: 133)

EPOCH 276/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2334
  ‚Ä¢ Validation Loss: 0.3334
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3334, best: 0.3229)
    ‚ö† No improvement for 18 epochs (patience: 150, remaining: 132)

EPOCH 277/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2167
  ‚Ä¢ Validation Loss: 0.3324
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3324, best: 0.3229)
    ‚ö† No improvement for 19 epochs (patience: 150, remaining: 131)

EPOCH 278/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2267
  ‚Ä¢ Validation Loss: 0.3322
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3322, best: 0.3229)
    ‚ö† No improvement for 20 epochs (patience: 150, remaining: 130)

EPOCH 279/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2164
  ‚Ä¢ Validation Loss: 0.3317
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3317, best: 0.3229)
    ‚ö† No improvement for 21 epochs (patience: 150, remaining: 129)

EPOCH 280/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2223
  ‚Ä¢ Validation Loss: 0.3262
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3262, best: 0.3229)
    ‚ö† No improvement for 22 epochs (patience: 150, remaining: 128)

EPOCH 281/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2190
  ‚Ä¢ Validation Loss: 0.3285
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3285, best: 0.3229)
    ‚ö† No improvement for 23 epochs (patience: 150, remaining: 127)

EPOCH 282/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2105
  ‚Ä¢ Validation Loss: 0.3275
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3275, best: 0.3229)
    ‚ö† No improvement for 24 epochs (patience: 150, remaining: 126)

EPOCH 283/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2062
  ‚Ä¢ Validation Loss: 0.3310
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3310, best: 0.3229)
    ‚ö† No improvement for 25 epochs (patience: 150, remaining: 125)

EPOCH 284/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2207
  ‚Ä¢ Validation Loss: 0.3270
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3270, best: 0.3229)
    ‚ö† No improvement for 26 epochs (patience: 150, remaining: 124)

EPOCH 285/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2207
  ‚Ä¢ Validation Loss: 0.3306
  ‚Ä¢ Learning Rate: 0.000003
    No improvement (current: 0.3306, best: 0.3229)
    ‚ö† No improvement for 27 epochs (patience: 150, remaining: 123)

EPOCH 286/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2187
  ‚Ä¢ Validation Loss: 0.3281
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3281, best: 0.3229)
    ‚ö† No improvement for 28 epochs (patience: 150, remaining: 122)

EPOCH 287/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2097
  ‚Ä¢ Validation Loss: 0.3296
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3296, best: 0.3229)
    ‚ö† No improvement for 29 epochs (patience: 150, remaining: 121)

EPOCH 288/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2235
  ‚Ä¢ Validation Loss: 0.3292
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3292, best: 0.3229)
    ‚ö† No improvement for 30 epochs (patience: 150, remaining: 120)

EPOCH 289/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2179
  ‚Ä¢ Validation Loss: 0.3313
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3313, best: 0.3229)
    ‚ö† No improvement for 31 epochs (patience: 150, remaining: 119)

EPOCH 290/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2225
  ‚Ä¢ Validation Loss: 0.3302
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3302, best: 0.3229)
    ‚ö† No improvement for 32 epochs (patience: 150, remaining: 118)

EPOCH 291/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2212
  ‚Ä¢ Validation Loss: 0.3289
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3289, best: 0.3229)
    ‚ö† No improvement for 33 epochs (patience: 150, remaining: 117)

EPOCH 292/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2245
  ‚Ä¢ Validation Loss: 0.3251
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3251, best: 0.3229)
    ‚ö† No improvement for 34 epochs (patience: 150, remaining: 116)

EPOCH 293/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2220
  ‚Ä¢ Validation Loss: 0.3278
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3278, best: 0.3229)
    ‚ö† No improvement for 35 epochs (patience: 150, remaining: 115)

EPOCH 294/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2050
  ‚Ä¢ Validation Loss: 0.3297
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3297, best: 0.3229)
    ‚ö† No improvement for 36 epochs (patience: 150, remaining: 114)

EPOCH 295/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2261
  ‚Ä¢ Validation Loss: 0.3288
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3288, best: 0.3229)
    ‚ö† No improvement for 37 epochs (patience: 150, remaining: 113)

EPOCH 296/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2295
  ‚Ä¢ Validation Loss: 0.3287
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3287, best: 0.3229)
    ‚ö† No improvement for 38 epochs (patience: 150, remaining: 112)

EPOCH 297/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2173
  ‚Ä¢ Validation Loss: 0.3275
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3275, best: 0.3229)
    ‚ö† No improvement for 39 epochs (patience: 150, remaining: 111)

EPOCH 298/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2203
  ‚Ä¢ Validation Loss: 0.3299
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3299, best: 0.3229)
    ‚ö† No improvement for 40 epochs (patience: 150, remaining: 110)

EPOCH 299/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2136
  ‚Ä¢ Validation Loss: 0.3249
  ‚Ä¢ Learning Rate: 0.000002
    No improvement (current: 0.3249, best: 0.3229)
    ‚ö† No improvement for 41 epochs (patience: 150, remaining: 109)

EPOCH 300/300
--------------------------------------------------
Results:
  ‚Ä¢ Train Loss: 0.2222
  ‚Ä¢ Validation Loss: 0.3271
  ‚Ä¢ Learning Rate: 0.000002
   üíæ Periodic checkpoint saved: epoch_300.pth
    No improvement (current: 0.3271, best: 0.3229)
    ‚ö† No improvement for 42 epochs (patience: 150, remaining: 108)

================================================================================
TRAINING COMPLETED
================================================================================
Best Val Loss:  0.3229
Total Epochs:   300
Models Saved:   ./Result/a4/Syr341
TensorBoard:    ./Result/a4/Syr341/tensorboard_logs
================================================================================

[21:50:09] Training completed. Best val loss: 0.3229

=== TRAINING COMPLETED SUCCESSFULLY ===
Training Finished!

========================================================================
Testing Hybrid2 Baseline Model with EfficientNet-B4 Decoder + Simple Skip Connections: Syr341
========================================================================
=== Historical Document Segmentation Testing ===

Detected Syriaque341 manuscript: using 5 classes (no Chapter Headings)
Model: Hybrid2
Dataset: UDIADS_BIB
Manuscript: Syr341
Test-Time Augmentation: Enabled
CRF post-processing: Disabled

================================================================================
üöÄ Loading Hybrid2 with EfficientNet-B4 Decoder for Testing
================================================================================
================================================================================
üöÄ EFFICIENTNET-B4 DECODER (Real MBConv Blocks)
================================================================================
  ‚Ä¢ Decoder Channels: [256, 128, 64, 32]
  ‚Ä¢ Using MBConv blocks (NOT simple Conv)
  ‚Ä¢ Bottleneck Swin Blocks: True

üìä Optional Features:
  ‚Ä¢ Deep Supervision: False
  ‚Ä¢ CBAM Attention: False
  ‚Ä¢ Smart Skip Connections: False
  ‚Ä¢ Cross-Attention: False
  ‚Ä¢ Multi-Scale Aggregation: False
  ‚Ä¢ GroupNorm: True (else BatchNorm)
  ‚Ä¢ Positional Embeddings: True
================================================================================
Loaded checkpoint from epoch 257
Best validation loss: 0.3229
  ‚úÖ Model checkpoint loaded successfully (exact match)
Loaded checkpoint: best_model_latest.pth
Namespace(cfg=None, output_dir='./Result/a4/Syr341', use_baseline=True, decoder='EfficientNet-B4', efficientnet_variant='b4', use_deep_supervision=False, use_cbam=False, use_smart_skip=False, use_cross_attn=False, use_multiscale_agg=False, use_groupnorm=True, use_batchnorm=False, use_pos_embed=True, dataset='UDIADS_BIB', manuscript='Syr341', udiadsbib_root='../../U-DIADS-Bib-MS_patched', divahisdb_root='../../DivaHisDB', use_patched_data=True, num_classes=5, img_size=224, batch_size=24, is_savenii=True, test_save_dir='../predictions', use_crf=False, deterministic=1, seed=1234, opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, use_tta=True)
Testing with checkpoint: best_model_latest.pth
Saving predictions to: ./Result/a4/Syr341/predictions

=== Starting Testing ===
Dataset: UDIADS_BIB
Model: Hybrid2
Manuscript: Syr341
Save predictions: True

Starting inference on UDIADS_BIB dataset
Found 1620 patches for Syr341
Using Test-Time Augmentation (TTA) for improved accuracy
CRF post-processing: Disabled
Processing: 031 (54 patches)
Completed: 031
Processing: 053 (54 patches)
Completed: 053
Processing: 054 (54 patches)
Completed: 054
Processing: 071 (54 patches)
Completed: 071
Processing: 073 (54 patches)
Completed: 073
Processing: 075 (54 patches)
Completed: 075
Processing: 100 (54 patches)
Completed: 100
Processing: 137 (54 patches)
Completed: 137
Processing: 150 (54 patches)
Completed: 150
Processing: 160 (54 patches)
Completed: 160
Processing: 167 (54 patches)
Completed: 167
Processing: 184 (54 patches)
Completed: 184
Processing: 190 (54 patches)
Completed: 190
Processing: 201 (54 patches)
Completed: 201
Processing: 210 (54 patches)
Completed: 210
Processing: 222 (54 patches)
Completed: 222
Processing: 224 (54 patches)
Completed: 224
Processing: 231 (54 patches)
Completed: 231
Processing: 241 (54 patches)
Completed: 241
Processing: 249 (54 patches)
Completed: 249
Processing: 252 (54 patches)
Completed: 252
Processing: 267 (54 patches)
Completed: 267
Processing: 281 (54 patches)
Completed: 281
Processing: 286 (54 patches)
Completed: 286
Processing: 290 (54 patches)
Completed: 290
Processing: 313 (54 patches)
Completed: 313
Processing: 362 (54 patches)
Completed: 362
Processing: 368 (54 patches)
Completed: 368
Processing: 376 (54 patches)
Completed: 376
Processing: 446 (54 patches)
Completed: 446

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9717, Recall=0.9795, F1=0.9756, IoU=0.9523
Paratext       : Precision=0.6280, Recall=0.3844, F1=0.4769, IoU=0.3131
Decoration     : Precision=0.9573, Recall=0.6425, F1=0.7689, IoU=0.6246
Main Text      : Precision=0.8580, Recall=0.8722, F1=0.8651, IoU=0.7622
Title          : Precision=0.4747, Recall=0.5387, F1=0.5047, IoU=0.3375

Mean metrics:
----------------------------------------
Mean Precision: 0.7779
Mean Recall: 0.6835
Mean F1-Score: 0.7182
Mean IoU: 0.5980

Per-class metrics:
--------------------------------------------------------------------------------
Background     : Precision=0.9717, Recall=0.9795, F1=0.9756, IoU=0.9523
Paratext       : Precision=0.6280, Recall=0.3844, F1=0.4769, IoU=0.3131
Decoration     : Precision=0.9573, Recall=0.6425, F1=0.7689, IoU=0.6246
Main Text      : Precision=0.8580, Recall=0.8722, F1=0.8651, IoU=0.7622
Title          : Precision=0.4747, Recall=0.5387, F1=0.5047, IoU=0.3375

Mean metrics:
----------------------------------------
Mean Precision: 0.7779
Mean Recall: 0.6835
Mean F1-Score: 0.7182
Mean IoU: 0.5980
Inference completed on 30 images

=== TESTING COMPLETED SUCCESSFULLY ===
Results saved to: ./Result/a4/Syr341/predictions
==================================================

Calculating average metrics...
Looking for metrics files in: ./Result/a4
  ‚úó Metrics file not found: ./Result/a4/metrics_Latin2.json
  ‚úó Metrics file not found: ./Result/a4/metrics_Latin14396.json
  ‚úó Metrics file not found: ./Result/a4/metrics_Latin16746.json
  ‚úì Found metrics for Syr341

================================================================================
AVERAGE METRICS ACROSS 1 MANUSCRIPT(S)
================================================================================
Manuscripts: Syr341
Missing: Latin2, Latin14396, Latin16746
--------------------------------------------------------------------------------
Mean Precision: 0.7779
Mean Recall:    0.6835
Mean F1-Score:  0.7182
Mean IoU:       0.5980
================================================================================

========================================================================
ALL MANUSCRIPTS COMPLETED - HYBRID2 BASELINE MODEL WITH EFFICIENTNET-B4 DECODER + SIMPLE SKIP CONNECTIONS
========================================================================
Model: Hybrid2 Baseline (Swin Encoder + EfficientNet-B4 Decoder with Simple Skip Connections)
Results saved in: ./Result/a4/


========================================================================
AGGREGATING RESULTS ACROSS ALL MANUSCRIPTS
========================================================================

================================================================================
PARSING MANUSCRIPT RESULTS
================================================================================

Processing: Latin2
  Directory: ./Result/a4/Latin2
  ‚úó Could not find metrics for Latin2
    Please ensure testing has completed and output files exist

Processing: Latin14396
  Directory: ./Result/a4/Latin14396
  ‚úó Could not find metrics for Latin14396
    Please ensure testing has completed and output files exist

Processing: Latin16746
  Directory: ./Result/a4/Latin16746
  ‚úó Could not find metrics for Latin16746
    Please ensure testing has completed and output files exist

Processing: Syr341
  Directory: ./Result/a4/Syr341
  ‚úó Could not find metrics for Syr341
    Please ensure testing has completed and output files exist

================================================================================
ERROR: No metrics found!
================================================================================
Please ensure that:
  1. Testing has completed for all manuscripts
  2. Output files (.out or .txt) exist in the results directory
  3. The results_dir path is correct
================================================================================

========================================================================
AGGREGATION COMPLETE
========================================================================
Aggregated metrics saved to: ./Result/a4/aggregated_metrics.txt

=== JOB_STATISTICS ===
=== current date     : Thu Nov 20 09:53:41 PM CET 2025
= Job-ID             : 1400668 on tinygpu
= Job-Name           : r1
= Job-Command        : /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid/run1.sh
= Initial workdir    : /home/hpc/iwi5/iwi5250h/DAS_Using_SwinUnet_Missformer/Models/Swin-Unet-main/models/hybrid
= Queue/Partition    : work
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 22:00:00
= Elapsed runtime    : 04:54:23
= Total RAM usage    : 7.2 GiB of requested  GiB (%)   
= Node list          : tg065
= Subm/Elig/Start/End: 2025-11-20T16:59:17 / 2025-11-20T16:59:17 / 2025-11-20T16:59:18 / 2025-11-20T21:53:41
======================
=== Quota infos ======
    Path                 Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
!!! /home/hpc             130.9G   104.9G   209.7G  -29291days     248K     500K   1,000K        N/A !!!
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA GeForce RTX 2080 Ti, 00000000:3B:00.0, 1279207, 76 %, 56 %, 10762 MiB, 4238676 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:3B:00.0, 1299881, 28 %, 12 %, 490 MiB, 165316 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:3B:00.0, 1300338, 77 %, 56 %, 10762 MiB, 4230867 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:3B:00.0, 1320955, 27 %, 11 %, 490 MiB, 174950 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:3B:00.0, 1321395, 77 %, 56 %, 10762 MiB, 4213210 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:3B:00.0, 1360239, 28 %, 11 %, 490 MiB, 169194 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:3B:00.0, 1360449, 78 %, 57 %, 10718 MiB, 4149346 ms
NVIDIA GeForce RTX 2080 Ti, 00000000:3B:00.0, 1381787, 23 %, 9 %, 480 MiB, 201864 ms
